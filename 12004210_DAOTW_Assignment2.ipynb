{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "RB0Zq1024UmQ",
        "XfOkQa04Wgr6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthew110395/12004210_DataAnalytics/blob/main/12004210_DAOTW_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "This assignment builds on the New York taxi problem identified in assignment 1, where the City of New York is looking for a way to accurately predict the number of collisions on a particular day of the week. Within this document two different types of machine learning models will be utilised to predict the number of collisions. The linear relationships identified in assignment 1 will be used to create linear regression models. Deep Learning Neural Network (DNN) models will be used to predict the number of collisions where the relationship is not linear. "
      ],
      "metadata": {
        "id": "-MIIDzFYc6Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports\n",
        "To prepare data for machine learning the pandas package has been used, alongside the numpy package which has been used to aid with mathematical functions.\n",
        "\n",
        "As within part 1 of this assignment, the data file containing location data exceeds the size limit for hosting within github. To overcome this the file was zipped. To extract the data the zipfile package has been used.\n",
        "\n",
        "Within this document, TensorFlow is used for machine learning, with both linear regression models and a Deep Neural Network models. TensorFlow version 1 is unsupported within Google Colab, therefore must be installed using a package manager.\n",
        "\n",
        "Shutil is also imported to allow for file management, in particular the removal of saved models."
      ],
      "metadata": {
        "id": "PP_OBRRWE3tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "!pip install tensorflow==1.15.2\n",
        "import tensorflow as tf\n",
        "import shutil  "
      ],
      "metadata": {
        "id": "J3Vp_IJAE49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40a189e-58c2-4bc3-9175-69cfccc0c7b8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.50.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.38.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.3.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.14.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (2.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regressor\n",
        "Throughout assignment 1 a number of linear relationships were uncovered within the dataset. These relationships form the basis of the linear regression models below.\n",
        "\n",
        "A linear regressor is used to predict an output variable based on one or more input variables (IBM n.d.)."
      ],
      "metadata": {
        "id": "SxU2LFGDjN9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the accuracy of the model the target values are scaled. This reduces the range of collisions from 188-1161 to 0.1619... - 1 which allows for quicker training  (Zhang 2019)."
      ],
      "metadata": {
        "id": "vKNbHovb6hXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale to maximum number of collisions\n",
        "SCALE_COLLISIONS=1161"
      ],
      "metadata": {
        "id": "k-aEMQX9EuJJ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precipitation\n",
        "As uncovered in assignment 1; as the volume of precipitation increases, the number of collisions increase. \n",
        "\n",
        "The datafile produced in assignment is imported."
      ],
      "metadata": {
        "id": "VtJ7HqhA3bIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read File\n",
        "df_prcp = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean.csv', index_col=0, )\n",
        "print(df_prcp[:6])"
      ],
      "metadata": {
        "id": "Gr0ljmfBkDwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bdf141-043a-4995-ee97-61334d0bb0e7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create the linear regression model, extra columns are removed to simplify the model with the aim of reducing error values.\n",
        "\n",
        "The incomplete years (2012 and 2022) are removed, along with the erroneous data for 2020 and 2021.\n",
        "\n",
        "To aid with the production of the model the target is moved to the end of the data table."
      ],
      "metadata": {
        "id": "NnrlNKFM0R-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_prcp = df_prcp.drop(columns=['collision_date', 'temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] != 2012]\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] < 2020]\n",
        "cols = df_prcp['NUM_COLLISIONS']\n",
        "df_prcp = df_prcp.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move NUM_COLLISIONS to end\n",
        "df_prcp.insert(loc=9, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp[:6])\n",
        "df_prcp.describe()"
      ],
      "metadata": {
        "id": "nRcEly727YQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "5e5fcafc-f34a-4260-bfe7-19e65462c83d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "49    4  2016   1  28  0.09    0             0                 0     0   \n",
            "51    5  2014   1  17  0.00    1             0                 0     0   \n",
            "54    1  2016   1  25  0.02    0             0                 0     0   \n",
            "55    5  2016   1  29  0.00    0             0                 0     0   \n",
            "58    5  2017   1  20  0.00    0             0                 0     0   \n",
            "59    7  2013   1  13  0.01    1             0                 0     0   \n",
            "\n",
            "    NUM_COLLISIONS  \n",
            "49             681  \n",
            "51             589  \n",
            "54             658  \n",
            "55             645  \n",
            "58             605  \n",
            "59             373  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         prcp  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean      3.998425  2015.989366     6.518708    15.745569     0.122588   \n",
              "std       2.003542     1.996126     3.455211     8.803199     0.329143   \n",
              "min       1.000000  2013.000000     1.000000     1.000000     0.000000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000     0.000000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000     0.000000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000     0.060000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000     3.760000   \n",
              "\n",
              "               fog  rain_drizzle  snow_ice_pellets         hail  \\\n",
              "count  2539.000000   2539.000000       2539.000000  2539.000000   \n",
              "mean      0.253249      0.375345          0.085467     0.000394   \n",
              "std       0.434958      0.484307          0.279630     0.019846   \n",
              "min       0.000000      0.000000          0.000000     0.000000   \n",
              "25%       0.000000      0.000000          0.000000     0.000000   \n",
              "50%       0.000000      0.000000          0.000000     0.000000   \n",
              "75%       1.000000      1.000000          0.000000     0.000000   \n",
              "max       1.000000      1.000000          1.000000     1.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2539.000000  \n",
              "mean       599.135093  \n",
              "std        100.299164  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a20ca166-aecc-44cf-a757-1a5ed994ccda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998425</td>\n",
              "      <td>2015.989366</td>\n",
              "      <td>6.518708</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.003542</td>\n",
              "      <td>1.996126</td>\n",
              "      <td>3.455211</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20ca166-aecc-44cf-a757-1a5ed994ccda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a20ca166-aecc-44cf-a757-1a5ed994ccda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a20ca166-aecc-44cf-a757-1a5ed994ccda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove any bias within the dataset, it is randomly shuffled. The data is then split into the predictors and the target."
      ],
      "metadata": {
        "id": "eBk7xJt-Ag0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle = df_prcp.iloc[np.random.permutation(len(df_prcp))]\n",
        "\n",
        "# Select all apart from last col\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "8xT4g-UZFi01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d79d5c1-c365-47a0-bcdd-a3c992bbdabf"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail\n",
            "3492    4  2015  12  31  0.00    0             1                 0     0\n",
            "1307    5  2013   5  10  0.00    1             0                 0     0\n",
            "506     2  2016   2   9  0.06    0             0                 1     0\n",
            "1716    3  2019   6   5  0.00    0             1                 0     0\n",
            "486     5  2017   2  17  0.00    0             0                 0     0\n",
            "2648    5  2018   9  28  0.10    0             1                 0     0\n",
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "3492    4  2015  12  31  0.00    0             1                 0     0   \n",
            "1307    5  2013   5  10  0.00    1             0                 0     0   \n",
            "506     2  2016   2   9  0.06    0             0                 1     0   \n",
            "1716    3  2019   6   5  0.00    0             1                 0     0   \n",
            "486     5  2017   2  17  0.00    0             0                 0     0   \n",
            "2648    5  2018   9  28  0.10    0             1                 0     0   \n",
            "\n",
            "      NUM_COLLISIONS  \n",
            "3492             527  \n",
            "1307             698  \n",
            "506              571  \n",
            "1716             655  \n",
            "486              680  \n",
            "2648             712  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Target (last col)\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "O_xkzkVBQjL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594dd9a4-bd21-42a4-e3f8-a3bb0c50b108"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3492    527\n",
            "1307    698\n",
            "506     571\n",
            "1716    655\n",
            "486     680\n",
            "2648    712\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 9\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "NwSG_P_nRgPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3786bb06-907b-45ca-a5eb-b2b04df0e7fd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2031\n",
            "508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_prcp', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "pred = format(str(predslistscale))\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "AUKI-paISKeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872fd393-5e63-4e17-81bc-c164da8da108"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184c36790>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.28435007, step = 1\n",
            "INFO:tensorflow:global_step/sec: 610.428\n",
            "INFO:tensorflow:loss = 0.006029467, step = 101 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.111\n",
            "INFO:tensorflow:loss = 0.006208708, step = 201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 763.028\n",
            "INFO:tensorflow:loss = 0.00811196, step = 301 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.671\n",
            "INFO:tensorflow:loss = 0.006580451, step = 401 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.39\n",
            "INFO:tensorflow:loss = 0.0064119017, step = 501 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.678\n",
            "INFO:tensorflow:loss = 0.006235397, step = 601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.563\n",
            "INFO:tensorflow:loss = 0.0064507676, step = 701 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.948\n",
            "INFO:tensorflow:loss = 0.0046583666, step = 801 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.994\n",
            "INFO:tensorflow:loss = 0.007425333, step = 901 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.383\n",
            "INFO:tensorflow:loss = 0.0071029505, step = 1001 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.367\n",
            "INFO:tensorflow:loss = 0.007856553, step = 1101 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.096\n",
            "INFO:tensorflow:loss = 0.008026991, step = 1201 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 762.721\n",
            "INFO:tensorflow:loss = 0.006906911, step = 1301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.059\n",
            "INFO:tensorflow:loss = 0.0066928538, step = 1401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.996\n",
            "INFO:tensorflow:loss = 0.0058590914, step = 1501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.551\n",
            "INFO:tensorflow:loss = 0.007314265, step = 1601 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.395\n",
            "INFO:tensorflow:loss = 0.0072767627, step = 1701 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.813\n",
            "INFO:tensorflow:loss = 0.0057639307, step = 1801 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.095\n",
            "INFO:tensorflow:loss = 0.0055811442, step = 1901 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.681\n",
            "INFO:tensorflow:loss = 0.0053872583, step = 2001 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.26\n",
            "INFO:tensorflow:loss = 0.0068361387, step = 2101 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.443\n",
            "INFO:tensorflow:loss = 0.007955866, step = 2201 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.374\n",
            "INFO:tensorflow:loss = 0.004962411, step = 2301 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.423\n",
            "INFO:tensorflow:loss = 0.0064429003, step = 2401 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.323\n",
            "INFO:tensorflow:loss = 0.0059308987, step = 2501 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.214\n",
            "INFO:tensorflow:loss = 0.0057227802, step = 2601 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.224\n",
            "INFO:tensorflow:loss = 0.0064573046, step = 2701 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.9\n",
            "INFO:tensorflow:loss = 0.006172032, step = 2801 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.779\n",
            "INFO:tensorflow:loss = 0.00801239, step = 2901 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.265\n",
            "INFO:tensorflow:loss = 0.008003514, step = 3001 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.754\n",
            "INFO:tensorflow:loss = 0.009353781, step = 3101 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.347\n",
            "INFO:tensorflow:loss = 0.006517724, step = 3201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.653\n",
            "INFO:tensorflow:loss = 0.007837445, step = 3301 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.529\n",
            "INFO:tensorflow:loss = 0.0060175676, step = 3401 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.454\n",
            "INFO:tensorflow:loss = 0.0052023306, step = 3501 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.995\n",
            "INFO:tensorflow:loss = 0.0067790123, step = 3601 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.629\n",
            "INFO:tensorflow:loss = 0.0049821055, step = 3701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.851\n",
            "INFO:tensorflow:loss = 0.005931261, step = 3801 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 300.947\n",
            "INFO:tensorflow:loss = 0.0065164524, step = 3901 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.278\n",
            "INFO:tensorflow:loss = 0.0061863647, step = 4001 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.157\n",
            "INFO:tensorflow:loss = 0.004513663, step = 4101 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.232\n",
            "INFO:tensorflow:loss = 0.004990297, step = 4201 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 295.958\n",
            "INFO:tensorflow:loss = 0.00699097, step = 4301 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.865\n",
            "INFO:tensorflow:loss = 0.0057783835, step = 4401 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 214.002\n",
            "INFO:tensorflow:loss = 0.005527532, step = 4501 (0.469 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.733\n",
            "INFO:tensorflow:loss = 0.0063707875, step = 4601 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.945\n",
            "INFO:tensorflow:loss = 0.0053799395, step = 4701 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.646\n",
            "INFO:tensorflow:loss = 0.005120126, step = 4801 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.405\n",
            "INFO:tensorflow:loss = 0.007896943, step = 4901 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.105\n",
            "INFO:tensorflow:loss = 0.007009151, step = 5001 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.078\n",
            "INFO:tensorflow:loss = 0.006320907, step = 5101 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.256\n",
            "INFO:tensorflow:loss = 0.006098697, step = 5201 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.675\n",
            "INFO:tensorflow:loss = 0.005452591, step = 5301 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.833\n",
            "INFO:tensorflow:loss = 0.005169979, step = 5401 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.838\n",
            "INFO:tensorflow:loss = 0.006324291, step = 5501 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.277\n",
            "INFO:tensorflow:loss = 0.010015059, step = 5601 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 400.181\n",
            "INFO:tensorflow:loss = 0.0056345817, step = 5701 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.102\n",
            "INFO:tensorflow:loss = 0.006894122, step = 5801 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.475\n",
            "INFO:tensorflow:loss = 0.005814498, step = 5901 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 366.563\n",
            "INFO:tensorflow:loss = 0.004557113, step = 6001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.664\n",
            "INFO:tensorflow:loss = 0.006159946, step = 6101 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.225\n",
            "INFO:tensorflow:loss = 0.0048111724, step = 6201 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.28\n",
            "INFO:tensorflow:loss = 0.005655454, step = 6301 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.082\n",
            "INFO:tensorflow:loss = 0.0066588065, step = 6401 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.303\n",
            "INFO:tensorflow:loss = 0.0062325764, step = 6501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.261\n",
            "INFO:tensorflow:loss = 0.009714644, step = 6601 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.986\n",
            "INFO:tensorflow:loss = 0.007375148, step = 6701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.598\n",
            "INFO:tensorflow:loss = 0.0051732343, step = 6801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.548\n",
            "INFO:tensorflow:loss = 0.004705283, step = 6901 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.076\n",
            "INFO:tensorflow:loss = 0.0058283852, step = 7001 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.791\n",
            "INFO:tensorflow:loss = 0.0055763065, step = 7101 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.224\n",
            "INFO:tensorflow:loss = 0.0061665117, step = 7201 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.868\n",
            "INFO:tensorflow:loss = 0.0064396923, step = 7301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.612\n",
            "INFO:tensorflow:loss = 0.004723952, step = 7401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.93\n",
            "INFO:tensorflow:loss = 0.0046920525, step = 7501 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 795.569\n",
            "INFO:tensorflow:loss = 0.0069446466, step = 7601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.398\n",
            "INFO:tensorflow:loss = 0.008423658, step = 7701 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 798.412\n",
            "INFO:tensorflow:loss = 0.004839075, step = 7801 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.183\n",
            "INFO:tensorflow:loss = 0.008891412, step = 7901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.26\n",
            "INFO:tensorflow:loss = 0.0059559643, step = 8001 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.923\n",
            "INFO:tensorflow:loss = 0.0057020113, step = 8101 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.114\n",
            "INFO:tensorflow:loss = 0.0053385654, step = 8201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.867\n",
            "INFO:tensorflow:loss = 0.008999255, step = 8301 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.583\n",
            "INFO:tensorflow:loss = 0.0064664492, step = 8401 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.75\n",
            "INFO:tensorflow:loss = 0.0048507582, step = 8501 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.867\n",
            "INFO:tensorflow:loss = 0.0077269245, step = 8601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.538\n",
            "INFO:tensorflow:loss = 0.0051401877, step = 8701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.379\n",
            "INFO:tensorflow:loss = 0.0045297253, step = 8801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.481\n",
            "INFO:tensorflow:loss = 0.004936953, step = 8901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.895\n",
            "INFO:tensorflow:loss = 0.004428764, step = 9001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.198\n",
            "INFO:tensorflow:loss = 0.007652574, step = 9101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.933\n",
            "INFO:tensorflow:loss = 0.0063473643, step = 9201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.678\n",
            "INFO:tensorflow:loss = 0.005982277, step = 9301 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.009\n",
            "INFO:tensorflow:loss = 0.0067656944, step = 9401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 767.691\n",
            "INFO:tensorflow:loss = 0.005355211, step = 9501 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.4\n",
            "INFO:tensorflow:loss = 0.005350487, step = 9601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.269\n",
            "INFO:tensorflow:loss = 0.007836929, step = 9701 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.61\n",
            "INFO:tensorflow:loss = 0.005872808, step = 9801 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.08\n",
            "INFO:tensorflow:loss = 0.0070758876, step = 9901 (0.124 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0057841525.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 102.05434614543951\n",
            "Just using average = 600.2299359921221 has RMSE of 105.566287878724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A number of learning rates were used to determine a suitable learning rate for the model. As the learning rate decreases the overall time to train the dataset increases (Zulkifli 2018)."
      ],
      "metadata": {
        "id": "3uYG_ScZR3yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Error Rate\n",
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "1fifEsTD98hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9599cac-c431-4e12-a48e-da6acbacc6f8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21845a0e50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n",
            "[0.5122645  0.47875375 0.52287126 0.5635435  0.46389306 0.55077493\n",
            " 0.56979203 0.47948697 0.54274005 0.5035545  0.5411757  0.54123\n",
            " 0.5133076  0.48793462 0.55686814 0.48470786 0.53721666 0.50310105\n",
            " 0.47432306 0.5792667  0.54587805 0.4638464  0.5302459  0.4894051\n",
            " 0.55784094 0.5486665  0.50999916 0.46061707 0.5070047  0.5136187\n",
            " 0.53376424 0.53320867 0.51746637 0.5568299  0.51152563 0.5712332\n",
            " 0.5349731  0.49143696 0.4980978  0.53075117 0.50611013 0.5668902\n",
            " 0.5099612  0.53449446 0.5607861  0.5116442  0.54498    0.5537348\n",
            " 0.54023683 0.5213465  0.55704856 0.49917585 0.52356577 0.55058366\n",
            " 0.489171   0.5526224  0.5368833  0.48330578 0.5391398  0.48670578\n",
            " 0.51017135 0.54889625 0.5786473  0.56032413 0.50977975 0.51447284\n",
            " 0.48049292 0.48267332 0.5532888  0.5355576  0.46934167 0.4938137\n",
            " 0.54982024 0.4537593  0.48576254 0.5497053  0.5488554  0.54657066\n",
            " 0.59345555 0.49571893 0.4655688  0.504705   0.49902675 0.5296054\n",
            " 0.48964164 0.54712546 0.50650275 0.46399084 0.5053166  0.55089676\n",
            " 0.46235624 0.5372828  0.5251164  0.4660914  0.52908725 0.54862154\n",
            " 0.5446464  0.54298717 0.5226878  0.5630963  0.5970185  0.5177022\n",
            " 0.52253884 0.5326607  0.52936214 0.4503949  0.47778085 0.48127964\n",
            " 0.5013348  0.50163186 0.49138218 0.4965117  0.5197148  0.5505\n",
            " 0.50040174 0.46084183 0.56650734 0.5365601  0.5516496  0.51640046\n",
            " 0.48224673 0.48780283 0.53373903 0.5317239  0.52661085 0.5074755\n",
            " 0.5217122  0.5301556  0.47458735 0.49838656 0.5616193  0.46442246\n",
            " 0.58647484 0.55886644 0.52957565 0.4873158  0.46163112 0.52439475\n",
            " 0.54058504 0.58119875 0.5323516  0.51428014 0.49698192 0.4919624\n",
            " 0.4929311  0.5363306  0.48507077 0.46688697 0.50894064 0.56619394\n",
            " 0.45250085 0.50100344 0.54390657 0.51163507 0.46930197 0.5777619\n",
            " 0.54952466 0.47234756 0.57156277 0.47618264 0.48777175 0.56288016\n",
            " 0.5149122  0.53586394 0.5009805  0.45968398 0.5214099  0.5526196\n",
            " 0.52386886 0.52881885 0.52016747 0.50853735 0.5504946  0.4794129\n",
            " 0.48904684 0.49764827 0.54138905 0.57680875 0.57094073 0.5285267\n",
            " 0.5296823  0.54718643 0.45920107 0.50969356 0.5193512  0.47161922\n",
            " 0.53470486 0.50967103 0.54727674 0.48910242 0.5424346  0.49741375\n",
            " 0.5182201  0.532238   0.5599094  0.47559947 0.49563494 0.524032\n",
            " 0.5561868  0.57096887 0.56266487 0.45871687 0.5192802  0.49275076\n",
            " 0.5587234  0.52423394 0.51606715 0.5243241  0.488433   0.45144847\n",
            " 0.48979348 0.494943   0.5565037  0.5428917  0.52029085 0.5496739\n",
            " 0.51477647 0.5214099  0.4745806  0.5335944  0.5150351  0.4554738\n",
            " 0.48895785 0.55799234 0.52482736 0.50132483 0.5398974  0.56345046\n",
            " 0.4833397  0.49991864 0.5790738  0.51994157 0.49629894 0.55402935\n",
            " 0.5281257  0.57542574 0.55077845 0.54435384 0.53615457 0.52103466\n",
            " 0.558417   0.50142956 0.5328526  0.48535645 0.5412814  0.4726795\n",
            " 0.5188701  0.46676064 0.47258252 0.5347077  0.5028782  0.538524\n",
            " 0.5429659  0.46491066 0.5021715  0.51130545 0.50474054 0.5504043\n",
            " 0.46985713 0.48111776 0.52381873 0.49165604 0.5608557  0.5077654\n",
            " 0.5443033  0.5656466  0.53054816 0.55976397 0.51719725 0.49924648\n",
            " 0.55092806 0.50938725 0.5695912  0.52444714 0.5490389  0.51622444\n",
            " 0.49612066 0.5406858  0.48600098 0.5580542  0.44421935 0.46809906\n",
            " 0.48343003 0.46287358 0.5208142  0.54697883 0.5726039  0.4943833\n",
            " 0.50225616 0.5556044  0.57224596 0.533523   0.5408806  0.54726136\n",
            " 0.5130413  0.46570125 0.51400995 0.49782836 0.51413417 0.570078\n",
            " 0.50342864 0.49453184 0.5024433  0.49797833 0.5627055  0.53593045\n",
            " 0.4766287  0.46287644 0.49217787 0.49320972 0.4897873  0.45804763\n",
            " 0.5667701  0.4964063  0.52636343 0.54233927 0.5088625  0.5287521\n",
            " 0.5156112  0.54272044 0.4789966  0.5570814  0.48417175 0.5117241\n",
            " 0.5138491  0.47082993 0.4719821  0.536793   0.47799405 0.56762993\n",
            " 0.482385   0.52332217 0.54491645 0.548693   0.5665342  0.5198092\n",
            " 0.51366687 0.49949944 0.5191015  0.51915693 0.5234952  0.534336\n",
            " 0.54709464 0.5621447  0.5042577  0.5471836  0.55589783 0.47603327\n",
            " 0.5647192  0.5497968  0.50846803 0.5464685  0.52860993 0.49144885\n",
            " 0.52594364 0.5566265  0.5444429  0.5216891  0.525369   0.5068545\n",
            " 0.5558995  0.5196451  0.5626611  0.5563852  0.56692684 0.54032576\n",
            " 0.55747813 0.46462232 0.5356626  0.5050976  0.48186776 0.51970124\n",
            " 0.46535835 0.54222894 0.54779637 0.4840951  0.55473256 0.5140445\n",
            " 0.49464974 0.52162313 0.55103576 0.54832995 0.49566877 0.54011256\n",
            " 0.50698847 0.49650142 0.4948962  0.5003124  0.49854922 0.4869406\n",
            " 0.5182998  0.46793994 0.45240498 0.5220663  0.5048112  0.5366269\n",
            " 0.5501726  0.4932967  0.5337558  0.5127135  0.54263395 0.50049067\n",
            " 0.49717966 0.53088135 0.534373   0.45650002 0.49917296 0.49039373\n",
            " 0.5303377  0.5448794  0.49893013 0.5316706  0.53512114 0.5687227\n",
            " 0.48179087 0.5370867  0.524235   0.48209426 0.5351609  0.50777495\n",
            " 0.49293616 0.53348327 0.5090611  0.5679194  0.52127236 0.5211361\n",
            " 0.5042392  0.53924143 0.48800966 0.5196402  0.5289949  0.49116313\n",
            " 0.5544735  0.48979482 0.55569756 0.48244098 0.4962449  0.5364042\n",
            " 0.49037963 0.51661485 0.53805953 0.55724645 0.45742872 0.5049538\n",
            " 0.5337934  0.5746904  0.5079995  0.50881577 0.53079087 0.523422\n",
            " 0.4600336  0.48317108 0.52938056 0.56937796 0.4970212  0.51073635\n",
            " 0.5090481  0.57223403 0.5195844  0.5395309  0.54545534 0.51928496\n",
            " 0.45533302 0.57098025 0.46829605 0.51008624 0.5363101  0.5062597\n",
            " 0.4990715  0.46299368 0.50423515 0.5118291  0.49189633 0.52181846\n",
            " 0.4809112  0.5510523  0.4943907  0.5467006  0.5109687  0.5424451\n",
            " 0.50735545 0.5541022  0.5429656  0.5096968  0.55854124 0.5598163\n",
            " 0.5296845  0.5215249  0.4829458  0.53439146 0.5487325  0.54311717\n",
            " 0.55487025 0.51057196 0.5101764  0.45573092 0.49855977 0.54991853\n",
            " 0.48940682 0.48446718 0.46372685 0.50686836 0.49979448 0.5545436\n",
            " 0.5218025  0.46484894 0.5023761  0.496821  ]\n",
            "[0.45994832 0.52627046 0.52799311 0.49095607 0.39534884 0.52799311\n",
            " 0.63135228 0.42980189 0.63049096 0.4788975  0.57536606 0.53402239\n",
            " 0.53229974 0.60206718 0.54866494 0.41343669 0.45305771 0.56330749\n",
            " 0.50559862 0.58484065 0.49956934 0.42980189 0.60809647 0.40826873\n",
            " 0.57450474 0.4005168  0.55813953 0.46597761 0.50215332 0.40999139\n",
            " 0.56244617 0.27648579 0.44444444 0.55727821 0.52540913 0.48234281\n",
            " 0.59776055 0.45822567 0.48923342 0.50301464 0.47803618 0.54694229\n",
            " 0.47028424 0.5374677  0.47631352 0.60034453 0.5796727  0.43583118\n",
            " 0.52282515 0.54349699 0.4461671  0.62704565 0.58053402 0.62962963\n",
            " 0.47114556 0.60034453 0.5211025  0.51851852 0.5047373  0.64857881\n",
            " 0.4754522  0.53402239 0.53143842 0.58742463 0.53832903 0.70542636\n",
            " 0.41946598 0.39018088 0.53919035 0.59173127 0.4203273  0.47803618\n",
            " 0.54694229 0.35658915 0.58139535 0.56158484 0.61843239 0.37295435\n",
            " 0.58742463 0.63996555 0.38587425 0.43066322 0.51162791 0.41257537\n",
            " 0.44358312 0.63824289 0.61584841 0.39362618 0.52540913 0.45736434\n",
            " 0.39190353 0.48062016 0.32988803 0.42635659 0.55727821 0.49698536\n",
            " 0.53229974 0.48062016 0.47631352 0.60120586 0.47286822 0.50732127\n",
            " 0.64685616 0.25064599 0.57795004 0.36003445 0.48492679 0.47028424\n",
            " 0.5960379  0.54091301 0.57364341 0.4754522  0.63135228 0.62790698\n",
            " 0.54177433 0.40568475 0.45822567 0.34280792 0.53574505 0.43410853\n",
            " 0.49956934 0.4461671  0.4918174  0.45391904 0.63221361 0.67183463\n",
            " 0.46511628 0.60292851 0.32816537 0.66838932 0.47028424 0.46597761\n",
            " 0.3712317  0.64944014 0.5667528  0.33074935 0.48751077 0.56416882\n",
            " 0.5211025  0.57881137 0.57536606 0.59086994 0.4788975  0.4496124\n",
            " 0.49698536 0.44875108 0.41343669 0.45564169 0.65891473 0.37898363\n",
            " 0.39534884 0.42807924 0.22739018 0.66063738 0.49009475 0.60206718\n",
            " 0.55469423 0.39793282 0.63996555 0.41257537 0.51421189 0.54435831\n",
            " 0.68561585 0.49612403 0.54780362 0.42204996 0.61584841 0.6089578\n",
            " 0.45391904 0.50559862 0.55986219 0.64341085 0.58570198 0.48923342\n",
            " 0.7002584  0.46511628 0.54091301 0.62446167 0.42204996 0.45219638\n",
            " 0.44272179 0.49267873 0.31093885 0.45133506 0.51593454 0.50043066\n",
            " 0.41085271 0.52885444 0.45908699 0.45908699 0.51248923 0.56847545\n",
            " 0.56072351 0.54177433 0.56933678 0.44099914 0.63049096 0.69939707\n",
            " 0.45047373 0.46856158 0.44444444 0.41085271 0.50043066 0.52024117\n",
            " 0.50990525 0.65977606 0.48837209 0.32816537 0.55900086 0.33936262\n",
            " 0.35228252 0.68217054 0.6287683  0.32988803 0.55211025 0.50990525\n",
            " 0.6873385  0.60723514 0.40913006 0.54263566 0.56761413 0.40654608\n",
            " 0.43066322 0.37898363 0.46942291 0.44186047 0.4332472  0.58570198\n",
            " 0.4332472  0.52713178 0.625323   0.62790698 0.49698536 0.63652024\n",
            " 0.54694229 0.45908699 0.5994832  0.61412575 0.37639966 0.48751077\n",
            " 0.57881137 0.52627046 0.49267873 0.46080965 0.47114556 0.46597761\n",
            " 0.4461671  0.41429802 0.38587425 0.55641688 0.5374677  0.4788975\n",
            " 0.61843239 0.44013781 0.5538329  0.36606374 0.5081826  0.59000861\n",
            " 0.45391904 0.50559862 0.62790698 0.41257537 0.43583118 0.56158484\n",
            " 0.58225668 0.63824289 0.44013781 0.61068045 0.48837209 0.50215332\n",
            " 0.34969854 0.51765719 0.60034453 0.57105943 0.49870801 0.46167097\n",
            " 0.46339363 0.53057709 0.50301464 0.45650301 0.32730405 0.44358312\n",
            " 0.40137812 0.43927649 0.64857881 0.49095607 0.51593454 0.46511628\n",
            " 0.57278208 0.6744186  0.47459087 0.5994832  0.62704565 0.52368648\n",
            " 0.57536606 0.44272179 0.69336779 0.57192076 0.51507321 0.55555556\n",
            " 0.61068045 0.43755383 0.51335056 0.50904393 0.55555556 0.60981912\n",
            " 0.38587425 0.37209302 0.48320413 0.44702842 0.45305771 0.40482343\n",
            " 0.38845823 0.37984496 0.52971576 0.57019811 0.63479759 0.60034453\n",
            " 0.54349699 0.68217054 0.60551249 0.42549526 0.36434109 0.53488372\n",
            " 0.63652024 0.47717485 0.43410853 0.51248923 0.47975883 0.58570198\n",
            " 0.52024117 0.48492679 0.46683893 0.62101637 0.43927649 0.61154177\n",
            " 0.50387597 0.64857881 0.55555556 0.58225668 0.48492679 0.42721792\n",
            " 0.52282515 0.44702842 0.62790698 0.54608096 0.58914729 0.47028424\n",
            " 0.51507321 0.49009475 0.58656331 0.56158484 0.45478036 0.35745047\n",
            " 0.60292851 0.57019811 0.46597761 0.45822567 0.52799311 0.48751077\n",
            " 0.5538329  0.57019811 0.59173127 0.57536606 0.59345392 0.51507321\n",
            " 0.28251507 0.4625323  0.56330749 0.52713178 0.41602067 0.51937984\n",
            " 0.46856158 0.66666667 0.51679587 0.53402239 0.43152455 0.62704565\n",
            " 0.72265289 0.65202412 0.51851852 0.61584841 0.41257537 0.53660637\n",
            " 0.66063738 0.46080965 0.42291128 0.45047373 0.66236003 0.4918174\n",
            " 0.55124892 0.3910422  0.38329027 0.56589147 0.5047373  0.5245478\n",
            " 0.59431525 0.62273902 0.57019811 0.59776055 0.42894057 0.54263566\n",
            " 0.55469423 0.55555556 0.54694229 0.3875969  0.46167097 0.44530577\n",
            " 0.59086994 0.60292851 0.62273902 0.60809647 0.57536606 0.64427218\n",
            " 0.45478036 0.61498708 0.47286822 0.52024117 0.52368648 0.45564169\n",
            " 0.5994832  0.57622739 0.40568475 0.36778639 0.52627046 0.6287683\n",
            " 0.34797588 0.59173127 0.45650301 0.36606374 0.61757106 0.47372954\n",
            " 0.52885444 0.45564169 0.63738157 0.4788975  0.33936262 0.66063738\n",
            " 0.6416882  0.66666667 0.59776055 0.49956934 0.37812231 0.42635659\n",
            " 0.49784668 0.38156761 0.4625323  0.53919035 0.45822567 0.45047373\n",
            " 0.50387597 0.53143842 0.16192937 0.43152455 0.47286822 0.57795004\n",
            " 0.65374677 0.28682171 0.54005168 0.39018088 0.55469423 0.72437554\n",
            " 0.32385874 0.51421189 0.41085271 0.70887166 0.59345392 0.48148148\n",
            " 0.45478036 0.45908699 0.53574505 0.62704565 0.76141258 0.42807924\n",
            " 0.47975883 0.59345392 0.44358312 0.50129199 0.41343669 0.56072351\n",
            " 0.54177433 0.52885444 0.60723514 0.42291128 0.53402239 0.53660637\n",
            " 0.7329888  0.49612403 0.45994832 0.48664944 0.5667528  0.57019811\n",
            " 0.4039621  0.61068045 0.41343669 0.48062016 0.54263566 0.6709733\n",
            " 0.56158484 0.63049096 0.43669251 0.56761413 0.56761413 0.47975883\n",
            " 0.54866494 0.46339363 0.34022394 0.43755383]\n",
            "The trained model has an aproximate error rate of -7.264750952619738 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'day' : [1,1,1,10],\n",
        "         'year' : [2019,2019,2019,2020],\n",
        "         'mo' : [3,3,3,12],\n",
        "         'da' : [10,10,10,12],\n",
        "         'prcp' : [0,2.34,5.5,2.24],\n",
        "         'fog' : [0,0,1,1],\n",
        "         'rain_drizzle' : [0,1,1,1],\n",
        "         'snow_ice_pellets' : [0,0,0,0],\n",
        "         'hail' : [0,0,0,0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRwTIlrs_nvk",
        "outputId": "5e66f5ab-8956-45bd-9268-88b913195625"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180c349d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[631.5835  628.92267 644.65247 542.87445]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two main tests have been applied to the model. The Route Mean Squared Error (RMSE) and a comparison between the target values in the testing dataset and the predicted values using the predictors in the testing dataset.\n",
        "\n",
        "Predominantly the RMSE of the model is lower than that of the average. This indicates that the model makes more accurate predictions compared to the average."
      ],
      "metadata": {
        "id": "kKckcLmPVIMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dew Point (dewp)\n",
        "A relationship between dew point and the number of collisions was also uncovered in assignment 1. This linear relationship suggests that as the dew point increases the number of collisions increase. \n",
        "\n",
        "The process to produce the model follows the same process as the precipitation model."
      ],
      "metadata": {
        "id": "RB0Zq1024UmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_dewp = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/dewp_clean.csv', index_col=0, )\n",
        "print(df_dewp[:6])"
      ],
      "metadata": {
        "id": "d2NB6odM5G9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d677ac-3bf9-4ea7-bffb-688446b2cc5a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_dewp = df_dewp.drop(columns=['collision_date', 'temp', 'prcp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_dewp = df_dewp.loc[df_dewp[\"year\"] != 2012]\n",
        "df_dewp = df_dewp.loc[df_dewp[\"year\"] < 2020]\n",
        "cols = df_dewp['NUM_COLLISIONS']\n",
        "df_dewp = df_dewp.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move target to end\n",
        "df_dewp.insert(loc=5, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_dewp[:6])\n",
        "df_dewp.describe()"
      ],
      "metadata": {
        "id": "WwtmLQ6a5rHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "48221d99-452e-40f9-d4bc-18b64d9d2aac"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  dewp  NUM_COLLISIONS\n",
            "49    4  2016   1  28  24.4             681\n",
            "51    5  2014   1  17  35.8             589\n",
            "54    1  2016   1  25  21.2             658\n",
            "55    5  2016   1  29  36.8             645\n",
            "58    5  2017   1  20  32.5             605\n",
            "59    7  2013   1  13  44.9             373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         dewp  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      3.998434  2015.999217     6.524070    15.723679    44.163170   \n",
              "std       2.000391     2.000000     3.449676     8.801271    16.995303   \n",
              "min       1.000000  2013.000000     1.000000     1.000000    -6.700000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000    32.150000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000    45.300000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000    58.500000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000    74.100000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2555.000000  \n",
              "mean       599.109980  \n",
              "std        100.277185  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8a28623-69c0-4d69-b01a-3093ac005d36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>dewp</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998434</td>\n",
              "      <td>2015.999217</td>\n",
              "      <td>6.524070</td>\n",
              "      <td>15.723679</td>\n",
              "      <td>44.163170</td>\n",
              "      <td>599.109980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000391</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.449676</td>\n",
              "      <td>8.801271</td>\n",
              "      <td>16.995303</td>\n",
              "      <td>100.277185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8a28623-69c0-4d69-b01a-3093ac005d36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8a28623-69c0-4d69-b01a-3093ac005d36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8a28623-69c0-4d69-b01a-3093ac005d36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle Data\n",
        "shuffle = df_dewp.iloc[np.random.permutation(len(df_dewp))]\n",
        "#Select Predictors\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "KXbAqzNN694C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff99f739-fbda-48a5-ebff-7ba2d774dfe9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  dewp\n",
            "1587    2  2019   6  18  58.8\n",
            "2698    3  2016   9   7  66.8\n",
            "1724    5  2017   6  23  63.4\n",
            "1383    1  2018   5   7  49.7\n",
            "1877    5  2019   7  26  58.9\n",
            "2879    2  2013  10   1  51.8\n",
            "      day  year  mo  da  dewp  NUM_COLLISIONS\n",
            "1587    2  2019   6  18  58.8             721\n",
            "2698    3  2016   9   7  66.8             648\n",
            "1724    5  2017   6  23  63.4             793\n",
            "1383    1  2018   5   7  49.7             695\n",
            "1877    5  2019   7  26  58.9             650\n",
            "2879    2  2013  10   1  51.8             616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "iGbT5sAJ7KTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf311b7-e0c7-44df-a29f-ceac2ba4e86a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1587    721\n",
            "2698    648\n",
            "1724    793\n",
            "1383    695\n",
            "1877    650\n",
            "2879    616\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 5\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "vpHbBnml7PZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55f9db0-e258-48e7-cc2e-3393ae11c430"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2044\n",
            "511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_dewp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#test Model\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "j4GKf5BL7WI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25071b13-87ea-45e7-ed78-774149d5f624"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184825110>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.27910894, step = 1\n",
            "INFO:tensorflow:global_step/sec: 585.842\n",
            "INFO:tensorflow:loss = 0.0071757007, step = 101 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.49\n",
            "INFO:tensorflow:loss = 0.009145996, step = 201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.143\n",
            "INFO:tensorflow:loss = 0.006120279, step = 301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.497\n",
            "INFO:tensorflow:loss = 0.0068645384, step = 401 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.93\n",
            "INFO:tensorflow:loss = 0.0065441383, step = 501 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 718.277\n",
            "INFO:tensorflow:loss = 0.005712265, step = 601 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 756.416\n",
            "INFO:tensorflow:loss = 0.0065529943, step = 701 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 763.885\n",
            "INFO:tensorflow:loss = 0.0074291234, step = 801 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.516\n",
            "INFO:tensorflow:loss = 0.0064876494, step = 901 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.259\n",
            "INFO:tensorflow:loss = 0.0070132073, step = 1001 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 758.645\n",
            "INFO:tensorflow:loss = 0.007427176, step = 1101 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.352\n",
            "INFO:tensorflow:loss = 0.008275729, step = 1201 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.486\n",
            "INFO:tensorflow:loss = 0.008530104, step = 1301 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 377.271\n",
            "INFO:tensorflow:loss = 0.0061031026, step = 1401 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.276\n",
            "INFO:tensorflow:loss = 0.007176334, step = 1501 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.328\n",
            "INFO:tensorflow:loss = 0.0063570933, step = 1601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.481\n",
            "INFO:tensorflow:loss = 0.0072192913, step = 1701 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.851\n",
            "INFO:tensorflow:loss = 0.005751349, step = 1801 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.81\n",
            "INFO:tensorflow:loss = 0.00858137, step = 1901 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.227\n",
            "INFO:tensorflow:loss = 0.0068627414, step = 2001 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.978\n",
            "INFO:tensorflow:loss = 0.0047110915, step = 2101 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.977\n",
            "INFO:tensorflow:loss = 0.007619273, step = 2201 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.966\n",
            "INFO:tensorflow:loss = 0.0064425655, step = 2301 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.671\n",
            "INFO:tensorflow:loss = 0.006739822, step = 2401 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.782\n",
            "INFO:tensorflow:loss = 0.0068638753, step = 2501 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 399.443\n",
            "INFO:tensorflow:loss = 0.00650636, step = 2601 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.945\n",
            "INFO:tensorflow:loss = 0.006377356, step = 2701 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.298\n",
            "INFO:tensorflow:loss = 0.007627611, step = 2801 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.008\n",
            "INFO:tensorflow:loss = 0.0075903423, step = 2901 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.037\n",
            "INFO:tensorflow:loss = 0.008274168, step = 3001 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.169\n",
            "INFO:tensorflow:loss = 0.0057349103, step = 3101 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.107\n",
            "INFO:tensorflow:loss = 0.006691985, step = 3201 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.857\n",
            "INFO:tensorflow:loss = 0.0054842513, step = 3301 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.512\n",
            "INFO:tensorflow:loss = 0.0063920356, step = 3401 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.371\n",
            "INFO:tensorflow:loss = 0.006456484, step = 3501 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.174\n",
            "INFO:tensorflow:loss = 0.006904257, step = 3601 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.62\n",
            "INFO:tensorflow:loss = 0.0061804852, step = 3701 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.217\n",
            "INFO:tensorflow:loss = 0.005532725, step = 3801 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.91\n",
            "INFO:tensorflow:loss = 0.00870128, step = 3901 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.159\n",
            "INFO:tensorflow:loss = 0.005885532, step = 4001 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.723\n",
            "INFO:tensorflow:loss = 0.0061193057, step = 4101 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.281\n",
            "INFO:tensorflow:loss = 0.0062840246, step = 4201 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.34\n",
            "INFO:tensorflow:loss = 0.0058887666, step = 4301 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.889\n",
            "INFO:tensorflow:loss = 0.006267621, step = 4401 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.201\n",
            "INFO:tensorflow:loss = 0.0077075316, step = 4501 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.271\n",
            "INFO:tensorflow:loss = 0.0069782697, step = 4601 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 407.38\n",
            "INFO:tensorflow:loss = 0.0061693573, step = 4701 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.399\n",
            "INFO:tensorflow:loss = 0.0051371753, step = 4801 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.123\n",
            "INFO:tensorflow:loss = 0.0062765065, step = 4901 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.007\n",
            "INFO:tensorflow:loss = 0.0073586637, step = 5001 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.257\n",
            "INFO:tensorflow:loss = 0.006521263, step = 5101 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.876\n",
            "INFO:tensorflow:loss = 0.0051808357, step = 5201 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.35\n",
            "INFO:tensorflow:loss = 0.0064858664, step = 5301 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.698\n",
            "INFO:tensorflow:loss = 0.005778677, step = 5401 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.922\n",
            "INFO:tensorflow:loss = 0.006358114, step = 5501 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.448\n",
            "INFO:tensorflow:loss = 0.005667003, step = 5601 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.797\n",
            "INFO:tensorflow:loss = 0.006210869, step = 5701 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.214\n",
            "INFO:tensorflow:loss = 0.004809019, step = 5801 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.381\n",
            "INFO:tensorflow:loss = 0.006987954, step = 5901 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 294.482\n",
            "INFO:tensorflow:loss = 0.0070811426, step = 6001 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 369.968\n",
            "INFO:tensorflow:loss = 0.009145645, step = 6101 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 172.48\n",
            "INFO:tensorflow:loss = 0.005567722, step = 6201 (0.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.918\n",
            "INFO:tensorflow:loss = 0.0060405647, step = 6301 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.737\n",
            "INFO:tensorflow:loss = 0.0055036265, step = 6401 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.878\n",
            "INFO:tensorflow:loss = 0.005654744, step = 6501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.056\n",
            "INFO:tensorflow:loss = 0.008668926, step = 6601 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.518\n",
            "INFO:tensorflow:loss = 0.006052752, step = 6701 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.426\n",
            "INFO:tensorflow:loss = 0.0073277927, step = 6801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.715\n",
            "INFO:tensorflow:loss = 0.005175301, step = 6901 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.917\n",
            "INFO:tensorflow:loss = 0.0058476683, step = 7001 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.516\n",
            "INFO:tensorflow:loss = 0.007243996, step = 7101 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.561\n",
            "INFO:tensorflow:loss = 0.005623378, step = 7201 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.589\n",
            "INFO:tensorflow:loss = 0.006515202, step = 7301 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.93\n",
            "INFO:tensorflow:loss = 0.006132504, step = 7401 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.022\n",
            "INFO:tensorflow:loss = 0.005530668, step = 7501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.629\n",
            "INFO:tensorflow:loss = 0.00521371, step = 7601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.023\n",
            "INFO:tensorflow:loss = 0.0067268144, step = 7701 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.026\n",
            "INFO:tensorflow:loss = 0.0057989266, step = 7801 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.526\n",
            "INFO:tensorflow:loss = 0.007417523, step = 7901 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.6\n",
            "INFO:tensorflow:loss = 0.0070543485, step = 8001 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.967\n",
            "INFO:tensorflow:loss = 0.005738203, step = 8101 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.118\n",
            "INFO:tensorflow:loss = 0.006946933, step = 8201 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.124\n",
            "INFO:tensorflow:loss = 0.005553347, step = 8301 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 757.93\n",
            "INFO:tensorflow:loss = 0.0056874603, step = 8401 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.901\n",
            "INFO:tensorflow:loss = 0.0059882808, step = 8501 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.968\n",
            "INFO:tensorflow:loss = 0.0059762653, step = 8601 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 741.14\n",
            "INFO:tensorflow:loss = 0.007290546, step = 8701 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.976\n",
            "INFO:tensorflow:loss = 0.0073462366, step = 8801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.105\n",
            "INFO:tensorflow:loss = 0.0063031493, step = 8901 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 796.867\n",
            "INFO:tensorflow:loss = 0.005898542, step = 9001 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 805.876\n",
            "INFO:tensorflow:loss = 0.0066786343, step = 9101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.946\n",
            "INFO:tensorflow:loss = 0.007888571, step = 9201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.385\n",
            "INFO:tensorflow:loss = 0.0076215817, step = 9301 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.5\n",
            "INFO:tensorflow:loss = 0.005833526, step = 9401 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.404\n",
            "INFO:tensorflow:loss = 0.0068534315, step = 9501 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 757.781\n",
            "INFO:tensorflow:loss = 0.0060513746, step = 9601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 761.612\n",
            "INFO:tensorflow:loss = 0.0056732455, step = 9701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 710.521\n",
            "INFO:tensorflow:loss = 0.007188744, step = 9801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.487\n",
            "INFO:tensorflow:loss = 0.006826111, step = 9901 (0.118 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0069436403.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 93.96416755097607\n",
            "Just using average = 598.9432485322897 has RMSE of 102.3375683663379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "CmqqgLT09593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348a6751-fe91-45ba-f49b-3693ae4a37dc"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2193f8d590>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n",
            "[0.54108864 0.5150208  0.51542944 0.51455796 0.47583237 0.5577232\n",
            " 0.56107754 0.52491874 0.5058224  0.5312116  0.57578826 0.4976822\n",
            " 0.5146251  0.47125548 0.54165584 0.5187817  0.54353875 0.48916832\n",
            " 0.5086365  0.51474327 0.4938765  0.47406805 0.54567677 0.57583743\n",
            " 0.53132784 0.5793128  0.5340886  0.5401705  0.53567487 0.56672806\n",
            " 0.507975   0.5596787  0.53980374 0.52301604 0.47560015 0.49049875\n",
            " 0.52553046 0.48754847 0.5383884  0.49556622 0.5098874  0.529255\n",
            " 0.56506574 0.49334618 0.5572748  0.5790375  0.55949205 0.4743112\n",
            " 0.5073691  0.53109753 0.46992546 0.5120298  0.5085686  0.57224846\n",
            " 0.5523468  0.50943124 0.53462005 0.48818082 0.51841134 0.5310553\n",
            " 0.5350835  0.580653   0.5600857  0.5329062  0.5573527  0.5525702\n",
            " 0.5150917  0.518853   0.49951407 0.5492718  0.5072489  0.548728\n",
            " 0.51278436 0.48733842 0.48348555 0.5607031  0.46873987 0.5772446\n",
            " 0.54728687 0.5182029  0.47003058 0.48797196 0.58404195 0.5136731\n",
            " 0.5490102  0.44753367 0.5624638  0.5363252  0.5077698  0.5223185\n",
            " 0.5647131  0.53296053 0.5311435  0.45915756 0.5383896  0.52778465\n",
            " 0.50772107 0.48073635 0.46005115 0.5643885  0.52050877 0.53915364\n",
            " 0.47376418 0.5291812  0.5316149  0.57221764 0.50233936 0.5749045\n",
            " 0.5195794  0.58106124 0.5015247  0.52341264 0.5791856  0.54169655\n",
            " 0.5179704  0.49738026 0.58506763 0.562683   0.5014503  0.5359829\n",
            " 0.49600577 0.5417481  0.51964784 0.4918763  0.5395946  0.5456967\n",
            " 0.5258083  0.4615731  0.5589868  0.57399124 0.5266814  0.5556721\n",
            " 0.5204989  0.51010114 0.5629906  0.5677934  0.5099794  0.5101632\n",
            " 0.46556857 0.5130429  0.5088091  0.5477641  0.533126   0.5244356\n",
            " 0.4880653  0.51941603 0.5629181  0.5027197  0.5748539  0.53744197\n",
            " 0.4911248  0.55418473 0.5099713  0.5438294  0.5291913  0.51656616\n",
            " 0.5043808  0.49378875 0.5658045  0.5742666  0.5115534  0.5255683\n",
            " 0.5408959  0.5192384  0.52800554 0.4907549  0.5201664  0.5022712\n",
            " 0.52749896 0.49686885 0.5379528  0.4929482  0.49575558 0.5091372\n",
            " 0.52279586 0.4886876  0.479897   0.50207    0.5362723  0.46801957\n",
            " 0.5206949  0.51806706 0.54768634 0.5036697  0.5434192  0.4803427\n",
            " 0.49922448 0.550738   0.499836   0.5142034  0.5452298  0.48413566\n",
            " 0.55458874 0.47859424 0.50596595 0.5498642  0.5685965  0.47783923\n",
            " 0.5002379  0.4992798  0.5333279  0.4976158  0.48554757 0.55075973\n",
            " 0.48538044 0.52437603 0.50453764 0.48055372 0.5248616  0.49792236\n",
            " 0.52434886 0.5134821  0.55376095 0.53997666 0.5119878  0.52128774\n",
            " 0.54187113 0.54070324 0.523219   0.5140302  0.5822087  0.49417746\n",
            " 0.5053261  0.5448133  0.50911653 0.513521   0.4999316  0.5382092\n",
            " 0.5151459  0.5505595  0.5429388  0.4778663  0.5239519  0.51999915\n",
            " 0.56870246 0.5558545  0.5410267  0.54752064 0.55876815 0.5264027\n",
            " 0.55601645 0.5222852  0.49241278 0.5613162  0.5164091  0.567348\n",
            " 0.5418663  0.5409191  0.45717958 0.5568921  0.4891582  0.47621858\n",
            " 0.51051927 0.55769926 0.53311014 0.57283217 0.540937   0.5171946\n",
            " 0.5206638  0.55404264 0.5410526  0.53414035 0.53172547 0.57925946\n",
            " 0.5108401  0.5395705  0.55371046 0.45959055 0.5172581  0.543899\n",
            " 0.5540535  0.48851457 0.4640204  0.55025214 0.5303824  0.57901204\n",
            " 0.53455913 0.53971565 0.4788242  0.4715443  0.52637124 0.47154385\n",
            " 0.5630304  0.5567627  0.48489612 0.5056705  0.5084416  0.50329655\n",
            " 0.53464884 0.5233374  0.46753234 0.51766855 0.5644074  0.51348555\n",
            " 0.5140848  0.5589446  0.50416434 0.5675617  0.4962442  0.5457608\n",
            " 0.55659807 0.5254398  0.5732695  0.49685046 0.55320305 0.530385\n",
            " 0.529313   0.4881646  0.5098324  0.5423858  0.56070584 0.53553724\n",
            " 0.5166824  0.5069935  0.50816876 0.5695718  0.5595358  0.5234725\n",
            " 0.5594523  0.52237004 0.51563996 0.53060746 0.5079491  0.57450044\n",
            " 0.5430948  0.5135061  0.51167035 0.5339886  0.49223828 0.5103185\n",
            " 0.5102206  0.4854121  0.47086793 0.5418512  0.5783348  0.5213529\n",
            " 0.5813127  0.5075146  0.47741216 0.48958746 0.56194764 0.5175923\n",
            " 0.4644613  0.58068794 0.5542987  0.5444137  0.49073932 0.5381133\n",
            " 0.4745168  0.5213706  0.55103105 0.52668697 0.5738027  0.55382997\n",
            " 0.49778694 0.5263539  0.5095734  0.5291051  0.57043386 0.45855048\n",
            " 0.49511877 0.55450445 0.4908795  0.48974425 0.5609539  0.53970325\n",
            " 0.48845464 0.54853857 0.51469666 0.5511472  0.5042448  0.53032047\n",
            " 0.5183261  0.5024437  0.49122676 0.54270077 0.49579433 0.47879753\n",
            " 0.5648128  0.5349496  0.5063429  0.48789123 0.547935   0.46537974\n",
            " 0.5245902  0.5083281  0.5257869  0.535143   0.54618734 0.5672864\n",
            " 0.4815183  0.51203954 0.4788181  0.5242893  0.5639166  0.46593848\n",
            " 0.50493115 0.5047898  0.5403574  0.50033826 0.48278597 0.4537321\n",
            " 0.55885434 0.53192544 0.51250017 0.51003206 0.4967232  0.5751745\n",
            " 0.50074774 0.5264961  0.53491265 0.5035847  0.5333813  0.47456107\n",
            " 0.48825306 0.53684956 0.5042847  0.5111529  0.5397072  0.50899994\n",
            " 0.512863   0.5717247  0.4668577  0.53421354 0.5186316  0.50372183\n",
            " 0.5779205  0.49999714 0.54701155 0.48963317 0.5165203  0.5317221\n",
            " 0.5297121  0.47898808 0.48183885 0.4977342  0.5360973  0.49959457\n",
            " 0.55645806 0.528866   0.4522385  0.5559241  0.5109132  0.53523386\n",
            " 0.57489276 0.5703531  0.5460177  0.51864666 0.5199364  0.5047125\n",
            " 0.54501015 0.5124917  0.5206937  0.5671324  0.5209091  0.5401893\n",
            " 0.5630166  0.5206738  0.5197941  0.5517631  0.5457354  0.5360193\n",
            " 0.4801066  0.4926353  0.5575767  0.56088686 0.53406847 0.5528147\n",
            " 0.51076263 0.5361917  0.49752912 0.55641687 0.52756524 0.5296206\n",
            " 0.4913484  0.50925815 0.5321994  0.51275694 0.5121953  0.49233717\n",
            " 0.4713706  0.5205171  0.5384881  0.55368763 0.49089685 0.52918386\n",
            " 0.4834323  0.49148476 0.5431942  0.5091376  0.45677802 0.5164526\n",
            " 0.56503344 0.47267884 0.54127246 0.51009476 0.5562523  0.50759655\n",
            " 0.47628433 0.5593053  0.519566   0.53316087 0.46996322 0.50838274\n",
            " 0.57078654 0.5092215  0.57673067 0.5446872  0.4878115  0.5409762\n",
            " 0.4992038 ]\n",
            "[0.53574505 0.42721792 0.60120586 0.46856158 0.35917313 0.47631352\n",
            " 0.7002584  0.61154177 0.60206718 0.45822567 0.5047373  0.5081826\n",
            " 0.40913006 0.41085271 0.52627046 0.63479759 0.63652024 0.44099914\n",
            " 0.56158484 0.43496985 0.42635659 0.37898363 0.58914729 0.52627046\n",
            " 0.63135228 0.43152455 0.56761413 0.62273902 0.51507321 0.52713178\n",
            " 1.         0.46511628 0.60034453 0.49267873 0.39362618 0.45305771\n",
            " 0.63910422 0.47286822 0.26098191 0.46770026 0.4754522  0.70542636\n",
            " 0.52971576 0.44444444 0.52971576 0.48837209 0.5503876  0.43410853\n",
            " 0.42291128 0.46339363 0.4203273  0.39276486 0.46511628 0.51248923\n",
            " 0.33936262 0.43238587 0.64771748 0.46425495 0.49095607 0.4005168\n",
            " 0.57622739 0.5047373  0.59345392 0.52971576 0.49009475 0.65633075\n",
            " 0.58225668 0.44875108 0.46080965 0.64254953 0.48062016 0.45908699\n",
            " 0.5047373  0.40482343 0.4918174  0.56158484 0.36434109 0.52799311\n",
            " 0.61412575 0.55641688 0.49784668 0.38242894 0.53229974 0.40310078\n",
            " 0.47803618 0.4005168  0.51593454 0.41257537 0.47114556 0.49870801\n",
            " 0.65202412 0.54263566 0.54780362 0.56416882 0.49095607 0.61326443\n",
            " 0.54005168 0.40999139 0.36692506 0.56589147 0.46683893 0.54349699\n",
            " 0.52713178 0.6124031  0.52799311 0.57364341 0.40137812 0.51248923\n",
            " 0.74677003 0.54521964 0.48751077 0.41343669 0.51937984 0.51851852\n",
            " 0.49956934 0.41602067 0.4952627  0.66149871 0.53402239 0.65891473\n",
            " 0.42463394 0.60809647 0.39190353 0.53660637 0.48837209 0.55124892\n",
            " 0.50043066 0.43066322 0.56330749 0.5960379  0.59259259 0.5667528\n",
            " 0.55813953 0.43066322 0.56761413 0.62618432 0.46339363 0.53660637\n",
            " 0.36520241 0.42377261 0.57278208 0.57450474 0.60292851 0.4754522\n",
            " 0.55900086 0.51593454 0.63824289 0.47631352 0.57536606 0.45305771\n",
            " 0.45564169 0.58914729 0.38501292 0.65202412 0.54263566 0.44099914\n",
            " 0.5374677  0.50990525 0.61843239 0.63738157 0.49440138 0.53488372\n",
            " 0.60378984 0.49698536 0.44444444 0.53832903 0.57019811 0.52627046\n",
            " 0.46167097 0.48148148 0.51937984 0.50904393 0.4625323  0.46080965\n",
            " 0.48664944 0.49267873 0.49440138 0.44358312 0.49354005 0.33936262\n",
            " 0.58914729 0.57536606 0.47372954 0.54780362 0.6089578  0.4918174\n",
            " 0.47803618 0.43755383 0.43496985 0.59259259 0.48320413 0.40826873\n",
            " 0.50904393 0.58139535 0.60378984 0.54608096 0.3910422  0.44272179\n",
            " 0.51162791 0.56589147 0.36864772 0.56933678 0.45908699 0.68044789\n",
            " 0.5047373  0.66408269 0.41429802 0.51851852 0.56416882 0.30060293\n",
            " 0.48148148 0.91731266 0.52282515 0.63910422 0.57708872 0.4952627\n",
            " 0.45305771 0.5796727  0.75107666 0.51076658 0.53143842 0.53143842\n",
            " 0.42118863 0.4332472  0.76141258 0.70456503 0.38587425 0.56158484\n",
            " 0.55900086 0.62704565 0.61068045 0.58570198 0.47459087 0.42980189\n",
            " 0.52885444 0.47717485 0.82687339 0.63393626 0.5667528  0.5667528\n",
            " 0.58828596 0.64082687 0.4754522  0.56589147 0.47286822 0.4918174\n",
            " 0.51507321 0.56158484 0.60723514 0.47459087 0.60551249 0.44444444\n",
            " 0.39793282 0.52627046 0.44186047 0.47286822 0.57364341 0.53316107\n",
            " 0.5245478  0.64254953 0.47975883 0.52713178 0.58225668 0.5667528\n",
            " 0.63738157 0.64254953 0.57881137 0.38845823 0.49784668 0.62101637\n",
            " 0.57364341 0.39362618 0.36950904 0.55900086 0.53919035 0.54005168\n",
            " 0.58828596 0.49267873 0.47372954 0.33419466 0.56761413 0.38845823\n",
            " 0.49440138 0.57019811 0.34366925 0.55986219 0.43238587 0.52540913\n",
            " 0.56416882 0.48923342 0.44702842 0.51593454 0.40568475 0.66838932\n",
            " 0.60809647 0.4952627  0.50990525 0.51162791 0.583118   0.5667528\n",
            " 0.5503876  0.5245478  0.6089578  0.40913006 0.55641688 0.61154177\n",
            " 0.51765719 0.47372954 0.4952627  0.61929371 0.4918174  0.61498708\n",
            " 0.36950904 0.41774332 0.43583118 0.63996555 0.60120586 0.51248923\n",
            " 0.5994832  0.39362618 0.55813953 0.66666667 0.46856158 0.53919035\n",
            " 0.53660637 0.5960379  0.51851852 0.44186047 0.45650301 0.42118863\n",
            " 0.47631352 0.40913006 0.43238587 0.4496124  0.55900086 0.54780362\n",
            " 0.55211025 0.54694229 0.44530577 0.58656331 0.59173127 0.41085271\n",
            " 0.39793282 0.51851852 0.41257537 0.52971576 0.47114556 0.47114556\n",
            " 0.44875108 0.56847545 0.64427218 0.72782084 0.47975883 0.55727821\n",
            " 0.59862188 0.54866494 0.39879414 0.58656331 0.62360034 0.37812231\n",
            " 0.33936262 0.62790698 0.47803618 0.54521964 0.56330749 0.54866494\n",
            " 0.31438415 0.57450474 0.48492679 0.50129199 0.59431525 0.58828596\n",
            " 0.44702842 0.38501292 0.50301464 0.51937984 0.45219638 0.50732127\n",
            " 0.50990525 0.48664944 0.43496985 0.64857881 0.43927649 0.49698536\n",
            " 0.47459087 0.36606374 0.51248923 0.57364341 0.63221361 0.52540913\n",
            " 0.4788975  0.53229974 0.3875969  0.625323   0.56847545 0.4005168\n",
            " 0.55211025 0.48664944 0.44788975 0.54177433 0.39276486 0.34453058\n",
            " 0.53402239 0.66063738 0.39707149 0.44358312 0.40310078 0.54866494\n",
            " 0.45822567 0.56847545 0.66063738 0.50129199 0.52971576 0.47631352\n",
            " 0.44099914 0.48148148 0.45478036 0.42204996 0.48751077 0.49095607\n",
            " 0.46339363 0.4754522  0.33850129 0.51593454 0.5374677  0.45736434\n",
            " 0.59689922 0.43927649 0.51937984 0.43410853 0.6546081  0.56158484\n",
            " 0.46770026 0.38587425 0.39793282 0.53574505 0.6416882  0.5081826\n",
            " 0.52799311 0.49870801 0.51593454 0.56072351 0.45391904 0.65546942\n",
            " 0.60378984 0.49698536 0.6416882  0.47028424 0.41343669 0.48234281\n",
            " 0.45908699 0.47975883 0.54435831 0.57622739 0.42549526 0.57364341\n",
            " 0.68130922 0.50387597 0.59431525 0.57105943 0.65719208 0.49440138\n",
            " 0.39534884 0.44272179 0.56158484 0.64944014 0.55211025 0.63824289\n",
            " 0.54694229 0.58570198 0.45564169 0.54005168 0.49784668 0.57536606\n",
            " 0.52024117 0.50990525 0.53488372 0.53057709 0.52971576 0.64685616\n",
            " 0.3453919  0.65202412 0.49870801 0.42807924 0.51507321 0.47286822\n",
            " 0.44702842 0.51851852 0.63910422 0.50990525 0.37209302 0.59689922\n",
            " 0.60206718 0.33505599 0.55900086 0.53402239 0.49870801 0.59776055\n",
            " 0.48923342 0.50215332 0.51421189 0.60809647 0.51765719 0.51765719\n",
            " 0.50215332 0.41343669 0.68475452 0.54349699 0.33074935 0.55124892\n",
            " 0.43238587]\n",
            "The trained model has an aproximate error rate of -7.645719182234686 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'day' : [1,1,1,10],\n",
        "         'year' : [2019,2019,2019,2020],\n",
        "         'mo' : [3,3,3,12],\n",
        "         'da' : [10,10,10,12],\n",
        "         'dewp' : [0,2.34,5.5,2.24],\n",
        "         \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567b5422-06f0-48e5-d285-1b24f14a96a8",
        "id": "SrAmbEAeHknA"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f218474e550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[596.0713  598.4295  601.614   503.96735]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE for the dewp model is slightly lower in comparison to the model produced for precipitation. As the RMSE is lower than the RMSE of the mean, it shows that the model has a higher level of accuracy in comparison to the using the mean."
      ],
      "metadata": {
        "id": "k_jNEZ_dS62M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visibility (visib)\n",
        "A relationship was also uncovered between visibility and the number of collisions. This is a negative linear relationship where the visibility increases the number of collisions decrease. \n",
        "\n",
        "The process to produce the model follows the same process as above."
      ],
      "metadata": {
        "id": "XfOkQa04Wgr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_visib = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/coldata.csv', index_col=0, )\n",
        "print(df_visib[:6])"
      ],
      "metadata": {
        "id": "tOsAfHzhWgr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497890c0-f7f2-4d5b-bc99-9ef2d216680d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_visib = df_visib.drop(columns=['collision_date', 'temp', 'prcp', 'slp','dewp','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_visib = df_visib.loc[df_visib[\"year\"] != 2012]\n",
        "df_visib = df_visib.loc[df_visib[\"year\"] < 2020]\n",
        "cols = df_visib['NUM_COLLISIONS']\n",
        "df_visib = df_visib.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move target to end\n",
        "df_visib.insert(loc=5, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_visib[:6])\n",
        "df_visib.describe()"
      ],
      "metadata": {
        "id": "pAaWfrlBWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7ebcd1d2-16e3-4f36-f11f-8d1e296583dc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  visib  NUM_COLLISIONS\n",
            "49    4  2016   1  28   10.0             681\n",
            "51    5  2014   1  17    6.7             589\n",
            "54    1  2016   1  25   10.0             658\n",
            "55    5  2016   1  29   10.0             645\n",
            "58    5  2017   1  20   10.0             605\n",
            "59    7  2013   1  13    4.3             373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day    year           mo           da        visib  \\\n",
              "count  2556.000000  2556.0  2556.000000  2556.000000  2556.000000   \n",
              "mean      3.999218  2016.0     6.524257    15.725743     8.295618   \n",
              "std       2.000391     2.0     3.449013     8.800168     2.207870   \n",
              "min       1.000000  2013.0     1.000000     1.000000     0.200000   \n",
              "25%       2.000000  2014.0     4.000000     8.000000     7.100000   \n",
              "50%       4.000000  2016.0     7.000000    16.000000     9.400000   \n",
              "75%       6.000000  2018.0    10.000000    23.000000    10.000000   \n",
              "max       7.000000  2019.0    12.000000    31.000000    10.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2556.000000  \n",
              "mean       599.118936  \n",
              "std        100.258581  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab434ebf-6a46-4af2-8016-b3b1c99898ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>visib</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.0</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.999218</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.524257</td>\n",
              "      <td>15.725743</td>\n",
              "      <td>8.295618</td>\n",
              "      <td>599.118936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000391</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.449013</td>\n",
              "      <td>8.800168</td>\n",
              "      <td>2.207870</td>\n",
              "      <td>100.258581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab434ebf-6a46-4af2-8016-b3b1c99898ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab434ebf-6a46-4af2-8016-b3b1c99898ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab434ebf-6a46-4af2-8016-b3b1c99898ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data\n",
        "shuffle = df_visib.iloc[np.random.permutation(len(df_visib))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "9VOgsgFJWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f41be07-b5b0-491d-c50c-9d1a12e2e1d4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  visib\n",
            "2825    4  2019  10  24   10.0\n",
            "1856    1  2019   7   8   10.0\n",
            "1021    7  2015   4  12   10.0\n",
            "2935    3  2016  10   5   10.0\n",
            "1685    6  2018   6  23    5.7\n",
            "2187    2  2016   8   9   10.0\n",
            "      day  year  mo  da  visib  NUM_COLLISIONS\n",
            "2825    4  2019  10  24   10.0             613\n",
            "1856    1  2019   7   8   10.0             592\n",
            "1021    7  2015   4  12   10.0             443\n",
            "2935    3  2016  10   5   10.0             695\n",
            "1685    6  2018   6  23    5.7             513\n",
            "2187    2  2016   8   9   10.0             650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "dx2bYy6zWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60917e28-07c9-4a47-fe7d-b21625907959"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2825    613\n",
            "1856    592\n",
            "1021    443\n",
            "2935    695\n",
            "1685    513\n",
            "2187    650\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 5\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "TKLeYNUiWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c72fa7c-90d2-4fe9-92d9-9f6a9c987061"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2044\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_visib', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "J24fhLeNWgr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138ec4ae-9f5c-4d7b-888a-30196f964678"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21848e5050>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_visib/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.27459064, step = 1\n",
            "INFO:tensorflow:global_step/sec: 657.885\n",
            "INFO:tensorflow:loss = 0.009505197, step = 101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.991\n",
            "INFO:tensorflow:loss = 0.008307781, step = 201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.181\n",
            "INFO:tensorflow:loss = 0.0071506426, step = 301 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.623\n",
            "INFO:tensorflow:loss = 0.0070540262, step = 401 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.632\n",
            "INFO:tensorflow:loss = 0.007330095, step = 501 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 797.108\n",
            "INFO:tensorflow:loss = 0.0065802094, step = 601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.471\n",
            "INFO:tensorflow:loss = 0.0069297077, step = 701 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.927\n",
            "INFO:tensorflow:loss = 0.0067370385, step = 801 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.604\n",
            "INFO:tensorflow:loss = 0.0064073256, step = 901 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 732.192\n",
            "INFO:tensorflow:loss = 0.007578803, step = 1001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.24\n",
            "INFO:tensorflow:loss = 0.00867, step = 1101 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.069\n",
            "INFO:tensorflow:loss = 0.0065758135, step = 1201 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.068\n",
            "INFO:tensorflow:loss = 0.0068451595, step = 1301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.137\n",
            "INFO:tensorflow:loss = 0.007285299, step = 1401 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.249\n",
            "INFO:tensorflow:loss = 0.0064365007, step = 1501 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 756.277\n",
            "INFO:tensorflow:loss = 0.0049128546, step = 1601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.147\n",
            "INFO:tensorflow:loss = 0.007026744, step = 1701 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.1\n",
            "INFO:tensorflow:loss = 0.0075818216, step = 1801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.645\n",
            "INFO:tensorflow:loss = 0.0066062314, step = 1901 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 749.079\n",
            "INFO:tensorflow:loss = 0.006248415, step = 2001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.685\n",
            "INFO:tensorflow:loss = 0.005182577, step = 2101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.835\n",
            "INFO:tensorflow:loss = 0.0059992033, step = 2201 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.475\n",
            "INFO:tensorflow:loss = 0.006666119, step = 2301 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.386\n",
            "INFO:tensorflow:loss = 0.008299904, step = 2401 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.026\n",
            "INFO:tensorflow:loss = 0.005268941, step = 2501 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.067\n",
            "INFO:tensorflow:loss = 0.00860627, step = 2601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.288\n",
            "INFO:tensorflow:loss = 0.007959292, step = 2701 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 734.305\n",
            "INFO:tensorflow:loss = 0.008902807, step = 2801 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 756.775\n",
            "INFO:tensorflow:loss = 0.0068417303, step = 2901 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.191\n",
            "INFO:tensorflow:loss = 0.0083650425, step = 3001 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.053\n",
            "INFO:tensorflow:loss = 0.005891314, step = 3101 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.402\n",
            "INFO:tensorflow:loss = 0.0073317527, step = 3201 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 792.494\n",
            "INFO:tensorflow:loss = 0.00620248, step = 3301 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 774.061\n",
            "INFO:tensorflow:loss = 0.0084326295, step = 3401 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.734\n",
            "INFO:tensorflow:loss = 0.009049901, step = 3501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.061\n",
            "INFO:tensorflow:loss = 0.0061233398, step = 3601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.806\n",
            "INFO:tensorflow:loss = 0.006067221, step = 3701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.475\n",
            "INFO:tensorflow:loss = 0.005854753, step = 3801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.185\n",
            "INFO:tensorflow:loss = 0.0059032897, step = 3901 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 729.141\n",
            "INFO:tensorflow:loss = 0.0068065533, step = 4001 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.401\n",
            "INFO:tensorflow:loss = 0.008008072, step = 4101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 788.449\n",
            "INFO:tensorflow:loss = 0.0051779924, step = 4201 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 790.293\n",
            "INFO:tensorflow:loss = 0.005235537, step = 4301 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.695\n",
            "INFO:tensorflow:loss = 0.0067226123, step = 4401 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 794.43\n",
            "INFO:tensorflow:loss = 0.0076974332, step = 4501 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.549\n",
            "INFO:tensorflow:loss = 0.0072712135, step = 4601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.431\n",
            "INFO:tensorflow:loss = 0.006950234, step = 4701 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 775.501\n",
            "INFO:tensorflow:loss = 0.006682454, step = 4801 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 751.537\n",
            "INFO:tensorflow:loss = 0.0075197644, step = 4901 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.714\n",
            "INFO:tensorflow:loss = 0.008675145, step = 5001 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.078\n",
            "INFO:tensorflow:loss = 0.008781816, step = 5101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.529\n",
            "INFO:tensorflow:loss = 0.007178896, step = 5201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.706\n",
            "INFO:tensorflow:loss = 0.0064572757, step = 5301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 705.533\n",
            "INFO:tensorflow:loss = 0.0048701763, step = 5401 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.061\n",
            "INFO:tensorflow:loss = 0.0056445585, step = 5501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 752.886\n",
            "INFO:tensorflow:loss = 0.004679214, step = 5601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.283\n",
            "INFO:tensorflow:loss = 0.0065129786, step = 5701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.841\n",
            "INFO:tensorflow:loss = 0.00816129, step = 5801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 789.411\n",
            "INFO:tensorflow:loss = 0.00916107, step = 5901 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.034\n",
            "INFO:tensorflow:loss = 0.006169971, step = 6001 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 785.197\n",
            "INFO:tensorflow:loss = 0.0053570108, step = 6101 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.179\n",
            "INFO:tensorflow:loss = 0.0067909528, step = 6201 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.192\n",
            "INFO:tensorflow:loss = 0.0079180105, step = 6301 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 791.059\n",
            "INFO:tensorflow:loss = 0.007313135, step = 6401 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 794.058\n",
            "INFO:tensorflow:loss = 0.008182682, step = 6501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.186\n",
            "INFO:tensorflow:loss = 0.0057457527, step = 6601 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.871\n",
            "INFO:tensorflow:loss = 0.009332962, step = 6701 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.575\n",
            "INFO:tensorflow:loss = 0.004983102, step = 6801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.042\n",
            "INFO:tensorflow:loss = 0.0070657404, step = 6901 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.467\n",
            "INFO:tensorflow:loss = 0.006353494, step = 7001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.209\n",
            "INFO:tensorflow:loss = 0.006096108, step = 7101 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 750.296\n",
            "INFO:tensorflow:loss = 0.007504399, step = 7201 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.571\n",
            "INFO:tensorflow:loss = 0.006361652, step = 7301 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 772.009\n",
            "INFO:tensorflow:loss = 0.0074365623, step = 7401 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.665\n",
            "INFO:tensorflow:loss = 0.0062454185, step = 7501 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.697\n",
            "INFO:tensorflow:loss = 0.0076758293, step = 7601 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 710.06\n",
            "INFO:tensorflow:loss = 0.0052281683, step = 7701 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 718.054\n",
            "INFO:tensorflow:loss = 0.005865478, step = 7801 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.06\n",
            "INFO:tensorflow:loss = 0.0060072597, step = 7901 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.638\n",
            "INFO:tensorflow:loss = 0.005717426, step = 8001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.988\n",
            "INFO:tensorflow:loss = 0.006591914, step = 8101 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 760.238\n",
            "INFO:tensorflow:loss = 0.0053211963, step = 8201 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.264\n",
            "INFO:tensorflow:loss = 0.006874784, step = 8301 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.04\n",
            "INFO:tensorflow:loss = 0.007064792, step = 8401 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 770.445\n",
            "INFO:tensorflow:loss = 0.006961857, step = 8501 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.164\n",
            "INFO:tensorflow:loss = 0.006254699, step = 8601 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 784.655\n",
            "INFO:tensorflow:loss = 0.0059917914, step = 8701 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 786.07\n",
            "INFO:tensorflow:loss = 0.005850648, step = 8801 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.6\n",
            "INFO:tensorflow:loss = 0.007045309, step = 8901 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.716\n",
            "INFO:tensorflow:loss = 0.0060406034, step = 9001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 836.287\n",
            "INFO:tensorflow:loss = 0.0068637263, step = 9101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 770.82\n",
            "INFO:tensorflow:loss = 0.006374861, step = 9201 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.675\n",
            "INFO:tensorflow:loss = 0.0072171343, step = 9301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.324\n",
            "INFO:tensorflow:loss = 0.0061317505, step = 9401 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.461\n",
            "INFO:tensorflow:loss = 0.0062216986, step = 9501 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.607\n",
            "INFO:tensorflow:loss = 0.006983169, step = 9601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 783.155\n",
            "INFO:tensorflow:loss = 0.0076330435, step = 9701 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.71\n",
            "INFO:tensorflow:loss = 0.0062445304, step = 9801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.485\n",
            "INFO:tensorflow:loss = 0.0074864775, step = 9901 (0.119 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_visib/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.005660077.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 93.30438690969395\n",
            "Just using average = 600.527397260274 has RMSE of 97.94271362023213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#testd = pd.DataFrame.from_records(predictors[trainsize:].values,columns=['day','year','month','da','prcp','fog','rain','snow','hail'])\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "0ZA56JV3Wgr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72167a8a-32f9-49ec-90fe-fa0f322f26d7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184612150>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "512\n",
            "[0.51203763 0.56929165 0.49971002 0.53724235 0.5331647  0.4596194\n",
            " 0.5065841  0.5196762  0.4785367  0.50867176 0.5652723  0.4853061\n",
            " 0.52714485 0.5508507  0.5110668  0.49564546 0.5065315  0.4916242\n",
            " 0.51037836 0.5458444  0.5211129  0.48834977 0.5527546  0.50391304\n",
            " 0.5037089  0.49517938 0.5110578  0.5189451  0.5335094  0.5112895\n",
            " 0.4963031  0.5103712  0.5012339  0.53205377 0.5731611  0.55361545\n",
            " 0.55337316 0.50122494 0.5149181  0.49802685 0.5079251  0.48917392\n",
            " 0.51711273 0.5218819  0.4799218  0.5363916  0.49335063 0.5628964\n",
            " 0.5526853  0.47750828 0.48871735 0.4885171  0.5009921  0.52025706\n",
            " 0.49132308 0.5235904  0.5267433  0.50128156 0.5249217  0.4807761\n",
            " 0.51871735 0.54851705 0.46648568 0.51754755 0.51672596 0.4948084\n",
            " 0.4541079  0.55862695 0.50122607 0.5371028  0.4885851  0.563091\n",
            " 0.45256427 0.5198303  0.51368785 0.50315446 0.52299356 0.55308145\n",
            " 0.49334005 0.5486676  0.45334056 0.46320236 0.51783854 0.5497701\n",
            " 0.5620634  0.5276797  0.5162332  0.5170213  0.4965934  0.53592235\n",
            " 0.5566871  0.5105881  0.563803   0.55293685 0.52336955 0.48582587\n",
            " 0.51315135 0.47224262 0.4823065  0.51875395 0.49169073 0.5514865\n",
            " 0.51816535 0.50808233 0.491865   0.55566555 0.55633783 0.51450694\n",
            " 0.50135505 0.5012591  0.49317792 0.551061   0.5658793  0.55414444\n",
            " 0.5155473  0.46498403 0.55153966 0.50015885 0.47565606 0.49800155\n",
            " 0.578818   0.53191113 0.50613534 0.5206934  0.49257863 0.53193104\n",
            " 0.46980837 0.54089    0.4871836  0.53007376 0.52011    0.48947325\n",
            " 0.49949697 0.5154014  0.5261102  0.5490378  0.51382244 0.53601146\n",
            " 0.5584137  0.48373464 0.50698495 0.4938628  0.5300925  0.49796495\n",
            " 0.49174026 0.4993398  0.4995988  0.5536746  0.5571887  0.54920846\n",
            " 0.48107013 0.55720943 0.46793702 0.53099257 0.51655924 0.5699312\n",
            " 0.50404847 0.47838575 0.4824796  0.5429521  0.4935901  0.49431852\n",
            " 0.5035002  0.53430915 0.49497446 0.46307224 0.570035   0.52547437\n",
            " 0.48468342 0.55058837 0.46326745 0.5098612  0.49552485 0.5073505\n",
            " 0.47267255 0.50138384 0.5319164  0.45051166 0.47994125 0.50012887\n",
            " 0.49941906 0.5155849  0.44074023 0.46722537 0.54359967 0.52249813\n",
            " 0.53160965 0.52940446 0.5293143  0.47087136 0.48063937 0.46867552\n",
            " 0.48740256 0.50502515 0.5681491  0.50606155 0.51032704 0.47822657\n",
            " 0.5235557  0.48232892 0.5278218  0.4640812  0.5258037  0.5198077\n",
            " 0.44836193 0.4886846  0.46314472 0.48830846 0.5425115  0.5543131\n",
            " 0.48832956 0.5145724  0.5374341  0.4797099  0.49296904 0.48360503\n",
            " 0.48214868 0.5426228  0.51071674 0.5520636  0.5221811  0.52544373\n",
            " 0.52054226 0.5372299  0.54572195 0.45395648 0.5176153  0.47973403\n",
            " 0.48807803 0.48999092 0.5213104  0.54021436 0.53049725 0.5225597\n",
            " 0.49072802 0.45141235 0.54984385 0.49504027 0.48088676 0.4486275\n",
            " 0.4779938  0.5337854  0.49110213 0.4927739  0.47270158 0.4822699\n",
            " 0.46934178 0.5466148  0.48725018 0.48122966 0.5648721  0.4724256\n",
            " 0.53544664 0.5025251  0.5232479  0.5143011  0.45641416 0.47064862\n",
            " 0.5425929  0.48407462 0.5479373  0.54259753 0.53314245 0.5113878\n",
            " 0.4489989  0.5024516  0.5442611  0.51345533 0.52938354 0.5044102\n",
            " 0.52247894 0.50150317 0.48208293 0.48723796 0.49616152 0.5014949\n",
            " 0.5245498  0.5302125  0.5191029  0.47947297 0.5296931  0.5254648\n",
            " 0.55208594 0.4973616  0.49274006 0.55382985 0.49288762 0.5239713\n",
            " 0.46678516 0.53049195 0.49822307 0.47138837 0.45245442 0.5107868\n",
            " 0.50967336 0.51412356 0.5404622  0.55086976 0.4554987  0.47619858\n",
            " 0.49403366 0.47803056 0.5430428  0.5135534  0.48211947 0.4667766\n",
            " 0.5655517  0.5336911  0.5357829  0.47171584 0.55513084 0.5526431\n",
            " 0.5576662  0.5411068  0.45632586 0.4563072  0.57327    0.5292376\n",
            " 0.5062609  0.5491694  0.4871065  0.534338   0.5081734  0.48764\n",
            " 0.48792335 0.4843757  0.47468254 0.52206737 0.5268236  0.47610208\n",
            " 0.5240242  0.5492452  0.50368404 0.48352423 0.4799802  0.49996763\n",
            " 0.46597046 0.49036238 0.5666378  0.49638444 0.5074466  0.46270415\n",
            " 0.48136112 0.4758108  0.5235155  0.49640444 0.51379    0.48140898\n",
            " 0.4676461  0.49287635 0.52218056 0.47969475 0.53724265 0.48479518\n",
            " 0.54235435 0.5286229  0.56015503 0.5640686  0.50607014 0.4864616\n",
            " 0.5415367  0.45769194 0.5406648  0.50153434 0.46600893 0.49917182\n",
            " 0.54217404 0.48631123 0.53731984 0.4965237  0.553581   0.53486574\n",
            " 0.49782687 0.46552163 0.55319905 0.4964117  0.56330854 0.4926615\n",
            " 0.51511705 0.48973575 0.4967141  0.48210993 0.51153046 0.5109704\n",
            " 0.4943364  0.5356155  0.49062067 0.4976307  0.48123565 0.5287177\n",
            " 0.49430063 0.5072946  0.4548225  0.5685027  0.5259524  0.5689447\n",
            " 0.51863515 0.4482999  0.5460699  0.55600023 0.50036025 0.4563296\n",
            " 0.51556146 0.5320023  0.48996744 0.5343272  0.5649458  0.474057\n",
            " 0.49863395 0.46554935 0.5645336  0.46571788 0.5666088  0.5789059\n",
            " 0.5401667  0.5296164  0.5146444  0.45189115 0.57826686 0.5016073\n",
            " 0.5095208  0.5079355  0.5300477  0.48728096 0.51518667 0.48901603\n",
            " 0.48796287 0.5288336  0.53894687 0.5487506  0.5612592  0.501364\n",
            " 0.51073927 0.46960196 0.556449   0.5202604  0.54774296 0.5692953\n",
            " 0.52173144 0.51299495 0.5298965  0.5051066  0.45415542 0.5001797\n",
            " 0.5121589  0.5336395  0.57799226 0.4705132  0.5320099  0.5325722\n",
            " 0.53573096 0.48033637 0.52798545 0.5199958  0.5570687  0.5090936\n",
            " 0.49672198 0.4827074  0.49782825 0.4813657  0.5661708  0.49347243\n",
            " 0.49477854 0.49764082 0.47963157 0.49664918 0.51382184 0.5185517\n",
            " 0.5445689  0.5026472  0.568777   0.5617079  0.5379524  0.4526008\n",
            " 0.5111724  0.53365076 0.49925292 0.54698473 0.5085913  0.5220064\n",
            " 0.5150931  0.48557082 0.5057786  0.48328775 0.48108152 0.51851517\n",
            " 0.4776791  0.5023244  0.52025205 0.5065323  0.50280696 0.55804324\n",
            " 0.4710859  0.4891558  0.54744977 0.4538277  0.5630176  0.4638695\n",
            " 0.46452093 0.47020063 0.552427   0.51125765 0.57834744 0.45675597\n",
            " 0.52849644 0.44996372 0.50651455 0.544172   0.48511028 0.48059615\n",
            " 0.5005361  0.48237407]\n",
            "[0.60206718 0.34453058 0.4918174  0.48148148 0.51248923 0.39793282\n",
            " 0.64341085 0.53402239 0.53660637 0.51248923 0.35400517 0.5245478\n",
            " 0.58397933 0.51507321 0.43238587 0.49009475 0.5211025  0.5960379\n",
            " 0.52540913 0.53919035 0.51765719 0.59431525 0.53660637 0.48664944\n",
            " 0.3875969  0.48751077 0.60551249 0.59431525 0.5374677  0.40568475\n",
            " 0.66838932 0.58570198 0.4005168  0.6124031  0.28682171 0.49095607\n",
            " 0.58914729 0.40913006 0.56244617 0.53574505 0.5081826  0.34797588\n",
            " 0.5503876  0.5081826  0.39793282 0.51248923 0.49354005 0.64427218\n",
            " 0.61929371 0.45478036 0.44702842 0.54349699 0.64082687 0.70801034\n",
            " 0.55124892 0.44875108 0.53660637 0.47028424 0.55727821 0.57278208\n",
            " 0.48578811 0.69250646 0.45305771 0.5667528  0.60120586 0.41343669\n",
            " 0.39362618 0.52196382 0.53919035 0.54091301 0.44444444 0.52282515\n",
            " 0.43238587 0.53919035 0.55813953 0.54263566 0.52196382 0.64771748\n",
            " 0.36175711 0.35228252 0.42118863 0.41085271 0.31007752 0.51248923\n",
            " 0.56416882 0.34625323 0.51507321 0.61412575 0.33936262 0.61670973\n",
            " 0.67700258 0.54349699 0.50387597 0.59862188 0.60809647 0.45305771\n",
            " 0.59517657 0.40999139 0.43066322 0.57795004 0.4203273  0.63996555\n",
            " 0.59431525 0.58225668 0.57536606 0.60378984 0.6089578  0.62790698\n",
            " 0.34969854 0.52885444 0.52971576 0.46942291 0.36089578 0.6287683\n",
            " 0.55555556 0.47372954 0.43927649 0.46770026 0.51851852 0.54177433\n",
            " 0.47286822 0.48062016 0.65374677 0.48148148 0.50904393 0.56330749\n",
            " 0.42635659 0.31955211 0.62618432 0.47717485 0.70542636 0.54694229\n",
            " 0.60120586 0.56158484 0.46942291 0.56761413 0.54005168 0.5503876\n",
            " 0.55986219 0.47631352 0.57019811 0.47631352 0.4625323  0.50387597\n",
            " 0.48062016 0.61068045 0.57708872 0.48837209 0.53057709 0.52799311\n",
            " 0.6089578  0.54952627 0.56847545 0.50990525 0.59862188 0.60292851\n",
            " 0.41946598 0.39879414 0.51593454 0.37898363 0.40568475 0.58053402\n",
            " 0.38845823 0.59259259 0.49870801 0.43496985 0.58914729 0.48923342\n",
            " 0.374677   0.47028424 0.50732127 0.45219638 0.625323   0.57536606\n",
            " 0.47200689 0.43238587 0.57795004 0.36950904 0.55297158 0.625323\n",
            " 0.52799311 0.46856158 0.36864772 0.45219638 0.52368648 0.60809647\n",
            " 0.46683893 0.57881137 0.57622739 0.41429802 0.51851852 0.39534884\n",
            " 0.41343669 0.50645995 0.4952627  0.45219638 0.63996555 0.44702842\n",
            " 0.59431525 0.51679587 0.57450474 0.37553833 0.47631352 0.55211025\n",
            " 0.41774332 0.59000861 0.44875108 0.4754522  0.50990525 0.60981912\n",
            " 0.36606374 0.51593454 0.63738157 0.41774332 0.49095607 0.80878553\n",
            " 0.4332472  0.58570198 0.55555556 0.43583118 0.60120586 0.56072351\n",
            " 0.52282515 0.49784668 0.56330749 0.39793282 0.53919035 0.54866494\n",
            " 0.43496985 0.30060293 0.62015504 0.55986219 0.4496124  0.41429802\n",
            " 0.4461671  0.45305771 0.5667528  0.41343669 0.46511628 0.38329027\n",
            " 0.40999139 0.5667528  0.47114556 0.65030146 0.40223945 0.40740741\n",
            " 0.57450474 0.54866494 0.43238587 0.45391904 0.45908699 0.52713178\n",
            " 0.53057709 0.55900086 0.54091301 0.46511628 0.34969854 0.48492679\n",
            " 0.59086994 0.45305771 0.63738157 0.62101637 0.44186047 0.44358312\n",
            " 0.38845823 0.52713178 0.58225668 0.57622739 0.5667528  0.55555556\n",
            " 0.52971576 0.47459087 0.47286822 0.38242894 0.43669251 0.50387597\n",
            " 0.47459087 0.53057709 0.48492679 0.4788975  0.5211025  0.43755383\n",
            " 0.52196382 0.44875108 0.47975883 0.53143842 0.34797588 0.36950904\n",
            " 0.583118   0.47631352 0.54177433 0.37639966 0.42291128 0.68561585\n",
            " 0.54177433 0.68217054 0.59862188 0.4918174  0.33936262 0.49267873\n",
            " 0.51076658 0.38501292 0.51679587 0.36606374 0.5994832  0.40310078\n",
            " 0.3712317  0.53316107 0.37295435 0.42894057 0.55727821 0.63135228\n",
            " 0.36778639 0.52799311 0.47717485 0.38845823 0.53402239 0.61757106\n",
            " 0.57364341 0.42549526 0.51421189 0.56072351 0.52713178 0.47114556\n",
            " 0.60292851 0.42549526 0.43583118 0.65719208 0.46683893 0.52282515\n",
            " 0.4039621  0.50732127 0.5211025  0.49956934 0.45908699 0.55986219\n",
            " 0.42807924 0.43496985 0.33763997 0.42377261 0.44186047 0.47803618\n",
            " 0.63135228 0.48492679 0.59345392 0.45736434 0.53488372 0.45478036\n",
            " 0.48492679 0.59776055 0.51679587 0.50387597 0.55469423 0.50990525\n",
            " 0.55641688 0.35486649 0.5503876  0.62446167 0.48837209 0.43066322\n",
            " 0.60809647 0.33419466 0.62962963 0.50387597 0.60723514 0.44013781\n",
            " 0.6709733  0.57192076 0.46683893 0.52971576 0.52885444 0.53574505\n",
            " 0.33936262 0.40826873 0.60034453 0.64857881 0.39276486 0.53316107\n",
            " 0.54091301 0.54349699 0.43238587 0.47372954 0.66925065 0.54952627\n",
            " 0.60292851 0.6124031  0.58484065 0.54521964 0.55900086 0.69853575\n",
            " 0.53057709 0.53229974 0.39965547 0.52713178 0.60809647 0.55555556\n",
            " 0.54435831 0.36434109 0.26098191 0.53402239 0.4754522  0.59689922\n",
            " 0.56416882 0.59173127 0.4918174  0.58139535 0.53832903 0.49440138\n",
            " 0.58742463 0.49784668 0.42807924 0.55555556 0.60637382 0.62187769\n",
            " 0.66063738 0.51507321 0.5503876  0.26614987 0.5503876  0.50904393\n",
            " 0.52885444 0.44530577 0.57105943 0.45822567 0.50387597 0.44358312\n",
            " 0.56158484 0.58828596 0.5667528  0.55900086 0.55727821 0.50043066\n",
            " 0.583118   0.51851852 0.55297158 0.60809647 0.55900086 0.56072351\n",
            " 0.38673557 0.57278208 0.53229974 0.56244617 0.40482343 0.45822567\n",
            " 0.51937984 0.54608096 0.55469423 0.38845823 0.48406546 0.47717485\n",
            " 0.50129199 0.60981912 0.56158484 0.52971576 0.52627046 0.72782084\n",
            " 0.50559862 0.59259259 0.59431525 0.47459087 0.53660637 0.51335056\n",
            " 0.4788975  0.47975883 0.60809647 0.53574505 0.60034453 0.6546081\n",
            " 0.56158484 0.61412575 0.56416882 0.54694229 0.55641688 0.4005168\n",
            " 0.63910422 0.45564169 0.61154177 0.57019811 0.57536606 0.49267873\n",
            " 0.55727821 0.44272179 0.57019811 0.44358312 0.41602067 0.5796727\n",
            " 0.45650301 0.41860465 0.60551249 0.63738157 0.54091301 0.45822567\n",
            " 0.44272179 0.55297158 0.43583118 0.43927649 0.53229974 0.3910422\n",
            " 0.49784668 0.60551249 0.56933678 0.54780362 0.63479759 0.416882\n",
            " 0.32213609 0.39534884 0.41085271 0.46770026 0.52024117 0.51765719\n",
            " 0.50215332 0.44358312]\n",
            "The trained model has an aproximate error rate of 0.4050294426851904 which equates to 0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'day' : [1,1,1,10],\n",
        "         'year' : [2019,2019,2019,2020],\n",
        "         'mo' : [3,3,3,12],\n",
        "         'da' : [10,10,10,12],\n",
        "         'visib' : [1,5,9.5,5],\n",
        "         \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3081032f-f2a7-47bd-8628-dab3cb3a43c9",
        "id": "us9wEUCuHvZj"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21848b7d90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[648.7901  633.99225 617.3446  546.5106 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the difference RMSE between the mean and the model is less, it is arguable that the model is not as accurate.\n",
        "\n",
        "Although the RMSE value indicates a weaker model, the error rate is lower indicating that there is a significant error increasing the RMSE."
      ],
      "metadata": {
        "id": "ntCQ4Pkefi3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Neural Network (DNN)\n",
        "Although the primary outcome of assignment 1 was uncovering linear relationships, more complex relationships which cannot be predicted using a linear regressor were uncovered. In this case a Deep Learning Neural Network (DNN) can be used.\n",
        "\n",
        "A Deep Learning Neural Network (DNN) is a form of unsupervised learning, where a number of hidden layers are used to uncover non-linear relationships. Karhunen, Raiko and Cho (2015) infer that deep learning neural networks work in a similar way to the human brain. This is where both the relationship between the input and output data is explored, as well as the relationship between the underlying data."
      ],
      "metadata": {
        "id": "xIvme6cXJF9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precipitation (prcp)\n",
        "The process for training a DNN follows a similar process followed above for a Linear Regressor. The data cleansed and one hot encoded as part of assignment 1 is loaded from GitHub."
      ],
      "metadata": {
        "id": "cixnwflQxNZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean_dnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "F9YrBdhTYhyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287766bb-f10b-42f3-93c7-6b2a21dd5921"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_prcp_dnn = df.drop(columns=['temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp_dnn = df_prcp_dnn.loc[df_prcp_dnn[\"year\"] != 2012]\n",
        "df_prcp_dnn = df_prcp_dnn.loc[df_prcp_dnn[\"year\"] < 2020]\n",
        "#Move target to the end\n",
        "cols = df_prcp_dnn['NUM_COLLISIONS']\n",
        "df_prcp_dnn = df_prcp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_prcp_dnn.insert(loc=26, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp_dnn[:6])\n",
        "df_prcp_dnn.describe()"
      ],
      "metadata": {
        "id": "jw5elr-LbRBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "05f4bde6-ece7-42ee-d404-e346e115c915"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  Apr  Aug  Dec  \\\n",
            "49  2016  28  0.09    0             0                 0     0    0    0    0   \n",
            "51  2014  17  0.00    1             0                 0     0    0    0    0   \n",
            "54  2016  25  0.02    0             0                 0     0    0    0    0   \n",
            "55  2016  29  0.00    0             0                 0     0    0    0    0   \n",
            "58  2017  20  0.00    0             0                 0     0    0    0    0   \n",
            "59  2013  13  0.01    1             0                 0     0    0    0    0   \n",
            "\n",
            "    ...  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49  ...    0    0    0    0    0    0    0    0    1             681  \n",
            "51  ...    0    0    0    0    0    0    1    0    0             589  \n",
            "54  ...    0    0    0    0    0    1    0    0    0             658  \n",
            "55  ...    0    0    0    0    0    0    1    0    0             645  \n",
            "58  ...    0    0    0    0    0    0    1    0    0             605  \n",
            "59  ...    0    0    0    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 27 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da         prcp          fog  rain_drizzle  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000   2539.000000   \n",
              "mean   2015.989366    15.745569     0.122588     0.253249      0.375345   \n",
              "std       1.996126     8.803199     0.329143     0.434958      0.484307   \n",
              "min    2013.000000     1.000000     0.000000     0.000000      0.000000   \n",
              "25%    2014.000000     8.000000     0.000000     0.000000      0.000000   \n",
              "50%    2016.000000    16.000000     0.000000     0.000000      0.000000   \n",
              "75%    2018.000000    23.000000     0.060000     1.000000      1.000000   \n",
              "max    2019.000000    31.000000     3.760000     1.000000      1.000000   \n",
              "\n",
              "       snow_ice_pellets         hail          Apr          Aug          Dec  \\\n",
              "count       2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean           0.085467     0.000394     0.082316     0.083497     0.085467   \n",
              "std            0.279630     0.019846     0.274899     0.276687     0.279630   \n",
              "min            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max            1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "       ...          Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  ...  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean   ...     0.085467     0.079953     0.142970     0.142970     0.143364   \n",
              "std    ...     0.279630     0.271273     0.350111     0.350111     0.350512   \n",
              "min    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max    ...     1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000     2539.000000  \n",
              "mean      0.143757     0.142182     0.142576     0.142182      599.135093  \n",
              "std       0.350913     0.349305     0.349709     0.349305      100.299164  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42e298dd-ce94-43fe-b635-046b18e8c2a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.989366</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.082316</td>\n",
              "      <td>0.083497</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.079953</td>\n",
              "      <td>0.142970</td>\n",
              "      <td>0.142970</td>\n",
              "      <td>0.143364</td>\n",
              "      <td>0.143757</td>\n",
              "      <td>0.142182</td>\n",
              "      <td>0.142576</td>\n",
              "      <td>0.142182</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.996126</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>0.274899</td>\n",
              "      <td>0.276687</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.271273</td>\n",
              "      <td>0.350111</td>\n",
              "      <td>0.350111</td>\n",
              "      <td>0.350512</td>\n",
              "      <td>0.350913</td>\n",
              "      <td>0.349305</td>\n",
              "      <td>0.349709</td>\n",
              "      <td>0.349305</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42e298dd-ce94-43fe-b635-046b18e8c2a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42e298dd-ce94-43fe-b635-046b18e8c2a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42e298dd-ce94-43fe-b635-046b18e8c2a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "shuffle = df_prcp_dnn.iloc[np.random.permutation(len(df_prcp_dnn))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "rpJi3P_8YcIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623cd6a0-a1c1-4185-eca3-96c32270106c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  Apr  Aug  \\\n",
            "3308  2019  30  0.00    0             0                 0     0    0    0   \n",
            "1460  2018  25  0.00    1             0                 0     0    0    0   \n",
            "638   2015   1  0.00    0             0                 1     0    0    0   \n",
            "279   2013  31  0.02    1             1                 0     0    0    0   \n",
            "1007  2014   4  0.00    0             0                 0     0    1    0   \n",
            "3447  2017   4  0.00    0             0                 0     0    0    0   \n",
            "\n",
            "      Dec  ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "3308    0  ...    1    0    0    1    0    0    0    0    0    0  \n",
            "1460    0  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "638     0  ...    0    0    0    0    0    1    0    0    0    0  \n",
            "279     0  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "1007    0  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "3447    1  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select target as last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "a_A0EFvxZpeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d403bc4e-93f9-44b4-a04d-78d304d2885b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3308    465\n",
            "1460    799\n",
            "638     693\n",
            "279     592\n",
            "1007    622\n",
            "3447    684\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "noutputs = 1\n",
        "# calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "bdO_kvOZZuii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097b3880-5b87-4f54-ecc6-3caab929b91b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between the training of a DNN and linear regression model, is the addition of hidden layers. In order to optimise the trained model, the number of hidden layers, the number of nodes within each layer and the learning rate were all modified."
      ],
      "metadata": {
        "id": "XTeNjj2Rp1Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_prcp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#Test model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "GaTuIaPRfMxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d52aa88-badb-43c4-c4c3-e2ea7de5d588"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2186e71cd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:loss = 28197.518, step = 1\n",
            "INFO:tensorflow:global_step/sec: 368.348\n",
            "INFO:tensorflow:loss = 0.058571868, step = 101 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.723\n",
            "INFO:tensorflow:loss = 0.018285077, step = 201 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.143\n",
            "INFO:tensorflow:loss = 0.015707014, step = 301 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.757\n",
            "INFO:tensorflow:loss = 0.013750879, step = 401 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.117\n",
            "INFO:tensorflow:loss = 0.012924065, step = 501 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.161\n",
            "INFO:tensorflow:loss = 0.010729466, step = 601 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.617\n",
            "INFO:tensorflow:loss = 0.009711044, step = 701 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.619\n",
            "INFO:tensorflow:loss = 0.009850172, step = 801 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.77\n",
            "INFO:tensorflow:loss = 0.010669984, step = 901 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.049\n",
            "INFO:tensorflow:loss = 0.009647443, step = 1001 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.124\n",
            "INFO:tensorflow:loss = 0.010369648, step = 1101 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.522\n",
            "INFO:tensorflow:loss = 0.006390795, step = 1201 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.03\n",
            "INFO:tensorflow:loss = 0.008498821, step = 1301 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.219\n",
            "INFO:tensorflow:loss = 0.0070004025, step = 1401 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.197\n",
            "INFO:tensorflow:loss = 0.006544087, step = 1501 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.325\n",
            "INFO:tensorflow:loss = 0.0050424784, step = 1601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.648\n",
            "INFO:tensorflow:loss = 0.0061235684, step = 1701 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.724\n",
            "INFO:tensorflow:loss = 0.005112189, step = 1801 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.093\n",
            "INFO:tensorflow:loss = 0.009180754, step = 1901 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.63\n",
            "INFO:tensorflow:loss = 0.0075571644, step = 2001 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.722\n",
            "INFO:tensorflow:loss = 0.0057880348, step = 2101 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.202\n",
            "INFO:tensorflow:loss = 0.0068227462, step = 2201 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.646\n",
            "INFO:tensorflow:loss = 0.003893372, step = 2301 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.843\n",
            "INFO:tensorflow:loss = 0.0048379116, step = 2401 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.471\n",
            "INFO:tensorflow:loss = 0.0055139516, step = 2501 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.483\n",
            "INFO:tensorflow:loss = 0.007057158, step = 2601 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.945\n",
            "INFO:tensorflow:loss = 0.0056810966, step = 2701 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.195\n",
            "INFO:tensorflow:loss = 0.00795025, step = 2801 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.255\n",
            "INFO:tensorflow:loss = 0.005440796, step = 2901 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.293\n",
            "INFO:tensorflow:loss = 0.0058566327, step = 3001 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.133\n",
            "INFO:tensorflow:loss = 0.003320374, step = 3101 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.031\n",
            "INFO:tensorflow:loss = 0.003785471, step = 3201 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.177\n",
            "INFO:tensorflow:loss = 0.0049930634, step = 3301 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.024\n",
            "INFO:tensorflow:loss = 0.00638594, step = 3401 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.823\n",
            "INFO:tensorflow:loss = 0.006061405, step = 3501 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.662\n",
            "INFO:tensorflow:loss = 0.011623897, step = 3601 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.937\n",
            "INFO:tensorflow:loss = 0.0078372955, step = 3701 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.231\n",
            "INFO:tensorflow:loss = 0.012285264, step = 3801 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.297\n",
            "INFO:tensorflow:loss = 0.25630695, step = 3901 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.776\n",
            "INFO:tensorflow:loss = 0.00989804, step = 4001 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.924\n",
            "INFO:tensorflow:loss = 0.50555074, step = 4101 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.494\n",
            "INFO:tensorflow:loss = 0.003448948, step = 4201 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.752\n",
            "INFO:tensorflow:loss = 0.02044304, step = 4301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.469\n",
            "INFO:tensorflow:loss = 0.06204996, step = 4401 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.824\n",
            "INFO:tensorflow:loss = 0.011593249, step = 4501 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.383\n",
            "INFO:tensorflow:loss = 0.023909668, step = 4601 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.066\n",
            "INFO:tensorflow:loss = 0.004419298, step = 4701 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.811\n",
            "INFO:tensorflow:loss = 0.04099662, step = 4801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.584\n",
            "INFO:tensorflow:loss = 0.007290703, step = 4901 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.965\n",
            "INFO:tensorflow:loss = 0.009256976, step = 5001 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.943\n",
            "INFO:tensorflow:loss = 0.27460814, step = 5101 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.715\n",
            "INFO:tensorflow:loss = 0.048207626, step = 5201 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.255\n",
            "INFO:tensorflow:loss = 0.00494378, step = 5301 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.903\n",
            "INFO:tensorflow:loss = 0.072196424, step = 5401 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.326\n",
            "INFO:tensorflow:loss = 0.008037421, step = 5501 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.31\n",
            "INFO:tensorflow:loss = 0.0048041353, step = 5601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.094\n",
            "INFO:tensorflow:loss = 0.0063660005, step = 5701 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.159\n",
            "INFO:tensorflow:loss = 0.011139707, step = 5801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.753\n",
            "INFO:tensorflow:loss = 0.015475281, step = 5901 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.261\n",
            "INFO:tensorflow:loss = 0.014230383, step = 6001 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.858\n",
            "INFO:tensorflow:loss = 0.01657064, step = 6101 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.62\n",
            "INFO:tensorflow:loss = 0.007975213, step = 6201 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 487.086\n",
            "INFO:tensorflow:loss = 0.08392891, step = 6301 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.639\n",
            "INFO:tensorflow:loss = 0.043169055, step = 6401 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.487\n",
            "INFO:tensorflow:loss = 0.1166074, step = 6501 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.542\n",
            "INFO:tensorflow:loss = 0.021797298, step = 6601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.583\n",
            "INFO:tensorflow:loss = 0.0062131486, step = 6701 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.057\n",
            "INFO:tensorflow:loss = 0.019553067, step = 6801 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.345\n",
            "INFO:tensorflow:loss = 0.005939351, step = 6901 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.977\n",
            "INFO:tensorflow:loss = 0.016480949, step = 7001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.25\n",
            "INFO:tensorflow:loss = 0.01140381, step = 7101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.88\n",
            "INFO:tensorflow:loss = 0.0077559426, step = 7201 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.7\n",
            "INFO:tensorflow:loss = 0.024156483, step = 7301 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.494\n",
            "INFO:tensorflow:loss = 0.010573729, step = 7401 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.187\n",
            "INFO:tensorflow:loss = 0.011884902, step = 7501 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.585\n",
            "INFO:tensorflow:loss = 0.0060989102, step = 7601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.648\n",
            "INFO:tensorflow:loss = 0.041338183, step = 7701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.96\n",
            "INFO:tensorflow:loss = 0.0038009183, step = 7801 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.771\n",
            "INFO:tensorflow:loss = 0.012467199, step = 7901 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.265\n",
            "INFO:tensorflow:loss = 0.016011447, step = 8001 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.818\n",
            "INFO:tensorflow:loss = 0.0063640857, step = 8101 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.329\n",
            "INFO:tensorflow:loss = 0.0139763905, step = 8201 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.941\n",
            "INFO:tensorflow:loss = 0.005744415, step = 8301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 493\n",
            "INFO:tensorflow:loss = 0.007665877, step = 8401 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.578\n",
            "INFO:tensorflow:loss = 0.016970487, step = 8501 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.964\n",
            "INFO:tensorflow:loss = 0.026326392, step = 8601 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.952\n",
            "INFO:tensorflow:loss = 0.0045011393, step = 8701 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.934\n",
            "INFO:tensorflow:loss = 0.004854688, step = 8801 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.102\n",
            "INFO:tensorflow:loss = 0.008144667, step = 8901 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.084\n",
            "INFO:tensorflow:loss = 0.0055252844, step = 9001 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.209\n",
            "INFO:tensorflow:loss = 0.013170288, step = 9101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.586\n",
            "INFO:tensorflow:loss = 0.010704804, step = 9201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.374\n",
            "INFO:tensorflow:loss = 0.0049586426, step = 9301 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.635\n",
            "INFO:tensorflow:loss = 0.005862482, step = 9401 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.887\n",
            "INFO:tensorflow:loss = 0.01035581, step = 9501 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.132\n",
            "INFO:tensorflow:loss = 0.00813574, step = 9601 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.731\n",
            "INFO:tensorflow:loss = 0.0038228408, step = 9701 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.02\n",
            "INFO:tensorflow:loss = 0.019123495, step = 9801 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.675\n",
            "INFO:tensorflow:loss = 11.123209, step = 9901 (0.177 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.030048106.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 213.61763574817323\n",
            "Just using average = 598.4052191038897 has RMSE of 107.25214718599702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "#Ensure hidden layers match the model trained above\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "Ld6baV60hPOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76e71cf-91bb-4bdb-a4cd-9547969789ec"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184cc6ad0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.47063005 0.6991395  0.8176476  0.66398084 0.61244667 0.894935\n",
            " 0.5318612  0.7843565  0.7408217  0.6858996  0.6934792  0.76377094\n",
            " 0.464527   0.28804004 0.62882197 0.58927953 0.82757103 0.7063514\n",
            " 0.82870376 0.21499814 0.3918761  0.5395268  0.6454295  0.23120536\n",
            " 0.6257101  0.34818208 0.6918303  0.47304833 0.8110062  0.41884673\n",
            " 0.7397896  0.7759863  0.55743444 0.8293468  0.35304892 0.5767642\n",
            " 0.7565862  0.61564577 0.6500515  0.23896016 0.5030142  0.45227635\n",
            " 0.23676957 0.64034975 0.38316047 0.7324356  0.4970585  0.3158275\n",
            " 0.44244444 0.71325433 0.30481946 0.4245578  0.3584088  0.49355876\n",
            " 0.77216065 0.45941007 0.6146046  0.47531474 0.43749297 0.40387356\n",
            " 0.7924274  0.34974182 0.74032223 0.77735436 0.6322795  0.39708936\n",
            " 0.6952187  0.16465868 0.5950438  0.77372396 0.44510806 0.15381922\n",
            " 0.46390307 0.44802248 0.48448598 0.3597015  0.5361577  0.47861397\n",
            " 0.22917189 0.49556386 0.82228625 0.2928096  0.65191424 0.5200051\n",
            " 0.54712164 0.22848238 0.37621343 0.46496904 0.32403052 0.33914268\n",
            " 0.22733916 0.5279044  0.31486118 0.24522842 0.78780067 0.24957909\n",
            " 0.5587896  0.49450624 0.42019188 0.59910023 0.7625452  0.3191396\n",
            " 0.6524199  0.8964077  0.31066263 0.86710393 0.35722196 0.17338313\n",
            " 0.32638657 0.5201582  0.50849783 0.77487457 0.42115414 0.76247776\n",
            " 0.3547641  0.5351707  0.49576056 0.67016923 0.1809801  0.16781773\n",
            " 0.58341706 0.25886977 0.87169874 0.3463179  0.36171472 0.49477065\n",
            " 0.6013206  0.30757105 0.7839731  0.5778886  0.5297686  0.19624986\n",
            " 0.4789487  0.36444986 0.27106416 0.3371905  0.6646055  0.61217225\n",
            " 0.68199384 0.21655644 0.7266947  0.51599705 0.8318094  0.82572997\n",
            " 0.5007647  0.5027195  0.5357841  0.42527163 0.8232573  0.67933357\n",
            " 0.6888138  0.25427783 0.85293496 0.48300445 0.4435941  0.41780102\n",
            " 0.24953808 0.27723563 0.608101   0.6358944  0.51739895 0.321025\n",
            " 0.11130823 0.45544684 0.6992663  0.43263257 0.27683032 0.48670256\n",
            " 0.4646653  0.3465358  0.34093106 0.46876824 0.69454396 0.4257754\n",
            " 0.8020314  0.39895308 0.8006445  0.15696229 0.6677984  0.7908803\n",
            " 0.30171812 0.5558311  0.33795583 0.6263603  0.28030026 0.63699543\n",
            " 0.36369884 0.77531326 0.45781147 0.46645463 0.31979287 0.23956193\n",
            " 0.75614965 0.40861166 0.3716904  0.29064643 0.34029615 0.4597479\n",
            " 0.6768445  0.63577306 0.70733917 0.22327389 0.4879681  0.85391176\n",
            " 0.48065913 0.92848384 0.69063795 0.26880968 0.5977639  0.7551044\n",
            " 0.6598636  0.62998164 0.6937002  0.8313335  0.4953984  0.36718285\n",
            " 0.28058064 0.24255337 0.4809364  0.5215131  0.29446924 0.34538782\n",
            " 0.7223681  0.3349017  0.48021472 0.44040143 0.48394597 0.43094456\n",
            " 0.5382     0.18928637 0.28603733 0.2908901  0.2864231  0.2671429\n",
            " 0.6175283  0.48906267 0.72118866 0.38253772 0.30405724 0.50597274\n",
            " 0.16901053 0.55277884 0.55022514 0.344334   0.4945792  0.58390343\n",
            " 0.26065886 0.8591019  0.45549977 0.49665225 0.61225855 0.5726899\n",
            " 0.7662989  0.44235528 0.48105443 0.39014947 0.7702085  0.6525568\n",
            " 0.7753264  0.5943843  0.3186885  0.2668749  0.42217553 0.57059824\n",
            " 0.6901678  0.4561032  0.5739485  0.43050373 0.3729185  0.5160762\n",
            " 0.5481585  0.5630356  0.6441926  0.7525445  0.41836226 0.46743357\n",
            " 0.5867864  0.77929795 0.5658649  0.7259816  0.2191831  0.7985681\n",
            " 0.5627507  0.54268515 0.58715594 0.44431818 0.33439767 0.54671514\n",
            " 0.28953636 0.4193908  0.5983144  0.8347312  0.7670747  0.7560805\n",
            " 0.67471635 0.53984773 0.65004146 0.71012914 0.5940064  0.69023025\n",
            " 0.7600032  0.29926312 0.25846207 0.7697109  0.41336477 0.6811687\n",
            " 0.31431568 0.66781294 0.5490979  0.6143843  0.387977   0.5533024\n",
            " 0.5384141  0.8813077  0.36155617 0.26979363 0.54497397 0.71269214\n",
            " 0.4276942  0.46438777 0.68084157 0.7061199  0.73670304 0.5355245\n",
            " 0.6327678  0.17107548 0.45881927 0.58747184 0.68570817 0.7022873\n",
            " 0.6500639  0.68270314 0.57515943 0.8008231  0.31611693 0.6954664\n",
            " 0.8189992  0.38617957 0.3450011  0.12939943 0.42519534 0.52615464\n",
            " 0.438496   0.43311727 0.6325122  0.3799113  0.3749889  0.1442038\n",
            " 0.4832238  0.31009257 0.485561   0.4147843  0.38959014 0.20768274\n",
            " 0.7595583  0.37015784 0.7453989  0.4298452  0.3793944  0.72174466\n",
            " 0.36865127 0.6822089  0.34926736 0.52176607 0.14538993 0.5065459\n",
            " 0.38940966 0.68131125 0.52431285 0.6286849  0.5717226  0.58958924\n",
            " 0.40687692 0.7061635  0.53885186 0.81542003 0.38239896 0.31326258\n",
            " 0.5669941  0.40266812 0.58910906 0.22243322 0.53622925 0.32194507\n",
            " 0.09203757 0.62680423 0.611724   0.43512762 0.15623106 0.6444782\n",
            " 0.38481867 0.27773082 0.79050887 0.71693695 0.69751585 0.25727737\n",
            " 0.8070673  0.59584033 0.51383436 0.62534654 0.503703   0.7030307\n",
            " 0.70777524 0.6058103  0.48505104 0.5233444  0.47703683 0.35630548\n",
            " 0.577639   0.43880808 0.5308057  0.45375192 0.7780193  0.51360023\n",
            " 0.49368608 0.76587975 0.33258235 0.48264134 0.22334851 0.7096771\n",
            " 0.35957944 0.40789616 0.6349946  0.46581852 0.7983798  0.47676384\n",
            " 0.51178086 0.5126368  0.52852976 0.36382616 0.21873297 0.2636615\n",
            " 0.3988496  0.8050488  0.49670184 0.5693432  0.34277594 0.47114384\n",
            " 0.5438689  0.40643537 0.513693   0.6644243  0.67062557 0.5571207\n",
            " 0.70897543 0.25998533 0.72715175 0.32648575 0.69717443 0.6971792\n",
            " 0.755052   0.55009115 0.48284805 0.31750286 0.61349    0.622553\n",
            " 0.69423354 0.49959767 0.12762894 0.3533908  0.28445137 0.5178026\n",
            " 0.4618832  0.42794025 0.64471114 0.38683903 0.5694932  0.34349525\n",
            " 0.5090567  0.84007704 0.27006423 0.5863637  0.83044946 0.33456767\n",
            " 0.67381227 0.3924061  0.24647917 0.71659815 0.402305   0.29033816\n",
            " 0.6199733  0.5284399  0.67985165 0.28781068 0.46465385 0.34797966\n",
            " 0.48157752 0.6599542  0.59543145 0.60753214 0.45604336 0.41123807\n",
            " 0.33507574 0.42348325 0.77738225 0.73577964 0.13128485 0.33033502\n",
            " 0.6012858  0.31865847 0.3133744  0.7256187  0.3426758  0.79669464\n",
            " 0.3764819  0.25450504 0.77338207 0.566362  ]\n",
            "[0.54263566 0.57364341 0.57278208 0.62704565 0.41946598 0.61154177\n",
            " 0.53402239 0.51507321 0.51076658 0.46597761 0.48751077 0.51765719\n",
            " 0.64427218 0.60206718 0.49956934 0.59345392 0.62704565 0.54694229\n",
            " 0.58139535 0.33419466 0.54349699 0.41343669 0.35228252 0.50559862\n",
            " 0.56761413 0.26098191 0.54091301 0.39190353 0.52971576 0.44875108\n",
            " 0.55555556 0.46511628 0.51937984 0.48062016 0.65030146 0.42721792\n",
            " 0.45908699 0.49784668 0.51937984 0.55900086 0.56158484 0.46942291\n",
            " 0.57795004 0.65030146 0.32213609 0.63393626 0.55727821 0.46339363\n",
            " 0.65891473 0.53057709 0.4625323  0.53660637 0.55297158 0.57364341\n",
            " 0.80878553 0.44444444 0.41515935 0.34625323 0.52971576 0.51162791\n",
            " 0.53229974 0.75107666 0.56158484 0.56416882 0.63307494 0.47459087\n",
            " 0.41860465 0.52799311 0.44186047 0.67700258 0.63049096 0.47803618\n",
            " 0.50215332 0.53660637 0.33850129 0.59086994 0.58484065 0.60206718\n",
            " 0.4461671  0.42980189 0.55900086 0.48751077 0.54435831 0.55469423\n",
            " 0.66063738 0.56589147 0.53919035 0.35486649 0.45650301 0.53402239\n",
            " 0.43927649 0.69595177 0.54349699 0.57881137 0.45822567 0.58828596\n",
            " 0.51593454 0.6416882  0.50990525 0.47286822 0.45822567 0.56761413\n",
            " 0.64427218 0.67355728 0.37984496 0.68217054 0.45822567 0.43152455\n",
            " 0.53660637 0.72265289 0.4952627  0.37726098 0.61929371 0.45564169\n",
            " 0.46942291 0.68303187 0.57881137 0.64341085 0.44099914 0.44444444\n",
            " 0.59173127 0.43496985 0.6124031  0.44788975 0.54349699 0.59431525\n",
            " 0.53057709 0.40913006 0.61929371 0.57536606 0.48837209 0.48664944\n",
            " 0.56589147 0.50990525 0.4039621  0.43927649 0.49870801 0.67786391\n",
            " 0.46942291 0.38156761 0.54263566 0.53574505 0.42291128 0.45133506\n",
            " 0.49698536 0.64082687 0.58914729 0.50559862 0.60378984 0.47803618\n",
            " 0.53919035 0.57708872 0.68044789 0.66666667 0.5374677  0.39793282\n",
            " 0.52885444 0.36606374 0.65374677 0.54177433 0.54780362 0.53574505\n",
            " 0.48492679 0.45478036 0.4754522  0.61929371 0.40913006 0.34797588\n",
            " 0.34969854 0.45822567 0.42204996 0.44186047 0.39362618 0.52713178\n",
            " 0.60723514 0.41085271 0.55469423 0.49009475 0.56933678 0.36434109\n",
            " 0.52971576 0.63049096 0.44358312 0.51076658 0.52799311 0.54349699\n",
            " 0.36175711 0.56847545 0.63049096 0.46511628 0.45305771 0.46511628\n",
            " 0.49354005 0.36950904 0.4332472  0.61584841 0.416882   0.61929371\n",
            " 0.62790698 0.46425495 0.52368648 0.52885444 0.64685616 0.55986219\n",
            " 0.51679587 0.60120586 0.26873385 0.47631352 0.52971576 0.55727821\n",
            " 0.6089578  0.54608096 0.4788975  0.5538329  0.52282515 1.\n",
            " 0.50301464 0.48664944 0.57536606 0.58139535 0.54177433 0.59431525\n",
            " 0.6124031  0.48320413 0.70198105 0.34280792 0.60551249 0.5374677\n",
            " 0.51851852 0.40826873 0.42894057 0.49267873 0.38845823 0.35228252\n",
            " 0.83893196 0.63738157 0.51851852 0.48148148 0.5538329  0.39965547\n",
            " 0.44530577 0.54177433 0.44272179 0.44530577 0.51335056 0.51421189\n",
            " 0.4918174  0.5994832  0.54608096 0.69939707 0.64944014 0.47028424\n",
            " 0.53832903 0.52024117 0.60378984 0.52713178 0.53574505 0.38931955\n",
            " 0.625323   0.43410853 0.53919035 0.38501292 0.56761413 0.36520241\n",
            " 0.47286822 0.60809647 0.45047373 0.55986219 0.47631352 0.61929371\n",
            " 0.60120586 0.62790698 0.50043066 0.5503876  0.40654608 0.35745047\n",
            " 0.51593454 0.60120586 0.49095607 0.45822567 0.44358312 0.50301464\n",
            " 0.44702842 0.48837209 0.5994832  0.42721792 0.54694229 0.56158484\n",
            " 0.49612403 0.50904393 0.52024117 0.57278208 0.53660637 0.54866494\n",
            " 0.52196382 0.53229974 0.56847545 0.59086994 0.42291128 0.40740741\n",
            " 0.43927649 0.5994832  0.49956934 0.34022394 0.43841516 0.53229974\n",
            " 0.57105943 0.54435831 0.52885444 0.63049096 0.55555556 0.41946598\n",
            " 0.58225668 0.66838932 0.43066322 0.6287683  0.56589147 0.65288544\n",
            " 0.51421189 0.48148148 0.51421189 0.50990525 0.47717485 0.63910422\n",
            " 0.45822567 0.39534884 0.4005168  0.2962963  0.49698536 0.68475452\n",
            " 0.56847545 0.45994832 0.4918174  0.50732127 0.44875108 0.48751077\n",
            " 0.55297158 0.45650301 0.46339363 0.39793282 0.51507321 0.51421189\n",
            " 0.54521964 0.41515935 0.55297158 0.44875108 0.5667528  0.48148148\n",
            " 0.4496124  0.53229974 0.60292851 0.39534884 0.60206718 0.40137812\n",
            " 0.56244617 0.35658915 0.58742463 0.57622739 0.47028424 0.54952627\n",
            " 0.71576227 0.47459087 0.46339363 0.4005168  0.47975883 0.5211025\n",
            " 0.72782084 0.51765719 0.59776055 0.5796727  0.45305771 0.44702842\n",
            " 0.53488372 0.56072351 0.70542636 0.59345392 0.57622739 0.53919035\n",
            " 0.63824289 0.63135228 0.55900086 0.41774332 0.47372954 0.46167097\n",
            " 0.42635659 0.54608096 0.43669251 0.4332472  0.37898363 0.5245478\n",
            " 0.41429802 0.55900086 0.33763997 0.55641688 0.65977606 0.51851852\n",
            " 0.44702842 0.53488372 0.56847545 0.46425495 0.51679587 0.55641688\n",
            " 0.47631352 0.53574505 0.60034453 0.63135228 0.49009475 0.52713178\n",
            " 0.35917313 0.66666667 0.27562446 0.55900086 0.33936262 0.52971576\n",
            " 0.5374677  0.52024117 0.38587425 0.62015504 0.37639966 0.56072351\n",
            " 0.53574505 0.58914729 0.49784668 0.37984496 0.62618432 0.60120586\n",
            " 0.46770026 0.52799311 0.58656331 0.42549526 0.31438415 0.47372954\n",
            " 0.36606374 0.63221361 0.67355728 0.37209302 0.52196382 0.45305771\n",
            " 0.68217054 0.52368648 0.6089578  0.59086994 0.47028424 0.53143842\n",
            " 0.58484065 0.5503876  0.45564169 0.4788975  0.56503015 0.50904393\n",
            " 0.49870801 0.69853575 0.48320413 0.48148148 0.55813953 0.53229974\n",
            " 0.60981912 0.55297158 0.34797588 0.63996555 0.43152455 0.53488372\n",
            " 0.52971576 0.43755383 0.56589147 0.69336779 0.47717485 0.49956934\n",
            " 0.57450474 0.63221361 0.43496985 0.51765719 0.4754522  0.52885444\n",
            " 0.59086994 0.60551249 0.34022394 0.4918174  0.36175711 0.37209302\n",
            " 0.63652024 0.62618432 0.60206718 0.3910422  0.58225668 0.44186047\n",
            " 0.32385874 0.4625323  0.40223945 0.5374677  0.42291128 0.64857881\n",
            " 0.51679587 0.47200689 0.59431525 0.50387597 0.34022394 0.55900086\n",
            " 0.42980189 0.5245478  0.57105943 0.59689922 0.59259259 0.57881137\n",
            " 0.6287683  0.56072351 0.44358312 0.55211025]\n",
            "The trained model has an aproximate error rate of 5.772424824418514 which equates to 1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "            'year':[2019,2019,2019,2020],\n",
        "          'da':[10,10,10,20],\n",
        "         'prcp' : [0,2.34,5.5,2.24],\n",
        "         'fog' : [0,0,1,1],\n",
        "         'rain_drizzle' : [0,1,1,1],\n",
        "         'snow_ice_pellets' : [0,0,0,0],\n",
        "         'hail' : [0,0,0,0],\n",
        "         'Apr' : [0,0,0,0],\n",
        "         'Aug' : [1,1,1,1],\n",
        "         'Dec' : [0,0,0,0],\n",
        "         'Feb' : [0,0,0,0],\n",
        "         'Jan' : [0,0,0,0],\n",
        "         'Jul' : [0,0,0,0],\n",
        "         'Jun' : [0,0,0,0],\n",
        "         'Mar' : [0,0,0,0],\n",
        "         'May' : [0,0,0,0],\n",
        "         'Nov' : [0,0,0,0],\n",
        "         'Oct' : [0,0,0,0],\n",
        "         'Sep' : [0,0,0,0],\n",
        "         'Fri' : [0,0,0,0],\n",
        "         'Mon' : [1,1,1,1],\n",
        "         'Sat' : [0,0,0,0],\n",
        "         'Sun' : [0,0,0,0],\n",
        "         'Thu' : [0,0,0,0],\n",
        "         'Tue' : [0,0,0,0],\n",
        "         'Wed' : [0,0,0,0]\n",
        "      \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a759a2-f827-47f1-fbc5-97774aa5a0b0",
        "id": "4fOP899kI8XR"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180fb9950>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[932.5393 882.323  850.8384 659.843 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE value is very similar to that of the linear regression model, indicating that both models are accurate predictors. The error rate of the DNN is higher, indicating the there is a higher number of errors, but the margin of error is lower."
      ],
      "metadata": {
        "id": "HAhdrU04ttZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dew Point (dewp)\n",
        "As with the linear regressor the process of training each model follows a very similar process, with the number of hidden layers, the number of nodes within each layer and the learning rate changing dependant on the dataset."
      ],
      "metadata": {
        "id": "yT91LA7Xx77W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_dewp_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/dewp_clean_dnn.csv', index_col=0, )\n",
        "print(df_dewp_dnn[:6])"
      ],
      "metadata": {
        "id": "zQAH_kVzyAOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a3b6e7-2e61-401a-d03a-82fe04c53f82"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_dewp_dnn = df_dewp_dnn.drop(columns=['temp', 'prcp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_dewp_dnn = df_dewp_dnn.loc[df_dewp_dnn[\"year\"] != 2012]\n",
        "df_dewp_dnn = df_dewp_dnn.loc[df_dewp_dnn[\"year\"] < 2020]\n",
        "#Move target to end\n",
        "cols = df_dewp_dnn['NUM_COLLISIONS']\n",
        "df_dewp_dnn = df_dewp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_dewp_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_dewp_dnn[:6])\n",
        "df_dewp_dnn.describe()"
      ],
      "metadata": {
        "id": "_qzGppAwyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "a18ec6da-f669-47cb-c258-79434440c078"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  dewp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "49  2016  28  24.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17  35.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25  21.2    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29  36.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20  32.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13  44.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da         dewp          Apr          Aug  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean   2015.999217    15.723679    44.163170     0.082192     0.084932   \n",
              "std       2.000000     8.801271    16.995303     0.274710     0.278834   \n",
              "min    2013.000000     1.000000    -6.700000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000    32.150000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000    45.300000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000    58.500000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000    74.100000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000  ...   \n",
              "mean      0.084932     0.077104     0.084932     0.084540     0.082192  ...   \n",
              "std       0.278834     0.266808     0.278834     0.278251     0.274710  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      0.084932     0.082192     0.142466     0.143249     0.142857   \n",
              "std       0.278834     0.274710     0.349596     0.350395     0.349996   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000     2555.000000  \n",
              "mean      0.142857     0.142857     0.142857     0.142857      599.109980  \n",
              "std       0.349996     0.349996     0.349996     0.349996      100.277185  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8222668c-37b8-4450-8f8e-5d7992c3bce6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>dewp</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.999217</td>\n",
              "      <td>15.723679</td>\n",
              "      <td>44.163170</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.077104</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084540</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.142466</td>\n",
              "      <td>0.143249</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>599.109980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.801271</td>\n",
              "      <td>16.995303</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.266808</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278251</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.349596</td>\n",
              "      <td>0.350395</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>100.277185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8222668c-37b8-4450-8f8e-5d7992c3bce6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8222668c-37b8-4450-8f8e-5d7992c3bce6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8222668c-37b8-4450-8f8e-5d7992c3bce6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle Data\n",
        "shuffle = df_dewp_dnn.iloc[np.random.permutation(len(df_dewp_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "z5-eCTxByAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91213ef-0278-4efb-9033-dd01da4cae17"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  dewp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "2556  2018  21  54.6    0    0    0    0    0    0    0  ...    0    0    1   \n",
            "2514  2013  25  45.3    0    0    0    0    0    0    0  ...    0    0    1   \n",
            "502   2019   7  37.9    0    0    0    1    0    0    0  ...    0    0    0   \n",
            "3349  2014   1  46.9    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "2916  2019   7  61.7    0    0    0    0    0    0    0  ...    0    1    0   \n",
            "189   2017  12  45.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "2556    0    0    0    0    1    0    0  \n",
            "2514    0    0    0    0    0    1    0  \n",
            "502     0    0    0    0    0    0    1  \n",
            "3349    1    0    0    0    0    0    0  \n",
            "2916    0    0    0    1    0    0    0  \n",
            "189     0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "BbrOrPfQyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade1f2c5-f37a-467e-fb25-b394f4964931"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2556    715\n",
            "2514    539\n",
            "502     588\n",
            "3349    656\n",
            "2916    575\n",
            "189     646\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "#Calculate number of outputs\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "T2v7BylMyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a54cfe-e246-4190-a8bb-6586cb8b0030"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_dewp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[21,17,9], optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "#Train model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "HMGFsHtkyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968784c2-70ea-41c5-a136-76aeddb62c62"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21846dd690>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:loss = 6797.327, step = 1\n",
            "INFO:tensorflow:global_step/sec: 389.68\n",
            "INFO:tensorflow:loss = 9.369931, step = 101 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.251\n",
            "INFO:tensorflow:loss = 5.141411, step = 201 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.123\n",
            "INFO:tensorflow:loss = 4.6838293, step = 301 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.193\n",
            "INFO:tensorflow:loss = 3.7785985, step = 401 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.663\n",
            "INFO:tensorflow:loss = 2.8587873, step = 501 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.056\n",
            "INFO:tensorflow:loss = 2.564952, step = 601 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.993\n",
            "INFO:tensorflow:loss = 2.0920012, step = 701 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.456\n",
            "INFO:tensorflow:loss = 1.4530969, step = 801 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.477\n",
            "INFO:tensorflow:loss = 1.1808155, step = 901 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.245\n",
            "INFO:tensorflow:loss = 0.7926267, step = 1001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.204\n",
            "INFO:tensorflow:loss = 0.50933576, step = 1101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.456\n",
            "INFO:tensorflow:loss = 0.35257834, step = 1201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.076\n",
            "INFO:tensorflow:loss = 0.24036372, step = 1301 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.897\n",
            "INFO:tensorflow:loss = 0.19308908, step = 1401 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.312\n",
            "INFO:tensorflow:loss = 0.13742328, step = 1501 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.805\n",
            "INFO:tensorflow:loss = 0.10278131, step = 1601 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.997\n",
            "INFO:tensorflow:loss = 0.08122799, step = 1701 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.27\n",
            "INFO:tensorflow:loss = 0.08482272, step = 1801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.847\n",
            "INFO:tensorflow:loss = 0.07821304, step = 1901 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.186\n",
            "INFO:tensorflow:loss = 0.07286255, step = 2001 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.713\n",
            "INFO:tensorflow:loss = 0.062192857, step = 2101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.21\n",
            "INFO:tensorflow:loss = 0.05368697, step = 2201 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.959\n",
            "INFO:tensorflow:loss = 0.054225758, step = 2301 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.54\n",
            "INFO:tensorflow:loss = 0.061387964, step = 2401 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.141\n",
            "INFO:tensorflow:loss = 0.050539598, step = 2501 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.502\n",
            "INFO:tensorflow:loss = 0.04909313, step = 2601 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.013\n",
            "INFO:tensorflow:loss = 0.048067395, step = 2701 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.023\n",
            "INFO:tensorflow:loss = 0.040790185, step = 2801 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.86\n",
            "INFO:tensorflow:loss = 0.04566484, step = 2901 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.278\n",
            "INFO:tensorflow:loss = 0.049610756, step = 3001 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.896\n",
            "INFO:tensorflow:loss = 0.039174233, step = 3101 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.799\n",
            "INFO:tensorflow:loss = 0.033849474, step = 3201 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.458\n",
            "INFO:tensorflow:loss = 0.032430023, step = 3301 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.767\n",
            "INFO:tensorflow:loss = 0.035833985, step = 3401 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.232\n",
            "INFO:tensorflow:loss = 0.0360109, step = 3501 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.883\n",
            "INFO:tensorflow:loss = 0.033564158, step = 3601 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.077\n",
            "INFO:tensorflow:loss = 0.027018916, step = 3701 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.222\n",
            "INFO:tensorflow:loss = 0.027668256, step = 3801 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.093\n",
            "INFO:tensorflow:loss = 0.034272883, step = 3901 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.031\n",
            "INFO:tensorflow:loss = 0.023456357, step = 4001 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.126\n",
            "INFO:tensorflow:loss = 0.022849347, step = 4101 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.149\n",
            "INFO:tensorflow:loss = 0.02225043, step = 4201 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.709\n",
            "INFO:tensorflow:loss = 0.023483554, step = 4301 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.013\n",
            "INFO:tensorflow:loss = 0.021589188, step = 4401 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.214\n",
            "INFO:tensorflow:loss = 0.016893303, step = 4501 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.949\n",
            "INFO:tensorflow:loss = 0.01599554, step = 4601 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.996\n",
            "INFO:tensorflow:loss = 0.015233744, step = 4701 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.594\n",
            "INFO:tensorflow:loss = 0.016672695, step = 4801 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.325\n",
            "INFO:tensorflow:loss = 0.013676194, step = 4901 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.56\n",
            "INFO:tensorflow:loss = 0.013676157, step = 5001 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.475\n",
            "INFO:tensorflow:loss = 0.014720791, step = 5101 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.149\n",
            "INFO:tensorflow:loss = 0.016351912, step = 5201 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.546\n",
            "INFO:tensorflow:loss = 0.0122696925, step = 5301 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.338\n",
            "INFO:tensorflow:loss = 0.010608771, step = 5401 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.299\n",
            "INFO:tensorflow:loss = 0.012106111, step = 5501 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.384\n",
            "INFO:tensorflow:loss = 0.010121316, step = 5601 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.767\n",
            "INFO:tensorflow:loss = 0.00834423, step = 5701 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.949\n",
            "INFO:tensorflow:loss = 0.011896225, step = 5801 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.968\n",
            "INFO:tensorflow:loss = 0.012456194, step = 5901 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.084\n",
            "INFO:tensorflow:loss = 0.010049382, step = 6001 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.089\n",
            "INFO:tensorflow:loss = 0.008935591, step = 6101 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.028\n",
            "INFO:tensorflow:loss = 0.009000262, step = 6201 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.554\n",
            "INFO:tensorflow:loss = 0.006847664, step = 6301 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.114\n",
            "INFO:tensorflow:loss = 0.008887485, step = 6401 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.914\n",
            "INFO:tensorflow:loss = 0.007235623, step = 6501 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.164\n",
            "INFO:tensorflow:loss = 0.0071105496, step = 6601 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.227\n",
            "INFO:tensorflow:loss = 0.009284985, step = 6701 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.307\n",
            "INFO:tensorflow:loss = 0.0062603448, step = 6801 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.415\n",
            "INFO:tensorflow:loss = 0.005587696, step = 6901 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.664\n",
            "INFO:tensorflow:loss = 0.006553109, step = 7001 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.67\n",
            "INFO:tensorflow:loss = 0.004462048, step = 7101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.097\n",
            "INFO:tensorflow:loss = 0.008260548, step = 7201 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.233\n",
            "INFO:tensorflow:loss = 0.0058538867, step = 7301 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.549\n",
            "INFO:tensorflow:loss = 0.005653543, step = 7401 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.961\n",
            "INFO:tensorflow:loss = 0.004557387, step = 7501 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.526\n",
            "INFO:tensorflow:loss = 0.0064947046, step = 7601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.965\n",
            "INFO:tensorflow:loss = 0.005854461, step = 7701 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.34\n",
            "INFO:tensorflow:loss = 0.005536833, step = 7801 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.544\n",
            "INFO:tensorflow:loss = 0.005774577, step = 7901 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.915\n",
            "INFO:tensorflow:loss = 0.004822048, step = 8001 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.756\n",
            "INFO:tensorflow:loss = 0.0057455404, step = 8101 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.236\n",
            "INFO:tensorflow:loss = 0.006221906, step = 8201 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.668\n",
            "INFO:tensorflow:loss = 0.004289442, step = 8301 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.798\n",
            "INFO:tensorflow:loss = 0.004923083, step = 8401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.986\n",
            "INFO:tensorflow:loss = 0.0050033024, step = 8501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.555\n",
            "INFO:tensorflow:loss = 0.004416842, step = 8601 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.439\n",
            "INFO:tensorflow:loss = 0.0044510528, step = 8701 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.835\n",
            "INFO:tensorflow:loss = 0.004518591, step = 8801 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.225\n",
            "INFO:tensorflow:loss = 0.007069747, step = 8901 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.217\n",
            "INFO:tensorflow:loss = 0.005061719, step = 9001 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.885\n",
            "INFO:tensorflow:loss = 0.00479824, step = 9101 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.705\n",
            "INFO:tensorflow:loss = 0.0046741245, step = 9201 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.547\n",
            "INFO:tensorflow:loss = 0.004933348, step = 9301 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.664\n",
            "INFO:tensorflow:loss = 0.0066500315, step = 9401 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.162\n",
            "INFO:tensorflow:loss = 0.008261639, step = 9501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.987\n",
            "INFO:tensorflow:loss = 0.004904991, step = 9601 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.295\n",
            "INFO:tensorflow:loss = 0.00479128, step = 9701 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.606\n",
            "INFO:tensorflow:loss = 0.0063122017, step = 9801 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.568\n",
            "INFO:tensorflow:loss = 0.0053011104, step = 9901 (0.189 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0050018984.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 82.12004390938685\n",
            "Just using average = 598.3923679060665 has RMSE of 99.44265935333182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "# Ensure number of hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[21,17,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NCz6izVhyAOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1115ead0-815f-4278-fb04-b2ed91564ab0"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21809a56d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5936745  0.5735634  0.5188759  0.5288704  0.5355385  0.5756081\n",
            " 0.56106645 0.5687416  0.4068001  0.43673784 0.50471574 0.55792314\n",
            " 0.5229042  0.4728554  0.41969377 0.55380327 0.5918434  0.40025407\n",
            " 0.51411515 0.4107979  0.5256966  0.4297188  0.51452714 0.588105\n",
            " 0.52067643 0.42454606 0.42288285 0.4568947  0.50116044 0.4597786\n",
            " 0.39795    0.4763649  0.41940385 0.43850785 0.51870805 0.5434273\n",
            " 0.56633073 0.53166276 0.5426491  0.5306862  0.4337929  0.47738725\n",
            " 0.5656288  0.46231157 0.5537575  0.5093697  0.51821977 0.47634965\n",
            " 0.48704606 0.50370866 0.49202043 0.5383614  0.5662697  0.47586137\n",
            " 0.4889534  0.53044206 0.5877693  0.59246904 0.6017464  0.44694597\n",
            " 0.5096901  0.49504167 0.5294655  0.53344804 0.53041154 0.50907975\n",
            " 0.5255287  0.5096596  0.4078377  0.53514177 0.5080574  0.5009926\n",
            " 0.5144966  0.5104378  0.5056465  0.6004036  0.54144365 0.52833635\n",
            " 0.47476274 0.5176094  0.5780495  0.547242   0.4281624  0.5160988\n",
            " 0.5456551  0.52584916 0.47622758 0.552079   0.5000923  0.3929146\n",
            " 0.43072587 0.5837868  0.4621132  0.39056474 0.46150285 0.49952775\n",
            " 0.5372322  0.5266579  0.5202339  0.47953874 0.5130623  0.46362382\n",
            " 0.522065   0.5586403  0.5135353  0.5058144  0.5570839  0.52472\n",
            " 0.53965837 0.5149391  0.5261696  0.53410417 0.44854814 0.5441902\n",
            " 0.50912553 0.4292     0.5118721  0.5025795  0.5392006  0.60196\n",
            " 0.47691423 0.48248369 0.5635689  0.55336076 0.52859575 0.5017708\n",
            " 0.47805864 0.4934395  0.57354814 0.4744423  0.45034868 0.41291887\n",
            " 0.4745186  0.55462724 0.5864876  0.48494035 0.621476   0.527314\n",
            " 0.53978044 0.41203386 0.4069069  0.43466264 0.53688127 0.50552446\n",
            " 0.5352333  0.43655473 0.5063637  0.5047615  0.5204018  0.557679\n",
            " 0.47030717 0.61064225 0.5731514  0.5844429  0.5387276  0.5538338\n",
            " 0.52703935 0.5361336  0.52922136 0.49687272 0.53547746 0.628907\n",
            " 0.48194963 0.45613176 0.48297197 0.5151985  0.56309587 0.5271614\n",
            " 0.5295113  0.47009355 0.50978166 0.471299   0.40615922 0.5330666\n",
            " 0.48265153 0.51699907 0.5221413  0.5463112  0.49311906 0.56176835\n",
            " 0.54521257 0.4687813  0.5565041  0.48330766 0.5214394  0.5265053\n",
            " 0.60971147 0.5462349  0.46220475 0.53210527 0.5350197  0.41754228\n",
            " 0.4645546  0.6014412  0.5433052  0.5106819  0.40452653 0.5072182\n",
            " 0.5495766  0.60783464 0.4893654  0.39999467 0.45251542 0.55940324\n",
            " 0.5199593  0.5655373  0.5461891  0.5142372  0.54377824 0.53625566\n",
            " 0.45884782 0.5614632  0.43827897 0.529908   0.60415727 0.51867753\n",
            " 0.46476823 0.5121315  0.47294694 0.57876664 0.5578621  0.5414589\n",
            " 0.47169572 0.5325478  0.522126   0.5766457  0.5906685  0.49046403\n",
            " 0.49636918 0.42454606 0.56254655 0.5309151  0.528199   0.61723405\n",
            " 0.45668107 0.5955666  0.5549477  0.48939592 0.5813454  0.5250252\n",
            " 0.49626237 0.4970253  0.5464943  0.4052742  0.5407112  0.4207161\n",
            " 0.5850075  0.56594926 0.5553749  0.6066597  0.5059517  0.5202797\n",
            " 0.5265663  0.5049599  0.49174577 0.4163521  0.48924333 0.57643205\n",
            " 0.5128334  0.54637223 0.5006569  0.575074   0.53282243 0.49470598\n",
            " 0.51596147 0.41348344 0.51338273 0.4077614  0.54506    0.51164323\n",
            " 0.5022896  0.51500016 0.46640092 0.57154924 0.55510026 0.52867204\n",
            " 0.5390938  0.6075905  0.42134172 0.5782631  0.5632637  0.51974565\n",
            " 0.5462807  0.40089494 0.5452278  0.5184944  0.52107316 0.4233864\n",
            " 0.45735246 0.49920732 0.53396684 0.52197343 0.5074013  0.46957475\n",
            " 0.5485695  0.5764931  0.5296944  0.5113228  0.52467424 0.42758256\n",
            " 0.5209816  0.49105912 0.5627907  0.48335344 0.52584916 0.50059587\n",
            " 0.51852494 0.5233467  0.5103615  0.51089555 0.49075395 0.5428017\n",
            " 0.5482643  0.40010148 0.55476457 0.53755265 0.5707558  0.44116288\n",
            " 0.50515825 0.56080705 0.57254106 0.5124977  0.56051713 0.46794206\n",
            " 0.49208146 0.54544145 0.56095964 0.41703874 0.4819954  0.4875191\n",
            " 0.52319413 0.5674599  0.40078813 0.52507097 0.46623307 0.52829057\n",
            " 0.526902   0.57254106 0.5597542  0.39010698 0.49620134 0.6013344\n",
            " 0.59787065 0.53508073 0.59234697 0.5847481  0.5125893  0.55291826\n",
            " 0.58754045 0.46901017 0.56280595 0.5647591  0.568055   0.51741105\n",
            " 0.5448616  0.5447548  0.60186845 0.544709   0.5544594  0.43699723\n",
            " 0.5497597  0.5024727  0.59379655 0.55143815 0.6282204  0.5560768\n",
            " 0.5370644  0.5127266  0.47934037 0.5490425  0.5129402  0.46724015\n",
            " 0.5225685  0.5894173  0.42402726 0.41055375 0.52296525 0.5544289\n",
            " 0.4340065  0.5523079  0.5006569  0.52685624 0.51208574 0.5188454\n",
            " 0.47934037 0.43948442 0.4447487  0.47308427 0.5102547  0.46612626\n",
            " 0.4819649  0.51945573 0.45353776 0.52519304 0.5358589  0.55839616\n",
            " 0.56347734 0.5589302  0.5357216  0.48242265 0.4460457  0.51445085\n",
            " 0.46191484 0.5250862  0.5149086  0.43118364 0.42318803 0.5497139\n",
            " 0.36892778 0.5955666  0.51915056 0.5209053  0.5657814  0.46563798\n",
            " 0.5481575  0.38644487 0.5321358  0.56483537 0.61131364 0.44024736\n",
            " 0.57248    0.57643205 0.5573738  0.52333146 0.52174455 0.46545488\n",
            " 0.57136613 0.47865373 0.57417375 0.52426225 0.47419816 0.3983925\n",
            " 0.45117265 0.5450142  0.4299019  0.5478218  0.47764665 0.56591874\n",
            " 0.55380327 0.53204423 0.5695656  0.41388017 0.5701912  0.4989174\n",
            " 0.56166154 0.47146684 0.43402177 0.51989824 0.545533   0.5663765\n",
            " 0.5100563  0.5125435  0.5575569  0.53326494 0.5336769  0.6001442\n",
            " 0.48263627 0.49075395 0.6091774  0.5462349  0.5515755  0.56062394\n",
            " 0.5383919  0.6163185  0.4188698  0.39645463 0.56228715 0.5248726\n",
            " 0.5005043  0.51152116 0.5777748  0.5154732  0.40515214 0.5230568\n",
            " 0.5731972  0.46934587 0.4818123  0.48359758 0.5150307  0.41088945\n",
            " 0.5797127  0.5773323  0.5783089  0.48193437 0.56062394 0.5785225\n",
            " 0.5611885  0.5852516  0.56169206 0.49914628 0.46260148 0.506028\n",
            " 0.5118874  0.53295976 0.60926896 0.42125016 0.49008256 0.46801835\n",
            " 0.5539406  0.56695634 0.559388   0.56117326 0.57420427 0.47795182\n",
            " 0.51126176 0.5916603  0.44825822 0.5500801  0.52537614 0.5568703\n",
            " 0.5816048 ]\n",
            "[0.5538329  0.57105943 0.40999139 0.46511628 0.59259259 0.54435831\n",
            " 0.52713178 0.61068045 0.40482343 0.43927649 0.46339363 0.60120586\n",
            " 0.38845823 0.41946598 0.42463394 0.54349699 0.54521964 0.43496985\n",
            " 0.54694229 0.41946598 0.58225668 0.53574505 0.37037037 0.55813953\n",
            " 0.57278208 0.40568475 0.40482343 0.52024117 0.39707149 0.47803618\n",
            " 0.38845823 0.46511628 0.44099914 0.49095607 0.54780362 0.56761413\n",
            " 0.42204996 0.50215332 0.44702842 0.49698536 0.50387597 0.47114556\n",
            " 0.55555556 0.45219638 0.42980189 0.56072351 0.46080965 0.56589147\n",
            " 0.42980189 0.51851852 0.51248923 0.62790698 0.48062016 0.39276486\n",
            " 0.82687339 0.52196382 0.49009475 0.6546081  0.62618432 0.44702842\n",
            " 0.42291128 0.58139535 0.52799311 0.57536606 0.49784668 0.58914729\n",
            " 0.57019811 0.54005168 0.49267873 0.52627046 0.55986219 0.51851852\n",
            " 0.47286822 0.59000861 0.5538329  0.5667528  0.53402239 0.47631352\n",
            " 0.52971576 0.68130922 0.56847545 0.56589147 0.43152455 0.62015504\n",
            " 0.52282515 0.5245478  0.51248923 0.55555556 0.44788975 0.42980189\n",
            " 0.4461671  0.52799311 0.43410853 0.33936262 0.4005168  0.46770026\n",
            " 0.5211025  0.54005168 0.46167097 0.42894057 0.50301464 0.49612403\n",
            " 0.51593454 0.57622739 0.51507321 0.5245478  0.45047373 0.44530577\n",
            " 0.46425495 0.52885444 0.47717485 0.45822567 0.47803618 0.63738157\n",
            " 0.56158484 0.44358312 0.56933678 0.5374677  0.31955211 0.56847545\n",
            " 0.52713178 0.47717485 0.59000861 0.53919035 0.60378984 0.48923342\n",
            " 0.62015504 0.45305771 0.50387597 0.55986219 0.45564169 0.34366925\n",
            " 0.50990525 0.57278208 0.52885444 0.49956934 0.69853575 0.56847545\n",
            " 0.59259259 0.47459087 0.42635659 0.40826873 0.3712317  0.53143842\n",
            " 0.53057709 0.53229974 0.60723514 0.43066322 0.51076658 0.59345392\n",
            " 0.49440138 0.7002584  0.58742463 0.58656331 0.46683893 0.54091301\n",
            " 0.51507321 0.43496985 0.53229974 0.54521964 0.44444444 0.52368648\n",
            " 0.44702842 0.49870801 0.48320413 0.45736434 0.6416882  0.54263566\n",
            " 0.50990525 0.45478036 0.51765719 0.47114556 0.40999139 0.91731266\n",
            " 0.46339363 0.60120586 0.60551249 0.60637382 0.56072351 0.59000861\n",
            " 0.53919035 0.50559862 0.40999139 0.53832903 0.42118863 0.48751077\n",
            " 0.83893196 0.49956934 0.47372954 0.38070629 0.56330749 0.37812231\n",
            " 0.49784668 0.67355728 0.6416882  0.51162791 0.42635659 0.56933678\n",
            " 0.51593454 0.68819983 0.50301464 0.41515935 0.43238587 0.67011197\n",
            " 0.63307494 0.54866494 0.54694229 0.45736434 0.51851852 0.52627046\n",
            " 0.49354005 0.6089578  0.36089578 0.52024117 0.61068045 0.51162791\n",
            " 0.44186047 0.4203273  0.51765719 0.59259259 0.56589147 0.52196382\n",
            " 0.58397933 0.50129199 0.47028424 0.38415159 0.57278208 0.45564169\n",
            " 0.5081826  0.3875969  0.64341085 0.54263566 0.46942291 0.64427218\n",
            " 0.45305771 0.64082687 0.58397933 0.47286822 0.58225668 0.50904393\n",
            " 0.43755383 0.50559862 0.51937984 0.39793282 0.56847545 0.48062016\n",
            " 0.45994832 0.70801034 0.62618432 0.66838932 0.45822567 0.54005168\n",
            " 0.57278208 0.54866494 0.51851852 0.44875108 0.51162791 0.51851852\n",
            " 0.48148148 0.48320413 0.55900086 0.47459087 0.57536606 0.4754522\n",
            " 0.5047373  0.43496985 0.55555556 0.39276486 0.65030146 0.43410853\n",
            " 0.4918174  0.54521964 0.416882   0.50129199 0.46856158 0.43755383\n",
            " 0.42204996 0.65977606 0.40999139 0.66408269 0.50129199 0.47631352\n",
            " 0.38156761 0.46597761 0.66666667 0.56416882 0.48751077 0.38242894\n",
            " 0.46770026 0.42807924 0.54435831 0.55986219 0.44272179 0.52885444\n",
            " 0.58828596 0.56416882 0.47286822 0.374677   0.56330749 0.44099914\n",
            " 0.51765719 0.49095607 0.57019811 0.47286822 0.61584841 0.54005168\n",
            " 0.51162791 0.51507321 0.59689922 0.59173127 0.46942291 0.63652024\n",
            " 0.38070629 0.38845823 0.32213609 0.59345392 0.64944014 0.37984496\n",
            " 0.43755383 0.59517657 0.67786391 0.49267873 0.57622739 0.56933678\n",
            " 0.59259259 0.47200689 0.51248923 0.41515935 0.55641688 0.4918174\n",
            " 0.49870801 0.4754522  0.32127476 0.38931955 0.40913006 0.54780362\n",
            " 0.60378984 0.5960379  0.67700258 0.27562446 0.61154177 0.62273902\n",
            " 0.63824289 0.47631352 0.60034453 0.5211025  0.52540913 0.49440138\n",
            " 0.58914729 0.53832903 0.63393626 0.60378984 0.58484065 0.48234281\n",
            " 0.56158484 0.62015504 0.56072351 0.53402239 0.53057709 0.52024117\n",
            " 0.49009475 0.50990525 0.66063738 0.59086994 0.64341085 0.48664944\n",
            " 0.62962963 0.56761413 0.46167097 0.59517657 0.51765719 0.5211025\n",
            " 0.63049096 0.7002584  0.46597761 0.44788975 0.44358312 0.44530577\n",
            " 0.41257537 0.6124031  0.40913006 0.5994832  0.53574505 0.28682171\n",
            " 0.5211025  0.43669251 0.40826873 0.51421189 0.4332472  0.43669251\n",
            " 0.36864772 0.36606374 0.57622739 0.61757106 0.36864772 0.54608096\n",
            " 0.52540913 0.55900086 0.60809647 0.42894057 0.43669251 0.5503876\n",
            " 0.4005168  0.56503015 0.60120586 0.40137812 0.42807924 0.56503015\n",
            " 0.38329027 0.66925065 0.54177433 0.52885444 0.69250646 0.53057709\n",
            " 0.56589147 0.37209302 0.48234281 0.63049096 0.66838932 0.44875108\n",
            " 0.49095607 0.6873385  0.51937984 0.37898363 0.55813953 0.47372954\n",
            " 0.51851852 0.42291128 0.63910422 0.41257537 0.41343669 0.41429802\n",
            " 0.48492679 0.59345392 0.43066322 0.55727821 0.44444444 0.5081826\n",
            " 0.57881137 0.54263566 0.59086994 0.38845823 0.7329888  0.49698536\n",
            " 0.49095607 0.43496985 0.77174849 0.56847545 0.47631352 0.55813953\n",
            " 0.72265289 0.49956934 0.53488372 0.50215332 0.60378984 0.50301464\n",
            " 0.65202412 0.52713178 0.63393626 0.66149871 0.45391904 0.48148148\n",
            " 0.57622739 0.59689922 0.37984496 0.46597761 0.56503015 0.32213609\n",
            " 0.41946598 0.51248923 0.5796727  0.5994832  0.4005168  0.51248923\n",
            " 0.52971576 0.5211025  0.53832903 0.49698536 0.57450474 0.42377261\n",
            " 0.65633075 0.63135228 0.64685616 0.57450474 0.57364341 0.57450474\n",
            " 0.45047373 0.58656331 0.52713178 0.45736434 0.48148148 0.47459087\n",
            " 0.53919035 0.60206718 0.62273902 0.39879414 0.48664944 0.49870801\n",
            " 0.4952627  0.55727821 0.625323   0.57019811 0.66666667 0.54177433\n",
            " 0.44272179 0.53488372 0.47717485 0.56072351 0.54694229 0.45650301\n",
            " 0.63910422]\n",
            "The trained model has an aproximate error rate of 3.533810578796963 which equates to 1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown by the RMSE value, this model is a more efficient way to predict the number of collisions in comparison to using the mean. In comparison to the linear regression model trained, the RMSE is lower indicating the DNN makes more accurate predictions. As with the DNN for precipitation, the RMSE is lower than the linear model the error rate is higher indicating there is more errors but the margin of error is lower."
      ],
      "metadata": {
        "id": "LJTFyYeIFHwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sea Level Pressure(slp)\n",
        "Through the analysis carried out in assignment 1, no clear relationship between sea level pressure and the number of collisions was uncovered. A DNN will be used to attempt to predict the number of collisions at a given pressure point."
      ],
      "metadata": {
        "id": "eJ4eYJryNjGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_slp_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/slp_clean_dnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "mhUamxCZOTrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdae1227-b826-4c39-c98b-a91b256180e2"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_slp_dnn = df_slp_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_slp_dnn = df_slp_dnn.loc[df_slp_dnn[\"year\"] != 2012]\n",
        "df_slp_dnn = df_slp_dnn.loc[df_slp_dnn[\"year\"] < 2020]\n",
        "#Move target to the end\n",
        "cols = df_slp_dnn['NUM_COLLISIONS']\n",
        "df_slp_dnn = df_slp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_slp_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_slp_dnn[:6])\n",
        "df_slp_dnn.describe()"
      ],
      "metadata": {
        "id": "P-VEj2lxOTrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "cafc4ccc-312b-4513-99e5-0aeda2495fe4"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da     slp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "49  2016  28  1016.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17  1014.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25  1021.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29   999.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20  1015.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13  1020.7    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da          slp          Apr          Aug  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean   2016.000391    15.719765  1016.777221     0.082192     0.084932   \n",
              "std       2.000294     8.796698     7.628429     0.274710     0.278834   \n",
              "min    2013.000000     1.000000   989.500000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000  1012.200000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000  1016.700000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000  1021.700000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000  1044.200000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000  ...   \n",
              "mean      0.084540     0.077104     0.084932     0.084932     0.082192  ...   \n",
              "std       0.278251     0.266808     0.278834     0.278834     0.274710  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      0.084932     0.082192     0.142857     0.143249     0.142857   \n",
              "std       0.278834     0.274710     0.349996     0.350395     0.349996   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000     2555.000000  \n",
              "mean      0.142857     0.142857     0.142857     0.142466      599.147162  \n",
              "std       0.349996     0.349996     0.349996     0.349596      100.268048  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e31e8669-96ed-494d-a3ce-14966e2d5e34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>slp</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.000391</td>\n",
              "      <td>15.719765</td>\n",
              "      <td>1016.777221</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084540</td>\n",
              "      <td>0.077104</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.143249</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142466</td>\n",
              "      <td>599.147162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000294</td>\n",
              "      <td>8.796698</td>\n",
              "      <td>7.628429</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278251</td>\n",
              "      <td>0.266808</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.350395</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349596</td>\n",
              "      <td>100.268048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1012.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1016.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1021.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>1044.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e31e8669-96ed-494d-a3ce-14966e2d5e34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e31e8669-96ed-494d-a3ce-14966e2d5e34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e31e8669-96ed-494d-a3ce-14966e2d5e34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle dataset\n",
        "shuffle = df_slp_dnn.iloc[np.random.permutation(len(df_slp_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "EG2EcMoLOTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435242ec-5e49-4d2f-fbb9-d67b3ed7d115"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da     slp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "3150  2014   5  1018.3    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "3100  2015  18  1034.9    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "1807  2017   6  1006.3    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "3133  2013  17  1024.9    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "3666  2014   8  1035.8    0    0    1    0    0    0    0  ...    0    0    0   \n",
            "857   2019   2  1016.8    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "3150    0    0    0    0    0    1    0  \n",
            "3100    0    0    0    0    0    1    0  \n",
            "1807    0    1    0    0    0    0    0  \n",
            "3133    0    0    1    0    0    0    0  \n",
            "3666    0    0    0    1    0    0    0  \n",
            "857     1    0    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of the targets data.\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "pd6Uk6a9OTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d6d2f2-dd99-4df1-e355-63b4d3568956"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3150    554\n",
            "3100    628\n",
            "1807    660\n",
            "3133    532\n",
            "3666    579\n",
            "857     642\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "#Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "QX1fWn3jOTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560a034d-6cd7-4b2a-cc53-5027a424959c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_slp', ignore_errors=True)\n",
        "#Setup model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[19,15,11], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "C9uL6bF7OTrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19693c07-e406-4be9-bda9-541b3c3f62e1"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21846fe950>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_slp/model.ckpt.\n",
            "INFO:tensorflow:loss = 4669.8906, step = 1\n",
            "INFO:tensorflow:global_step/sec: 382.448\n",
            "INFO:tensorflow:loss = 0.052570075, step = 101 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.265\n",
            "INFO:tensorflow:loss = 0.041005157, step = 201 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.107\n",
            "INFO:tensorflow:loss = 0.030781014, step = 301 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.473\n",
            "INFO:tensorflow:loss = 0.035366643, step = 401 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.736\n",
            "INFO:tensorflow:loss = 0.025151623, step = 501 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.3\n",
            "INFO:tensorflow:loss = 0.032797255, step = 601 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.196\n",
            "INFO:tensorflow:loss = 0.017441947, step = 701 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.265\n",
            "INFO:tensorflow:loss = 0.017582156, step = 801 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.962\n",
            "INFO:tensorflow:loss = 0.017789625, step = 901 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.917\n",
            "INFO:tensorflow:loss = 0.015397823, step = 1001 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.078\n",
            "INFO:tensorflow:loss = 0.013258632, step = 1101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.167\n",
            "INFO:tensorflow:loss = 0.016653527, step = 1201 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.085\n",
            "INFO:tensorflow:loss = 0.019047074, step = 1301 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.557\n",
            "INFO:tensorflow:loss = 0.012952085, step = 1401 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.528\n",
            "INFO:tensorflow:loss = 0.012023982, step = 1501 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.207\n",
            "INFO:tensorflow:loss = 0.020473845, step = 1601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.94\n",
            "INFO:tensorflow:loss = 0.010755371, step = 1701 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.861\n",
            "INFO:tensorflow:loss = 0.015740564, step = 1801 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.729\n",
            "INFO:tensorflow:loss = 0.008998938, step = 1901 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.209\n",
            "INFO:tensorflow:loss = 0.01154596, step = 2001 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.706\n",
            "INFO:tensorflow:loss = 0.011354902, step = 2101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.862\n",
            "INFO:tensorflow:loss = 0.04514441, step = 2201 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.246\n",
            "INFO:tensorflow:loss = 0.24337398, step = 2301 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.239\n",
            "INFO:tensorflow:loss = 0.07152875, step = 2401 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.135\n",
            "INFO:tensorflow:loss = 0.008257926, step = 2501 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.234\n",
            "INFO:tensorflow:loss = 0.84722555, step = 2601 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.078\n",
            "INFO:tensorflow:loss = 0.02687271, step = 2701 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.111\n",
            "INFO:tensorflow:loss = 0.020572806, step = 2801 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.861\n",
            "INFO:tensorflow:loss = 1.7720261, step = 2901 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.29\n",
            "INFO:tensorflow:loss = 0.012608741, step = 3001 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.027\n",
            "INFO:tensorflow:loss = 0.23926778, step = 3101 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.884\n",
            "INFO:tensorflow:loss = 12.33806, step = 3201 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.07\n",
            "INFO:tensorflow:loss = 0.005330048, step = 3301 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.367\n",
            "INFO:tensorflow:loss = 0.01786527, step = 3401 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.278\n",
            "INFO:tensorflow:loss = 0.02173439, step = 3501 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.153\n",
            "INFO:tensorflow:loss = 0.05218575, step = 3601 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.38\n",
            "INFO:tensorflow:loss = 3.8961797, step = 3701 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.868\n",
            "INFO:tensorflow:loss = 0.014286187, step = 3801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.079\n",
            "INFO:tensorflow:loss = 0.09958176, step = 3901 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.012\n",
            "INFO:tensorflow:loss = 0.081210814, step = 4001 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.614\n",
            "INFO:tensorflow:loss = 0.08598116, step = 4101 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.217\n",
            "INFO:tensorflow:loss = 0.106726095, step = 4201 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.434\n",
            "INFO:tensorflow:loss = 0.7211597, step = 4301 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.922\n",
            "INFO:tensorflow:loss = 0.042824183, step = 4401 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.208\n",
            "INFO:tensorflow:loss = 0.031412177, step = 4501 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.378\n",
            "INFO:tensorflow:loss = 0.01649925, step = 4601 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.434\n",
            "INFO:tensorflow:loss = 0.22878575, step = 4701 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.164\n",
            "INFO:tensorflow:loss = 0.034904517, step = 4801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.26\n",
            "INFO:tensorflow:loss = 0.005422904, step = 4901 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.297\n",
            "INFO:tensorflow:loss = 0.004182251, step = 5001 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.138\n",
            "INFO:tensorflow:loss = 0.2022576, step = 5101 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.52\n",
            "INFO:tensorflow:loss = 0.029129937, step = 5201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.907\n",
            "INFO:tensorflow:loss = 0.026111783, step = 5301 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.913\n",
            "INFO:tensorflow:loss = 0.03544357, step = 5401 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.234\n",
            "INFO:tensorflow:loss = 0.0040471987, step = 5501 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.058\n",
            "INFO:tensorflow:loss = 0.04652129, step = 5601 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.58\n",
            "INFO:tensorflow:loss = 0.025768131, step = 5701 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.182\n",
            "INFO:tensorflow:loss = 0.0067913844, step = 5801 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.364\n",
            "INFO:tensorflow:loss = 0.0062620053, step = 5901 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.772\n",
            "INFO:tensorflow:loss = 0.003916041, step = 6001 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.168\n",
            "INFO:tensorflow:loss = 0.09667127, step = 6101 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.939\n",
            "INFO:tensorflow:loss = 0.0052968636, step = 6201 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.948\n",
            "INFO:tensorflow:loss = 0.023460219, step = 6301 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.097\n",
            "INFO:tensorflow:loss = 0.0103878025, step = 6401 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.211\n",
            "INFO:tensorflow:loss = 0.061109215, step = 6501 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.692\n",
            "INFO:tensorflow:loss = 0.02489242, step = 6601 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.655\n",
            "INFO:tensorflow:loss = 0.012328649, step = 6701 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.348\n",
            "INFO:tensorflow:loss = 0.07347254, step = 6801 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.041\n",
            "INFO:tensorflow:loss = 0.015261916, step = 6901 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.545\n",
            "INFO:tensorflow:loss = 0.0071688313, step = 7001 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.809\n",
            "INFO:tensorflow:loss = 0.03509267, step = 7101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.536\n",
            "INFO:tensorflow:loss = 0.00582763, step = 7201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.063\n",
            "INFO:tensorflow:loss = 0.009233391, step = 7301 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.337\n",
            "INFO:tensorflow:loss = 0.015327731, step = 7401 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.814\n",
            "INFO:tensorflow:loss = 0.0053916145, step = 7501 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.143\n",
            "INFO:tensorflow:loss = 0.006977802, step = 7601 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.374\n",
            "INFO:tensorflow:loss = 0.03575083, step = 7701 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.04\n",
            "INFO:tensorflow:loss = 0.0073264837, step = 7801 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.832\n",
            "INFO:tensorflow:loss = 0.004506317, step = 7901 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.586\n",
            "INFO:tensorflow:loss = 0.016081292, step = 8001 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.41\n",
            "INFO:tensorflow:loss = 0.0032049525, step = 8101 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.606\n",
            "INFO:tensorflow:loss = 0.0050421143, step = 8201 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.045\n",
            "INFO:tensorflow:loss = 0.008318035, step = 8301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.495\n",
            "INFO:tensorflow:loss = 0.0053724158, step = 8401 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.281\n",
            "INFO:tensorflow:loss = 0.0047881496, step = 8501 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.282\n",
            "INFO:tensorflow:loss = 0.009020594, step = 8601 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.932\n",
            "INFO:tensorflow:loss = 0.004651146, step = 8701 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.723\n",
            "INFO:tensorflow:loss = 0.0052711684, step = 8801 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.349\n",
            "INFO:tensorflow:loss = 0.009200061, step = 8901 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.373\n",
            "INFO:tensorflow:loss = 0.0037595215, step = 9001 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.814\n",
            "INFO:tensorflow:loss = 0.004619903, step = 9101 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.417\n",
            "INFO:tensorflow:loss = 0.0042438093, step = 9201 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.207\n",
            "INFO:tensorflow:loss = 0.005248973, step = 9301 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.253\n",
            "INFO:tensorflow:loss = 0.0079938015, step = 9401 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.274\n",
            "INFO:tensorflow:loss = 0.0046173856, step = 9501 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.257\n",
            "INFO:tensorflow:loss = 0.00462234, step = 9601 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.99\n",
            "INFO:tensorflow:loss = 0.0062454506, step = 9701 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.98\n",
            "INFO:tensorflow:loss = 0.005616191, step = 9801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.555\n",
            "INFO:tensorflow:loss = 0.004434903, step = 9901 (0.211 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_slp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0047285846.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 98.85118429161771\n",
            "Just using average = 596.4124266144814 has RMSE of 103.92185858384369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#Ensure hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[19,15,11], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "mTPv83i1OTrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0365abc2-bf17-49f0-b5f3-1f97c82d7660"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21845ebd50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5917966  0.5788905  0.5427968  0.6050431  0.60605115 0.53256863\n",
            " 0.55283135 0.6348626  0.58504266 0.56610745 0.5229327  0.57837456\n",
            " 0.57006425 0.57838696 0.42912263 0.62351006 0.5539052  0.598273\n",
            " 0.544069   0.5425717  0.55858487 0.48077077 0.6013991  0.593394\n",
            " 0.60126084 0.62328976 0.52626103 0.56571263 0.56194466 0.5511157\n",
            " 0.5327956  0.5393569  0.5615527  0.59272546 0.541166   0.5956523\n",
            " 0.57379025 0.62063664 0.44211453 0.48356122 0.58795995 0.6356494\n",
            " 0.56791276 0.55647916 0.5654122  0.6186139  0.5639493  0.53519696\n",
            " 0.44032258 0.43082494 0.5323474  0.57730263 0.48051232 0.528588\n",
            " 0.61530846 0.5364129  0.5203511  0.58852357 0.5159642  0.621514\n",
            " 0.59628934 0.5974147  0.626517   0.44697922 0.55336446 0.60993356\n",
            " 0.53923196 0.5500466  0.60500497 0.60565156 0.5661542  0.6001603\n",
            " 0.5909774  0.5644137  0.5798623  0.6243207  0.62324303 0.50806206\n",
            " 0.6059577  0.56019753 0.5835902  0.6280181  0.6066901  0.58339375\n",
            " 0.5862071  0.4644019  0.6453149  0.6018407  0.5802838  0.577357\n",
            " 0.5504386  0.5760171  0.42445153 0.5823476  0.5846459  0.642759\n",
            " 0.58387345 0.5299155  0.5538394  0.6098706  0.55026025 0.5397536\n",
            " 0.62950104 0.53848904 0.58057755 0.6186673  0.5802905  0.568649\n",
            " 0.6207444  0.5531861  0.66114014 0.6050679  0.52220887 0.545119\n",
            " 0.6001851  0.46318597 0.53076905 0.59636086 0.59171075 0.5804669\n",
            " 0.627814   0.57413167 0.6090266  0.44245404 0.56720895 0.5530221\n",
            " 0.56446046 0.5962245  0.55239075 0.5674817  0.5699727  0.56866616\n",
            " 0.55576867 0.58576936 0.575339   0.61926717 0.54657334 0.5389306\n",
            " 0.5895993  0.5999715  0.6068322  0.5374209  0.4893605  0.51643723\n",
            " 0.65971917 0.61984414 0.6301276  0.60861176 0.5638024  0.58441323\n",
            " 0.61241215 0.57409924 0.62041825 0.53725594 0.4550044  0.55973786\n",
            " 0.5346524  0.61448354 0.63024014 0.56461304 0.5799987  0.5681674\n",
            " 0.4776885  0.47584122 0.5890843  0.574557   0.59549683 0.5436742\n",
            " 0.5744273  0.5879151  0.522391   0.6425931  0.5865037  0.5343997\n",
            " 0.47931355 0.6084935  0.5224559  0.5371844  0.5285279  0.5794799\n",
            " 0.6147248  0.56851166 0.58303803 0.64579934 0.56363267 0.48574513\n",
            " 0.5628926  0.5455987  0.5902621  0.48213547 0.5626876  0.57494515\n",
            " 0.5434548  0.5770852  0.5874488  0.613651   0.4382779  0.56840104\n",
            " 0.5632474  0.5685479  0.57219857 0.5987212  0.6117026  0.4872586\n",
            " 0.5976588  0.5709998  0.5161111  0.59813184 0.47790498 0.48457116\n",
            " 0.58976907 0.61265725 0.58859795 0.60889214 0.46796578 0.60810155\n",
            " 0.45843667 0.5625083  0.6664817  0.53736466 0.5332143  0.582153\n",
            " 0.5446965  0.5781457  0.4767682  0.6138713  0.51894444 0.4764201\n",
            " 0.5684611  0.52746075 0.5694768  0.6174771  0.602925   0.5790183\n",
            " 0.60876435 0.5453641  0.57465047 0.56147546 0.61008424 0.6080319\n",
            " 0.5960271  0.5799739  0.614412   0.5414893  0.54653805 0.5965535\n",
            " 0.6103541  0.48179215 0.58066434 0.5808007  0.55071133 0.5227229\n",
            " 0.5722701  0.466726   0.52105683 0.6565682  0.58673733 0.5794732\n",
            " 0.48623437 0.6164815  0.42824048 0.59378976 0.5744359  0.49478406\n",
            " 0.5726716  0.5591294  0.60309285 0.57843465 0.62203664 0.4344136\n",
            " 0.6230828  0.6184394  0.543369   0.5800645  0.46436375 0.544233\n",
            " 0.5780923  0.55177563 0.60231084 0.6158826  0.5656039  0.6151778\n",
            " 0.52598923 0.5680682  0.5035474  0.57431763 0.5095393  0.61839074\n",
            " 0.6193177  0.5717723  0.5336024  0.60355157 0.53321046 0.5496289\n",
            " 0.59133023 0.59523076 0.5818698  0.5701825  0.5710189  0.61020535\n",
            " 0.58907574 0.6544892  0.6012656  0.58246964 0.5955674  0.62339467\n",
            " 0.5437104  0.582956   0.62774724 0.5667111  0.48092908 0.6225402\n",
            " 0.56786317 0.5779397  0.5488593  0.57054585 0.57058877 0.59413785\n",
            " 0.5759837  0.54835767 0.563791   0.5415856  0.5990159  0.5928666\n",
            " 0.55545396 0.62466305 0.5365445  0.56586236 0.5799281  0.610789\n",
            " 0.5622098  0.5690829  0.603151   0.5686633  0.5291535  0.6147334\n",
            " 0.52974766 0.52651757 0.54835004 0.57317895 0.593743   0.6135804\n",
            " 0.5135495  0.56596535 0.529597   0.5838105  0.56256074 0.5248782\n",
            " 0.5873229  0.47903222 0.6014001  0.60213345 0.4741246  0.580033\n",
            " 0.50928277 0.5001399  0.54578465 0.616039   0.562349   0.580795\n",
            " 0.5870473  0.5392234  0.51273507 0.5692975  0.5616929  0.6610467\n",
            " 0.50559586 0.53191155 0.51572484 0.54398125 0.5665385  0.55479497\n",
            " 0.59386605 0.59931344 0.4806916  0.5786187  0.51909035 0.5811841\n",
            " 0.56867665 0.5840909  0.53558034 0.58450097 0.5688569  0.62601537\n",
            " 0.5835435  0.570049   0.56828946 0.6044547  0.61129254 0.5016877\n",
            " 0.5613076  0.6042773  0.5889422  0.54523534 0.60989827 0.5240275\n",
            " 0.6266658  0.6246087  0.5604417  0.51386994 0.5681836  0.62160844\n",
            " 0.47023743 0.5159289  0.6091353  0.5926263  0.5976197  0.5783431\n",
            " 0.4267537  0.5622899  0.5063359  0.538552   0.62199754 0.5971257\n",
            " 0.5172259  0.4664666  0.61623067 0.51391095 0.5866038  0.5613639\n",
            " 0.588844   0.5578305  0.5734708  0.56782883 0.59646195 0.5700566\n",
            " 0.59356946 0.5171792  0.5415284  0.53804463 0.5790555  0.5940358\n",
            " 0.60751027 0.56917447 0.6270148  0.57482594 0.44175214 0.50968903\n",
            " 0.53101224 0.5466067  0.58394593 0.5899665  0.591315   0.44429272\n",
            " 0.44321316 0.5906188  0.6199586  0.46868962 0.64510316 0.64888257\n",
            " 0.5362746  0.51279896 0.61168164 0.5432822  0.61617917 0.56829804\n",
            " 0.64498776 0.5779349  0.5527503  0.5170838  0.61430997 0.49277467\n",
            " 0.56446236 0.42835397 0.52736443 0.5753991  0.62640065 0.66283196\n",
            " 0.51750916 0.5564887  0.528258   0.56935567 0.6001536  0.47403687\n",
            " 0.5555884  0.5834176  0.5125844  0.4819724  0.60243386 0.642801\n",
            " 0.52478    0.48388165 0.51269025 0.46359318 0.52626294 0.5917384\n",
            " 0.56769055 0.5961129  0.56984204 0.6373469  0.52072114 0.5812976\n",
            " 0.63580865 0.4649083  0.61126107 0.5854661  0.54934186 0.58906716\n",
            " 0.619682   0.57738084 0.6115367  0.5707652  0.51842564 0.5353095\n",
            " 0.62745637 0.4912383  0.63137215 0.6106097  0.61929387 0.516669\n",
            " 0.5479724 ]\n",
            "[0.53919035 0.50904393 0.57708872 0.65116279 0.72437554 1.\n",
            " 0.57192076 0.5667528  0.51248923 0.60292851 0.45908699 0.41774332\n",
            " 0.62187769 0.56589147 0.35400517 0.57278208 0.4918174  0.55900086\n",
            " 0.5503876  0.48923342 0.51851852 0.42807924 0.58656331 0.55555556\n",
            " 0.60378984 0.57364341 0.42635659 0.5503876  0.50990525 0.54349699\n",
            " 0.45391904 0.53919035 0.44444444 0.56158484 0.49095607 0.49095607\n",
            " 0.51679587 0.50387597 0.37726098 0.41429802 0.58397933 0.56330749\n",
            " 0.60378984 0.62015504 0.53402239 0.60120586 0.53057709 0.43496985\n",
            " 0.41429802 0.38845823 0.58397933 0.57622739 0.43152455 0.25064599\n",
            " 0.63996555 0.47028424 0.54091301 0.60981912 0.41343669 0.64341085\n",
            " 0.5994832  0.57622739 0.61757106 0.42204996 0.48406546 0.59776055\n",
            " 0.47200689 0.44702842 0.5081826  0.59000861 0.45908699 0.45047373\n",
            " 0.38070629 0.60120586 0.59259259 0.56072351 0.69939707 0.52024117\n",
            " 0.68217054 0.54866494 0.60981912 0.63910422 0.59000861 0.53229974\n",
            " 0.51162791 0.44272179 0.60120586 0.58225668 0.52024117 0.61068045\n",
            " 0.4918174  0.57450474 0.45822567 0.61757106 0.68217054 0.63824289\n",
            " 0.59345392 0.59173127 0.47286822 0.65374677 0.50559862 0.57795004\n",
            " 0.57795004 0.52540913 0.4918174  0.625323   0.47975883 0.50732127\n",
            " 0.70111972 0.44875108 0.66408269 0.56589147 0.60465116 0.43410853\n",
            " 0.51765719 0.40310078 0.39276486 0.62790698 0.60465116 0.60723514\n",
            " 0.56158484 0.58570198 0.6416882  0.39965547 0.5503876  0.50301464\n",
            " 0.47459087 0.67011197 0.58828596 0.56244617 0.42807924 0.59259259\n",
            " 0.48923342 0.49612403 0.50990525 0.53919035 0.46425495 0.48062016\n",
            " 0.54349699 0.68044789 0.6416882  0.48406546 0.41085271 0.42980189\n",
            " 0.64427218 0.63652024 0.59345392 0.51937984 0.583118   0.51421189\n",
            " 0.625323   0.6089578  0.53488372 0.61670973 0.43496985 0.54091301\n",
            " 0.43152455 0.6124031  0.7329888  0.54091301 0.54608096 0.37639966\n",
            " 0.49440138 0.48751077 0.65374677 0.63910422 0.67700258 0.4461671\n",
            " 0.56761413 0.36520241 0.45305771 0.62273902 0.53229974 0.51421189\n",
            " 0.40913006 0.59173127 0.55900086 0.51248923 0.57536606 0.61498708\n",
            " 0.38242894 0.49784668 0.43152455 0.61068045 0.52799311 0.5047373\n",
            " 0.46683893 0.61154177 0.49870801 0.40826873 0.50990525 0.50301464\n",
            " 0.40310078 0.54521964 0.52971576 0.53143842 0.35658915 0.60034453\n",
            " 0.55813953 0.32213609 0.56847545 0.54263566 0.37639966 0.44099914\n",
            " 0.60981912 0.63996555 0.30577089 0.47459087 0.45305771 0.47717485\n",
            " 0.6089578  0.55727821 0.53402239 0.60551249 0.4332472  0.6089578\n",
            " 0.42291128 0.55555556 0.64685616 0.54091301 0.55555556 0.5667528\n",
            " 0.49956934 0.5667528  0.43927649 0.55555556 0.5374677  0.46511628\n",
            " 0.51593454 0.44099914 0.5047373  0.64685616 0.61843239 0.51851852\n",
            " 0.62790698 0.54263566 0.53229974 0.4918174  0.4754522  0.5374677\n",
            " 0.48148148 0.51248923 0.56503015 0.51507321 0.54177433 0.53919035\n",
            " 0.67011197 0.4203273  0.58656331 0.3712317  0.4952627  0.49870801\n",
            " 0.625323   0.2962963  0.40826873 0.69853575 0.56933678 0.53488372\n",
            " 0.51421189 0.57105943 0.82773471 0.61498708 0.63910422 0.49095607\n",
            " 0.53660637 0.52024117 0.45908699 0.53316107 0.62015504 0.32816537\n",
            " 0.58139535 0.55986219 0.50387597 0.48148148 0.4039621  0.45564169\n",
            " 0.5538329  0.45564169 0.38587425 0.66236003 0.51507321 0.60120586\n",
            " 0.51765719 0.49009475 0.49784668 0.42291128 0.50732127 0.57364341\n",
            " 0.66838932 0.52627046 0.53660637 0.62015504 0.47975883 0.45908699\n",
            " 0.60206718 0.48320413 0.58570198 0.48492679 0.45391904 0.60723514\n",
            " 0.37295435 0.56847545 0.48148148 0.54263566 0.45650301 0.52799311\n",
            " 0.58139535 0.43496985 0.55727821 0.54177433 0.40913006 0.62360034\n",
            " 0.4952627  0.54263566 0.45305771 0.50129199 0.47975883 0.5211025\n",
            " 0.69509044 0.4918174  0.44358312 0.52368648 0.47028424 0.5211025\n",
            " 0.49612403 0.6546081  0.60809647 0.62790698 0.48234281 0.66322136\n",
            " 0.46511628 0.53574505 0.42291128 0.53229974 0.4005168  0.52540913\n",
            " 0.46167097 0.49267873 0.47975883 0.62962963 0.46511628 0.63049096\n",
            " 0.43410853 0.54694229 0.53057709 0.5667528  0.50559862 0.41946598\n",
            " 0.4918174  0.45908699 0.65116279 0.52282515 0.47459087 0.47286822\n",
            " 0.45822567 0.40826873 0.51937984 0.67011197 0.51765719 0.51593454\n",
            " 0.35486649 0.56503015 0.43669251 0.5047373  0.54435831 0.38845823\n",
            " 0.45564169 0.49698536 0.43496985 0.49870801 0.5211025  0.56072351\n",
            " 0.68475452 0.66149871 0.46942291 0.52885444 0.48837209 0.34969854\n",
            " 0.56847545 0.54091301 0.51162791 0.50215332 0.38931955 0.62015504\n",
            " 0.51421189 0.47631352 0.52885444 0.53402239 0.69250646 0.43927649\n",
            " 0.39534884 0.56158484 0.50301464 0.5796727  0.5374677  0.46339363\n",
            " 0.71231697 0.59259259 0.49698536 0.45736434 0.56072351 0.65202412\n",
            " 0.41429802 0.47717485 0.4496124  0.56847545 0.47286822 0.58914729\n",
            " 0.36864772 0.49956934 0.43927649 0.5047373  0.74677003 0.62704565\n",
            " 0.51162791 0.47114556 0.63996555 0.46511628 0.66666667 0.45822567\n",
            " 0.31955211 0.55900086 0.53229974 0.45478036 0.49440138 0.54005168\n",
            " 0.32988803 0.43669251 0.48664944 0.30749354 0.40999139 0.58656331\n",
            " 0.86046512 0.5211025  0.5538329  0.4754522  0.34453058 0.58484065\n",
            " 0.52713178 0.47372954 0.63221361 0.69853575 0.6709733  0.33936262\n",
            " 0.3875969  0.42894057 0.58139535 0.4754522  0.625323   0.56072351\n",
            " 0.44013781 0.51593454 0.48492679 0.48751077 0.60034453 0.61929371\n",
            " 0.50301464 0.52282515 0.55641688 0.49009475 0.59173127 0.44444444\n",
            " 0.52196382 0.44530577 0.47975883 0.33850129 0.49009475 0.5960379\n",
            " 0.45047373 0.55986219 0.46683893 0.43583118 0.52024117 0.39879414\n",
            " 0.46339363 0.52540913 0.5374677  0.44099914 0.45822567 0.62704565\n",
            " 0.46942291 0.45822567 0.4203273  0.374677   0.42204996 0.51937984\n",
            " 0.47631352 0.52799311 0.55555556 0.55986219 0.49870801 0.36778639\n",
            " 0.71490095 0.59689922 0.63910422 0.4788975  0.56072351 0.56416882\n",
            " 0.49612403 0.55986219 0.63393626 0.56072351 0.42807924 0.47631352\n",
            " 0.72782084 0.46511628 0.66063738 0.52368648 0.50904393 0.44788975\n",
            " 0.5047373 ]\n",
            "The trained model has an aproximate error rate of -45.88657218987694 which equates to -8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although no linear relationship was uncovered, it can be argued there is a relationship present due to the RMSE value which is lower than the mean value. This relationship is also shown in the error rate which is comparative to the other models produced."
      ],
      "metadata": {
        "id": "rYGXd0opI-i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gust\n",
        "As with sea level pressure, no linear relationship between the maximum gust and the number of collisions was uncovered."
      ],
      "metadata": {
        "id": "lHX1HoDlQwJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data\n",
        "df_gust_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/gust_clean_dnn.csv', index_col=0, )\n",
        "print(df_gust_dnn[:6])"
      ],
      "metadata": {
        "id": "Tf_wMIWXQ7zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb0c10a-cac4-4ce6-ed26-a80063427b53"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd  gust  \\\n",
            "3   2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0  20.0   \n",
            "11  2020  15             508  43.9  38.3  1019.4    8.2   5.4   14.0  15.0   \n",
            "12  2021   1             257  39.6  29.3  1029.3   10.0   7.6   14.0  20.0   \n",
            "14  2022  25             235  41.6  31.8  1013.2   10.0   9.6   15.0  19.0   \n",
            "18  2021   3             186  41.1  32.3  1018.0   10.0  10.3   19.0  27.0   \n",
            "19  2020   2             413  39.6  28.9  1011.8   10.0  13.0   19.0  26.0   \n",
            "\n",
            "    ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "3   ...    0    0    0    0    0    0    0    1    0    0  \n",
            "11  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "12  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "14  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "18  ...    0    0    0    0    0    1    0    0    0    0  \n",
            "19  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_gust_dnn = df_gust_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','mxpsd','slp','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_gust_dnn = df_gust_dnn.loc[df_gust_dnn[\"year\"] != 2012]\n",
        "df_gust_dnn = df_gust_dnn.loc[df_gust_dnn[\"year\"] < 2020]\n",
        "#Move target col to end\n",
        "cols = df_gust_dnn['NUM_COLLISIONS']\n",
        "df_gust_dnn = df_gust_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_gust_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_gust_dnn[:6])\n",
        "df_gust_dnn.describe()"
      ],
      "metadata": {
        "id": "oTbpzolhQ7zh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "3f6a41f0-dc94-4261-b8e9-c7a5114f6c2f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  gust  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "74  2016  17  18.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "76  2014   9  20.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "79  2019  19  21.0    0    0    0    0    1    0    0  ...    0    0    1   \n",
            "80  2015  11  17.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "83  2015  29  20.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "85  2019  13  15.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "74    0    1    0    0    0    0             451  \n",
            "76    0    0    0    0    0    1             561  \n",
            "79    0    0    0    0    0    0             479  \n",
            "80    0    1    0    0    0    0             341  \n",
            "83    0    0    0    0    0    1             519  \n",
            "85    0    1    0    0    0    0             374  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             year           da         gust          Apr          Aug  \\\n",
              "count  1629.00000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean   2015.91283    15.702885    27.511602     0.095764     0.042357   \n",
              "std       2.01341     8.667634     7.366770     0.294358     0.201465   \n",
              "min    2013.00000     1.000000    14.000000     0.000000     0.000000   \n",
              "25%    2014.00000     8.000000    22.000000     0.000000     0.000000   \n",
              "50%    2016.00000    16.000000    26.000000     0.000000     0.000000   \n",
              "75%    2018.00000    23.000000    31.100000     0.000000     0.000000   \n",
              "max    2019.00000    31.000000    71.100000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000  ...   \n",
              "mean      0.104359     0.095150     0.108656     0.046041     0.061387  ...   \n",
              "std       0.305819     0.293513     0.311302     0.209637     0.240113  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean      0.087784     0.071209     0.143646     0.139963     0.141191   \n",
              "std       0.283067     0.257253     0.350839     0.347055     0.348325   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000     1629.000000  \n",
              "mean      0.139963     0.151627     0.138122     0.145488      596.513198  \n",
              "std       0.347055     0.358769     0.345133     0.352700      104.479660  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      526.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      597.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      663.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bf76ed4-32b7-4ebf-a260-839a7a113424\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>gust</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1629.00000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.91283</td>\n",
              "      <td>15.702885</td>\n",
              "      <td>27.511602</td>\n",
              "      <td>0.095764</td>\n",
              "      <td>0.042357</td>\n",
              "      <td>0.104359</td>\n",
              "      <td>0.095150</td>\n",
              "      <td>0.108656</td>\n",
              "      <td>0.046041</td>\n",
              "      <td>0.061387</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087784</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.143646</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.151627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>596.513198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.01341</td>\n",
              "      <td>8.667634</td>\n",
              "      <td>7.366770</td>\n",
              "      <td>0.294358</td>\n",
              "      <td>0.201465</td>\n",
              "      <td>0.305819</td>\n",
              "      <td>0.293513</td>\n",
              "      <td>0.311302</td>\n",
              "      <td>0.209637</td>\n",
              "      <td>0.240113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.257253</td>\n",
              "      <td>0.350839</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.348325</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.358769</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>104.479660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>526.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>597.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.00000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>663.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.00000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bf76ed4-32b7-4ebf-a260-839a7a113424')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3bf76ed4-32b7-4ebf-a260-839a7a113424 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3bf76ed4-32b7-4ebf-a260-839a7a113424');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "shuffle = df_gust_dnn.iloc[np.random.permutation(len(df_gust_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "a_4bidEbQ7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e020a0-d58f-4a34-e7a1-40efb2bc8be1"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  gust  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "1346  2018  19  21.0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "1793  2017  20  27.0    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "2313  2014  22  19.0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "2261  2017   7  26.0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "2658  2018  11  24.1    0    0    0    0    0    0    0  ...    0    0    1   \n",
            "2396  2018  16  20.0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1346    1    0    0    0    0    0    0  \n",
            "1793    0    1    0    0    0    0    0  \n",
            "2313    0    0    0    0    1    0    0  \n",
            "2261    0    0    0    1    0    0    0  \n",
            "2658    0    1    0    0    0    0    0  \n",
            "2396    0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select last col as a target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "l4TDr10XQ7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6ae8d2-16a2-4230-ba48-a6d8a19db596"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1346    583\n",
            "1793    813\n",
            "2313    568\n",
            "2261    606\n",
            "2658    544\n",
            "2396    647\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "75AKCrz7Q7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec48fda-4fe1-4d8a-d86f-0f868f64e8b4"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_gust', ignore_errors=True)\n",
        "\n",
        "#Setup model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_gust', hidden_units=[23,19,11], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "v4av8KXMQ7zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503b0384-6151-429f-8287-8c8b44fa9c2a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180f5fed0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_gust', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_gust/model.ckpt.\n",
            "INFO:tensorflow:loss = 17590.316, step = 1\n",
            "INFO:tensorflow:global_step/sec: 382.345\n",
            "INFO:tensorflow:loss = 0.15763947, step = 101 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.143\n",
            "INFO:tensorflow:loss = 0.02768094, step = 201 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.775\n",
            "INFO:tensorflow:loss = 0.02600477, step = 301 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.587\n",
            "INFO:tensorflow:loss = 0.025448497, step = 401 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.087\n",
            "INFO:tensorflow:loss = 0.016932437, step = 501 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.131\n",
            "INFO:tensorflow:loss = 0.022061246, step = 601 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.747\n",
            "INFO:tensorflow:loss = 0.020206688, step = 701 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.45\n",
            "INFO:tensorflow:loss = 0.016071862, step = 801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.137\n",
            "INFO:tensorflow:loss = 0.022033911, step = 901 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.341\n",
            "INFO:tensorflow:loss = 0.01065508, step = 1001 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.467\n",
            "INFO:tensorflow:loss = 0.015383666, step = 1101 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.222\n",
            "INFO:tensorflow:loss = 0.018492209, step = 1201 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.853\n",
            "INFO:tensorflow:loss = 0.01865209, step = 1301 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.01\n",
            "INFO:tensorflow:loss = 0.015423054, step = 1401 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.522\n",
            "INFO:tensorflow:loss = 0.015782176, step = 1501 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.804\n",
            "INFO:tensorflow:loss = 0.014998669, step = 1601 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.057\n",
            "INFO:tensorflow:loss = 0.01300603, step = 1701 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.1\n",
            "INFO:tensorflow:loss = 0.015856035, step = 1801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.268\n",
            "INFO:tensorflow:loss = 0.01618066, step = 1901 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.533\n",
            "INFO:tensorflow:loss = 0.014182078, step = 2001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.658\n",
            "INFO:tensorflow:loss = 0.019931946, step = 2101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.74\n",
            "INFO:tensorflow:loss = 0.011236677, step = 2201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.474\n",
            "INFO:tensorflow:loss = 0.010185135, step = 2301 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.832\n",
            "INFO:tensorflow:loss = 0.010925912, step = 2401 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.53\n",
            "INFO:tensorflow:loss = 0.008026052, step = 2501 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.014\n",
            "INFO:tensorflow:loss = 0.0072260695, step = 2601 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.831\n",
            "INFO:tensorflow:loss = 0.012288099, step = 2701 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.043\n",
            "INFO:tensorflow:loss = 0.008888613, step = 2801 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.892\n",
            "INFO:tensorflow:loss = 0.010076074, step = 2901 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.896\n",
            "INFO:tensorflow:loss = 0.008318121, step = 3001 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.375\n",
            "INFO:tensorflow:loss = 0.007197695, step = 3101 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.505\n",
            "INFO:tensorflow:loss = 0.00506469, step = 3201 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.742\n",
            "INFO:tensorflow:loss = 0.006998185, step = 3301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.53\n",
            "INFO:tensorflow:loss = 0.005173073, step = 3401 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.994\n",
            "INFO:tensorflow:loss = 0.0074057495, step = 3501 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.836\n",
            "INFO:tensorflow:loss = 0.009959235, step = 3601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.761\n",
            "INFO:tensorflow:loss = 0.0069604935, step = 3701 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 286.431\n",
            "INFO:tensorflow:loss = 0.0075102854, step = 3801 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.296\n",
            "INFO:tensorflow:loss = 0.0080135185, step = 3901 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.024\n",
            "INFO:tensorflow:loss = 0.0068547735, step = 4001 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.567\n",
            "INFO:tensorflow:loss = 0.0060051284, step = 4101 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.138\n",
            "INFO:tensorflow:loss = 0.007897478, step = 4201 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.018\n",
            "INFO:tensorflow:loss = 0.008695474, step = 4301 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.19\n",
            "INFO:tensorflow:loss = 0.0059855347, step = 4401 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.443\n",
            "INFO:tensorflow:loss = 0.0064470144, step = 4501 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.291\n",
            "INFO:tensorflow:loss = 0.0071354234, step = 4601 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.414\n",
            "INFO:tensorflow:loss = 0.00679786, step = 4701 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.358\n",
            "INFO:tensorflow:loss = 0.007278029, step = 4801 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.14\n",
            "INFO:tensorflow:loss = 0.007850241, step = 4901 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.995\n",
            "INFO:tensorflow:loss = 0.006853246, step = 5001 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.9\n",
            "INFO:tensorflow:loss = 0.009673155, step = 5101 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.028\n",
            "INFO:tensorflow:loss = 0.009862028, step = 5201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.097\n",
            "INFO:tensorflow:loss = 0.0075580496, step = 5301 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.418\n",
            "INFO:tensorflow:loss = 0.0038111883, step = 5401 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.554\n",
            "INFO:tensorflow:loss = 0.005785291, step = 5501 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.742\n",
            "INFO:tensorflow:loss = 0.005891057, step = 5601 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.979\n",
            "INFO:tensorflow:loss = 0.008034136, step = 5701 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.087\n",
            "INFO:tensorflow:loss = 0.008426403, step = 5801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.924\n",
            "INFO:tensorflow:loss = 0.008678697, step = 5901 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.395\n",
            "INFO:tensorflow:loss = 0.005947882, step = 6001 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.425\n",
            "INFO:tensorflow:loss = 0.004473101, step = 6101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.633\n",
            "INFO:tensorflow:loss = 0.007186715, step = 6201 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.227\n",
            "INFO:tensorflow:loss = 0.0046763094, step = 6301 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.88\n",
            "INFO:tensorflow:loss = 0.0056250286, step = 6401 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.824\n",
            "INFO:tensorflow:loss = 0.004618496, step = 6501 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.662\n",
            "INFO:tensorflow:loss = 0.003240937, step = 6601 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.113\n",
            "INFO:tensorflow:loss = 0.0039913245, step = 6701 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.185\n",
            "INFO:tensorflow:loss = 0.008530461, step = 6801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.032\n",
            "INFO:tensorflow:loss = 0.027757699, step = 6901 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.069\n",
            "INFO:tensorflow:loss = 0.006351482, step = 7001 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.303\n",
            "INFO:tensorflow:loss = 0.0058640195, step = 7101 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.38\n",
            "INFO:tensorflow:loss = 0.006816173, step = 7201 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.928\n",
            "INFO:tensorflow:loss = 0.0046019675, step = 7301 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.548\n",
            "INFO:tensorflow:loss = 0.03459889, step = 7401 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.094\n",
            "INFO:tensorflow:loss = 0.007980447, step = 7501 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.665\n",
            "INFO:tensorflow:loss = 0.009221748, step = 7601 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.618\n",
            "INFO:tensorflow:loss = 0.015703984, step = 7701 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.408\n",
            "INFO:tensorflow:loss = 0.00629535, step = 7801 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.467\n",
            "INFO:tensorflow:loss = 0.0071337614, step = 7901 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.925\n",
            "INFO:tensorflow:loss = 0.015327483, step = 8001 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.619\n",
            "INFO:tensorflow:loss = 0.0037271534, step = 8101 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.177\n",
            "INFO:tensorflow:loss = 0.0047651716, step = 8201 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.908\n",
            "INFO:tensorflow:loss = 0.014984244, step = 8301 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.732\n",
            "INFO:tensorflow:loss = 0.007650955, step = 8401 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.615\n",
            "INFO:tensorflow:loss = 0.012347648, step = 8501 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.185\n",
            "INFO:tensorflow:loss = 0.027720314, step = 8601 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.991\n",
            "INFO:tensorflow:loss = 0.010529806, step = 8701 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.968\n",
            "INFO:tensorflow:loss = 0.052452013, step = 8801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.91\n",
            "INFO:tensorflow:loss = 0.02220778, step = 8901 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.394\n",
            "INFO:tensorflow:loss = 0.031899408, step = 9001 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.157\n",
            "INFO:tensorflow:loss = 0.059110012, step = 9101 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.343\n",
            "INFO:tensorflow:loss = 0.0077906866, step = 9201 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 444.187\n",
            "INFO:tensorflow:loss = 0.022589486, step = 9301 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.83\n",
            "INFO:tensorflow:loss = 0.009881642, step = 9401 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.962\n",
            "INFO:tensorflow:loss = 0.0048271855, step = 9501 (0.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.825\n",
            "INFO:tensorflow:loss = 0.005904177, step = 9601 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.867\n",
            "INFO:tensorflow:loss = 0.03330381, step = 9701 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 400.35\n",
            "INFO:tensorflow:loss = 0.012832437, step = 9801 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.634\n",
            "INFO:tensorflow:loss = 0.013877558, step = 9901 (0.297 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_gust/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0052700164.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_gust/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 83.0932609202468\n",
            "Just using average = 598.0214888718342 has RMSE of 102.22298263083186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_gust', hidden_units=[23,19,11], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NdhxllohQ7zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ef9f16-e8fa-4d67-cddf-0b948ec47436"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180c94650>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_gust', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326\n",
            "326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_gust/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5188271  0.36390457 0.49615058 0.56507266 0.51946986 0.47704086\n",
            " 0.48370704 0.49621543 0.47898063 0.4349266  0.56818354 0.5488583\n",
            " 0.48026428 0.42894325 0.4329563  0.42191657 0.35769233 0.5655476\n",
            " 0.5220982  0.46409377 0.37677345 0.50938    0.41703567 0.4025627\n",
            " 0.5555798  0.39144668 0.40776405 0.3493229  0.41965637 0.52045786\n",
            " 0.4768215  0.51956904 0.48221168 0.37879142 0.54401743 0.548946\n",
            " 0.5190159  0.4634796  0.55416644 0.45651206 0.46388015 0.42749175\n",
            " 0.48287925 0.42678413 0.47890243 0.49764976 0.40844688 0.44855842\n",
            " 0.45801505 0.54503787 0.4487072  0.5102097  0.4700218  0.4360977\n",
            " 0.54078066 0.47660407 0.4482666  0.50360453 0.51975214 0.5024048\n",
            " 0.4851223  0.50352824 0.5201527  0.4850479  0.5313755  0.486652\n",
            " 0.4737049  0.5966431  0.37022552 0.47613868 0.45756492 0.5713154\n",
            " 0.48762283 0.5024067  0.41706237 0.51967394 0.5035378  0.5616566\n",
            " 0.4640747  0.35955963 0.594936   0.50145495 0.48008308 0.423328\n",
            " 0.37171516 0.52702487 0.5273453  0.36366233 0.56755793 0.52733004\n",
            " 0.48752746 0.5254513  0.4635025  0.48082122 0.50218356 0.3484417\n",
            " 0.45032844 0.48535308 0.49390945 0.5273167  0.48726043 0.36060867\n",
            " 0.4863945  0.5179688  0.45905265 0.5544678  0.41822585 0.56322634\n",
            " 0.46626434 0.42642173 0.4708782  0.4891735  0.5250393  0.5244919\n",
            " 0.4621502  0.5025383  0.34685668 0.56681406 0.5329319  0.53992236\n",
            " 0.51347697 0.4767433  0.4741169  0.5440422  0.36414108 0.4756008\n",
            " 0.38244972 0.47237548 0.47107086 0.5292164  0.5224167  0.4571949\n",
            " 0.5169884  0.5493046  0.46346244 0.47242126 0.47631416 0.4120594\n",
            " 0.3463131  0.447908   0.4738575  0.47621116 0.4800125  0.49004707\n",
            " 0.5188767  0.36191902 0.41484985 0.36213073 0.5101162  0.5143601\n",
            " 0.38955268 0.50670016 0.37902793 0.50290644 0.5164372  0.41710624\n",
            " 0.5156952  0.5138012  0.541206   0.5669037  0.5252167  0.5505158\n",
            " 0.47532424 0.51757014 0.47408637 0.47179946 0.48687896 0.43085822\n",
            " 0.4681221  0.381929   0.5768124  0.532724   0.5744473  0.51658785\n",
            " 0.57332575 0.49018058 0.5020119  0.51969874 0.5173451  0.42366752\n",
            " 0.4672695  0.37005195 0.520229   0.56268656 0.40576515 0.49029884\n",
            " 0.50623286 0.541227   0.47563323 0.48366508 0.5129887  0.4498993\n",
            " 0.530336   0.5346657  0.49909553 0.45816574 0.47347984 0.47093162\n",
            " 0.3655487  0.42317733 0.48526725 0.4793392  0.52574885 0.52766\n",
            " 0.4480091  0.36480483 0.4766899  0.46874198 0.44665107 0.46837577\n",
            " 0.3734108  0.49313697 0.4170414  0.5008751  0.5155579  0.45800552\n",
            " 0.46315154 0.43423423 0.3889881  0.51090205 0.5316082  0.5313412\n",
            " 0.427528   0.4501358  0.4399086  0.5677811  0.46611556 0.47745475\n",
            " 0.44809303 0.50270045 0.47346076 0.44116172 0.46167335 0.5760857\n",
            " 0.5315205  0.5240246  0.4580551  0.39009818 0.52961886 0.34525833\n",
            " 0.36132964 0.411285   0.47062454 0.4604126  0.5311943  0.5293728\n",
            " 0.4943405  0.39128646 0.47934303 0.47408256 0.49579772 0.5242535\n",
            " 0.43221816 0.5229603  0.40228233 0.5106598  0.46855697 0.5417725\n",
            " 0.47452125 0.51199687 0.37378082 0.5346199  0.3732849  0.4748493\n",
            " 0.42134055 0.46462402 0.4737278  0.50216067 0.46011886 0.48545608\n",
            " 0.36672172 0.5271393  0.4637352  0.489328   0.40617904 0.54710543\n",
            " 0.37310752 0.5260769  0.4820114  0.5958973  0.56447566 0.53976023\n",
            " 0.50091517 0.5172802  0.48121795 0.37369308 0.34558257 0.36659202\n",
            " 0.44480285 0.5248772  0.5552422  0.5062405  0.51108897 0.48579177\n",
            " 0.5278603  0.40662727 0.4908825  0.5149437  0.51300585 0.3786064\n",
            " 0.47093162 0.53122675 0.51342356 0.4986187  0.47790298 0.495401\n",
            " 0.4679962  0.4992691  0.4773346  0.563295   0.5028473  0.50249445\n",
            " 0.48173675 0.38233718 0.4049984  0.4640499  0.50537074 0.47298202\n",
            " 0.5344845  0.4486862  0.47361144 0.41900024 0.5250565  0.4177681\n",
            " 0.5171143  0.5190064 ]\n",
            "[0.52282515 0.33850129 0.59259259 0.66063738 0.54005168 0.59776055\n",
            " 0.49440138 0.48234281 0.4625323  0.48837209 0.62360034 0.52971576\n",
            " 0.48406546 0.49009475 0.4203273  0.41171404 0.43841516 0.67786391\n",
            " 0.51851852 0.54005168 0.42635659 0.49354005 0.33419466 0.49267873\n",
            " 0.50387597 0.4332472  0.36003445 0.40913006 0.50732127 0.54435831\n",
            " 0.52713178 0.55211025 0.5503876  0.37639966 0.60378984 0.64944014\n",
            " 0.54091301 0.47717485 0.64082687 0.52713178 0.48664944 0.54005168\n",
            " 0.53143842 0.34711456 0.4918174  0.57364341 0.36347976 0.54091301\n",
            " 0.49009475 0.59431525 0.53660637 0.52024117 0.47372954 0.46167097\n",
            " 0.59086994 0.50559862 0.57450474 0.51507321 0.62790698 0.51421189\n",
            " 0.4918174  0.49009475 0.68475452 0.40913006 0.64944014 0.40999139\n",
            " 0.57192076 0.66322136 0.38845823 0.54091301 0.52540913 0.63824289\n",
            " 0.53832903 0.5503876  0.39190353 0.54521964 0.51765719 0.59259259\n",
            " 0.57019811 0.38587425 0.68130922 0.56933678 0.53488372 0.50301464\n",
            " 0.39276486 0.51679587 0.56416882 0.42204996 0.54608096 0.58225668\n",
            " 0.52713178 0.59345392 0.55297158 0.52799311 0.58656331 0.32730405\n",
            " 0.50990525 0.46942291 0.43152455 0.68044789 0.6546081  0.38329027\n",
            " 0.51507321 0.49870801 0.5211025  0.59086994 0.36520241 0.58570198\n",
            " 0.39965547 0.47803618 0.4005168  0.5047373  0.60465116 0.45650301\n",
            " 0.51937984 0.58570198 0.42204996 0.54521964 0.60378984 0.60034453\n",
            " 0.39276486 0.55813953 0.60034453 0.58053402 0.40482343 0.54521964\n",
            " 0.42118863 0.4952627  0.56072351 0.56761413 0.53919035 0.51851852\n",
            " 0.35228252 0.60809647 0.45736434 0.47459087 0.51765719 0.43496985\n",
            " 0.32213609 0.60551249 0.46770026 0.47631352 0.5538329  0.60034453\n",
            " 0.60378984 0.38673557 0.40826873 0.26614987 0.43152455 0.55813953\n",
            " 0.38845823 0.36434109 0.40999139 0.57019811 0.42463394 0.43669251\n",
            " 0.40568475 0.50129199 0.58656331 0.583118   0.74677003 0.65719208\n",
            " 0.53919035 0.60809647 0.5047373  0.44099914 0.59345392 0.43410853\n",
            " 0.51937984 0.41515935 0.62704565 0.53660637 0.62704565 0.73815676\n",
            " 0.57536606 0.49267873 0.4918174  0.49354005 0.50043066 0.56933678\n",
            " 0.44358312 0.43496985 0.60206718 0.65374677 0.43152455 0.5503876\n",
            " 0.45822567 0.6089578  0.49009475 0.47631352 0.44702842 0.51765719\n",
            " 0.56244617 0.48664944 0.63910422 0.43238587 0.53402239 0.4788975\n",
            " 0.40568475 0.49698536 0.6089578  0.44788975 0.45822567 0.5796727\n",
            " 0.49956934 0.34022394 0.62790698 0.58828596 0.45736434 0.52971576\n",
            " 0.50387597 0.28682171 0.47803618 0.54694229 0.5211025  0.34366925\n",
            " 0.58139535 0.49784668 0.44099914 0.54866494 0.54349699 0.7329888\n",
            " 0.51421189 0.45305771 0.42635659 0.66925065 0.45908699 0.53316107\n",
            " 0.35486649 0.64513351 0.53660637 0.46511628 0.47975883 0.66838932\n",
            " 0.59086994 0.62101637 0.54177433 0.3875969  0.68217054 0.35400517\n",
            " 0.37812231 0.36950904 0.53660637 0.34280792 0.51248923 0.61498708\n",
            " 0.58225668 0.48062016 0.41257537 0.51421189 0.49784668 0.44358312\n",
            " 0.44358312 0.5994832  0.48062016 0.5960379  0.37037037 0.65374677\n",
            " 0.51248923 0.42807924 0.4005168  0.6416882  0.37209302 0.42894057\n",
            " 0.43927649 0.44013781 0.56933678 0.46770026 0.47803618 0.51248923\n",
            " 0.416882   0.57881137 0.46597761 0.54349699 0.41429802 0.64082687\n",
            " 0.34797588 0.46339363 0.46942291 0.59689922 0.38242894 0.70542636\n",
            " 0.59689922 0.50990525 0.54780362 0.39534884 0.33850129 0.46597761\n",
            " 0.47459087 0.48406546 0.61326443 0.58914729 0.43152455 0.50129199\n",
            " 0.56158484 0.42635659 0.53832903 0.60206718 0.42291128 0.39362618\n",
            " 0.49440138 0.50387597 0.5211025  0.47372954 0.49095607 0.54866494\n",
            " 0.47372954 0.50301464 0.53919035 0.70887166 0.43496985 0.60551249\n",
            " 0.47286822 0.416882   0.46339363 0.48578811 0.49870801 0.50043066\n",
            " 0.53919035 0.58570198 0.55124892 0.49784668 0.35486649 0.50559862\n",
            " 0.53143842 0.61929371]\n",
            "The trained model has an aproximate error rate of 36.08413332271064 which equates to 6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model shows there is no relationship between gust and the number of collisions.\n",
        "\n",
        "The RMSE value is over 4 times the mean value indicating the model is unable to make accurate predictions. This is also reflected in the very high error rate."
      ],
      "metadata": {
        "id": "iCLt9ZygKrGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Maximum Sustained Wind Speed (mxpsd)\n",
        "In an attempt to predict the number of collisions given the maximum sustained wind speed a DNN will be used as no linear relationship was uncovered within assignment 1."
      ],
      "metadata": {
        "id": "tKaVpVT8T55I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "df_mxpsd_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/mxpsd_clean_dnn.csv', index_col=0, )\n",
        "print(df_mxpsd_dnn[:6])"
      ],
      "metadata": {
        "id": "_LbHDT1WUbJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3519bb6-91bb-4410-f782-a5fcffdca2be"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the cols not required\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','gust','slp','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.loc[df_mxpsd_dnn[\"year\"] != 2012]\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.loc[df_mxpsd_dnn[\"year\"] < 2020]\n",
        "#Move the target to the end\n",
        "cols = df_mxpsd_dnn['NUM_COLLISIONS']\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_mxpsd_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_mxpsd_dnn[:6])\n",
        "df_mxpsd_dnn.describe()"
      ],
      "metadata": {
        "id": "OoJSkkKHUbJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "3419d0da-73da-4915-e5a0-f1460622d2b2"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  mxpsd  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "49  2016  28    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da        mxpsd          Apr          Aug  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
              "mean   2016.001567    15.737172    17.240110     0.082256     0.084998   \n",
              "std       2.000587     8.797367     5.858333     0.274808     0.278933   \n",
              "min    2013.000000     1.000000     5.100000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000    13.000000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000    15.900000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000    20.000000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000    49.000000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000  ...   \n",
              "mean      0.084998     0.077164     0.084998     0.084998     0.082256  ...   \n",
              "std       0.278933     0.266904     0.278933     0.278933     0.274808  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
              "mean      0.084998     0.081473     0.142969     0.143361     0.142969   \n",
              "std       0.278933     0.273613     0.350110     0.350509     0.350110   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000     2553.000000  \n",
              "mean      0.142969     0.142969     0.142577     0.142186      599.033686  \n",
              "std       0.350110     0.350110     0.349710     0.349309      100.284761  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78d040fa-93d4-4adb-848c-886ad9ecae83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.001567</td>\n",
              "      <td>15.737172</td>\n",
              "      <td>17.240110</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.077164</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.081473</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.143361</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142577</td>\n",
              "      <td>0.142186</td>\n",
              "      <td>599.033686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000587</td>\n",
              "      <td>8.797367</td>\n",
              "      <td>5.858333</td>\n",
              "      <td>0.274808</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.266904</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.274808</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.273613</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350509</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.349710</td>\n",
              "      <td>0.349309</td>\n",
              "      <td>100.284761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78d040fa-93d4-4adb-848c-886ad9ecae83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78d040fa-93d4-4adb-848c-886ad9ecae83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78d040fa-93d4-4adb-848c-886ad9ecae83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the data\n",
        "shuffle = df_mxpsd_dnn.iloc[np.random.permutation(len(df_mxpsd_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "z1Ut5LCiUbJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b79e4a4-be03-47c8-a6a9-16ea486ab2ae"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  mxpsd  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "762   2016   3   19.0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "1093  2017  21   19.0    1    0    0    0    0    0    0  ...    0    0    0   \n",
            "3139  2015   3   14.0    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "2040  2014   2   14.0    0    0    0    0    0    1    0  ...    0    0    0   \n",
            "1266  2017  31   11.1    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "3456  2018   8   14.0    0    0    1    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "762     0    0    0    0    0    0    1  \n",
            "1093    0    0    0    0    1    0    0  \n",
            "3139    0    1    0    0    0    0    0  \n",
            "2040    0    0    0    0    0    1    0  \n",
            "1266    0    0    0    0    0    1    0  \n",
            "3456    1    0    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the target as the last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "QibQoUleUbJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a9676b-f817-4995-9e83-e7120c74c83d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "762     625\n",
            "1093    690\n",
            "3139    655\n",
            "2040    658\n",
            "1266    669\n",
            "3456    652\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "-C_tqkmUUbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cc8b28-7c20-4b35-a486-219a263b8255"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_mxpsd', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[17,13,7], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "# Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "C3O7xWeMUbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c7e460-fbcd-40d6-c3cb-1a5823f6e807"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184aec1d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_mxpsd/model.ckpt.\n",
            "INFO:tensorflow:loss = 3820.8137, step = 1\n",
            "INFO:tensorflow:global_step/sec: 399.426\n",
            "INFO:tensorflow:loss = 0.10032459, step = 101 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.258\n",
            "INFO:tensorflow:loss = 0.09438558, step = 201 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.886\n",
            "INFO:tensorflow:loss = 0.06858734, step = 301 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.562\n",
            "INFO:tensorflow:loss = 0.088231534, step = 401 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.642\n",
            "INFO:tensorflow:loss = 0.06222921, step = 501 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.405\n",
            "INFO:tensorflow:loss = 0.06289874, step = 601 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.426\n",
            "INFO:tensorflow:loss = 0.05743025, step = 701 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.505\n",
            "INFO:tensorflow:loss = 0.054177824, step = 801 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.873\n",
            "INFO:tensorflow:loss = 0.03399149, step = 901 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.954\n",
            "INFO:tensorflow:loss = 0.0346131, step = 1001 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.71\n",
            "INFO:tensorflow:loss = 0.039342903, step = 1101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.493\n",
            "INFO:tensorflow:loss = 0.034277227, step = 1201 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.393\n",
            "INFO:tensorflow:loss = 0.023548998, step = 1301 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.643\n",
            "INFO:tensorflow:loss = 0.01972928, step = 1401 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.023\n",
            "INFO:tensorflow:loss = 0.02265593, step = 1501 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.132\n",
            "INFO:tensorflow:loss = 0.020001786, step = 1601 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.03\n",
            "INFO:tensorflow:loss = 0.011481931, step = 1701 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.127\n",
            "INFO:tensorflow:loss = 0.014681353, step = 1801 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.338\n",
            "INFO:tensorflow:loss = 0.014938001, step = 1901 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.996\n",
            "INFO:tensorflow:loss = 0.013214126, step = 2001 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.803\n",
            "INFO:tensorflow:loss = 0.012796938, step = 2101 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.596\n",
            "INFO:tensorflow:loss = 0.009997603, step = 2201 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.588\n",
            "INFO:tensorflow:loss = 0.009204859, step = 2301 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.051\n",
            "INFO:tensorflow:loss = 0.008152517, step = 2401 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.632\n",
            "INFO:tensorflow:loss = 0.006715714, step = 2501 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.755\n",
            "INFO:tensorflow:loss = 0.00841695, step = 2601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.153\n",
            "INFO:tensorflow:loss = 0.006338844, step = 2701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.654\n",
            "INFO:tensorflow:loss = 0.0064210556, step = 2801 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.828\n",
            "INFO:tensorflow:loss = 0.00971571, step = 2901 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.084\n",
            "INFO:tensorflow:loss = 0.008801206, step = 3001 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.656\n",
            "INFO:tensorflow:loss = 0.0059172297, step = 3101 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.032\n",
            "INFO:tensorflow:loss = 0.0052744355, step = 3201 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.062\n",
            "INFO:tensorflow:loss = 0.0059610326, step = 3301 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.7\n",
            "INFO:tensorflow:loss = 0.004939149, step = 3401 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.557\n",
            "INFO:tensorflow:loss = 0.0052322512, step = 3501 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.754\n",
            "INFO:tensorflow:loss = 0.005317577, step = 3601 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.003\n",
            "INFO:tensorflow:loss = 0.0053719375, step = 3701 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.958\n",
            "INFO:tensorflow:loss = 0.00844981, step = 3801 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.352\n",
            "INFO:tensorflow:loss = 0.0061403215, step = 3901 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.376\n",
            "INFO:tensorflow:loss = 0.0040605497, step = 4001 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.629\n",
            "INFO:tensorflow:loss = 0.0040252563, step = 4101 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.945\n",
            "INFO:tensorflow:loss = 0.006548074, step = 4201 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.393\n",
            "INFO:tensorflow:loss = 0.005518563, step = 4301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.078\n",
            "INFO:tensorflow:loss = 0.0044178795, step = 4401 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.481\n",
            "INFO:tensorflow:loss = 0.0051078107, step = 4501 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.02\n",
            "INFO:tensorflow:loss = 0.006510229, step = 4601 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.02\n",
            "INFO:tensorflow:loss = 0.0077516343, step = 4701 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.762\n",
            "INFO:tensorflow:loss = 0.0040545315, step = 4801 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.875\n",
            "INFO:tensorflow:loss = 0.0047529535, step = 4901 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.02\n",
            "INFO:tensorflow:loss = 0.0032760901, step = 5001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.777\n",
            "INFO:tensorflow:loss = 0.0066870516, step = 5101 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.412\n",
            "INFO:tensorflow:loss = 0.0035467814, step = 5201 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.237\n",
            "INFO:tensorflow:loss = 0.0055929776, step = 5301 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.408\n",
            "INFO:tensorflow:loss = 0.004394261, step = 5401 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.247\n",
            "INFO:tensorflow:loss = 0.004921805, step = 5501 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.476\n",
            "INFO:tensorflow:loss = 0.005311965, step = 5601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 447.658\n",
            "INFO:tensorflow:loss = 0.0058513302, step = 5701 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.394\n",
            "INFO:tensorflow:loss = 0.004560776, step = 5801 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.086\n",
            "INFO:tensorflow:loss = 0.0038703878, step = 5901 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.79\n",
            "INFO:tensorflow:loss = 0.0058115153, step = 6001 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.215\n",
            "INFO:tensorflow:loss = 0.0059410883, step = 6101 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.892\n",
            "INFO:tensorflow:loss = 0.0042044534, step = 6201 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.348\n",
            "INFO:tensorflow:loss = 0.0058960523, step = 6301 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.587\n",
            "INFO:tensorflow:loss = 0.0033441326, step = 6401 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.081\n",
            "INFO:tensorflow:loss = 0.0070351753, step = 6501 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.242\n",
            "INFO:tensorflow:loss = 0.005645438, step = 6601 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.814\n",
            "INFO:tensorflow:loss = 0.0043623056, step = 6701 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.207\n",
            "INFO:tensorflow:loss = 0.007083628, step = 6801 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.436\n",
            "INFO:tensorflow:loss = 0.015764508, step = 6901 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.114\n",
            "INFO:tensorflow:loss = 0.0052931886, step = 7001 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.852\n",
            "INFO:tensorflow:loss = 0.004208502, step = 7101 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.904\n",
            "INFO:tensorflow:loss = 0.007939097, step = 7201 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.573\n",
            "INFO:tensorflow:loss = 0.0036479998, step = 7301 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.289\n",
            "INFO:tensorflow:loss = 0.018500803, step = 7401 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.974\n",
            "INFO:tensorflow:loss = 0.008462855, step = 7501 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.939\n",
            "INFO:tensorflow:loss = 0.019690879, step = 7601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.444\n",
            "INFO:tensorflow:loss = 0.0052479506, step = 7701 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.645\n",
            "INFO:tensorflow:loss = 0.0054613464, step = 7801 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.739\n",
            "INFO:tensorflow:loss = 0.01694778, step = 7901 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.933\n",
            "INFO:tensorflow:loss = 0.0071285716, step = 8001 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.646\n",
            "INFO:tensorflow:loss = 0.009293824, step = 8101 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.044\n",
            "INFO:tensorflow:loss = 0.01824795, step = 8201 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.972\n",
            "INFO:tensorflow:loss = 0.008382678, step = 8301 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.982\n",
            "INFO:tensorflow:loss = 0.018894544, step = 8401 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.906\n",
            "INFO:tensorflow:loss = 0.012409613, step = 8501 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.98\n",
            "INFO:tensorflow:loss = 0.008854899, step = 8601 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.617\n",
            "INFO:tensorflow:loss = 0.0049756146, step = 8701 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.974\n",
            "INFO:tensorflow:loss = 0.027496912, step = 8801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.637\n",
            "INFO:tensorflow:loss = 0.008678362, step = 8901 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.244\n",
            "INFO:tensorflow:loss = 0.026516194, step = 9001 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.756\n",
            "INFO:tensorflow:loss = 0.029654875, step = 9101 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.141\n",
            "INFO:tensorflow:loss = 0.00872088, step = 9201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.521\n",
            "INFO:tensorflow:loss = 0.008020515, step = 9301 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.388\n",
            "INFO:tensorflow:loss = 0.0068614297, step = 9401 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.479\n",
            "INFO:tensorflow:loss = 0.00628318, step = 9501 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.802\n",
            "INFO:tensorflow:loss = 0.023033483, step = 9601 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.57\n",
            "INFO:tensorflow:loss = 0.018766232, step = 9701 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.237\n",
            "INFO:tensorflow:loss = 0.003950208, step = 9801 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.24\n",
            "INFO:tensorflow:loss = 0.012236479, step = 9901 (0.221 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_mxpsd/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.047129508.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 126.8893000616561\n",
            "Just using average = 600.2110675808032 has RMSE of 101.47555317119034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "# Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[17,13,7], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NoIPNaT3UbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa13d895-5592-40be-fe25-2407cf82ce9b"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180cbe250>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.39268243 0.4446085  0.39462262 0.4229653  0.40537995 0.4528101\n",
            " 0.46087682 0.4553193  0.37730294 0.5131892  0.38035578 0.37657112\n",
            " 0.54442966 0.46268564 0.38788593 0.46993047 0.42935663 0.52092224\n",
            " 0.3892156  0.41852123 0.39377582 0.4082241  0.46014094 0.4402147\n",
            " 0.49742794 0.46659845 0.3072858  0.42291182 0.40117145 0.46393573\n",
            " 0.47856373 0.4420275  0.3226732  0.36103457 0.2902478  0.4914152\n",
            " 0.45491165 0.35645604 0.44823664 0.38749093 0.3582512  0.39780056\n",
            " 0.40780783 0.45763743 0.41064835 0.45277768 0.39463216 0.44341397\n",
            " 0.4106112  0.431199   0.43909818 0.4483075  0.31129444 0.40828365\n",
            " 0.43611014 0.30921847 0.43347925 0.45490915 0.34705853 0.34650886\n",
            " 0.51033145 0.44218838 0.34909105 0.3695376  0.4356609  0.48392373\n",
            " 0.51446706 0.5027646  0.2930268  0.4717847  0.46217448 0.46470493\n",
            " 0.31352776 0.48107713 0.5097548  0.42300713 0.4510312  0.32764596\n",
            " 0.30814892 0.4236434  0.36185902 0.41950643 0.4597814  0.40655673\n",
            " 0.48074442 0.28789425 0.4793766  0.46170086 0.38569885 0.43933767\n",
            " 0.41900533 0.35732323 0.46170628 0.45064408 0.4533465  0.44134605\n",
            " 0.50548697 0.48911285 0.44383037 0.45937985 0.42048782 0.4653669\n",
            " 0.5197101  0.50072086 0.4885949  0.46529353 0.40269017 0.39894295\n",
            " 0.442299   0.32968068 0.4154948  0.41381252 0.41189885 0.34995878\n",
            " 0.3583039  0.43571883 0.48897624 0.4687881  0.29942906 0.43144238\n",
            " 0.40757442 0.49685538 0.435883   0.44386458 0.4525935  0.40858114\n",
            " 0.38254648 0.45042783 0.46677244 0.39847428 0.5039593  0.4651764\n",
            " 0.41271335 0.43693417 0.44279063 0.41201663 0.44705468 0.38741142\n",
            " 0.37302333 0.3549922  0.42362207 0.4653926  0.4366058  0.43153185\n",
            " 0.42349565 0.36458486 0.4631061  0.37562907 0.4608891  0.2880816\n",
            " 0.43521327 0.3299495  0.37014252 0.48380935 0.4995743  0.42505854\n",
            " 0.47083884 0.42225277 0.46480685 0.3801365  0.44146347 0.4397624\n",
            " 0.42688608 0.4386062  0.41692793 0.40677553 0.32958066 0.36127597\n",
            " 0.5079663  0.421072   0.3817917  0.43163258 0.5116188  0.36045915\n",
            " 0.4265737  0.41337383 0.45315313 0.4048524  0.45799232 0.45330054\n",
            " 0.42257023 0.51397735 0.32611656 0.46992368 0.44855148 0.4799047\n",
            " 0.4538898  0.4351244  0.4637131  0.35458404 0.46630007 0.47307146\n",
            " 0.44521713 0.44786692 0.35061055 0.41394413 0.42135143 0.47824842\n",
            " 0.4938156  0.47082108 0.3612848  0.447385   0.4081028  0.46259964\n",
            " 0.39105064 0.29995555 0.37660545 0.45725763 0.4703424  0.4101892\n",
            " 0.4480753  0.47997743 0.45542616 0.4302284  0.50560254 0.50847995\n",
            " 0.45810926 0.43072832 0.4215362  0.5118676  0.4458655  0.45403343\n",
            " 0.47893238 0.490646   0.43491817 0.4248321  0.48173767 0.34849524\n",
            " 0.43443924 0.38154566 0.47568727 0.46685112 0.35014015 0.35261673\n",
            " 0.46174425 0.41705054 0.45906067 0.47413015 0.38967115 0.44470245\n",
            " 0.393304   0.4724347  0.44335407 0.46647906 0.42413545 0.47044474\n",
            " 0.46637774 0.42851955 0.40709656 0.4553749  0.37936258 0.35367674\n",
            " 0.47809023 0.4364242  0.47675228 0.42279077 0.50427485 0.4846328\n",
            " 0.41680247 0.4775738  0.41935247 0.33298832 0.46630746 0.45771843\n",
            " 0.4492476  0.41258788 0.47792864 0.40478504 0.3356794  0.46382374\n",
            " 0.5061526  0.33658195 0.43766642 0.43299252 0.4763465  0.4481994\n",
            " 0.46402723 0.43725938 0.4793501  0.4535014  0.3833328  0.3884428\n",
            " 0.45194405 0.49618298 0.49695516 0.36896193 0.41988128 0.4397019\n",
            " 0.4390934  0.44588023 0.49635553 0.4163683  0.44300705 0.4126894\n",
            " 0.40220863 0.44214302 0.46096307 0.4558534  0.44892615 0.30378693\n",
            " 0.42776656 0.46160257 0.5026027  0.41115898 0.5023977  0.4118808\n",
            " 0.4273221  0.46461225 0.3901884  0.47557926 0.4695862  0.42811376\n",
            " 0.44453388 0.40873414 0.43603456 0.42126125 0.40191877 0.4329387\n",
            " 0.4445871  0.5024195  0.43102312 0.40792966 0.29286003 0.36734706\n",
            " 0.45687044 0.40895283 0.30654544 0.41975802 0.4598328  0.46999097\n",
            " 0.4729631  0.49551785 0.32199746 0.4018274  0.4717142  0.38274872\n",
            " 0.33271307 0.4758669  0.51042724 0.4214617  0.38063562 0.3560744\n",
            " 0.38923174 0.49765843 0.35016304 0.336762   0.4263909  0.50919163\n",
            " 0.459257   0.45344037 0.4574229  0.43543643 0.45209086 0.441239\n",
            " 0.5022445  0.45479167 0.37541246 0.4176544  0.41373128 0.48153073\n",
            " 0.45798898 0.4489925  0.45472914 0.45568174 0.40730625 0.4829834\n",
            " 0.42867976 0.42755336 0.44689983 0.43154943 0.492478   0.31279498\n",
            " 0.43646204 0.4583189  0.39584666 0.4118687  0.48181665 0.5282292\n",
            " 0.3002681  0.48215705 0.41732872 0.4628086  0.450175   0.47554147\n",
            " 0.32383734 0.34364253 0.48865026 0.42056406 0.47878033 0.315812\n",
            " 0.5120182  0.42727625 0.42237222 0.39373845 0.45696175 0.44610637\n",
            " 0.44339222 0.4356374  0.4712863  0.34247732 0.35219473 0.41470551\n",
            " 0.4266476  0.45086932 0.5034501  0.34686804 0.44964802 0.47310573\n",
            " 0.4197185  0.45435905 0.46997064 0.45421094 0.44228488 0.4272437\n",
            " 0.43631607 0.44706404 0.4190874  0.3294794  0.41280156 0.41020745\n",
            " 0.43376416 0.4639653  0.46053272 0.44353515 0.35264593 0.35460192\n",
            " 0.460595   0.4687019  0.50304747 0.29804546 0.38738263 0.3955744\n",
            " 0.35286134 0.39856136 0.3887306  0.43174553 0.45381927 0.47224265\n",
            " 0.4397046  0.39071846 0.4363323  0.39010894 0.4451632  0.30795062\n",
            " 0.47479457 0.3532915  0.43058664 0.4581399  0.3175826  0.4780584\n",
            " 0.4865849  0.44665098 0.43483    0.38195765 0.46466583 0.4675123\n",
            " 0.42922914 0.39849502 0.46885318 0.39692003 0.42891198 0.5348768\n",
            " 0.3129794  0.4384901  0.41283697 0.3808303  0.36771935 0.39751816\n",
            " 0.41125256 0.35290736 0.4420097  0.50959474 0.4254076  0.4110766\n",
            " 0.52855766 0.39140892 0.46908933 0.445795   0.34624386 0.47109002\n",
            " 0.50994486 0.29742128 0.42795604 0.45619684 0.4074666  0.3128618\n",
            " 0.4436581  0.3653924  0.44433618 0.32081538 0.3044619  0.50210375\n",
            " 0.4608624  0.44315696 0.44882995 0.45555967 0.30502862 0.40494084\n",
            " 0.414096   0.47131938 0.5149743  0.4290678  0.4689104  0.51473016\n",
            " 0.42447287 0.46632957 0.34679544 0.43327612 0.4728294  0.48285526\n",
            " 0.4792912 ]\n",
            "[0.39018088 0.60206718 0.42807924 0.55900086 0.50215332 0.48062016\n",
            " 0.63049096 0.55900086 0.4625323  0.71490095 0.41946598 0.5374677\n",
            " 0.70456503 0.58139535 0.50129199 0.64857881 0.5245478  0.53057709\n",
            " 0.45305771 0.51851852 0.54866494 0.44099914 0.53660637 0.60723514\n",
            " 0.57105943 0.5211025  0.35917313 0.44358312 0.54177433 0.5667528\n",
            " 0.69595177 0.4788975  0.36347976 0.47286822 0.32127476 0.55641688\n",
            " 0.60465116 0.44875108 0.52196382 0.5374677  0.41860465 0.47631352\n",
            " 0.58914729 0.49009475 0.4754522  0.43496985 0.41946598 0.59173127\n",
            " 0.57364341 0.50215332 0.374677   0.48837209 0.31093885 0.52713178\n",
            " 0.37639966 0.38673557 0.41515935 0.58570198 0.44099914 0.41257537\n",
            " 0.71748493 0.56933678 0.38587425 0.50904393 0.47631352 0.52713178\n",
            " 0.58828596 0.6873385  0.32730405 0.67700258 0.54091301 0.53919035\n",
            " 0.41257537 0.48923342 0.62360034 0.53316107 0.47028424 0.38070629\n",
            " 0.43496985 0.59345392 0.41343669 0.42894057 0.62790698 0.45478036\n",
            " 0.48923342 0.35400517 0.51937984 0.47028424 0.45047373 0.58914729\n",
            " 0.58484065 0.41257537 0.4918174  0.6416882  0.53919035 0.58053402\n",
            " 0.58225668 0.625323   0.54521964 0.51765719 0.52713178 0.54091301\n",
            " 0.63824289 0.66063738 0.5796727  0.5667528  0.42894057 0.82687339\n",
            " 0.37898363 0.40999139 0.46942291 0.53574505 0.54608096 0.48492679\n",
            " 0.40826873 0.52627046 0.51765719 0.3255814  0.37726098 0.53402239\n",
            " 0.54177433 0.57536606 0.48234281 0.62962963 0.53832903 0.47717485\n",
            " 0.5374677  0.49870801 0.63824289 0.51507321 0.5538329  0.49095607\n",
            " 0.47200689 0.53574505 0.51679587 0.57795004 0.53316107 0.42204996\n",
            " 0.416882   0.33505599 0.47459087 0.56933678 0.61584841 0.62618432\n",
            " 0.52799311 0.50732127 0.52799311 0.43669251 0.5245478  0.34969854\n",
            " 0.48837209 0.41515935 0.42635659 0.60120586 0.55727821 0.48234281\n",
            " 0.3910422  0.53488372 0.63738157 0.48664944 0.55211025 0.625323\n",
            " 0.57278208 0.53402239 0.52196382 0.45305771 0.41429802 0.44444444\n",
            " 0.66408269 0.49440138 0.41085271 0.49009475 0.52885444 0.41085271\n",
            " 0.49009475 0.35400517 0.55727821 0.45822567 0.5211025  0.45822567\n",
            " 0.45305771 0.64254953 0.39362618 0.42291128 0.58914729 0.58742463\n",
            " 0.61757106 0.45564169 0.56072351 0.36089578 0.63565891 0.55211025\n",
            " 0.49784668 0.55555556 0.44358312 0.52799311 0.58828596 0.56416882\n",
            " 0.67011197 0.6089578  0.41343669 0.4918174  0.55555556 0.42463394\n",
            " 0.47803618 0.37812231 0.47975883 0.51593454 0.4039621  0.42291128\n",
            " 0.4754522  0.50215332 0.61068045 0.45822567 0.52971576 0.45994832\n",
            " 0.59345392 0.39707149 0.50215332 0.65891473 0.63996555 0.38070629\n",
            " 0.61757106 0.42204996 0.46339363 0.50990525 0.59086994 0.43066322\n",
            " 0.47028424 0.46167097 0.50129199 0.6709733  0.37984496 0.45994832\n",
            " 0.49956934 0.6089578  0.52282515 0.69853575 0.4461671  0.58570198\n",
            " 0.60292851 0.58828596 0.55900086 0.53402239 0.52024117 0.45047373\n",
            " 0.54091301 0.48492679 0.50990525 0.50129199 0.50129199 0.40999139\n",
            " 0.4754522  0.55813953 0.51937984 0.56158484 0.56416882 0.59776055\n",
            " 0.40999139 0.57622739 0.51765719 0.42980189 0.65374677 0.5994832\n",
            " 0.42204996 0.45391904 0.60206718 0.44358312 0.416882   0.5667528\n",
            " 0.67786391 0.40999139 0.43755383 0.43669251 0.60378984 0.49784668\n",
            " 0.43927649 0.48406546 0.59345392 0.33850129 0.48923342 0.49784668\n",
            " 0.45736434 0.55297158 0.41343669 0.43927649 0.56503015 0.54177433\n",
            " 0.59345392 0.48320413 0.6873385  0.59259259 0.48234281 0.43927649\n",
            " 0.53229974 0.4496124  0.5081826  0.49354005 0.63910422 0.26614987\n",
            " 0.56158484 0.52799311 0.47631352 0.50129199 0.52713178 0.42807924\n",
            " 0.47114556 0.60551249 0.46339363 0.55986219 0.65719208 0.52713178\n",
            " 0.43496985 0.68217054 0.55555556 0.55986219 0.52971576 0.39362618\n",
            " 0.52024117 0.36606374 0.55211025 0.49956934 0.82773471 0.41171404\n",
            " 0.48062016 0.47372954 0.37898363 0.49870801 0.57622739 0.49440138\n",
            " 0.46167097 0.57364341 0.33074935 0.45736434 0.56330749 0.4754522\n",
            " 0.44875108 0.59431525 0.7002584  0.41860465 0.40913006 0.36003445\n",
            " 0.45908699 0.51593454 0.4625323  0.36175711 0.53488372 0.56158484\n",
            " 0.59000861 0.57536606 0.56503015 0.54866494 0.52627046 0.71490095\n",
            " 0.75107666 0.64513351 0.51593454 0.42204996 0.63824289 0.54091301\n",
            " 0.36434109 0.59173127 0.51248923 0.64685616 0.43755383 0.6124031\n",
            " 0.5081826  0.55900086 0.60809647 0.4005168  0.60292851 0.48923342\n",
            " 0.44702842 0.34969854 0.41343669 0.56589147 0.48062016 0.59086994\n",
            " 0.41774332 0.55900086 0.4952627  0.62360034 0.5503876  0.62962963\n",
            " 0.42118863 0.45908699 0.59000861 0.57622739 0.53832903 0.34280792\n",
            " 0.45133506 0.55555556 0.48406546 0.44358312 0.47975883 0.69422911\n",
            " 0.583118   0.59776055 0.51679587 0.40568475 0.5047373  0.52368648\n",
            " 0.63049096 0.54866494 0.583118   0.4788975  0.4952627  0.57622739\n",
            " 0.54005168 0.5503876  0.57364341 0.56158484 0.47631352 0.63479759\n",
            " 0.51248923 0.39276486 0.47286822 0.43066322 0.48062016 0.5081826\n",
            " 0.43755383 0.63393626 0.55813953 0.51593454 0.51421189 0.41171404\n",
            " 0.64857881 0.55469423 0.54521964 0.36692506 0.47975883 0.55813953\n",
            " 0.43238587 0.41257537 0.58570198 0.56158484 0.54263566 0.56158484\n",
            " 0.5047373  0.48923342 0.4918174  0.52885444 0.46770026 0.3875969\n",
            " 0.56761413 0.33419466 0.4461671  0.50732127 0.43066322 0.59517657\n",
            " 0.65288544 0.56158484 0.56072351 0.43496985 0.53143842 0.52799311\n",
            " 0.55124892 0.4788975  0.61843239 0.34625323 0.52368648 0.66666667\n",
            " 0.40137812 0.51162791 0.45391904 0.5081826  0.45391904 0.47114556\n",
            " 0.55555556 0.4332472  0.60637382 0.58742463 0.48148148 0.54608096\n",
            " 0.62704565 0.62015504 0.44358312 0.41429802 0.40913006 0.35486649\n",
            " 0.62015504 0.27562446 0.53057709 0.57622739 0.41602067 0.40568475\n",
            " 0.5667528  0.45822567 0.36864772 0.38845823 0.37812231 0.65202412\n",
            " 0.59862188 0.54349699 0.47028424 0.56589147 0.38501292 0.59173127\n",
            " 0.48320413 0.5503876  0.50904393 0.55469423 0.59862188 0.61154177\n",
            " 0.48664944 0.59259259 0.36864772 0.44530577 0.53919035 0.63307494\n",
            " 0.53488372]\n",
            "The trained model has an aproximate error rate of 97.26084361967509 which equates to 16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low RMSE value suggests that a relationship between the maximum sustained wind speed and the number of collisions exist. The model produced can be used to predict the number of collisions with a degree of accuracy. As with the other DNN models produced the error rate is higher."
      ],
      "metadata": {
        "id": "6ugiuzBKuNne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Whole Dataset\n",
        "As the purpose of this assignment is to accurately predict the number of collisions given the weather condition**s**, all available weather conditions are used as input variables to train a DNN model."
      ],
      "metadata": {
        "id": "Dzn0MDJwVdg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/datadnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "r3AhZB1bVybn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf325ad-c5d4-4c99-ff85-885300a868f6"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the whole dataset contains the error values for Dew Point, Sea Level Pressure, Maximum Sustained Wind Speed and Gust; these must be removed."
      ],
      "metadata": {
        "id": "ZhkTk0XMApB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean the data\n",
        "dnn = df.loc[df[\"year\"] != 2012]\n",
        "dnn = dnn.loc[dnn[\"year\"] < 2020]\n",
        "dnn = dnn.loc[dnn[\"dewp\"] != 9999]\n",
        "dnn = dnn.loc[dnn[\"slp\"] != 9999]\n",
        "dnn = dnn.loc[dnn[\"mxpsd\"] != 999.9]\n",
        "dnn = dnn.loc[dnn[\"gust\"] != 999.9]\n",
        "#Move the target to the end\n",
        "cols = dnn['NUM_COLLISIONS']\n",
        "dnn = dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "dnn.insert(loc=38, column='NUM_COLLISIONS', value=cols)\n",
        "print(dnn[:6])\n",
        "dnn.describe()"
      ],
      "metadata": {
        "id": "izyExLEIVybo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "2749e81c-4520-41c5-c39c-e48918639aba"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  temp  dewp     slp  visib  wdsp  mxpsd  gust   max  ...  Oct  \\\n",
            "74  2016  17  40.2  32.3  1007.3    9.2   7.7   12.0  18.1  51.1  ...    0   \n",
            "76  2014   9  23.5   8.3  1034.2   10.0   7.9   12.0  20.0  28.9  ...    0   \n",
            "79  2019  19  34.5  29.7  1022.0    9.8   6.9   13.0  21.0  39.9  ...    0   \n",
            "80  2015  11  27.1  12.1  1035.5   10.0   8.8   13.0  17.1  37.0  ...    0   \n",
            "83  2015  29  29.2  20.9  1022.9   10.0   8.5   13.0  20.0  36.0  ...    0   \n",
            "85  2019  13  26.0  12.8  1030.5   10.0   8.0   13.0  15.9  30.9  ...    0   \n",
            "\n",
            "    Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "74    0    0    0    1    0    0    0    0             451  \n",
            "76    0    0    0    0    0    0    0    1             561  \n",
            "79    0    1    0    0    0    0    0    0             479  \n",
            "80    0    0    0    1    0    0    0    0             341  \n",
            "83    0    0    0    0    0    0    0    1             519  \n",
            "85    0    0    0    1    0    0    0    0             374  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             year           da         temp         dewp          slp  \\\n",
              "count  1629.00000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean   2015.91283    15.702885    47.909638    45.903254  1015.632904   \n",
              "std       2.01341     8.667634    13.746339   247.352840     8.134237   \n",
              "min    2013.00000     1.000000     5.800000    -6.700000   989.500000   \n",
              "25%    2014.00000     8.000000    38.100000    28.200000  1010.600000   \n",
              "50%    2016.00000    16.000000    47.000000    40.200000  1015.400000   \n",
              "75%    2018.00000    23.000000    58.800000    52.800000  1021.100000   \n",
              "max    2019.00000    31.000000    77.500000  9999.900000  1039.100000   \n",
              "\n",
              "             visib         wdsp        mxpsd         gust         max  ...  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.00000  ...   \n",
              "mean      8.225599    12.602087    20.060896    27.511602    55.73407  ...   \n",
              "std       2.227285     3.986056     5.294117     7.366770    13.52726  ...   \n",
              "min       0.600000     4.500000     8.900000    14.000000    18.00000  ...   \n",
              "25%       7.000000    10.000000    15.900000    22.000000    46.00000  ...   \n",
              "50%       9.300000    12.000000    19.000000    26.000000    55.00000  ...   \n",
              "75%      10.000000    14.400000    22.900000    31.100000    66.00000  ...   \n",
              "max      10.000000    39.300000    49.000000    71.100000    87.10000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean      0.087784     0.071209     0.143646     0.139963     0.141191   \n",
              "std       0.283067     0.257253     0.350839     0.347055     0.348325   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000     1629.000000  \n",
              "mean      0.139963     0.151627     0.138122     0.145488      596.513198  \n",
              "std       0.347055     0.358769     0.345133     0.352700      104.479660  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      526.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      597.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      663.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45edafde-115a-47c3-bfd0-928673a970b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>gust</th>\n",
              "      <th>max</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1629.00000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.91283</td>\n",
              "      <td>15.702885</td>\n",
              "      <td>47.909638</td>\n",
              "      <td>45.903254</td>\n",
              "      <td>1015.632904</td>\n",
              "      <td>8.225599</td>\n",
              "      <td>12.602087</td>\n",
              "      <td>20.060896</td>\n",
              "      <td>27.511602</td>\n",
              "      <td>55.73407</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087784</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.143646</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.151627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>596.513198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.01341</td>\n",
              "      <td>8.667634</td>\n",
              "      <td>13.746339</td>\n",
              "      <td>247.352840</td>\n",
              "      <td>8.134237</td>\n",
              "      <td>2.227285</td>\n",
              "      <td>3.986056</td>\n",
              "      <td>5.294117</td>\n",
              "      <td>7.366770</td>\n",
              "      <td>13.52726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.257253</td>\n",
              "      <td>0.350839</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.348325</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.358769</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>104.479660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.100000</td>\n",
              "      <td>28.200000</td>\n",
              "      <td>1010.600000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>46.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>526.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>40.200000</td>\n",
              "      <td>1015.400000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>55.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>597.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.00000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.800000</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>1021.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>66.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>663.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.00000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>9999.900000</td>\n",
              "      <td>1039.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>39.300000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45edafde-115a-47c3-bfd0-928673a970b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45edafde-115a-47c3-bfd0-928673a970b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45edafde-115a-47c3-bfd0-928673a970b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle = dnn.iloc[np.random.permutation(len(dnn))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "pOJhsz3dVybo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb1221c-4519-49ea-dc93-93d9c3e16430"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  temp  dewp     slp  visib  wdsp  mxpsd  gust   max  ...  Nov  \\\n",
            "573   2016  25  51.0  47.1   995.4    4.2  20.9   29.9  38.1  57.2  ...    0   \n",
            "878   2018  13  35.0  33.4   995.9    3.4  31.0   44.1  58.1  46.0  ...    0   \n",
            "870   2018  14  34.8  29.0   999.1    9.7  22.8   31.1  40.0  39.0  ...    0   \n",
            "2716  2019  29  66.9  62.0  1021.4    8.7  11.4   20.0  26.0  72.0  ...    0   \n",
            "782   2014  28  41.2  35.6  1023.4    8.9  13.7   20.0  27.0  48.0  ...    0   \n",
            "1086  2013  11  46.2  41.0  1013.7    6.6  10.0   19.0  26.0  52.0  ...    0   \n",
            "\n",
            "      Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "573     0    0    0    0    0    0    0    0    1  \n",
            "878     0    0    0    1    0    0    0    0    0  \n",
            "870     0    0    0    0    0    0    0    1    0  \n",
            "2716    0    1    0    0    1    0    0    0    0  \n",
            "782     0    0    0    0    0    0    1    0    0  \n",
            "1086    0    0    0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select the target as the last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "iOF3gP_XVybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91beffbc-e7b3-4096-8881-821162805602"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "573     663\n",
            "878     578\n",
            "870     652\n",
            "2716    488\n",
            "782     530\n",
            "1086    517\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)\n"
      ],
      "metadata": {
        "id": "7XAEry6uVybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93249131-3ca0-42ba-a70e-7e4b2f06c961"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,9,5,3], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "sb-ehJ2tVybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c7c9d8-1fef-4e92-a866-32a080e8a36d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2186e65550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 54331.492, step = 1\n",
            "INFO:tensorflow:global_step/sec: 368.083\n",
            "INFO:tensorflow:loss = 584.1095, step = 101 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.85\n",
            "INFO:tensorflow:loss = 72.88313, step = 201 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.544\n",
            "INFO:tensorflow:loss = 14.796068, step = 301 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.36\n",
            "INFO:tensorflow:loss = 21.750216, step = 401 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.56\n",
            "INFO:tensorflow:loss = 12.787994, step = 501 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.561\n",
            "INFO:tensorflow:loss = 0.4161414, step = 601 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.989\n",
            "INFO:tensorflow:loss = 2.3250408, step = 701 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.738\n",
            "INFO:tensorflow:loss = 0.19738634, step = 801 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.217\n",
            "INFO:tensorflow:loss = 0.21044116, step = 901 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.633\n",
            "INFO:tensorflow:loss = 0.20673533, step = 1001 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.848\n",
            "INFO:tensorflow:loss = 0.20181856, step = 1101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.723\n",
            "INFO:tensorflow:loss = 0.21043637, step = 1201 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.682\n",
            "INFO:tensorflow:loss = 0.1686028, step = 1301 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.333\n",
            "INFO:tensorflow:loss = 0.18496566, step = 1401 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.607\n",
            "INFO:tensorflow:loss = 0.16924393, step = 1501 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.426\n",
            "INFO:tensorflow:loss = 0.17795384, step = 1601 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.715\n",
            "INFO:tensorflow:loss = 0.16863984, step = 1701 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.995\n",
            "INFO:tensorflow:loss = 0.16886672, step = 1801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.286\n",
            "INFO:tensorflow:loss = 0.17848489, step = 1901 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.606\n",
            "INFO:tensorflow:loss = 0.1529735, step = 2001 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.213\n",
            "INFO:tensorflow:loss = 0.13966477, step = 2101 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.291\n",
            "INFO:tensorflow:loss = 0.14955944, step = 2201 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.357\n",
            "INFO:tensorflow:loss = 0.15552753, step = 2301 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.737\n",
            "INFO:tensorflow:loss = 0.13869685, step = 2401 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.317\n",
            "INFO:tensorflow:loss = 0.14097846, step = 2501 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.335\n",
            "INFO:tensorflow:loss = 0.14733236, step = 2601 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.922\n",
            "INFO:tensorflow:loss = 0.14417884, step = 2701 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.487\n",
            "INFO:tensorflow:loss = 0.12667626, step = 2801 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.121\n",
            "INFO:tensorflow:loss = 0.13530345, step = 2901 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.818\n",
            "INFO:tensorflow:loss = 0.1283475, step = 3001 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.916\n",
            "INFO:tensorflow:loss = 0.13372914, step = 3101 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.597\n",
            "INFO:tensorflow:loss = 0.13638651, step = 3201 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.861\n",
            "INFO:tensorflow:loss = 0.12571885, step = 3301 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.453\n",
            "INFO:tensorflow:loss = 0.13273977, step = 3401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.462\n",
            "INFO:tensorflow:loss = 0.10937712, step = 3501 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.622\n",
            "INFO:tensorflow:loss = 0.102629796, step = 3601 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.897\n",
            "INFO:tensorflow:loss = 0.105743155, step = 3701 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.491\n",
            "INFO:tensorflow:loss = 0.10540883, step = 3801 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.745\n",
            "INFO:tensorflow:loss = 0.09961977, step = 3901 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.645\n",
            "INFO:tensorflow:loss = 0.0902789, step = 4001 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.573\n",
            "INFO:tensorflow:loss = 0.083617866, step = 4101 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.005\n",
            "INFO:tensorflow:loss = 0.09247454, step = 4201 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.763\n",
            "INFO:tensorflow:loss = 0.07263674, step = 4301 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.002\n",
            "INFO:tensorflow:loss = 0.07440669, step = 4401 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.555\n",
            "INFO:tensorflow:loss = 0.07435009, step = 4501 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.013\n",
            "INFO:tensorflow:loss = 0.07968641, step = 4601 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.484\n",
            "INFO:tensorflow:loss = 0.06809367, step = 4701 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.038\n",
            "INFO:tensorflow:loss = 0.06724112, step = 4801 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.721\n",
            "INFO:tensorflow:loss = 0.06413473, step = 4901 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.901\n",
            "INFO:tensorflow:loss = 0.057095625, step = 5001 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.101\n",
            "INFO:tensorflow:loss = 0.055064604, step = 5101 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.579\n",
            "INFO:tensorflow:loss = 0.04706672, step = 5201 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.514\n",
            "INFO:tensorflow:loss = 0.048384108, step = 5301 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.328\n",
            "INFO:tensorflow:loss = 0.04462723, step = 5401 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.203\n",
            "INFO:tensorflow:loss = 0.03881757, step = 5501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.962\n",
            "INFO:tensorflow:loss = 0.03584543, step = 5601 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.758\n",
            "INFO:tensorflow:loss = 0.030524813, step = 5701 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.85\n",
            "INFO:tensorflow:loss = 0.034784574, step = 5801 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.881\n",
            "INFO:tensorflow:loss = 0.030593317, step = 5901 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.585\n",
            "INFO:tensorflow:loss = 0.027759662, step = 6001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.628\n",
            "INFO:tensorflow:loss = 0.03256575, step = 6101 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.636\n",
            "INFO:tensorflow:loss = 0.02193318, step = 6201 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.116\n",
            "INFO:tensorflow:loss = 0.017934445, step = 6301 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.678\n",
            "INFO:tensorflow:loss = 0.026084667, step = 6401 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.284\n",
            "INFO:tensorflow:loss = 0.022554854, step = 6501 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.821\n",
            "INFO:tensorflow:loss = 0.021793168, step = 6601 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.221\n",
            "INFO:tensorflow:loss = 0.013658907, step = 6701 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.857\n",
            "INFO:tensorflow:loss = 0.014460002, step = 6801 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.321\n",
            "INFO:tensorflow:loss = 0.01152461, step = 6901 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.216\n",
            "INFO:tensorflow:loss = 0.013072964, step = 7001 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.531\n",
            "INFO:tensorflow:loss = 0.01546569, step = 7101 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.347\n",
            "INFO:tensorflow:loss = 0.011941095, step = 7201 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.092\n",
            "INFO:tensorflow:loss = 0.00982564, step = 7301 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.498\n",
            "INFO:tensorflow:loss = 0.009231189, step = 7401 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.741\n",
            "INFO:tensorflow:loss = 0.012097848, step = 7501 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.721\n",
            "INFO:tensorflow:loss = 0.0066209706, step = 7601 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.321\n",
            "INFO:tensorflow:loss = 0.0073208907, step = 7701 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.522\n",
            "INFO:tensorflow:loss = 0.009409472, step = 7801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.489\n",
            "INFO:tensorflow:loss = 0.0077253007, step = 7901 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.01\n",
            "INFO:tensorflow:loss = 0.007352886, step = 8001 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.393\n",
            "INFO:tensorflow:loss = 0.007991467, step = 8101 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.859\n",
            "INFO:tensorflow:loss = 0.008638155, step = 8201 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.301\n",
            "INFO:tensorflow:loss = 0.008644422, step = 8301 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.638\n",
            "INFO:tensorflow:loss = 0.008723479, step = 8401 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.713\n",
            "INFO:tensorflow:loss = 0.008925532, step = 8501 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.429\n",
            "INFO:tensorflow:loss = 0.007744127, step = 8601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.957\n",
            "INFO:tensorflow:loss = 0.007779325, step = 8701 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.4\n",
            "INFO:tensorflow:loss = 0.010318449, step = 8801 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.794\n",
            "INFO:tensorflow:loss = 0.007082739, step = 8901 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.003\n",
            "INFO:tensorflow:loss = 0.006908483, step = 9001 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.844\n",
            "INFO:tensorflow:loss = 0.0074652974, step = 9101 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.094\n",
            "INFO:tensorflow:loss = 0.008110389, step = 9201 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.354\n",
            "INFO:tensorflow:loss = 0.0069567147, step = 9301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.629\n",
            "INFO:tensorflow:loss = 0.0070247063, step = 9401 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.702\n",
            "INFO:tensorflow:loss = 0.008173194, step = 9501 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.639\n",
            "INFO:tensorflow:loss = 0.006105957, step = 9601 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.704\n",
            "INFO:tensorflow:loss = 0.00783955, step = 9701 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.268\n",
            "INFO:tensorflow:loss = 0.007151322, step = 9801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.139\n",
            "INFO:tensorflow:loss = 0.007445994, step = 9901 (0.207 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.007985662.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 108.55842237291203\n",
            "Just using average = 595.7129700690714 has RMSE of 108.48606071336582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictors[trainsize:].values)\n",
        "\n",
        "#Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,9,5,3], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "ssTSefyuVybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b105f074-27af-4cd5-df1a-31c9d44df5f6"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180990cd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.018e+03 2.300e+01 4.640e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.017e+03 1.000e+00 3.870e+01 ... 0.000e+00 1.000e+00 0.000e+00]\n",
            " [2.019e+03 2.600e+01 5.520e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " ...\n",
            " [2.018e+03 1.900e+01 2.980e+01 ... 0.000e+00 1.000e+00 0.000e+00]\n",
            " [2.018e+03 3.000e+01 3.840e+01 ... 1.000e+00 0.000e+00 0.000e+00]\n",
            " [2.015e+03 1.300e+01 6.820e+01 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.48330584 0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052  0.5135052  0.5135052  0.5135052  0.5135052\n",
            " 0.5135052  0.5135052 ]\n",
            "[0.58139535 0.49440138 0.45219638 0.51937984 0.44186047 0.4005168\n",
            " 0.55641688 0.51593454 0.6124031  0.52540913 0.56330749 0.38242894\n",
            " 0.6416882  0.49956934 0.44444444 0.38673557 0.80878553 0.60034453\n",
            " 0.63135228 0.4788975  0.57019811 0.43927649 0.47631352 0.40137812\n",
            " 0.49698536 0.54263566 0.40999139 0.60981912 0.44272179 0.46942291\n",
            " 0.54521964 0.65202412 0.36950904 0.50215332 0.36864772 0.51421189\n",
            " 0.38845823 0.53660637 0.62187769 0.39965547 0.45822567 0.48492679\n",
            " 0.44702842 0.60981912 0.34797588 0.66925065 0.47114556 0.35486649\n",
            " 0.55813953 0.41860465 0.51765719 0.48062016 0.50990525 0.60637382\n",
            " 0.52196382 0.47803618 0.63910422 0.52799311 0.56330749 0.6089578\n",
            " 0.67700258 0.62101637 0.47028424 0.57364341 0.50387597 0.46770026\n",
            " 0.6709733  0.42894057 0.43066322 0.5667528  0.28682171 0.53057709\n",
            " 0.63996555 0.52971576 0.56330749 0.65030146 0.54091301 0.59173127\n",
            " 0.72782084 0.44272179 0.48751077 0.36692506 0.30749354 0.51593454\n",
            " 0.53143842 0.47286822 0.63135228 0.58828596 0.5245478  0.38070629\n",
            " 0.42118863 0.53143842 0.34969854 0.45047373 0.49095607 0.48923342\n",
            " 0.34625323 0.42204996 0.45391904 0.43755383 0.54694229 0.37295435\n",
            " 0.45391904 0.51851852 0.51851852 0.34280792 0.60292851 0.56761413\n",
            " 0.60465116 0.53402239 0.53402239 0.52799311 0.32988803 0.56933678\n",
            " 0.58053402 0.63393626 0.49612403 0.52885444 0.63049096 0.51507321\n",
            " 0.46339363 0.6089578  0.62187769 0.43669251 0.45908699 0.54177433\n",
            " 0.50387597 0.50387597 0.54952627 0.45822567 0.47803618 0.50129199\n",
            " 0.52971576 0.48148148 0.53402239 0.55555556 0.52196382 0.55469423\n",
            " 0.56330749 0.32730405 0.60551249 0.64685616 0.59259259 0.63652024\n",
            " 0.48923342 0.5667528  0.6546081  0.47803618 0.43496985 0.50215332\n",
            " 0.66236003 0.57019811 0.47803618 0.51593454 0.59345392 0.52024117\n",
            " 0.44702842 0.54694229 0.49956934 0.53574505 0.68217054 0.41602067\n",
            " 0.37984496 0.43066322 0.50387597 0.42463394 0.50990525 0.63910422\n",
            " 0.59689922 0.52713178 0.44702842 0.36864772 0.60981912 0.60465116\n",
            " 0.52885444 0.49956934 0.6873385  0.53488372 0.54780362 0.69250646\n",
            " 0.70887166 0.583118   0.66408269 0.57536606 0.35486649 0.5245478\n",
            " 0.56847545 0.52540913 0.41257537 0.50559862 0.40913006 0.44444444\n",
            " 0.36606374 0.64341085 0.42635659 0.52799311 0.37037037 0.36089578\n",
            " 0.63049096 0.42204996 0.5994832  0.52971576 0.58656331 0.49009475\n",
            " 0.41860465 0.40568475 0.64082687 0.63824289 0.42118863 0.46167097\n",
            " 0.16192937 0.47372954 0.3910422  0.51593454 0.54177433 0.60378984\n",
            " 0.4918174  0.43583118 0.55727821 0.46425495 0.55211025 0.83893196\n",
            " 0.62187769 0.68044789 0.56158484 0.5503876  0.56933678 0.49095607\n",
            " 0.54866494 0.54177433 0.42291128 0.44272179 0.45047373 0.67355728\n",
            " 0.53660637 0.63479759 0.53143842 0.46080965 0.45219638 0.39276486\n",
            " 0.48148148 0.49095607 0.44358312 0.52713178 0.55986219 0.5667528\n",
            " 0.68217054 0.5211025  0.5796727  0.48837209 0.55297158 0.35745047\n",
            " 0.59431525 0.60809647 0.59345392 0.57450474 0.47631352 0.52885444\n",
            " 0.5081826  0.50990525 0.65202412 0.56589147 0.46942291 0.31438415\n",
            " 0.58570198 0.36347976 0.62446167 0.44099914 0.45564169 0.58225668\n",
            " 0.30577089 0.58397933 0.51335056 0.49956934 0.54608096 0.54177433\n",
            " 0.56158484 0.55555556 0.53660637 0.53660637 0.45908699 0.61757106\n",
            " 0.51851852 0.55986219 0.58828596 0.71748493 0.4332472  0.32213609\n",
            " 0.5374677  0.41343669 0.42204996 0.54177433 0.52196382 0.374677\n",
            " 0.65202412 0.51593454 0.583118   0.39534884 0.53574505 0.5211025\n",
            " 0.53832903 0.46339363 0.60465116 0.48320413 0.64082687 0.61326443\n",
            " 0.4918174  0.49870801 0.53574505 0.34969854 0.52368648 0.64685616\n",
            " 0.43841516 0.36520241 0.55986219 0.57278208 0.58053402 0.52196382\n",
            " 0.46167097 0.42463394 0.38931955 0.63910422 0.54005168 0.64513351\n",
            " 0.63996555 0.41171404]\n",
            "The trained model has an aproximate error rate of 3.6396460901557295 which equates to 1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low RMSE and the low percentage error rate suggest that using the whole cleaned dataset is an accurate predictor of the number of collisions."
      ],
      "metadata": {
        "id": "pdkBGr4CCjzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Location\n",
        "As identified in assignment 1, as the location tends towards the centre of New York there is stronger linear relationships. This suggests there is a link between the number of collisions, location and the observed weather conditions. A DNN will be trained to attempt to predict the number of collisions given the location, day and weather conditions."
      ],
      "metadata": {
        "id": "kHVsefPtZOYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data and extract from the zip\n",
        "#Reference - (geeksforgeeks.org 2021)\n",
        "df_loc = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/locdnn.zip', index_col=0,compression='zip' )\n",
        "print(df_loc[:6])"
      ],
      "metadata": {
        "id": "d4VkDncof2uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ac75c0-1f06-4103-bec2-6e7b57052d5d"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS   latitude  longitude  temp  dewp     slp  visib  \\\n",
            "1  2018   2               1  40.681750 -73.967480  14.7   2.0  1024.9   10.0   \n",
            "2  2018   2               1  40.645370 -73.945110  14.7   2.0  1024.9   10.0   \n",
            "3  2018   2               1  40.614830 -73.998380  14.7   2.0  1024.9   10.0   \n",
            "4  2018   2               1  40.592190 -74.087395  14.7   2.0  1024.9   10.0   \n",
            "5  2018   2               1  40.769817 -73.782370  14.7   2.0  1024.9   10.0   \n",
            "6  2018   2               1  40.660175 -73.928200  14.7   2.0  1024.9   10.0   \n",
            "\n",
            "   wdsp  ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "2  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "4  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "5  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove unrequired cols\n",
        "df_loc_dnn = df_loc.drop(columns=['thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "#Clean data\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"year\"] != 2012]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"year\"] < 2020]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"dewp\"] != 9999]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"slp\"] != 9999]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"mxpsd\"] != 999.9]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"gust\"] != 999.9]\n",
        "#Move the target to the end\n",
        "cols = df_loc_dnn['NUM_COLLISIONS']\n",
        "df_loc_dnn = df_loc_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_loc_dnn.insert(loc=34, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_loc_dnn[:6])\n",
        "df_loc_dnn.describe()"
      ],
      "metadata": {
        "id": "hl2pF-yuf2u0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "ac229fdf-0c9b-4bc9-bff5-855f5181943a"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da   latitude  longitude  temp  dewp     slp  visib  wdsp  mxpsd  \\\n",
            "1  2018   2  40.681750 -73.967480  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "2  2018   2  40.645370 -73.945110  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "3  2018   2  40.614830 -73.998380  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "4  2018   2  40.592190 -74.087395  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "5  2018   2  40.769817 -73.782370  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "6  2018   2  40.660175 -73.928200  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "\n",
            "   ...  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "1  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "2  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "3  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "4  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "5  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "6  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "\n",
            "[6 rows x 35 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                year             da       latitude      longitude  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean     2016.070154      15.638823      40.723907     -73.920916   \n",
              "std         1.991298       8.613159       0.078454       0.086634   \n",
              "min      2013.000000       1.000000      40.498949     -74.253006   \n",
              "25%      2014.000000       8.000000      40.668860     -73.976715   \n",
              "50%      2016.000000      16.000000      40.722470     -73.929210   \n",
              "75%      2018.000000      23.000000      40.768165     -73.866650   \n",
              "max      2019.000000      31.000000      40.912884     -73.663010   \n",
              "\n",
              "                temp           dewp            slp          visib  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean       48.419836      47.274900    1015.556656       8.199143   \n",
              "std        13.750834     261.636367       8.136580       2.230079   \n",
              "min         5.800000      -6.700000     989.500000       0.600000   \n",
              "25%        38.400000      28.800000    1010.700000       6.900000   \n",
              "50%        47.800000      41.300000    1015.300000       9.300000   \n",
              "75%        59.500000      53.400000    1021.000000      10.000000   \n",
              "max        77.500000    9999.900000    1039.100000      10.000000   \n",
              "\n",
              "                wdsp          mxpsd  ...            Oct            Sep  \\\n",
              "count  830297.000000  830297.000000  ...  830297.000000  830297.000000   \n",
              "mean       12.598551      20.021545  ...       0.093866       0.074335   \n",
              "std         3.921832       5.219745  ...       0.291643       0.262315   \n",
              "min         4.500000       8.900000  ...       0.000000       0.000000   \n",
              "25%        10.000000      15.900000  ...       0.000000       0.000000   \n",
              "50%        12.000000      19.000000  ...       0.000000       0.000000   \n",
              "75%        14.400000      22.900000  ...       0.000000       0.000000   \n",
              "max        39.300000      49.000000  ...       1.000000       1.000000   \n",
              "\n",
              "                 Fri            Mon            Sat            Sun  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean        0.133032       0.146763       0.114698       0.142687   \n",
              "std         0.339609       0.353870       0.318657       0.349754   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 Thu            Tue            Wed  NUM_COLLISIONS  \n",
              "count  830297.000000  830297.000000  830297.000000   830297.000000  \n",
              "mean        0.170187       0.141897       0.150735        1.027090  \n",
              "std         0.375797       0.348945       0.357791        0.180994  \n",
              "min         0.000000       0.000000       0.000000        1.000000  \n",
              "25%         0.000000       0.000000       0.000000        1.000000  \n",
              "50%         0.000000       0.000000       0.000000        1.000000  \n",
              "75%         0.000000       0.000000       0.000000        1.000000  \n",
              "max         1.000000       1.000000       1.000000       11.000000  \n",
              "\n",
              "[8 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70833bfc-8a84-4806-a93d-824851f260bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.070154</td>\n",
              "      <td>15.638823</td>\n",
              "      <td>40.723907</td>\n",
              "      <td>-73.920916</td>\n",
              "      <td>48.419836</td>\n",
              "      <td>47.274900</td>\n",
              "      <td>1015.556656</td>\n",
              "      <td>8.199143</td>\n",
              "      <td>12.598551</td>\n",
              "      <td>20.021545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093866</td>\n",
              "      <td>0.074335</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.146763</td>\n",
              "      <td>0.114698</td>\n",
              "      <td>0.142687</td>\n",
              "      <td>0.170187</td>\n",
              "      <td>0.141897</td>\n",
              "      <td>0.150735</td>\n",
              "      <td>1.027090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.991298</td>\n",
              "      <td>8.613159</td>\n",
              "      <td>0.078454</td>\n",
              "      <td>0.086634</td>\n",
              "      <td>13.750834</td>\n",
              "      <td>261.636367</td>\n",
              "      <td>8.136580</td>\n",
              "      <td>2.230079</td>\n",
              "      <td>3.921832</td>\n",
              "      <td>5.219745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291643</td>\n",
              "      <td>0.262315</td>\n",
              "      <td>0.339609</td>\n",
              "      <td>0.353870</td>\n",
              "      <td>0.318657</td>\n",
              "      <td>0.349754</td>\n",
              "      <td>0.375797</td>\n",
              "      <td>0.348945</td>\n",
              "      <td>0.357791</td>\n",
              "      <td>0.180994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.498949</td>\n",
              "      <td>-74.253006</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>40.668860</td>\n",
              "      <td>-73.976715</td>\n",
              "      <td>38.400000</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>1010.700000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>40.722470</td>\n",
              "      <td>-73.929210</td>\n",
              "      <td>47.800000</td>\n",
              "      <td>41.300000</td>\n",
              "      <td>1015.300000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>40.768165</td>\n",
              "      <td>-73.866650</td>\n",
              "      <td>59.500000</td>\n",
              "      <td>53.400000</td>\n",
              "      <td>1021.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>40.912884</td>\n",
              "      <td>-73.663010</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>9999.900000</td>\n",
              "      <td>1039.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>39.300000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70833bfc-8a84-4806-a93d-824851f260bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70833bfc-8a84-4806-a93d-824851f260bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70833bfc-8a84-4806-a93d-824851f260bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the scale to the maximum value\n",
        "SCALE_LOC=11\n",
        "# Shuffle data\n",
        "shuffle = df_loc_dnn.iloc[np.random.permutation(len(df_loc_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "cPhXM4DJf2u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2083ed8-091c-4063-e7b6-a573f73396b5"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         year  da   latitude  longitude  temp  dewp     slp  visib  wdsp  \\\n",
            "1428318  2015  28  40.587210 -73.923860  21.6  14.7  1009.6    6.6  16.6   \n",
            "661367   2016   3  40.761223 -73.923800  58.8  56.2  1014.6    5.1   8.4   \n",
            "928834   2015   8  40.761486 -73.960599  69.7  61.1  1013.8   10.0  11.8   \n",
            "312058   2013  17  40.736005 -73.993617  63.2  59.2  1011.3    7.0   9.1   \n",
            "1551367  2016  18  40.789950 -73.942927  36.0  23.1  1023.3   10.0  12.5   \n",
            "1482098  2013  16  40.764736 -73.988033  32.0  15.5  1012.3   10.0  12.5   \n",
            "\n",
            "         mxpsd  ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1428318   29.9  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "661367    15.0  ...    1    0    0    0    0    0    0    0    0    1  \n",
            "928834    15.0  ...    0    0    0    1    0    0    0    0    0    0  \n",
            "312058    14.0  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "1551367   18.1  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "1482098   17.1  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "sol3wzXcf2u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee87894-077d-4889-8846-bd32c7e8d7a5"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1428318    1\n",
            "661367     1\n",
            "928834     1\n",
            "312058     1\n",
            "1551367    1\n",
            "1482098    1\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "_fZ3mPt-f2u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0849df9c-18c3-405e-bc89-ff287c9348b6"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_loc', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_loc', hidden_units=[19,15,11,7], optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model.\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_LOC, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_LOC\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "FEMInwLGf2u3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351734c0-c2db-43a3-bea6-8d432f2f85a9"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180f91550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_loc', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_loc/model.ckpt.\n",
            "INFO:tensorflow:loss = 1954.7893, step = 1\n",
            "INFO:tensorflow:global_step/sec: 349.222\n",
            "INFO:tensorflow:loss = 0.38380194, step = 101 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.001\n",
            "INFO:tensorflow:loss = 0.2817147, step = 201 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 425.272\n",
            "INFO:tensorflow:loss = 0.19359416, step = 301 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.515\n",
            "INFO:tensorflow:loss = 0.12018517, step = 401 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.549\n",
            "INFO:tensorflow:loss = 0.068043634, step = 501 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.06\n",
            "INFO:tensorflow:loss = 0.036159124, step = 601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 435.458\n",
            "INFO:tensorflow:loss = 0.018172484, step = 701 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 435.508\n",
            "INFO:tensorflow:loss = 0.008284309, step = 801 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.761\n",
            "INFO:tensorflow:loss = 0.0035772105, step = 901 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.569\n",
            "INFO:tensorflow:loss = 0.0014915861, step = 1001 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.924\n",
            "INFO:tensorflow:loss = 0.0006287639, step = 1101 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.815\n",
            "INFO:tensorflow:loss = 0.00043287565, step = 1201 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.173\n",
            "INFO:tensorflow:loss = 0.00039213942, step = 1301 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.729\n",
            "INFO:tensorflow:loss = 0.00020309021, step = 1401 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.907\n",
            "INFO:tensorflow:loss = 0.00032275205, step = 1501 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 444.603\n",
            "INFO:tensorflow:loss = 0.00019043896, step = 1601 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.614\n",
            "INFO:tensorflow:loss = 0.00043998586, step = 1701 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.615\n",
            "INFO:tensorflow:loss = 7.155051e-06, step = 1801 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.234\n",
            "INFO:tensorflow:loss = 0.0003184436, step = 1901 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.988\n",
            "INFO:tensorflow:loss = 6.4500487e-06, step = 2001 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.293\n",
            "INFO:tensorflow:loss = 0.00031151765, step = 2101 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.43\n",
            "INFO:tensorflow:loss = 0.00031118313, step = 2201 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 301.306\n",
            "INFO:tensorflow:loss = 0.0008209414, step = 2301 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.311\n",
            "INFO:tensorflow:loss = 6.676183e-05, step = 2401 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.047\n",
            "INFO:tensorflow:loss = 0.00018940489, step = 2501 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.043\n",
            "INFO:tensorflow:loss = 0.00018921713, step = 2601 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 290.558\n",
            "INFO:tensorflow:loss = 0.0003725977, step = 2701 (0.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.417\n",
            "INFO:tensorflow:loss = 0.00025033962, step = 2801 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 297.146\n",
            "INFO:tensorflow:loss = 0.0003720402, step = 2901 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.311\n",
            "INFO:tensorflow:loss = 0.00012811084, step = 3001 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.854\n",
            "INFO:tensorflow:loss = 6.730771e-05, step = 3101 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.997\n",
            "INFO:tensorflow:loss = 0.0002506844, step = 3201 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.151\n",
            "INFO:tensorflow:loss = 0.00018937339, step = 3301 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.244\n",
            "INFO:tensorflow:loss = 0.00012804008, step = 3401 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.497\n",
            "INFO:tensorflow:loss = 0.00050216296, step = 3501 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.49\n",
            "INFO:tensorflow:loss = 6.714381e-05, step = 3601 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.096\n",
            "INFO:tensorflow:loss = 0.0002502661, step = 3701 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 410.337\n",
            "INFO:tensorflow:loss = 0.00018920453, step = 3801 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.677\n",
            "INFO:tensorflow:loss = 0.00012825122, step = 3901 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.765\n",
            "INFO:tensorflow:loss = 0.0001280406, step = 4001 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.525\n",
            "INFO:tensorflow:loss = 0.00018943551, step = 4101 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.944\n",
            "INFO:tensorflow:loss = 0.0003109249, step = 4201 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.591\n",
            "INFO:tensorflow:loss = 0.00018928577, step = 4301 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.909\n",
            "INFO:tensorflow:loss = 0.00018919996, step = 4401 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.185\n",
            "INFO:tensorflow:loss = 0.00043369294, step = 4501 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.134\n",
            "INFO:tensorflow:loss = 0.00031216766, step = 4601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.634\n",
            "INFO:tensorflow:loss = 0.00012835438, step = 4701 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.51\n",
            "INFO:tensorflow:loss = 0.00018929126, step = 4801 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.783\n",
            "INFO:tensorflow:loss = 0.00012789239, step = 4901 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.984\n",
            "INFO:tensorflow:loss = 0.00018922659, step = 5001 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.967\n",
            "INFO:tensorflow:loss = 0.00012765612, step = 5101 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.28\n",
            "INFO:tensorflow:loss = 0.00025035776, step = 5201 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 440.561\n",
            "INFO:tensorflow:loss = 0.00018938133, step = 5301 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.193\n",
            "INFO:tensorflow:loss = 0.00043173844, step = 5401 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.516\n",
            "INFO:tensorflow:loss = 0.00025019402, step = 5501 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.694\n",
            "INFO:tensorflow:loss = 0.0003183171, step = 5601 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.736\n",
            "INFO:tensorflow:loss = 6.728763e-05, step = 5701 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 430.448\n",
            "INFO:tensorflow:loss = 0.0006258468, step = 5801 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.933\n",
            "INFO:tensorflow:loss = 0.0002506628, step = 5901 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.759\n",
            "INFO:tensorflow:loss = 0.00012772702, step = 6001 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.949\n",
            "INFO:tensorflow:loss = 0.0003125292, step = 6101 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 417.803\n",
            "INFO:tensorflow:loss = 6.588284e-05, step = 6201 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.725\n",
            "INFO:tensorflow:loss = 0.00037241643, step = 6301 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.551\n",
            "INFO:tensorflow:loss = 0.00018928987, step = 6401 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.503\n",
            "INFO:tensorflow:loss = 0.00043970242, step = 6501 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.898\n",
            "INFO:tensorflow:loss = 0.0002501976, step = 6601 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.318\n",
            "INFO:tensorflow:loss = 0.0004358738, step = 6701 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.526\n",
            "INFO:tensorflow:loss = 0.00018938462, step = 6801 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.129\n",
            "INFO:tensorflow:loss = 0.00018924533, step = 6901 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.482\n",
            "INFO:tensorflow:loss = 0.00043971482, step = 7001 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.938\n",
            "INFO:tensorflow:loss = 6.6626984e-05, step = 7101 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.969\n",
            "INFO:tensorflow:loss = 0.0001892019, step = 7201 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.199\n",
            "INFO:tensorflow:loss = 0.00031164632, step = 7301 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.238\n",
            "INFO:tensorflow:loss = 0.00037940865, step = 7401 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 423.366\n",
            "INFO:tensorflow:loss = 0.0002503376, step = 7501 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.863\n",
            "INFO:tensorflow:loss = 0.00012738646, step = 7601 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.46\n",
            "INFO:tensorflow:loss = 5.5689375e-06, step = 7701 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.023\n",
            "INFO:tensorflow:loss = 6.857363e-05, step = 7801 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.016\n",
            "INFO:tensorflow:loss = 0.0003183736, step = 7901 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 438.242\n",
            "INFO:tensorflow:loss = 0.00037331367, step = 8001 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.844\n",
            "INFO:tensorflow:loss = 0.0006999942, step = 8101 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.022\n",
            "INFO:tensorflow:loss = 0.00025019664, step = 8201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 426.672\n",
            "INFO:tensorflow:loss = 0.00031254004, step = 8301 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.386\n",
            "INFO:tensorflow:loss = 0.00025107403, step = 8401 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.725\n",
            "INFO:tensorflow:loss = 0.0001279846, step = 8501 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.754\n",
            "INFO:tensorflow:loss = 0.00012838129, step = 8601 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.29\n",
            "INFO:tensorflow:loss = 0.00031844544, step = 8701 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.42\n",
            "INFO:tensorflow:loss = 0.0022172343, step = 8801 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.63\n",
            "INFO:tensorflow:loss = 0.00037339987, step = 8901 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 447.239\n",
            "INFO:tensorflow:loss = 0.00018945782, step = 9001 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.379\n",
            "INFO:tensorflow:loss = 0.00043700053, step = 9101 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.794\n",
            "INFO:tensorflow:loss = 6.933482e-05, step = 9201 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.323\n",
            "INFO:tensorflow:loss = 0.00038009434, step = 9301 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.368\n",
            "INFO:tensorflow:loss = 0.0001339805, step = 9401 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.658\n",
            "INFO:tensorflow:loss = 0.000250212, step = 9501 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.455\n",
            "INFO:tensorflow:loss = 0.00013184026, step = 9601 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.3\n",
            "INFO:tensorflow:loss = 0.0001892283, step = 9701 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.928\n",
            "INFO:tensorflow:loss = 0.00019116458, step = 9801 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 487.045\n",
            "INFO:tensorflow:loss = 0.00012837519, step = 9901 (0.207 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_loc/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0001891608.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_loc/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 0.17941017063178782\n",
            "Just using average = 1.0270641352408854 has RMSE of 0.17934385792799779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictors[trainsize:].values)\n",
        "#Ensure the number of hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_loc', hidden_units=[19,15,11,7], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_LOC\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "UoS_IOAwf2u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3648c4c6-b16b-415c-84f9-fe3c4e7e751f"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180b7e290>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_loc', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.01700000e+03 2.80000000e+01 4.07359900e+01 ... 1.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01300000e+03 2.90000000e+01 4.06181866e+01 ... 0.00000000e+00\n",
            "  1.00000000e+00 0.00000000e+00]\n",
            " [2.01900000e+03 1.60000000e+01 4.07223320e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [2.01300000e+03 2.00000000e+01 4.05779450e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01800000e+03 2.80000000e+01 4.06322940e+01 ... 1.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01900000e+03 1.10000000e+01 4.05783580e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_loc/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09293779 0.09293779 0.09293779 ... 0.09293779 0.09293779 0.09293779]\n",
            "[0.00086133 0.00086133 0.00086133 ... 0.00086133 0.00086133 0.00086133]\n",
            "The trained model has an aproximate error rate of 0.5149880768946036 which equates to 50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite extensive training, the model is not accurately able to predict the number of collisions. This is inferred by the RMSE which is close to that of the mean RMSE. "
      ],
      "metadata": {
        "id": "Oir_cOA3ccIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "As shown above the given weather conditions for a particular day within New York, the number of collisions can be accurately predicted.\n",
        "\n",
        "Arguments can be made for both models; the linear regression models appear to be less efficient due to the higher RMSE values in comparison to the DNN models. In contrast the error rate is lower for the linear regression models. This suggests that although the DNN models produce more errors, but the margin of error is lower, due to the RMSE placing a larger weighting on larger errors.\n",
        "\n",
        "In hindsight the way location has been encoded does not allow for accurate predictions to be made as the number of collisions always tends towards 1 for a given location.\n",
        "\n",
        "It is clear that the models produced above can accurately predict the number of collisions as set out in the specification of the assignment.\n"
      ],
      "metadata": {
        "id": "qBaLwNJocvpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#References\n",
        "geeksforgeeks.org (2021) Read a zipped file as a Pandas DataFrame [online]. Available from <<https://www.geeksforgeeks.org/read-a-zipped-file-as-a-pandas-dataframe/>? [12 November 2022] \n",
        "\n",
        "IBM (n.d.) What is linear regression? [online]. Available from <<https://www.ibm.com/uk-en/topics/linear-regression>> [17 November 2022] \n",
        "\n",
        "Karhunen, J., Raiko, T. and Cho, K. (2015) 'Chapter 7 - Unsupervised deep learning: A short review.' In Advances in Independent Component Analysis and Learning Machines. Academic Press. Ch. 7. 135-142.\n",
        "\n",
        "Zhang, Z. (2019) Understand Data Normalization in Machine Learning [online]. Available from <<https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0>> [17 November 2022] \n",
        "\n",
        "Zulkifli, H. (2018) Understanding Learning Rates and How It Improves Performance in Deep Learning [online]. Available from <<https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10>> [17 November 2022] \n",
        "\n"
      ],
      "metadata": {
        "id": "iDBndm4x6xGv"
      }
    }
  ]
}