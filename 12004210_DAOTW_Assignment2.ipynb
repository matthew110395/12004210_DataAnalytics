{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthew110395/12004210_DataAnalytics/blob/main/12004210_DAOTW_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "This assignment builds on the New York taxi problem identified in assignment 1, where the City of New York is looking for a way to accurately predict the number of collisions on a particular day of the week. Within this document two different types of machine learning models will be utilised to predict the number of collisions. The linear relationships identified in assignment 1 will be used to create a linear regression model. A Deep Learning Neural Network (DNN) will be used to predict the number of collisions where the relationship is not linear. "
      ],
      "metadata": {
        "id": "-MIIDzFYc6Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "PP_OBRRWE3tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!pip install tensorflow==1.15.2\n",
        "import tensorflow as tf\n",
        "# needed for high-level file management\n",
        "import shutil  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Vp_IJAE49d",
        "outputId": "ca8904c8-9dfc-4b47-b36b-429eedb819f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.2\n",
            "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 37 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (2.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.21.6)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.50.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.14.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=ddd8b77ed2024a566910e240d182a80e9fbbdaad96847689fe847880dc43387d\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regressor\n"
      ],
      "metadata": {
        "id": "SxU2LFGDjN9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr0ljmfBkDwE",
        "outputId": "6bd8f320-d30d-42a5-c97c-96db51792bc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prcp = df.drop(columns=['collision_date', 'temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] != 2012]\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] < 2020]\n",
        "cols = df_prcp['NUM_COLLISIONS']\n",
        "df_prcp = df_prcp.drop(columns=['NUM_COLLISIONS'])\n",
        "df_prcp.insert(loc=9, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp[:6])\n",
        "df_prcp.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "nRcEly727YQb",
        "outputId": "0251429d-fb2e-47ce-edfa-60565e1704e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "49    4  2016   1  28  0.09    0             0                 0     0   \n",
            "51    5  2014   1  17  0.00    1             0                 0     0   \n",
            "54    1  2016   1  25  0.02    0             0                 0     0   \n",
            "55    5  2016   1  29  0.00    0             0                 0     0   \n",
            "58    5  2017   1  20  0.00    0             0                 0     0   \n",
            "59    7  2013   1  13  0.01    1             0                 0     0   \n",
            "\n",
            "    NUM_COLLISIONS  \n",
            "49             681  \n",
            "51             589  \n",
            "54             658  \n",
            "55             645  \n",
            "58             605  \n",
            "59             373  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         prcp  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean      3.998425  2015.989366     6.518708    15.745569     0.122588   \n",
              "std       2.003542     1.996126     3.455211     8.803199     0.329143   \n",
              "min       1.000000  2013.000000     1.000000     1.000000     0.000000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000     0.000000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000     0.000000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000     0.060000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000     3.760000   \n",
              "\n",
              "               fog  rain_drizzle  snow_ice_pellets         hail  \\\n",
              "count  2539.000000   2539.000000       2539.000000  2539.000000   \n",
              "mean      0.253249      0.375345          0.085467     0.000394   \n",
              "std       0.434958      0.484307          0.279630     0.019846   \n",
              "min       0.000000      0.000000          0.000000     0.000000   \n",
              "25%       0.000000      0.000000          0.000000     0.000000   \n",
              "50%       0.000000      0.000000          0.000000     0.000000   \n",
              "75%       1.000000      1.000000          0.000000     0.000000   \n",
              "max       1.000000      1.000000          1.000000     1.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2539.000000  \n",
              "mean       599.135093  \n",
              "std        100.299164  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ace40a19-0a3f-4c08-9717-f1c875a5e993\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998425</td>\n",
              "      <td>2015.989366</td>\n",
              "      <td>6.518708</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.003542</td>\n",
              "      <td>1.996126</td>\n",
              "      <td>3.455211</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ace40a19-0a3f-4c08-9717-f1c875a5e993')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ace40a19-0a3f-4c08-9717-f1c875a5e993 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ace40a19-0a3f-4c08-9717-f1c875a5e993');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iloc allows us to select by rows. Here, we are shuffling the data by rows determined at random.\n",
        "shuffle = df_prcp.iloc[np.random.permutation(len(df_prcp))]\n",
        "\n",
        "# we are selecting all rows of the columns outliined i.e. The 3rd (2 as indexes start from 0)\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "\n",
        "\n",
        "# print out the first 6 rows of predictors.\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xT4g-UZFi01",
        "outputId": "a323b5ef-ed26-4b48-a88f-79ecbfaed54a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail\n",
            "2127    5  2017   7   7  0.00    1             1                 0     0\n",
            "495     1  2015   2   9  0.04    0             1                 0     0\n",
            "295     4  2019   1  24  0.00    0             1                 0     0\n",
            "546     6  2019   2   2  0.00    0             0                 0     0\n",
            "2904    7  2013  10  13  0.00    0             0                 0     0\n",
            "545     7  2015   2   1  0.00    0             0                 0     0\n",
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "2127    5  2017   7   7  0.00    1             1                 0     0   \n",
            "495     1  2015   2   9  0.04    0             1                 0     0   \n",
            "295     4  2019   1  24  0.00    0             1                 0     0   \n",
            "546     6  2019   2   2  0.00    0             0                 0     0   \n",
            "2904    7  2013  10  13  0.00    0             0                 0     0   \n",
            "545     7  2015   2   1  0.00    0             0                 0     0   \n",
            "\n",
            "      NUM_COLLISIONS  \n",
            "2127             674  \n",
            "495              547  \n",
            "295              592  \n",
            "546              577  \n",
            "2904             502  \n",
            "545              361  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all rows for the 2nd column (i.e. 1)\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of the targets data.\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_xkzkVBQjL_",
        "outputId": "02ee2d60-a743-4008-d2c9-d87570733a87"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2127    674\n",
            "495     547\n",
            "295     592\n",
            "546     577\n",
            "2904    502\n",
            "545     361\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCALE_COLLISIONS=1161"
      ],
      "metadata": {
        "id": "k-aEMQX9EuJJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "# Define the number of input values (predictors)\n",
        "nppredictors = 9\n",
        "# Define the number of output values (targets)\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "NwSG_P_nRgPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7051478a-4f38-4ca9-97e8-4eaa925205fe"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2031\n",
            "508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "#print(preds)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUKI-paISKeh",
        "outputId": "d184818c-4a46-4356-fde6-8fd6e18948b5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f495da5fd10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.28681284, step = 1\n",
            "INFO:tensorflow:global_step/sec: 789.909\n",
            "INFO:tensorflow:loss = 0.005889251, step = 101 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.739\n",
            "INFO:tensorflow:loss = 0.00927359, step = 201 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.532\n",
            "INFO:tensorflow:loss = 0.0074369605, step = 301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.327\n",
            "INFO:tensorflow:loss = 0.00594569, step = 401 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.42\n",
            "INFO:tensorflow:loss = 0.006601665, step = 501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.937\n",
            "INFO:tensorflow:loss = 0.0063313283, step = 601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.334\n",
            "INFO:tensorflow:loss = 0.0074583776, step = 701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.436\n",
            "INFO:tensorflow:loss = 0.006712854, step = 801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.181\n",
            "INFO:tensorflow:loss = 0.010015748, step = 901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 926.412\n",
            "INFO:tensorflow:loss = 0.00809562, step = 1001 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 794.522\n",
            "INFO:tensorflow:loss = 0.006598563, step = 1101 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.173\n",
            "INFO:tensorflow:loss = 0.0063492805, step = 1201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.646\n",
            "INFO:tensorflow:loss = 0.0061792405, step = 1301 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 882.547\n",
            "INFO:tensorflow:loss = 0.007854376, step = 1401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.984\n",
            "INFO:tensorflow:loss = 0.008643709, step = 1501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.829\n",
            "INFO:tensorflow:loss = 0.007565604, step = 1601 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.647\n",
            "INFO:tensorflow:loss = 0.006513905, step = 1701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.636\n",
            "INFO:tensorflow:loss = 0.0067584002, step = 1801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.44\n",
            "INFO:tensorflow:loss = 0.007921301, step = 1901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.403\n",
            "INFO:tensorflow:loss = 0.02003172, step = 2001 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.503\n",
            "INFO:tensorflow:loss = 0.010215719, step = 2101 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.78\n",
            "INFO:tensorflow:loss = 0.007546805, step = 2201 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.906\n",
            "INFO:tensorflow:loss = 0.013861382, step = 2301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.042\n",
            "INFO:tensorflow:loss = 0.020300055, step = 2401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.673\n",
            "INFO:tensorflow:loss = 0.006801544, step = 2501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.257\n",
            "INFO:tensorflow:loss = 0.010718895, step = 2601 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.514\n",
            "INFO:tensorflow:loss = 0.0047401525, step = 2701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.845\n",
            "INFO:tensorflow:loss = 0.0072510405, step = 2801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.281\n",
            "INFO:tensorflow:loss = 0.05844213, step = 2901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.118\n",
            "INFO:tensorflow:loss = 0.0090940865, step = 3001 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.606\n",
            "INFO:tensorflow:loss = 0.013010087, step = 3101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.762\n",
            "INFO:tensorflow:loss = 0.005008704, step = 3201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.577\n",
            "INFO:tensorflow:loss = 0.005258669, step = 3301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.003\n",
            "INFO:tensorflow:loss = 0.009356707, step = 3401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.823\n",
            "INFO:tensorflow:loss = 0.0063437964, step = 3501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.893\n",
            "INFO:tensorflow:loss = 0.009075556, step = 3601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.797\n",
            "INFO:tensorflow:loss = 0.0058118682, step = 3701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 861.687\n",
            "INFO:tensorflow:loss = 0.010094107, step = 3801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 833.056\n",
            "INFO:tensorflow:loss = 0.0152708925, step = 3901 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.438\n",
            "INFO:tensorflow:loss = 0.009372117, step = 4001 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.493\n",
            "INFO:tensorflow:loss = 0.028237123, step = 4101 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.197\n",
            "INFO:tensorflow:loss = 0.0066145845, step = 4201 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.333\n",
            "INFO:tensorflow:loss = 0.010882053, step = 4301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 808.044\n",
            "INFO:tensorflow:loss = 0.014868727, step = 4401 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.793\n",
            "INFO:tensorflow:loss = 0.0070288605, step = 4501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 765.785\n",
            "INFO:tensorflow:loss = 0.00810552, step = 4601 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.265\n",
            "INFO:tensorflow:loss = 0.005342602, step = 4701 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.342\n",
            "INFO:tensorflow:loss = 0.00989318, step = 4801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.049\n",
            "INFO:tensorflow:loss = 0.008891759, step = 4901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.106\n",
            "INFO:tensorflow:loss = 0.015933938, step = 5001 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.842\n",
            "INFO:tensorflow:loss = 0.015868759, step = 5101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.4\n",
            "INFO:tensorflow:loss = 0.018424738, step = 5201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.842\n",
            "INFO:tensorflow:loss = 0.006761266, step = 5301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.873\n",
            "INFO:tensorflow:loss = 0.009749236, step = 5401 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.477\n",
            "INFO:tensorflow:loss = 0.0067591188, step = 5501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.04\n",
            "INFO:tensorflow:loss = 0.00956042, step = 5601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 898.117\n",
            "INFO:tensorflow:loss = 0.007874543, step = 5701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.865\n",
            "INFO:tensorflow:loss = 0.0091189565, step = 5801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.884\n",
            "INFO:tensorflow:loss = 0.009444788, step = 5901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.465\n",
            "INFO:tensorflow:loss = 0.01528259, step = 6001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.301\n",
            "INFO:tensorflow:loss = 0.007298322, step = 6101 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.627\n",
            "INFO:tensorflow:loss = 0.013397295, step = 6201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.778\n",
            "INFO:tensorflow:loss = 0.009476588, step = 6301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 898.157\n",
            "INFO:tensorflow:loss = 0.03227619, step = 6401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.252\n",
            "INFO:tensorflow:loss = 0.008013057, step = 6501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.688\n",
            "INFO:tensorflow:loss = 0.007829229, step = 6601 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 920.007\n",
            "INFO:tensorflow:loss = 0.010058563, step = 6701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.652\n",
            "INFO:tensorflow:loss = 0.007870253, step = 6801 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.371\n",
            "INFO:tensorflow:loss = 0.010046538, step = 6901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.773\n",
            "INFO:tensorflow:loss = 0.025440902, step = 7001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.995\n",
            "INFO:tensorflow:loss = 0.012497817, step = 7101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.968\n",
            "INFO:tensorflow:loss = 0.009044637, step = 7201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.295\n",
            "INFO:tensorflow:loss = 0.021972518, step = 7301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.614\n",
            "INFO:tensorflow:loss = 0.009411426, step = 7401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.169\n",
            "INFO:tensorflow:loss = 0.009559792, step = 7501 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.604\n",
            "INFO:tensorflow:loss = 0.0049472693, step = 7601 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.754\n",
            "INFO:tensorflow:loss = 0.011741035, step = 7701 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.607\n",
            "INFO:tensorflow:loss = 0.0111618955, step = 7801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 922.287\n",
            "INFO:tensorflow:loss = 0.00654481, step = 7901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.571\n",
            "INFO:tensorflow:loss = 0.02326175, step = 8001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 790.051\n",
            "INFO:tensorflow:loss = 0.0071551767, step = 8101 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.178\n",
            "INFO:tensorflow:loss = 0.011211117, step = 8201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.748\n",
            "INFO:tensorflow:loss = 0.006434665, step = 8301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.253\n",
            "INFO:tensorflow:loss = 0.006459223, step = 8401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.124\n",
            "INFO:tensorflow:loss = 0.008629579, step = 8501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.984\n",
            "INFO:tensorflow:loss = 0.0081429165, step = 8601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.299\n",
            "INFO:tensorflow:loss = 0.0089528505, step = 8701 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.033\n",
            "INFO:tensorflow:loss = 0.021095075, step = 8801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.801\n",
            "INFO:tensorflow:loss = 0.014123581, step = 8901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.287\n",
            "INFO:tensorflow:loss = 0.0457155, step = 9001 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 911.95\n",
            "INFO:tensorflow:loss = 0.009231631, step = 9101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.002\n",
            "INFO:tensorflow:loss = 0.0061361054, step = 9201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 903.579\n",
            "INFO:tensorflow:loss = 0.022245608, step = 9301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.231\n",
            "INFO:tensorflow:loss = 0.007616941, step = 9401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.89\n",
            "INFO:tensorflow:loss = 0.011221008, step = 9501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.387\n",
            "INFO:tensorflow:loss = 0.020609803, step = 9601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.835\n",
            "INFO:tensorflow:loss = 0.011362955, step = 9701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.306\n",
            "INFO:tensorflow:loss = 0.011520315, step = 9801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.201\n",
            "INFO:tensorflow:loss = 0.008314532, step = 9901 (0.116 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0082565565.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'scores': array([0.5141025 , 0.56370085, 0.5293338 , 0.50650656, 0.5460061 ,\n",
            "       0.46276766, 0.48901325, 0.5045964 , 0.55767345, 0.5474755 ,\n",
            "       0.47696412, 0.5719989 , 0.499372  , 0.54435164, 0.496742  ,\n",
            "       0.52334034, 0.5130221 , 0.5576516 , 0.5660157 , 0.50187653,\n",
            "       0.49803287, 0.5275236 , 0.5175727 , 0.5518675 , 0.46650067,\n",
            "       0.55129665, 0.526218  , 0.47557315, 0.5527711 , 0.52379066,\n",
            "       0.5528509 , 0.5527703 , 0.501649  , 0.5582163 , 0.47037572,\n",
            "       0.55934405, 0.5168263 , 0.5386811 , 0.46069485, 0.5659551 ,\n",
            "       0.49748445, 0.51326185, 0.55960935, 0.5027483 , 0.5531555 ,\n",
            "       0.5192229 , 0.5500306 , 0.5822944 , 0.5859781 , 0.5465521 ,\n",
            "       0.5313575 , 0.5444995 , 0.58136153, 0.5042304 , 0.46689093,\n",
            "       0.55589783, 0.5206485 , 0.5478087 , 0.5983786 , 0.59213996,\n",
            "       0.56438524, 0.558204  , 0.49582595, 0.5353597 , 0.5774194 ,\n",
            "       0.5115516 , 0.5272639 , 0.54816175, 0.55420434, 0.54816544,\n",
            "       0.5269321 , 0.47668824, 0.51236   , 0.49671885, 0.52924085,\n",
            "       0.58760697, 0.52983314, 0.4971317 , 0.5695469 , 0.5349508 ,\n",
            "       0.5067138 , 0.57710415, 0.5700293 , 0.5200887 , 0.51930255,\n",
            "       0.5406472 , 0.51061755, 0.5496228 , 0.5225133 , 0.49756598,\n",
            "       0.5071442 , 0.5709779 , 0.50776255, 0.5364808 , 0.5545966 ,\n",
            "       0.5072562 , 0.5074282 , 0.51344776, 0.5450192 , 0.53471446,\n",
            "       0.5074187 , 0.5013175 , 0.49250078, 0.50253487, 0.50993025,\n",
            "       0.5039537 , 0.47288013, 0.5605438 , 0.48128992, 0.5077824 ,\n",
            "       0.52107054, 0.52156633, 0.522213  , 0.5315333 , 0.48918   ,\n",
            "       0.5120106 , 0.5773296 , 0.49694583, 0.51620126, 0.48545736,\n",
            "       0.527607  , 0.49203202, 0.5748196 , 0.54806006, 0.5786657 ,\n",
            "       0.5379295 , 0.54069054, 0.5424009 , 0.519732  , 0.49609232,\n",
            "       0.53797984, 0.4991855 , 0.4680404 , 0.5499785 , 0.4985938 ,\n",
            "       0.50768036, 0.5353946 , 0.5717407 , 0.531098  , 0.5131335 ,\n",
            "       0.55763865, 0.56845826, 0.4776543 , 0.46935606, 0.46486548,\n",
            "       0.49592638, 0.49584016, 0.5223333 , 0.51390684, 0.5030139 ,\n",
            "       0.49308544, 0.47865355, 0.45576078, 0.5168024 , 0.49850535,\n",
            "       0.54380846, 0.51734406, 0.5534807 , 0.481727  , 0.54610634,\n",
            "       0.5488281 , 0.5088856 , 0.55553883, 0.4898577 , 0.5436436 ,\n",
            "       0.47541487, 0.45033324, 0.5218939 , 0.53644216, 0.549948  ,\n",
            "       0.53369415, 0.5268715 , 0.5611325 , 0.52621377, 0.5059001 ,\n",
            "       0.5385384 , 0.46773657, 0.49410582, 0.5480928 , 0.57338625,\n",
            "       0.56262064, 0.58298993, 0.5295071 , 0.5630687 , 0.5176709 ,\n",
            "       0.47726518, 0.53447706, 0.5378106 , 0.55336213, 0.5123199 ,\n",
            "       0.5367242 , 0.56443864, 0.5111323 , 0.52937406, 0.54074323,\n",
            "       0.52344626, 0.59133625, 0.51511216, 0.500892  , 0.5624472 ,\n",
            "       0.5750202 , 0.571557  , 0.53948814, 0.5069317 , 0.5639716 ,\n",
            "       0.54181844, 0.5479069 , 0.5573077 , 0.49225065, 0.55816114,\n",
            "       0.5331754 , 0.4848483 , 0.50569564, 0.510399  , 0.4868745 ,\n",
            "       0.50118804, 0.5562153 , 0.48219693, 0.5304134 , 0.5307823 ,\n",
            "       0.5516589 , 0.53805417, 0.54295915, 0.5341387 , 0.53485745,\n",
            "       0.5188361 , 0.49614888, 0.52335507, 0.50716054, 0.50232685,\n",
            "       0.56115013, 0.54665875, 0.5114891 , 0.47066182, 0.4947539 ,\n",
            "       0.557913  , 0.48514935, 0.5135974 , 0.497724  , 0.5464449 ,\n",
            "       0.5278247 , 0.47660786, 0.5249122 , 0.50811285, 0.49040693,\n",
            "       0.5295321 , 0.52955043, 0.51914144, 0.49271753, 0.53740305,\n",
            "       0.5199823 , 0.54843515, 0.5851877 , 0.5560492 , 0.5262699 ,\n",
            "       0.49057293, 0.47569105, 0.525442  , 0.4751237 , 0.5519035 ,\n",
            "       0.50848097, 0.57295287, 0.5265276 , 0.540917  , 0.56743747,\n",
            "       0.49081856, 0.48874274, 0.51836866, 0.5031811 , 0.49794728,\n",
            "       0.5148113 , 0.56945354, 0.5582693 , 0.5193881 , 0.5519448 ,\n",
            "       0.5471586 , 0.5417299 , 0.5811364 , 0.49825588, 0.5552867 ,\n",
            "       0.5500636 , 0.51083666, 0.5873087 , 0.52421933, 0.5281387 ,\n",
            "       0.5165385 , 0.56524825, 0.51522905, 0.5120947 , 0.54238284,\n",
            "       0.5780111 , 0.53188574, 0.5309761 , 0.4912316 , 0.5669418 ,\n",
            "       0.5614504 , 0.5098379 , 0.48996702, 0.5379887 , 0.5630977 ,\n",
            "       0.5094931 , 0.571346  , 0.56275076, 0.50832844, 0.49315986,\n",
            "       0.547107  , 0.512443  , 0.47192565, 0.48622632, 0.51489073,\n",
            "       0.5260627 , 0.5124703 , 0.548486  , 0.5428171 , 0.53539366,\n",
            "       0.5156663 , 0.5533227 , 0.5528856 , 0.54463273, 0.5498292 ,\n",
            "       0.5509775 , 0.5602435 , 0.53279334, 0.52752256, 0.5733439 ,\n",
            "       0.5257269 , 0.5115236 , 0.5389474 , 0.57164705, 0.4988519 ,\n",
            "       0.5569089 , 0.49205998, 0.5647084 , 0.5476641 , 0.5566481 ,\n",
            "       0.5140401 , 0.49563143, 0.496612  , 0.56211185, 0.56607324,\n",
            "       0.5009139 , 0.5372156 , 0.5319965 , 0.48721838, 0.4847758 ,\n",
            "       0.50334376, 0.5779778 , 0.52816874, 0.48260415, 0.4895571 ,\n",
            "       0.56370366, 0.47832742, 0.4773674 , 0.55237734, 0.47737855,\n",
            "       0.5384493 , 0.49087337, 0.5606751 , 0.55885684, 0.46669436,\n",
            "       0.5514972 , 0.52367455, 0.53362197, 0.50904894, 0.5507292 ,\n",
            "       0.5235208 , 0.512609  , 0.5400135 , 0.5695056 , 0.56157714,\n",
            "       0.49629292, 0.5217761 , 0.5266407 , 0.49543664, 0.5272674 ,\n",
            "       0.5168783 , 0.57063013, 0.52215296, 0.510708  , 0.5538017 ,\n",
            "       0.53724045, 0.5350513 , 0.5302445 , 0.4754688 , 0.5292261 ,\n",
            "       0.50036824, 0.5520227 , 0.56012845, 0.49538362, 0.551633  ,\n",
            "       0.5229305 , 0.5378968 , 0.5091011 , 0.48291773, 0.5045723 ,\n",
            "       0.55852944, 0.4978411 , 0.4953102 , 0.56460947, 0.4940233 ,\n",
            "       0.4890405 , 0.5612348 , 0.50300634, 0.47067678, 0.5136387 ,\n",
            "       0.56068236, 0.48587313, 0.50175154, 0.5309716 , 0.4930792 ,\n",
            "       0.48130068, 0.58247024, 0.5481031 , 0.4949296 , 0.5454963 ,\n",
            "       0.55201036, 0.531711  , 0.5445783 , 0.55184335, 0.51650345,\n",
            "       0.5095132 , 0.5150345 , 0.5469864 , 0.48939565, 0.4990266 ,\n",
            "       0.5299023 , 0.4912809 , 0.5087172 , 0.5012023 , 0.49965286,\n",
            "       0.54557157, 0.5296751 , 0.5808197 , 0.5119561 , 0.54930997,\n",
            "       0.4769875 , 0.5788832 , 0.47275355, 0.48521483, 0.5334053 ,\n",
            "       0.522519  , 0.47307956, 0.47382933, 0.47680217, 0.53243136,\n",
            "       0.56136   , 0.5359476 , 0.5072429 , 0.49903756, 0.51862884,\n",
            "       0.48589557, 0.57412547, 0.56529945, 0.5330825 , 0.5308804 ,\n",
            "       0.5248535 , 0.5744269 , 0.49439576, 0.5650095 , 0.5424064 ,\n",
            "       0.5176485 , 0.5176383 , 0.52333885, 0.5095687 , 0.5731715 ,\n",
            "       0.52958953, 0.47306484, 0.5324072 , 0.54886085, 0.54040945,\n",
            "       0.5571374 , 0.5279441 , 0.5028593 , 0.53931934, 0.53196645,\n",
            "       0.5142406 , 0.5456766 , 0.57329434, 0.5069403 , 0.5724843 ,\n",
            "       0.50201476, 0.5154688 , 0.54969686, 0.5408933 , 0.48852608,\n",
            "       0.5144082 , 0.5052939 , 0.50934863, 0.5379121 , 0.50942016,\n",
            "       0.54657805, 0.51295286, 0.5471061 , 0.5182256 , 0.5159326 ,\n",
            "       0.52693754, 0.5895108 , 0.5663743 , 0.4633181 , 0.5514873 ,\n",
            "       0.5882627 , 0.51821554, 0.520947  , 0.5427267 , 0.56114936,\n",
            "       0.49681994, 0.5045307 , 0.57866126], dtype=float32)}\n",
            "LinearRegression has RMSE of 90.65297169046003\n",
            "Just using average = 599.5396356474643 has RMSE of 98.08936171874117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#testd = pd.DataFrame.from_records(predictors[trainsize:].values,columns=['day','year','month','da','prcp','fog','rain','snow','hail'])\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fifEsTD98hy",
        "outputId": "96661376-0f4d-49ec-b772-c3808b83e77c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f495d737990>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n",
            "[0.5141025  0.56370085 0.5293338  0.50650656 0.5460061  0.46276766\n",
            " 0.48901325 0.5045964  0.55767345 0.5474755  0.47696412 0.5719989\n",
            " 0.499372   0.54435164 0.496742   0.52334034 0.5130221  0.5576516\n",
            " 0.5660157  0.50187653 0.49803287 0.5275236  0.5175727  0.5518675\n",
            " 0.46650067 0.55129665 0.526218   0.47557315 0.5527711  0.52379066\n",
            " 0.5528509  0.5527703  0.501649   0.5582163  0.47037572 0.55934405\n",
            " 0.5168263  0.5386811  0.46069485 0.5659551  0.49748445 0.51326185\n",
            " 0.55960935 0.5027483  0.5531555  0.5192229  0.5500306  0.5822944\n",
            " 0.5859781  0.5465521  0.5313575  0.5444995  0.58136153 0.5042304\n",
            " 0.46689093 0.55589783 0.5206485  0.5478087  0.5983786  0.59213996\n",
            " 0.56438524 0.558204   0.49582595 0.5353597  0.5774194  0.5115516\n",
            " 0.5272639  0.54816175 0.55420434 0.54816544 0.5269321  0.47668824\n",
            " 0.51236    0.49671885 0.52924085 0.58760697 0.52983314 0.4971317\n",
            " 0.5695469  0.5349508  0.5067138  0.57710415 0.5700293  0.5200887\n",
            " 0.51930255 0.5406472  0.51061755 0.5496228  0.5225133  0.49756598\n",
            " 0.5071442  0.5709779  0.50776255 0.5364808  0.5545966  0.5072562\n",
            " 0.5074282  0.51344776 0.5450192  0.53471446 0.5074187  0.5013175\n",
            " 0.49250078 0.50253487 0.50993025 0.5039537  0.47288013 0.5605438\n",
            " 0.48128992 0.5077824  0.52107054 0.52156633 0.522213   0.5315333\n",
            " 0.48918    0.5120106  0.5773296  0.49694583 0.51620126 0.48545736\n",
            " 0.527607   0.49203202 0.5748196  0.54806006 0.5786657  0.5379295\n",
            " 0.54069054 0.5424009  0.519732   0.49609232 0.53797984 0.4991855\n",
            " 0.4680404  0.5499785  0.4985938  0.50768036 0.5353946  0.5717407\n",
            " 0.531098   0.5131335  0.55763865 0.56845826 0.4776543  0.46935606\n",
            " 0.46486548 0.49592638 0.49584016 0.5223333  0.51390684 0.5030139\n",
            " 0.49308544 0.47865355 0.45576078 0.5168024  0.49850535 0.54380846\n",
            " 0.51734406 0.5534807  0.481727   0.54610634 0.5488281  0.5088856\n",
            " 0.55553883 0.4898577  0.5436436  0.47541487 0.45033324 0.5218939\n",
            " 0.53644216 0.549948   0.53369415 0.5268715  0.5611325  0.52621377\n",
            " 0.5059001  0.5385384  0.46773657 0.49410582 0.5480928  0.57338625\n",
            " 0.56262064 0.58298993 0.5295071  0.5630687  0.5176709  0.47726518\n",
            " 0.53447706 0.5378106  0.55336213 0.5123199  0.5367242  0.56443864\n",
            " 0.5111323  0.52937406 0.54074323 0.52344626 0.59133625 0.51511216\n",
            " 0.500892   0.5624472  0.5750202  0.571557   0.53948814 0.5069317\n",
            " 0.5639716  0.54181844 0.5479069  0.5573077  0.49225065 0.55816114\n",
            " 0.5331754  0.4848483  0.50569564 0.510399   0.4868745  0.50118804\n",
            " 0.5562153  0.48219693 0.5304134  0.5307823  0.5516589  0.53805417\n",
            " 0.54295915 0.5341387  0.53485745 0.5188361  0.49614888 0.52335507\n",
            " 0.50716054 0.50232685 0.56115013 0.54665875 0.5114891  0.47066182\n",
            " 0.4947539  0.557913   0.48514935 0.5135974  0.497724   0.5464449\n",
            " 0.5278247  0.47660786 0.5249122  0.50811285 0.49040693 0.5295321\n",
            " 0.52955043 0.51914144 0.49271753 0.53740305 0.5199823  0.54843515\n",
            " 0.5851877  0.5560492  0.5262699  0.49057293 0.47569105 0.525442\n",
            " 0.4751237  0.5519035  0.50848097 0.57295287 0.5265276  0.540917\n",
            " 0.56743747 0.49081856 0.48874274 0.51836866 0.5031811  0.49794728\n",
            " 0.5148113  0.56945354 0.5582693  0.5193881  0.5519448  0.5471586\n",
            " 0.5417299  0.5811364  0.49825588 0.5552867  0.5500636  0.51083666\n",
            " 0.5873087  0.52421933 0.5281387  0.5165385  0.56524825 0.51522905\n",
            " 0.5120947  0.54238284 0.5780111  0.53188574 0.5309761  0.4912316\n",
            " 0.5669418  0.5614504  0.5098379  0.48996702 0.5379887  0.5630977\n",
            " 0.5094931  0.571346   0.56275076 0.50832844 0.49315986 0.547107\n",
            " 0.512443   0.47192565 0.48622632 0.51489073 0.5260627  0.5124703\n",
            " 0.548486   0.5428171  0.53539366 0.5156663  0.5533227  0.5528856\n",
            " 0.54463273 0.5498292  0.5509775  0.5602435  0.53279334 0.52752256\n",
            " 0.5733439  0.5257269  0.5115236  0.5389474  0.57164705 0.4988519\n",
            " 0.5569089  0.49205998 0.5647084  0.5476641  0.5566481  0.5140401\n",
            " 0.49563143 0.496612   0.56211185 0.56607324 0.5009139  0.5372156\n",
            " 0.5319965  0.48721838 0.4847758  0.50334376 0.5779778  0.52816874\n",
            " 0.48260415 0.4895571  0.56370366 0.47832742 0.4773674  0.55237734\n",
            " 0.47737855 0.5384493  0.49087337 0.5606751  0.55885684 0.46669436\n",
            " 0.5514972  0.52367455 0.53362197 0.50904894 0.5507292  0.5235208\n",
            " 0.512609   0.5400135  0.5695056  0.56157714 0.49629292 0.5217761\n",
            " 0.5266407  0.49543664 0.5272674  0.5168783  0.57063013 0.52215296\n",
            " 0.510708   0.5538017  0.53724045 0.5350513  0.5302445  0.4754688\n",
            " 0.5292261  0.50036824 0.5520227  0.56012845 0.49538362 0.551633\n",
            " 0.5229305  0.5378968  0.5091011  0.48291773 0.5045723  0.55852944\n",
            " 0.4978411  0.4953102  0.56460947 0.4940233  0.4890405  0.5612348\n",
            " 0.50300634 0.47067678 0.5136387  0.56068236 0.48587313 0.50175154\n",
            " 0.5309716  0.4930792  0.48130068 0.58247024 0.5481031  0.4949296\n",
            " 0.5454963  0.55201036 0.531711   0.5445783  0.55184335 0.51650345\n",
            " 0.5095132  0.5150345  0.5469864  0.48939565 0.4990266  0.5299023\n",
            " 0.4912809  0.5087172  0.5012023  0.49965286 0.54557157 0.5296751\n",
            " 0.5808197  0.5119561  0.54930997 0.4769875  0.5788832  0.47275355\n",
            " 0.48521483 0.5334053  0.522519   0.47307956 0.47382933 0.47680217\n",
            " 0.53243136 0.56136    0.5359476  0.5072429  0.49903756 0.51862884\n",
            " 0.48589557 0.57412547 0.56529945 0.5330825  0.5308804  0.5248535\n",
            " 0.5744269  0.49439576 0.5650095  0.5424064  0.5176485  0.5176383\n",
            " 0.52333885 0.5095687  0.5731715  0.52958953 0.47306484 0.5324072\n",
            " 0.54886085 0.54040945 0.5571374  0.5279441  0.5028593  0.53931934\n",
            " 0.53196645 0.5142406  0.5456766  0.57329434 0.5069403  0.5724843\n",
            " 0.50201476 0.5154688  0.54969686 0.5408933  0.48852608 0.5144082\n",
            " 0.5052939  0.50934863 0.5379121  0.50942016 0.54657805 0.51295286\n",
            " 0.5471061  0.5182256  0.5159326  0.52693754 0.5895108  0.5663743\n",
            " 0.4633181  0.5514873  0.5882627  0.51821554 0.520947   0.5427267\n",
            " 0.56114936 0.49681994 0.5045307  0.57866126]\n",
            "[0.65202412 0.50301464 0.48923342 0.48923342 0.51248923 0.43841516\n",
            " 0.38845823 0.46339363 0.5245478  0.61068045 0.42980189 0.63307494\n",
            " 0.38673557 0.59086994 0.49354005 0.51765719 0.55986219 0.52282515\n",
            " 0.45650301 0.55900086 0.47717485 0.54349699 0.53919035 0.54177433\n",
            " 0.39534884 0.52971576 0.53488372 0.50732127 0.55727821 0.60292851\n",
            " 0.45736434 0.55641688 0.35745047 0.59259259 0.38329027 0.58828596\n",
            " 0.59259259 0.5796727  0.33936262 0.59173127 0.45305771 0.49009475\n",
            " 0.60034453 0.36089578 0.61412575 0.57105943 0.36175711 0.67700258\n",
            " 0.48492679 0.50559862 0.60206718 0.52368648 0.63479759 0.36434109\n",
            " 0.50387597 0.66494401 0.54349699 0.47717485 0.58742463 0.34453058\n",
            " 0.48751077 0.6709733  0.41343669 0.59086994 0.60809647 0.54177433\n",
            " 0.48062016 0.54349699 0.60292851 0.60206718 0.45219638 0.35486649\n",
            " 0.46425495 0.50387597 0.55641688 0.52024117 0.45822567 0.46425495\n",
            " 0.61584841 0.56933678 0.41946598 0.52196382 0.57278208 0.55555556\n",
            " 0.55124892 0.53488372 0.44099914 0.33936262 0.52799311 0.48320413\n",
            " 0.68130922 0.60981912 0.40568475 0.46683893 0.60551249 0.53316107\n",
            " 0.57708872 0.30577089 0.57364341 0.5667528  0.56244617 0.43669251\n",
            " 0.51076658 0.45305771 0.42807924 0.51162791 0.44013781 0.58914729\n",
            " 0.41085271 0.35228252 0.71490095 0.66925065 0.51765719 0.51765719\n",
            " 0.4203273  0.43496985 0.56416882 0.58225668 0.45564169 0.49009475\n",
            " 0.54177433 0.48492679 0.60378984 0.61757106 0.62360034 0.5538329\n",
            " 0.44702842 0.45736434 0.6287683  0.53402239 0.45564169 0.76141258\n",
            " 0.26614987 0.48148148 0.43496985 0.50215332 0.48148148 0.55986219\n",
            " 0.45478036 0.53660637 0.55641688 0.46339363 0.50732127 0.37898363\n",
            " 0.32385874 0.47459087 0.37984496 0.43410853 0.52799311 0.43066322\n",
            " 0.36434109 0.43496985 0.42291128 0.56933678 0.50904393 0.48062016\n",
            " 0.50990525 0.50129199 0.44358312 0.54952627 0.50129199 0.49956934\n",
            " 0.51851852 0.49267873 0.63910422 0.42118863 0.34969854 0.50387597\n",
            " 0.54866494 0.56933678 0.16192937 0.49354005 0.63135228 0.46080965\n",
            " 0.40568475 0.47459087 0.37812231 0.38070629 0.53574505 0.47028424\n",
            " 0.51076658 0.4952627  0.41602067 0.64944014 0.52971576 0.38845823\n",
            " 0.61498708 0.57450474 0.55555556 0.60551249 0.62790698 0.56761413\n",
            " 0.5047373  0.64857881 0.48751077 0.47028424 0.57622739 0.50387597\n",
            " 0.59345392 0.53919035 0.58570198 0.47803618 0.5503876  0.60551249\n",
            " 0.54091301 0.55813953 0.4203273  0.5667528  0.416882   0.53574505\n",
            " 0.57708872 0.46597761 0.54177433 0.4788975  0.49784668 0.46167097\n",
            " 0.52971576 0.50043066 0.47631352 0.45391904 0.59776055 0.44444444\n",
            " 0.60378984 0.58570198 0.42463394 0.62704565 0.55900086 0.5211025\n",
            " 0.56589147 0.5047373  0.44358312 0.44702842 0.4005168  0.41085271\n",
            " 0.4005168  0.52196382 0.43669251 0.48148148 0.53660637 0.54263566\n",
            " 0.49956934 0.50301464 0.49956934 0.51765719 0.52024117 0.54091301\n",
            " 0.60034453 0.58225668 0.58570198 0.57019811 0.59086994 0.59173127\n",
            " 0.65030146 0.49009475 0.57019811 0.40223945 0.42635659 0.66838932\n",
            " 0.37209302 0.51765719 0.42118863 0.41774332 0.69336779 0.57622739\n",
            " 0.62187769 0.54866494 0.44099914 0.49784668 0.47803618 0.47372954\n",
            " 0.5796727  0.56330749 0.54952627 0.52971576 0.60809647 0.50559862\n",
            " 0.55813953 0.49009475 0.51937984 0.49698536 0.45650301 0.5538329\n",
            " 0.51851852 0.56244617 0.53574505 0.45822567 0.52885444 0.4918174\n",
            " 0.52799311 0.54435831 0.59345392 0.6873385  0.51076658 0.55900086\n",
            " 0.4203273  0.54608096 0.44186047 0.56072351 0.57364341 0.62101637\n",
            " 0.51335056 0.55813953 0.37898363 0.50732127 0.3910422  0.5211025\n",
            " 0.34969854 0.40568475 0.48923342 0.4496124  0.62704565 0.50990525\n",
            " 0.5667528  0.48234281 0.60551249 0.58139535 0.49267873 0.52540913\n",
            " 0.47631352 0.48148148 0.4918174  0.46683893 0.70801034 0.58914729\n",
            " 0.4461671  0.55211025 0.52713178 0.6416882  0.54435831 0.35228252\n",
            " 0.56761413 0.41429802 0.61068045 0.51937984 0.49009475 0.46856158\n",
            " 0.49956934 0.55813953 0.34969854 0.53660637 0.31438415 0.63221361\n",
            " 0.50043066 0.52024117 0.41085271 0.40137812 0.70542636 0.52627046\n",
            " 0.60551249 0.44358312 0.54694229 0.41429802 0.55297158 0.60120586\n",
            " 0.39965547 0.61584841 0.44099914 0.60120586 0.58570198 0.41257537\n",
            " 0.44272179 0.66408269 0.59259259 0.48664944 0.37037037 0.38587425\n",
            " 0.58656331 0.65288544 0.60120586 0.58139535 0.53143842 0.41343669\n",
            " 0.62790698 0.583118   0.5960379  0.43238587 0.56503015 0.65977606\n",
            " 0.56761413 0.63738157 0.55727821 0.63307494 0.55900086 0.47803618\n",
            " 0.60120586 0.56158484 0.57105943 0.47631352 0.44530577 0.61757106\n",
            " 0.44530577 0.6546081  0.66236003 0.39793282 0.46942291 0.58570198\n",
            " 0.55900086 0.48492679 0.53316107 0.53057709 0.40999139 0.5796727\n",
            " 0.65202412 0.36434109 0.54177433 0.63393626 0.7329888  0.42204996\n",
            " 0.42894057 0.54349699 0.47372954 0.5503876  0.61068045 0.38845823\n",
            " 0.59173127 0.51076658 0.53919035 0.49009475 0.57019811 0.56158484\n",
            " 0.40310078 0.45564169 0.5667528  0.46942291 0.40826873 0.63135228\n",
            " 0.3875969  0.43669251 0.46511628 0.34797588 0.51507321 0.54952627\n",
            " 0.57622739 0.54521964 0.61412575 0.43669251 0.65374677 0.43927649\n",
            " 0.50215332 0.52196382 0.52627046 0.34797588 0.38501292 0.44444444\n",
            " 0.47114556 0.53402239 0.36864772 0.47717485 0.51851852 0.53143842\n",
            " 0.583118   0.38845823 0.45047373 0.47803618 0.40826873 0.57881137\n",
            " 0.51248923 0.51335056 0.5538329  0.5245478  0.45736434 0.53919035\n",
            " 0.40568475 0.54521964 0.50387597 0.44186047 0.4918174  0.31007752\n",
            " 0.44875108 0.60292851 0.52627046 0.61154177 0.4918174  0.5081826\n",
            " 0.44186047 0.58397933 0.54694229 0.56933678 0.39276486 0.53660637\n",
            " 0.44702842 0.49870801 0.51248923 0.42894057 0.42980189 0.51765719\n",
            " 0.66838932 0.60809647 0.65030146 0.5047373  0.58484065 0.54177433\n",
            " 0.60378984 0.52799311 0.51937984 0.58225668 0.57881137 0.56933678\n",
            " 0.2962963  0.68044789 0.52627046 0.64082687 0.59776055 0.4918174\n",
            " 0.59086994 0.42549526 0.43410853 0.69595177]\n",
            "The tained model has an aproximate error rate of -13.595321641721592 which equates to -2%\n"
          ]
        }
      ]
    }
  ]
}