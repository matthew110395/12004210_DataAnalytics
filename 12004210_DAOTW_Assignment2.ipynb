{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthew110395/12004210_DataAnalytics/blob/main/12004210_DAOTW_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "This assignment builds on the New York taxi problem identified in assignment 1, where the City of New York is looking for a way to accurately predict the number of collisions on a particular day of the week. Within this document two different types of machine learning models will be utilised to predict the number of collisions. The linear relationships identified in assignment 1 will be used to create linear regression models. Deep Learning Neural Network (DNN) models will be used to predict the number of collisions where the relationship is not linear. "
      ],
      "metadata": {
        "id": "-MIIDzFYc6Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports\n",
        "To prepare data for machine learning the pandas package has been used, alongside the numpy package which has been used to aid with mathematical functions.\n",
        "\n",
        "As within part 1 of this assignment, the data file containing location data exceeds the size limit for hosting within github. To overcome this the file was zipped. To extract the data the zipfile package has been used.\n",
        "\n",
        "Within this document, TensorFlow is used for machine learning, with both linear regression models and a Deep Neural Network models. TensorFlow version 1 is unsupported within Google Colab, therefore must be installed using a package manager.\n",
        "\n",
        "Shutil is also imported to allow for file management, in particular the removal of saved models."
      ],
      "metadata": {
        "id": "PP_OBRRWE3tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "!pip install tensorflow==1.15.2\n",
        "import tensorflow as tf\n",
        "import shutil  "
      ],
      "metadata": {
        "id": "J3Vp_IJAE49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3423109b-9048-456e-d93d-57778e36ad70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.2\n",
            "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 30 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.38.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.50.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 24.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (2.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.19.6)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=5e84397cd1cae56800e51dec65b16abafaf0e28c7b2e15129e0365fb1b615ee8\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.17.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regressor\n",
        "Throughout assignment 1 a number of linear relationships were uncovered within the dataset. These relationships form the basis of the linear regression models below.\n",
        "\n",
        "A linear regressor is used to predict an output variable based on one or more input variables (IBM n.d.)."
      ],
      "metadata": {
        "id": "SxU2LFGDjN9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the accuracy of the model the target values are scaled. This reduces the range of collisions from 188-1161 to 0.1619... - 1 which allows for quicker training  (Zhang 2019)."
      ],
      "metadata": {
        "id": "vKNbHovb6hXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale to maximum number of collisions\n",
        "SCALE_COLLISIONS=1161"
      ],
      "metadata": {
        "id": "k-aEMQX9EuJJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precipitation\n",
        "As uncovered in assignment 1; as the volume of precipitation increases, the number of collisions increase. \n",
        "\n",
        "The datafile produced in assignment is imported."
      ],
      "metadata": {
        "id": "VtJ7HqhA3bIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read File\n",
        "df_prcp = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean.csv', index_col=0, )\n",
        "print(df_prcp[:6])"
      ],
      "metadata": {
        "id": "Gr0ljmfBkDwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2a541b-b294-4503-cff8-d5e6a44ef1e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create the linear regression model, extra columns are removed to simplify the model with the aim of reducing error values.\n",
        "\n",
        "The incomplete years (2012 and 2022) are removed, along with the erroneous data for 2020 and 2021.\n",
        "\n",
        "To aid with the production of the model the target is moved to the end of the data table."
      ],
      "metadata": {
        "id": "NnrlNKFM0R-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_prcp = df_prcp.drop(columns=['collision_date', 'temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] != 2012]\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] < 2020]\n",
        "cols = df_prcp['NUM_COLLISIONS']\n",
        "df_prcp = df_prcp.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move NUM_COLLISIONS to end\n",
        "df_prcp.insert(loc=9, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp[:6])\n",
        "df_prcp.describe()"
      ],
      "metadata": {
        "id": "nRcEly727YQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "a69054b7-d622-4e58-cbb4-4f1ea68130cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "49    4  2016   1  28  0.09    0             0                 0     0   \n",
            "51    5  2014   1  17  0.00    1             0                 0     0   \n",
            "54    1  2016   1  25  0.02    0             0                 0     0   \n",
            "55    5  2016   1  29  0.00    0             0                 0     0   \n",
            "58    5  2017   1  20  0.00    0             0                 0     0   \n",
            "59    7  2013   1  13  0.01    1             0                 0     0   \n",
            "\n",
            "    NUM_COLLISIONS  \n",
            "49             681  \n",
            "51             589  \n",
            "54             658  \n",
            "55             645  \n",
            "58             605  \n",
            "59             373  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         prcp  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean      3.998425  2015.989366     6.518708    15.745569     0.122588   \n",
              "std       2.003542     1.996126     3.455211     8.803199     0.329143   \n",
              "min       1.000000  2013.000000     1.000000     1.000000     0.000000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000     0.000000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000     0.000000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000     0.060000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000     3.760000   \n",
              "\n",
              "               fog  rain_drizzle  snow_ice_pellets         hail  \\\n",
              "count  2539.000000   2539.000000       2539.000000  2539.000000   \n",
              "mean      0.253249      0.375345          0.085467     0.000394   \n",
              "std       0.434958      0.484307          0.279630     0.019846   \n",
              "min       0.000000      0.000000          0.000000     0.000000   \n",
              "25%       0.000000      0.000000          0.000000     0.000000   \n",
              "50%       0.000000      0.000000          0.000000     0.000000   \n",
              "75%       1.000000      1.000000          0.000000     0.000000   \n",
              "max       1.000000      1.000000          1.000000     1.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2539.000000  \n",
              "mean       599.135093  \n",
              "std        100.299164  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4dd8418b-7437-4400-af6c-cbca6048bdd6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998425</td>\n",
              "      <td>2015.989366</td>\n",
              "      <td>6.518708</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.003542</td>\n",
              "      <td>1.996126</td>\n",
              "      <td>3.455211</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dd8418b-7437-4400-af6c-cbca6048bdd6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4dd8418b-7437-4400-af6c-cbca6048bdd6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4dd8418b-7437-4400-af6c-cbca6048bdd6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove any bias within the dataset, it is randomly shuffled. The data is then split into the predictors and the target."
      ],
      "metadata": {
        "id": "eBk7xJt-Ag0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle = df_prcp.iloc[np.random.permutation(len(df_prcp))]\n",
        "\n",
        "# Select all apart from last col\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "8xT4g-UZFi01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6990ff-4ee4-45cd-87ac-b3b5c393559c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail\n",
            "2384    4  2013   8  15  0.00    0             0                 0     0\n",
            "1756    1  2019   6   3  0.00    0             0                 0     0\n",
            "519     6  2014   2  22  0.44    1             1                 0     0\n",
            "3229    5  2013  11  22  0.00    0             1                 0     0\n",
            "2823    4  2016  10  13  0.00    0             0                 0     0\n",
            "2559    6  2015   9  19  0.01    1             1                 0     0\n",
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "2384    4  2013   8  15  0.00    0             0                 0     0   \n",
            "1756    1  2019   6   3  0.00    0             0                 0     0   \n",
            "519     6  2014   2  22  0.44    1             1                 0     0   \n",
            "3229    5  2013  11  22  0.00    0             1                 0     0   \n",
            "2823    4  2016  10  13  0.00    0             0                 0     0   \n",
            "2559    6  2015   9  19  0.01    1             1                 0     0   \n",
            "\n",
            "      NUM_COLLISIONS  \n",
            "2384             599  \n",
            "1756             659  \n",
            "519              587  \n",
            "3229             702  \n",
            "2823             757  \n",
            "2559             655  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Target (last col)\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "O_xkzkVBQjL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540943fe-8411-4971-ded2-81f3db210063"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2384    599\n",
            "1756    659\n",
            "519     587\n",
            "3229    702\n",
            "2823    757\n",
            "2559    655\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 9\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "NwSG_P_nRgPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e313a1-a11f-477a-eea5-9718f69aa411"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2031\n",
            "508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_prcp', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "pred = format(str(predslistscale))\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "AUKI-paISKeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab35b47-26ea-4d45-c4db-7027cd3be1fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-8-959a182bfb57>:7: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/linear.py:740: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698c9af810>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-8-959a182bfb57>:7: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.2818297, step = 1\n",
            "INFO:tensorflow:global_step/sec: 780.763\n",
            "INFO:tensorflow:loss = 0.008050647, step = 101 (0.133 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 125 vs previous value: 125. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 739.456\n",
            "INFO:tensorflow:loss = 0.0068118866, step = 201 (0.135 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 201 vs previous value: 201. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 831.683\n",
            "INFO:tensorflow:loss = 0.0067442693, step = 301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.818\n",
            "INFO:tensorflow:loss = 0.0077139656, step = 401 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.761\n",
            "INFO:tensorflow:loss = 0.008002998, step = 501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.364\n",
            "INFO:tensorflow:loss = 0.008112436, step = 601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 863.098\n",
            "INFO:tensorflow:loss = 0.0065761926, step = 701 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.499\n",
            "INFO:tensorflow:loss = 0.006318624, step = 801 (0.115 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 801 vs previous value: 801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 822.348\n",
            "INFO:tensorflow:loss = 0.007487636, step = 901 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.239\n",
            "INFO:tensorflow:loss = 0.006685242, step = 1001 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 797.813\n",
            "INFO:tensorflow:loss = 0.0061943843, step = 1101 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.777\n",
            "INFO:tensorflow:loss = 0.0064801793, step = 1201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.72\n",
            "INFO:tensorflow:loss = 0.0068298457, step = 1301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.219\n",
            "INFO:tensorflow:loss = 0.0074735223, step = 1401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.058\n",
            "INFO:tensorflow:loss = 0.007364973, step = 1501 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.253\n",
            "INFO:tensorflow:loss = 0.0063390173, step = 1601 (0.138 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1601 vs previous value: 1601. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 302.746\n",
            "INFO:tensorflow:loss = 0.0074178823, step = 1701 (0.339 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1701 vs previous value: 1701. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 468.76\n",
            "INFO:tensorflow:loss = 0.006330996, step = 1801 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.029\n",
            "INFO:tensorflow:loss = 0.008528665, step = 1901 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.716\n",
            "INFO:tensorflow:loss = 0.006429676, step = 2001 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.034\n",
            "INFO:tensorflow:loss = 0.0067953463, step = 2101 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.879\n",
            "INFO:tensorflow:loss = 0.0072163, step = 2201 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.151\n",
            "INFO:tensorflow:loss = 0.007676853, step = 2301 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.554\n",
            "INFO:tensorflow:loss = 0.008878278, step = 2401 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.139\n",
            "INFO:tensorflow:loss = 0.0077319015, step = 2501 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.976\n",
            "INFO:tensorflow:loss = 0.006004615, step = 2601 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.981\n",
            "INFO:tensorflow:loss = 0.0063940864, step = 2701 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.122\n",
            "INFO:tensorflow:loss = 0.005959003, step = 2801 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.407\n",
            "INFO:tensorflow:loss = 0.0064665666, step = 2901 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.027\n",
            "INFO:tensorflow:loss = 0.0062518083, step = 3001 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.528\n",
            "INFO:tensorflow:loss = 0.006168846, step = 3101 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.622\n",
            "INFO:tensorflow:loss = 0.00516342, step = 3201 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.737\n",
            "INFO:tensorflow:loss = 0.006560115, step = 3301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.825\n",
            "INFO:tensorflow:loss = 0.006592313, step = 3401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.24\n",
            "INFO:tensorflow:loss = 0.0052673314, step = 3501 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.767\n",
            "INFO:tensorflow:loss = 0.0064634182, step = 3601 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.314\n",
            "INFO:tensorflow:loss = 0.0063776197, step = 3701 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.824\n",
            "INFO:tensorflow:loss = 0.005067871, step = 3801 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.743\n",
            "INFO:tensorflow:loss = 0.005760262, step = 3901 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.955\n",
            "INFO:tensorflow:loss = 0.0069255624, step = 4001 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 413.053\n",
            "INFO:tensorflow:loss = 0.006353015, step = 4101 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.643\n",
            "INFO:tensorflow:loss = 0.0052320734, step = 4201 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.057\n",
            "INFO:tensorflow:loss = 0.0067740683, step = 4301 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.002\n",
            "INFO:tensorflow:loss = 0.0055723945, step = 4401 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.705\n",
            "INFO:tensorflow:loss = 0.00568506, step = 4501 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.39\n",
            "INFO:tensorflow:loss = 0.006945992, step = 4601 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.178\n",
            "INFO:tensorflow:loss = 0.0068929773, step = 4701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.494\n",
            "INFO:tensorflow:loss = 0.008720597, step = 4801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.603\n",
            "INFO:tensorflow:loss = 0.0072346153, step = 4901 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.287\n",
            "INFO:tensorflow:loss = 0.006696515, step = 5001 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.259\n",
            "INFO:tensorflow:loss = 0.0057311514, step = 5101 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.017\n",
            "INFO:tensorflow:loss = 0.007299789, step = 5201 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.044\n",
            "INFO:tensorflow:loss = 0.0064365123, step = 5301 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.003\n",
            "INFO:tensorflow:loss = 0.00814686, step = 5401 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.721\n",
            "INFO:tensorflow:loss = 0.007668851, step = 5501 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.497\n",
            "INFO:tensorflow:loss = 0.0058724955, step = 5601 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.217\n",
            "INFO:tensorflow:loss = 0.0055972394, step = 5701 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.406\n",
            "INFO:tensorflow:loss = 0.0074903322, step = 5801 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.048\n",
            "INFO:tensorflow:loss = 0.007056836, step = 5901 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.812\n",
            "INFO:tensorflow:loss = 0.007834551, step = 6001 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.348\n",
            "INFO:tensorflow:loss = 0.006899057, step = 6101 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.185\n",
            "INFO:tensorflow:loss = 0.005423009, step = 6201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.719\n",
            "INFO:tensorflow:loss = 0.0062937886, step = 6301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.688\n",
            "INFO:tensorflow:loss = 0.006857587, step = 6401 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.019\n",
            "INFO:tensorflow:loss = 0.0059466036, step = 6501 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.243\n",
            "INFO:tensorflow:loss = 0.008526413, step = 6601 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.388\n",
            "INFO:tensorflow:loss = 0.007397239, step = 6701 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.312\n",
            "INFO:tensorflow:loss = 0.0066704266, step = 6801 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.93\n",
            "INFO:tensorflow:loss = 0.0071458598, step = 6901 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.696\n",
            "INFO:tensorflow:loss = 0.008995006, step = 7001 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.567\n",
            "INFO:tensorflow:loss = 0.0051866127, step = 7101 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.068\n",
            "INFO:tensorflow:loss = 0.006465229, step = 7201 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.952\n",
            "INFO:tensorflow:loss = 0.00837372, step = 7301 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.199\n",
            "INFO:tensorflow:loss = 0.0065326113, step = 7401 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.022\n",
            "INFO:tensorflow:loss = 0.0074264947, step = 7501 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.57\n",
            "INFO:tensorflow:loss = 0.007458902, step = 7601 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.75\n",
            "INFO:tensorflow:loss = 0.006023367, step = 7701 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.718\n",
            "INFO:tensorflow:loss = 0.006342846, step = 7801 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.824\n",
            "INFO:tensorflow:loss = 0.007166626, step = 7901 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.018\n",
            "INFO:tensorflow:loss = 0.007026542, step = 8001 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.559\n",
            "INFO:tensorflow:loss = 0.0065714046, step = 8101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.326\n",
            "INFO:tensorflow:loss = 0.0076078945, step = 8201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.477\n",
            "INFO:tensorflow:loss = 0.0064071584, step = 8301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 782.343\n",
            "INFO:tensorflow:loss = 0.0071290615, step = 8401 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.136\n",
            "INFO:tensorflow:loss = 0.005821663, step = 8501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.872\n",
            "INFO:tensorflow:loss = 0.0071430625, step = 8601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.098\n",
            "INFO:tensorflow:loss = 0.00650254, step = 8701 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.157\n",
            "INFO:tensorflow:loss = 0.007432456, step = 8801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.168\n",
            "INFO:tensorflow:loss = 0.009947285, step = 8901 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.327\n",
            "INFO:tensorflow:loss = 0.0069805626, step = 9001 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.814\n",
            "INFO:tensorflow:loss = 0.00765643, step = 9101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.311\n",
            "INFO:tensorflow:loss = 0.007691293, step = 9201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.133\n",
            "INFO:tensorflow:loss = 0.0067863194, step = 9301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 911.076\n",
            "INFO:tensorflow:loss = 0.0071165175, step = 9401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 893.002\n",
            "INFO:tensorflow:loss = 0.005942777, step = 9501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.919\n",
            "INFO:tensorflow:loss = 0.007679416, step = 9601 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.026\n",
            "INFO:tensorflow:loss = 0.007578564, step = 9701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.655\n",
            "INFO:tensorflow:loss = 0.00530891, step = 9801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.25\n",
            "INFO:tensorflow:loss = 0.00896691, step = 9901 (0.104 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0068106814.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 94.04293216822417\n",
            "Just using average = 597.4963072378139 has RMSE of 100.75322354041994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A number of learning rates were used to determine a suitable learning rate for the model. As the learning rate decreases the overall time to train the dataset increases (Zulkifli 2018)."
      ],
      "metadata": {
        "id": "3uYG_ScZR3yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Error Rate\n",
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "1fifEsTD98hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052442fe-f9f0-4873-86cc-f940c13d9201"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698b7c4c10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n",
            "[0.49244517 0.48378417 0.506735   0.5241162  0.49296534 0.515598\n",
            " 0.5320558  0.5080096  0.56285214 0.46699926 0.54114205 0.55445117\n",
            " 0.52352196 0.47925076 0.55024    0.5189467  0.53738964 0.5017981\n",
            " 0.48919103 0.51320815 0.48409644 0.46274322 0.5437057  0.48423973\n",
            " 0.5334265  0.5465016  0.47476095 0.47122625 0.511074   0.5185038\n",
            " 0.48082098 0.5352506  0.5126752  0.54007363 0.5392867  0.5332217\n",
            " 0.55164385 0.5502804  0.54471076 0.5083329  0.51693255 0.49409437\n",
            " 0.52621365 0.5461434  0.52084565 0.5519722  0.50297165 0.56764555\n",
            " 0.5146872  0.49352923 0.51807636 0.4931414  0.5235054  0.4998226\n",
            " 0.51515347 0.55737334 0.49201348 0.46954829 0.49867424 0.55823106\n",
            " 0.51544356 0.5282449  0.534032   0.45085797 0.50553536 0.521301\n",
            " 0.56145453 0.54818887 0.50697756 0.560859   0.5362219  0.51866055\n",
            " 0.4883773  0.46688813 0.5504946  0.485053   0.5291783  0.49491972\n",
            " 0.51075333 0.5039496  0.5533774  0.53664774 0.56532747 0.518715\n",
            " 0.48536047 0.5126382  0.5126378  0.5621793  0.46768704 0.52168953\n",
            " 0.52836525 0.49928507 0.49674872 0.52388066 0.5054523  0.5090926\n",
            " 0.5160577  0.5618131  0.49410027 0.48828158 0.5224745  0.5294159\n",
            " 0.53335285 0.53139454 0.50653523 0.5641293  0.55625594 0.5342525\n",
            " 0.5350465  0.5432478  0.47947893 0.5240332  0.54018664 0.48967078\n",
            " 0.47625428 0.4972208  0.4973519  0.48553345 0.49973196 0.46567717\n",
            " 0.4717611  0.5372895  0.49678913 0.52969176 0.49213615 0.55955267\n",
            " 0.51259965 0.54379696 0.51685476 0.55186546 0.5591577  0.4763361\n",
            " 0.5014149  0.5173823  0.53699946 0.5063302  0.5207316  0.5874573\n",
            " 0.5537199  0.50535035 0.48125792 0.51068497 0.49400374 0.5339636\n",
            " 0.5411967  0.5192944  0.4853537  0.50065774 0.48050207 0.5685435\n",
            " 0.5224633  0.49721423 0.49504462 0.49735653 0.5041874  0.49594736\n",
            " 0.4629744  0.4667786  0.5416313  0.4914401  0.4592746  0.46025854\n",
            " 0.54330266 0.49658018 0.51187    0.48769167 0.4804562  0.54627496\n",
            " 0.51894265 0.5616809  0.5099894  0.54688424 0.5628195  0.47802216\n",
            " 0.4915219  0.5078013  0.5167237  0.47631523 0.4970156  0.5626099\n",
            " 0.543147   0.44912118 0.49449044 0.51270646 0.46395436 0.4996855\n",
            " 0.4982703  0.535002   0.54256713 0.48686388 0.47611675 0.49875364\n",
            " 0.4428865  0.5641598  0.55325663 0.5330165  0.54892004 0.52155846\n",
            " 0.56276566 0.52996725 0.46723983 0.44975567 0.53461796 0.5335514\n",
            " 0.49318084 0.5409522  0.53681505 0.5236365  0.54297274 0.5020806\n",
            " 0.47535124 0.53168124 0.4800901  0.48203504 0.56105983 0.5069642\n",
            " 0.5078742  0.5404229  0.5047509  0.52386063 0.50082684 0.4984424\n",
            " 0.49163178 0.48108312 0.4566203  0.4563088  0.5346413  0.5042227\n",
            " 0.495664   0.4862531  0.50382745 0.53080267 0.52129346 0.555541\n",
            " 0.47327802 0.5299076  0.5376161  0.5389911  0.54083484 0.4889383\n",
            " 0.48365846 0.48996696 0.55489343 0.5380197  0.48861727 0.52578014\n",
            " 0.5392689  0.48082405 0.4760341  0.55628926 0.5323791  0.51049334\n",
            " 0.52652353 0.53063756 0.5099084  0.54676104 0.525215   0.54223084\n",
            " 0.54220843 0.5174671  0.50363654 0.44494164 0.50706816 0.49162418\n",
            " 0.5307658  0.5659089  0.52494913 0.47657934 0.5509345  0.5091117\n",
            " 0.5025131  0.4592643  0.53204817 0.46587077 0.48046353 0.54052365\n",
            " 0.53032434 0.45792496 0.5251752  0.4457056  0.5373587  0.53004\n",
            " 0.5158941  0.45636117 0.5239441  0.5467322  0.46583223 0.48184177\n",
            " 0.5046852  0.5077105  0.50806075 0.49898157 0.5344005  0.5423156\n",
            " 0.5278966  0.501399   0.48173723 0.46848652 0.53609085 0.5295388\n",
            " 0.51215357 0.4875842  0.505718   0.5370379  0.52086174 0.48934478\n",
            " 0.5395302  0.45484495 0.5486057  0.51772064 0.554078   0.4605407\n",
            " 0.5067944  0.48668024 0.47982064 0.50933224 0.4869791  0.49694574\n",
            " 0.50993145 0.48687148 0.51580924 0.43922988 0.50454193 0.48818257\n",
            " 0.5021189  0.4876181  0.5693867  0.5141411  0.46010602 0.5254352\n",
            " 0.4909142  0.4852005  0.5102893  0.56521463 0.4666559  0.503034\n",
            " 0.51660544 0.49518493 0.4780601  0.4848682  0.52408856 0.48084882\n",
            " 0.52708787 0.45413604 0.55868447 0.5544932  0.46637747 0.49146497\n",
            " 0.50528383 0.49416977 0.52714366 0.5234772  0.5555818  0.5213014\n",
            " 0.46655694 0.46976265 0.47862288 0.49840194 0.48718464 0.52189416\n",
            " 0.49383155 0.53156847 0.5036579  0.529653   0.50863266 0.5160448\n",
            " 0.5338919  0.47649387 0.5158186  0.5405757  0.5491109  0.5290364\n",
            " 0.52230036 0.52782077 0.5392337  0.47841176 0.48019615 0.5013558\n",
            " 0.49635044 0.5567572  0.4818561  0.4882135  0.48378074 0.535168\n",
            " 0.5260915  0.46644124 0.5147188  0.5112389  0.51139814 0.49531603\n",
            " 0.55785304 0.51834345 0.5517652  0.491388   0.5411092  0.47107485\n",
            " 0.49127162 0.56564057 0.49553657 0.49109188 0.56402105 0.48465946\n",
            " 0.4920047  0.5642967  0.4753712  0.5438408  0.45255625 0.48699376\n",
            " 0.49997523 0.5702749  0.5442685  0.48409712 0.5094172  0.50569654\n",
            " 0.5344433  0.51903695 0.46141067 0.48982936 0.49743637 0.5039032\n",
            " 0.4847398  0.48091465 0.48418638 0.4913996  0.4522046  0.5493179\n",
            " 0.5493652  0.49727422 0.5355403  0.55410826 0.5629937  0.55823874\n",
            " 0.48636147 0.51517606 0.46775377 0.5632542  0.53782886 0.46414348\n",
            " 0.4812633  0.54439944 0.5303932  0.5099265  0.45496702 0.48720428\n",
            " 0.5131014  0.5575014  0.50037515 0.4794343  0.5275473  0.5128897\n",
            " 0.5189058  0.49199882 0.5263879  0.49587584 0.48983008 0.5029291\n",
            " 0.53786933 0.5132563  0.5433155  0.55073893 0.50753486 0.5192665\n",
            " 0.5106602  0.545577   0.49566808 0.5026596  0.52587074 0.5571112\n",
            " 0.54692274 0.49887592 0.5408282  0.52547175 0.5298809  0.52517694\n",
            " 0.5086804  0.46334562 0.48104465 0.47494194 0.5431096  0.5020596\n",
            " 0.5587768  0.5222034  0.473649   0.57348126 0.5653894  0.49109736\n",
            " 0.5057635  0.45151633 0.5287653  0.53021884 0.53753453 0.4947958\n",
            " 0.5519125  0.48360637 0.52932537 0.50532424 0.47486416 0.50732726\n",
            " 0.49341738 0.51883394 0.53103554 0.48225674 0.52995574 0.5321199\n",
            " 0.46890023 0.5180744  0.5219181  0.52339256]\n",
            "[0.50387597 0.42635659 0.53919035 0.38931955 0.59086994 0.58053402\n",
            " 0.67011197 0.4918174  0.60206718 0.40913006 0.5503876  0.56589147\n",
            " 0.52540913 0.60292851 0.61929371 0.47459087 0.53229974 0.61584841\n",
            " 0.36434109 0.68217054 0.49440138 0.47803618 0.55900086 0.55900086\n",
            " 0.32988803 0.63049096 0.41946598 0.55555556 0.48837209 0.61412575\n",
            " 0.41343669 0.53402239 0.4952627  0.53832903 0.62790698 0.52282515\n",
            " 0.56416882 0.57881137 0.63393626 0.56330749 0.47372954 0.66236003\n",
            " 0.66666667 0.65891473 0.57105943 0.51162791 0.67183463 0.53143842\n",
            " 0.54521964 0.5047373  0.48923342 0.42204996 0.48578811 0.51507321\n",
            " 0.45822567 0.51937984 0.48751077 0.60551249 0.4918174  0.63996555\n",
            " 0.54866494 0.63738157 0.4203273  0.36692506 0.59345392 0.68647717\n",
            " 0.51593454 0.5538329  0.57364341 0.43152455 0.6124031  0.54780362\n",
            " 0.39448751 0.47200689 0.5503876  0.45650301 0.44875108 0.61154177\n",
            " 0.49956934 0.56072351 0.60637382 0.51937984 0.66666667 0.49612403\n",
            " 0.56933678 0.50387597 0.52627046 0.62360034 0.3453919  0.60292851\n",
            " 0.60551249 0.46770026 0.54521964 0.55986219 0.52540913 0.70111972\n",
            " 0.41429802 0.62618432 0.4788975  0.4788975  0.53402239 0.59689922\n",
            " 0.42894057 0.61068045 0.45219638 0.66149871 0.57105943 0.48664944\n",
            " 0.57105943 0.6416882  0.39018088 0.59086994 0.57278208 0.36175711\n",
            " 0.55986219 0.47631352 0.54177433 0.53057709 0.59000861 0.43841516\n",
            " 0.33419466 0.55727821 0.52627046 0.4918174  0.50215332 0.52196382\n",
            " 0.55211025 0.54952627 0.56761413 0.40568475 0.45908699 0.52713178\n",
            " 0.54091301 0.64771748 0.51421189 0.55813953 0.70198105 0.60034453\n",
            " 0.5667528  0.36606374 0.51937984 0.68561585 0.50129199 0.54091301\n",
            " 0.60292851 0.62790698 0.45822567 0.50215332 0.583118   0.46425495\n",
            " 0.46683893 0.51335056 0.5374677  0.46425495 0.56847545 0.75107666\n",
            " 0.46597761 0.52024117 0.56072351 0.63049096 0.48751077 0.45908699\n",
            " 0.59862188 0.54177433 0.42807924 0.5994832  0.46511628 0.63824289\n",
            " 0.69939707 0.57536606 0.57536606 0.50043066 0.51076658 0.39362618\n",
            " 0.44013781 0.64857881 0.52971576 0.52024117 0.48234281 0.46425495\n",
            " 0.61498708 0.82773471 0.44358312 0.56761413 0.36347976 0.47631352\n",
            " 0.62187769 0.45564169 0.6416882  0.44358312 0.54005168 0.58397933\n",
            " 0.42291128 0.45478036 0.46770026 0.59776055 0.45047373 0.53143842\n",
            " 0.4754522  0.58656331 0.44702842 0.38845823 0.60723514 0.46683893\n",
            " 0.48664944 0.49698536 0.67011197 0.54435831 0.47631352 0.49870801\n",
            " 0.52627046 0.55813953 0.33936262 0.52282515 0.60637382 0.46511628\n",
            " 0.42894057 0.49095607 0.46339363 0.55986219 0.54349699 0.48234281\n",
            " 0.46339363 0.41602067 0.41085271 0.43669251 0.61757106 0.59862188\n",
            " 0.5047373  0.63135228 0.41860465 0.56503015 0.51593454 0.55813953\n",
            " 0.51507321 0.47631352 0.49612403 0.63738157 0.52799311 0.5047373\n",
            " 0.36950904 0.44358312 0.54952627 0.54005168 0.46339363 0.60809647\n",
            " 0.59259259 0.51851852 0.43496985 0.57450474 0.46597761 0.43669251\n",
            " 0.53574505 0.48664944 0.55555556 0.60120586 0.38931955 0.51162791\n",
            " 0.69681309 0.70801034 0.65030146 0.45822567 0.66063738 0.40999139\n",
            " 0.4332472  0.68130922 0.53229974 0.56847545 0.52196382 0.66838932\n",
            " 0.59259259 0.38501292 0.61757106 0.49095607 0.5081826  0.63910422\n",
            " 0.48148148 0.374677   0.5538329  0.34453058 0.55641688 0.51248923\n",
            " 0.60120586 0.35486649 0.59345392 0.49440138 0.33505599 0.49354005\n",
            " 0.47975883 0.47114556 0.61929371 0.59776055 0.53229974 0.59000861\n",
            " 0.49784668 0.4461671  0.49354005 0.36520241 0.60809647 0.57622739\n",
            " 0.58225668 0.42894057 0.59776055 0.4203273  0.51593454 0.45305771\n",
            " 0.51679587 0.38673557 0.5211025  0.49612403 0.63824289 0.43238587\n",
            " 0.58484065 0.48664944 0.33850129 0.53143842 0.54263566 0.5047373\n",
            " 0.48406546 0.45822567 0.47631352 0.44530577 0.37639966 0.30749354\n",
            " 0.48751077 0.46942291 0.58484065 0.55813953 0.40654608 0.54349699\n",
            " 0.39276486 0.45391904 0.50215332 0.44702842 0.35400517 0.51937984\n",
            " 0.57881137 0.5245478  0.45822567 0.6546081  0.42721792 0.63049096\n",
            " 0.55813953 0.43496985 0.43496985 0.60809647 0.38845823 0.43410853\n",
            " 0.70887166 0.52713178 0.41085271 0.45219638 0.7166236  0.4039621\n",
            " 0.4203273  0.50990525 0.52024117 0.47631352 0.33505599 0.46425495\n",
            " 0.38242894 0.63479759 0.58656331 0.49354005 0.55124892 0.41602067\n",
            " 0.54521964 0.42204996 0.31007752 0.46770026 0.53057709 0.60981912\n",
            " 0.65288544 0.55986219 0.57881137 0.51851852 0.38070629 0.66063738\n",
            " 0.51421189 0.51162791 0.39965547 0.64341085 0.45564169 0.50904393\n",
            " 0.37639966 0.52196382 0.55641688 0.48751077 0.52799311 0.60292851\n",
            " 0.55211025 0.45391904 0.46339363 0.52799311 0.49009475 0.45478036\n",
            " 0.47717485 0.5503876  0.56761413 0.66838932 0.60292851 0.38242894\n",
            " 0.51765719 0.5667528  0.64857881 0.68475452 0.59689922 0.45305771\n",
            " 0.62790698 0.57019811 0.60120586 0.47631352 0.51335056 0.59086994\n",
            " 0.54091301 0.63307494 0.38156761 0.55641688 0.61326443 0.54177433\n",
            " 0.46167097 0.39793282 0.56847545 0.41257537 0.40310078 0.54005168\n",
            " 0.48406546 0.63221361 0.64513351 0.52196382 0.59345392 0.63135228\n",
            " 0.72265289 0.64513351 0.36347976 0.50215332 0.52971576 0.48148148\n",
            " 0.36606374 0.5245478  0.51937984 0.54177433 0.40137812 0.55900086\n",
            " 0.48923342 0.54694229 0.43238587 0.41343669 0.58656331 0.64254953\n",
            " 0.32988803 0.55469423 0.48062016 0.45822567 0.53574505 0.55297158\n",
            " 0.47717485 0.59086994 0.53919035 0.49956934 0.5211025  0.62273902\n",
            " 0.60292851 0.54263566 0.61068045 0.58570198 0.54349699 0.61154177\n",
            " 0.50301464 0.59431525 0.62101637 0.49267873 0.62790698 0.69422911\n",
            " 0.53488372 0.50301464 0.46511628 0.51765719 0.56158484 0.51335056\n",
            " 0.40999139 0.59086994 0.41257537 0.57450474 0.60206718 0.44358312\n",
            " 0.41343669 0.29371232 0.51593454 0.53229974 0.63824289 0.46167097\n",
            " 0.62187769 0.49095607 0.27648579 0.51076658 0.41429802 0.43238587\n",
            " 0.50559862 0.41257537 0.5047373  0.57278208 0.58828596 0.55124892\n",
            " 0.48492679 0.57105943 0.52971576 0.35658915]\n",
            "The trained model has an aproximate error rate of 11.114732726411086 which equates to 2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two main tests have been applied to the model. The Route Mean Squared Error (RMSE) and a comparison between the target values in the testing dataset and the predicted values using the predictors in the testing dataset.\n",
        "\n",
        "Predominantly the RMSE of the model is lower than that of the average. This indicates that the model makes more accurate predictions compared to the average."
      ],
      "metadata": {
        "id": "kKckcLmPVIMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dew Point (dewp)\n",
        "A relationship between dew point and the number of collisions was also uncovered in assignment 1. This linear relationship suggests that as the dew point increases the number of collisions increase. \n",
        "\n",
        "The process to produce the model follows the same process as the precipitation model."
      ],
      "metadata": {
        "id": "RB0Zq1024UmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_dewp = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/dewp_clean.csv', index_col=0, )\n",
        "print(df_dewp[:6])"
      ],
      "metadata": {
        "id": "d2NB6odM5G9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5dff2ce-00f3-4a80-964f-ed02b87ab16f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_dewp = df_dewp.drop(columns=['collision_date', 'temp', 'prcp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_dewp = df_dewp.loc[df_dewp[\"year\"] != 2012]\n",
        "df_dewp = df_dewp.loc[df_dewp[\"year\"] < 2020]\n",
        "cols = df_dewp['NUM_COLLISIONS']\n",
        "df_dewp = df_dewp.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move target to end\n",
        "df_dewp.insert(loc=5, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_dewp[:6])\n",
        "df_dewp.describe()"
      ],
      "metadata": {
        "id": "WwtmLQ6a5rHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "e3971416-45cf-41d4-8f06-46cb3176d535"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  dewp  NUM_COLLISIONS\n",
            "49    4  2016   1  28  24.4             681\n",
            "51    5  2014   1  17  35.8             589\n",
            "54    1  2016   1  25  21.2             658\n",
            "55    5  2016   1  29  36.8             645\n",
            "58    5  2017   1  20  32.5             605\n",
            "59    7  2013   1  13  44.9             373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         dewp  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      3.998434  2015.999217     6.524070    15.723679    44.163170   \n",
              "std       2.000391     2.000000     3.449676     8.801271    16.995303   \n",
              "min       1.000000  2013.000000     1.000000     1.000000    -6.700000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000    32.150000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000    45.300000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000    58.500000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000    74.100000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2555.000000  \n",
              "mean       599.109980  \n",
              "std        100.277185  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42e48688-6ea8-4272-8bee-41de2b490b51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>dewp</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998434</td>\n",
              "      <td>2015.999217</td>\n",
              "      <td>6.524070</td>\n",
              "      <td>15.723679</td>\n",
              "      <td>44.163170</td>\n",
              "      <td>599.109980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000391</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.449676</td>\n",
              "      <td>8.801271</td>\n",
              "      <td>16.995303</td>\n",
              "      <td>100.277185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42e48688-6ea8-4272-8bee-41de2b490b51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42e48688-6ea8-4272-8bee-41de2b490b51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42e48688-6ea8-4272-8bee-41de2b490b51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle Data\n",
        "shuffle = df_dewp.iloc[np.random.permutation(len(df_dewp))]\n",
        "#Select Predictors\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "KXbAqzNN694C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870a7792-ad8b-487c-d885-63dd4e858593"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  dewp\n",
            "1421    4  2017   5  25  51.1\n",
            "545     7  2015   2   1  10.2\n",
            "1320    2  2013   5  21  55.5\n",
            "2517    6  2017   9   2  45.2\n",
            "691     4  2016   3  24  38.1\n",
            "3340    1  2013  11  25   4.4\n",
            "      day  year  mo  da  dewp  NUM_COLLISIONS\n",
            "1421    4  2017   5  25  51.1             742\n",
            "545     7  2015   2   1  10.2             361\n",
            "1320    2  2013   5  21  55.5             697\n",
            "2517    6  2017   9   2  45.2             562\n",
            "691     4  2016   3  24  38.1             635\n",
            "3340    1  2013  11  25   4.4             710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "iGbT5sAJ7KTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e69bee6-d285-4f69-c68c-45317dbdf52b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1421    742\n",
            "545     361\n",
            "1320    697\n",
            "2517    562\n",
            "691     635\n",
            "3340    710\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 5\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "vpHbBnml7PZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e8844c-33af-43cf-8560-9a10b40bfb57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2044\n",
            "511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_dewp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#test Model\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "j4GKf5BL7WI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9167cd-447a-4a10-d0c5-0898b686c726"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69856ab7d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.2768998, step = 1\n",
            "INFO:tensorflow:global_step/sec: 767.36\n",
            "INFO:tensorflow:loss = 0.006016632, step = 101 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 750.23\n",
            "INFO:tensorflow:loss = 0.0055046105, step = 201 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 861.733\n",
            "INFO:tensorflow:loss = 0.0066261473, step = 301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.45\n",
            "INFO:tensorflow:loss = 0.0068937447, step = 401 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 882.746\n",
            "INFO:tensorflow:loss = 0.008133821, step = 501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.639\n",
            "INFO:tensorflow:loss = 0.008163027, step = 601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.254\n",
            "INFO:tensorflow:loss = 0.007626701, step = 701 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.559\n",
            "INFO:tensorflow:loss = 0.005834168, step = 801 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.394\n",
            "INFO:tensorflow:loss = 0.011139057, step = 901 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.696\n",
            "INFO:tensorflow:loss = 0.0069278562, step = 1001 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.033\n",
            "INFO:tensorflow:loss = 0.0077796536, step = 1101 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 719.134\n",
            "INFO:tensorflow:loss = 0.006376679, step = 1201 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.491\n",
            "INFO:tensorflow:loss = 0.006473023, step = 1301 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.961\n",
            "INFO:tensorflow:loss = 0.008173497, step = 1401 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.72\n",
            "INFO:tensorflow:loss = 0.007853782, step = 1501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.013\n",
            "INFO:tensorflow:loss = 0.007135943, step = 1601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.452\n",
            "INFO:tensorflow:loss = 0.005653677, step = 1701 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.893\n",
            "INFO:tensorflow:loss = 0.0058030337, step = 1801 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.126\n",
            "INFO:tensorflow:loss = 0.0064483504, step = 1901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 802.466\n",
            "INFO:tensorflow:loss = 0.0069499947, step = 2001 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.428\n",
            "INFO:tensorflow:loss = 0.00728286, step = 2101 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.411\n",
            "INFO:tensorflow:loss = 0.0062037995, step = 2201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.307\n",
            "INFO:tensorflow:loss = 0.007317763, step = 2301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.219\n",
            "INFO:tensorflow:loss = 0.005166267, step = 2401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.343\n",
            "INFO:tensorflow:loss = 0.0061187944, step = 2501 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 883.207\n",
            "INFO:tensorflow:loss = 0.007571473, step = 2601 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.091\n",
            "INFO:tensorflow:loss = 0.0071301847, step = 2701 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 753.352\n",
            "INFO:tensorflow:loss = 0.0071523283, step = 2801 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.57\n",
            "INFO:tensorflow:loss = 0.006828772, step = 2901 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.33\n",
            "INFO:tensorflow:loss = 0.0067866626, step = 3001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.39\n",
            "INFO:tensorflow:loss = 0.0062973723, step = 3101 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 780.645\n",
            "INFO:tensorflow:loss = 0.00692856, step = 3201 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.301\n",
            "INFO:tensorflow:loss = 0.0058163446, step = 3301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.689\n",
            "INFO:tensorflow:loss = 0.0073791565, step = 3401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.589\n",
            "INFO:tensorflow:loss = 0.0044062776, step = 3501 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.234\n",
            "INFO:tensorflow:loss = 0.006603537, step = 3601 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.497\n",
            "INFO:tensorflow:loss = 0.0062975753, step = 3701 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.992\n",
            "INFO:tensorflow:loss = 0.0063583674, step = 3801 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.354\n",
            "INFO:tensorflow:loss = 0.0055331304, step = 3901 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.605\n",
            "INFO:tensorflow:loss = 0.006094627, step = 4001 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.919\n",
            "INFO:tensorflow:loss = 0.0060966327, step = 4101 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.657\n",
            "INFO:tensorflow:loss = 0.0066190544, step = 4201 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.606\n",
            "INFO:tensorflow:loss = 0.0053636977, step = 4301 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.041\n",
            "INFO:tensorflow:loss = 0.0075166766, step = 4401 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.79\n",
            "INFO:tensorflow:loss = 0.0059144003, step = 4501 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.392\n",
            "INFO:tensorflow:loss = 0.005055042, step = 4601 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.568\n",
            "INFO:tensorflow:loss = 0.0066249035, step = 4701 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.143\n",
            "INFO:tensorflow:loss = 0.0063231466, step = 4801 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.591\n",
            "INFO:tensorflow:loss = 0.0064831385, step = 4901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.889\n",
            "INFO:tensorflow:loss = 0.0073098144, step = 5001 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.229\n",
            "INFO:tensorflow:loss = 0.0063363984, step = 5101 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.874\n",
            "INFO:tensorflow:loss = 0.009948071, step = 5201 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.117\n",
            "INFO:tensorflow:loss = 0.006186283, step = 5301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.502\n",
            "INFO:tensorflow:loss = 0.0048905415, step = 5401 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.379\n",
            "INFO:tensorflow:loss = 0.0062473714, step = 5501 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.066\n",
            "INFO:tensorflow:loss = 0.007651432, step = 5601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.133\n",
            "INFO:tensorflow:loss = 0.007063891, step = 5701 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.495\n",
            "INFO:tensorflow:loss = 0.0065044565, step = 5801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.858\n",
            "INFO:tensorflow:loss = 0.0067960904, step = 5901 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.576\n",
            "INFO:tensorflow:loss = 0.0077376645, step = 6001 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.539\n",
            "INFO:tensorflow:loss = 0.006201948, step = 6101 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.894\n",
            "INFO:tensorflow:loss = 0.0064796517, step = 6201 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.556\n",
            "INFO:tensorflow:loss = 0.0071585635, step = 6301 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.421\n",
            "INFO:tensorflow:loss = 0.007714671, step = 6401 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.274\n",
            "INFO:tensorflow:loss = 0.0062464844, step = 6501 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.745\n",
            "INFO:tensorflow:loss = 0.009516491, step = 6601 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.213\n",
            "INFO:tensorflow:loss = 0.006383951, step = 6701 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.095\n",
            "INFO:tensorflow:loss = 0.0058696736, step = 6801 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.441\n",
            "INFO:tensorflow:loss = 0.0079053845, step = 6901 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.459\n",
            "INFO:tensorflow:loss = 0.006305363, step = 7001 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 408.651\n",
            "INFO:tensorflow:loss = 0.00716344, step = 7101 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.105\n",
            "INFO:tensorflow:loss = 0.006167639, step = 7201 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.098\n",
            "INFO:tensorflow:loss = 0.008396933, step = 7301 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.154\n",
            "INFO:tensorflow:loss = 0.0070848027, step = 7401 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.57\n",
            "INFO:tensorflow:loss = 0.006737233, step = 7501 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.951\n",
            "INFO:tensorflow:loss = 0.0061316453, step = 7601 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.436\n",
            "INFO:tensorflow:loss = 0.006877497, step = 7701 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.796\n",
            "INFO:tensorflow:loss = 0.008573623, step = 7801 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.074\n",
            "INFO:tensorflow:loss = 0.005827421, step = 7901 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.685\n",
            "INFO:tensorflow:loss = 0.0063955225, step = 8001 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.419\n",
            "INFO:tensorflow:loss = 0.007334615, step = 8101 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.712\n",
            "INFO:tensorflow:loss = 0.0078085214, step = 8201 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.47\n",
            "INFO:tensorflow:loss = 0.0067804186, step = 8301 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.069\n",
            "INFO:tensorflow:loss = 0.006557109, step = 8401 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.652\n",
            "INFO:tensorflow:loss = 0.00687196, step = 8501 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.995\n",
            "INFO:tensorflow:loss = 0.0063322615, step = 8601 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.985\n",
            "INFO:tensorflow:loss = 0.0057140957, step = 8701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.565\n",
            "INFO:tensorflow:loss = 0.00649611, step = 8801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.004\n",
            "INFO:tensorflow:loss = 0.006834928, step = 8901 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.509\n",
            "INFO:tensorflow:loss = 0.005355109, step = 9001 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.129\n",
            "INFO:tensorflow:loss = 0.0043980125, step = 9101 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.988\n",
            "INFO:tensorflow:loss = 0.007911651, step = 9201 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.392\n",
            "INFO:tensorflow:loss = 0.005600581, step = 9301 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.299\n",
            "INFO:tensorflow:loss = 0.006365844, step = 9401 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.959\n",
            "INFO:tensorflow:loss = 0.005334211, step = 9501 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.538\n",
            "INFO:tensorflow:loss = 0.0059063267, step = 9601 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.401\n",
            "INFO:tensorflow:loss = 0.0074143903, step = 9701 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 765.943\n",
            "INFO:tensorflow:loss = 0.0059195627, step = 9801 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.47\n",
            "INFO:tensorflow:loss = 0.0045063514, step = 9901 (0.127 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.008595552.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 95.75721709818401\n",
            "Just using average = 599.4006849315068 has RMSE of 101.27851174723051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "CmqqgLT09593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8096d642-0458-4d91-8786-3856e38c5b5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6989698a90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n",
            "[0.53421575 0.49107456 0.49575955 0.49392542 0.56014323 0.5377786\n",
            " 0.5223685  0.53651047 0.48761994 0.5390038  0.49725395 0.4435207\n",
            " 0.5142695  0.55664724 0.5556217  0.4559405  0.47730133 0.5024583\n",
            " 0.48681208 0.4818581  0.55331534 0.48931074 0.4903469  0.45501387\n",
            " 0.5434811  0.512435   0.53500646 0.5193931  0.49469087 0.49011216\n",
            " 0.50368583 0.57227135 0.5332097  0.5539787  0.48971078 0.5274615\n",
            " 0.5359507  0.48769894 0.48654956 0.44337437 0.47959533 0.5250092\n",
            " 0.46282938 0.52377385 0.52091324 0.4930509  0.47698689 0.4867593\n",
            " 0.56791437 0.48990378 0.50849086 0.46699712 0.47940958 0.47724116\n",
            " 0.5077634  0.49327928 0.55553806 0.4620578  0.52435994 0.5629149\n",
            " 0.5488726  0.4735266  0.5382052  0.51620543 0.49822935 0.5469527\n",
            " 0.49283955 0.49834624 0.49440598 0.4798046  0.50224555 0.50002277\n",
            " 0.5314395  0.4875895  0.5164654  0.47403085 0.5110501  0.49407378\n",
            " 0.5435952  0.48025957 0.51183796 0.5238735  0.5174607  0.44084144\n",
            " 0.50646    0.4979614  0.5576722  0.54823166 0.5386734  0.49832204\n",
            " 0.5319148  0.5566402  0.5370837  0.4678933  0.534151   0.5507961\n",
            " 0.538146   0.56151193 0.46897173 0.45600024 0.5507008  0.49575794\n",
            " 0.51402277 0.4966991  0.54865104 0.4850135  0.45670736 0.4934501\n",
            " 0.52561116 0.55522317 0.491001   0.55451494 0.4721671  0.53128767\n",
            " 0.44253832 0.46357208 0.50030845 0.49393815 0.4671268  0.5020611\n",
            " 0.47627494 0.49526227 0.5646661  0.4672722  0.5473358  0.543781\n",
            " 0.56591123 0.51844096 0.56181085 0.4630721  0.44327414 0.53514665\n",
            " 0.5100439  0.49867547 0.49491516 0.48092905 0.48610955 0.49235475\n",
            " 0.4767612  0.4968008  0.5180867  0.49753836 0.5195467  0.45384657\n",
            " 0.4873432  0.5419876  0.52890027 0.49534348 0.48744348 0.45483762\n",
            " 0.46792582 0.55165327 0.56838727 0.4801331  0.5464264  0.50356656\n",
            " 0.550815   0.4911041  0.44891065 0.41922763 0.5022579  0.49113142\n",
            " 0.5428561  0.5325001  0.50831157 0.49621278 0.5491994  0.537402\n",
            " 0.5145859  0.54066455 0.55689675 0.47690448 0.5076707  0.4918595\n",
            " 0.5611301  0.5015871  0.5636849  0.48482478 0.53107697 0.49947152\n",
            " 0.4923675  0.54050845 0.49783042 0.49278498 0.4763463  0.5160303\n",
            " 0.50885993 0.5182642  0.4880862  0.48138863 0.50854605 0.4706723\n",
            " 0.46546444 0.52300376 0.48262268 0.49504566 0.50406724 0.45935616\n",
            " 0.5685141  0.5262262  0.5428328  0.54010504 0.50496274 0.53744584\n",
            " 0.45256698 0.4602387  0.50924337 0.5193502  0.5150973  0.4595402\n",
            " 0.5459269  0.5041982  0.5167975  0.5399957  0.5424848  0.49723879\n",
            " 0.52763015 0.5497738  0.517187   0.5420074  0.54403365 0.5664647\n",
            " 0.5062566  0.49747792 0.4407439  0.55642104 0.49067378 0.5232949\n",
            " 0.5555198  0.44716373 0.51529765 0.55889523 0.4752335  0.4970123\n",
            " 0.49862754 0.48569885 0.4975388  0.5217137  0.4414717  0.51002866\n",
            " 0.5381575  0.5334331  0.4850427  0.5556047  0.4989292  0.49341136\n",
            " 0.49882194 0.5511796  0.4815451  0.5004672  0.5487616  0.5098304\n",
            " 0.55583066 0.48916537 0.5040487  0.510084   0.56384677 0.51586604\n",
            " 0.4657072  0.48165548 0.5180228  0.47764242 0.5058726  0.5508397\n",
            " 0.50521797 0.49722064 0.5054046  0.44345242 0.5563468  0.52320474\n",
            " 0.5354333  0.4702021  0.45749208 0.5599726  0.5120475  0.42904606\n",
            " 0.570647   0.49122164 0.45928767 0.487832   0.48334667 0.4996532\n",
            " 0.5484792  0.45275372 0.4889679  0.48131308 0.5439778  0.5020044\n",
            " 0.5315738  0.5715465  0.5671006  0.4515485  0.5354006  0.5023712\n",
            " 0.48095796 0.4852251  0.51566565 0.5592785  0.5112998  0.51718885\n",
            " 0.48734564 0.57278526 0.4778432  0.53039175 0.53167593 0.54318535\n",
            " 0.48048726 0.5154773  0.48898593 0.46517614 0.5316904  0.5328534\n",
            " 0.49488428 0.5022873  0.5230931  0.52037084 0.55387187 0.4961295\n",
            " 0.4530958  0.49017882 0.5741512  0.46120393 0.49160618 0.5142453\n",
            " 0.5319724  0.4917349  0.48484665 0.48945364 0.494704   0.5260376\n",
            " 0.5013408  0.43430054 0.5160483  0.51622164 0.51544905 0.5094888\n",
            " 0.5575289  0.50295645 0.5107726  0.4763311  0.48658025 0.45912975\n",
            " 0.519478   0.5394092  0.48356658 0.5663733  0.5000686  0.4764033\n",
            " 0.56312037 0.49330625 0.51448715 0.49923348 0.51334935 0.4584794\n",
            " 0.47475597 0.51009125 0.55912364 0.49926057 0.5421914  0.4935986\n",
            " 0.5544947  0.45133615 0.5624043  0.5120318  0.5007936  0.48750466\n",
            " 0.5383637  0.4917827  0.55578744 0.46971604 0.45628747 0.43720493\n",
            " 0.4440047  0.57329786 0.5031251  0.53362274 0.5195886  0.46425614\n",
            " 0.53067386 0.51839614 0.553383   0.5006774  0.51292217 0.4730869\n",
            " 0.548877   0.55577976 0.5490654  0.5038712  0.50123614 0.44885746\n",
            " 0.52329266 0.5214182  0.56448853 0.48802036 0.5510372  0.4726357\n",
            " 0.4715623  0.5096324  0.5436093  0.4379236  0.5439993  0.4869932\n",
            " 0.5307772  0.49438778 0.4786108  0.48771387 0.49898398 0.5022432\n",
            " 0.5531764  0.5248796  0.57368106 0.49000636 0.5202303  0.5117905\n",
            " 0.44262257 0.54532075 0.5153702  0.4762922  0.4600883  0.4582029\n",
            " 0.4752905  0.5330993  0.4603485  0.46850732 0.46924427 0.5542063\n",
            " 0.45083708 0.46546492 0.5511693  0.54421246 0.5601035  0.49180132\n",
            " 0.55036813 0.51321715 0.5055009  0.46205997 0.4664695  0.47685966\n",
            " 0.54270154 0.55006826 0.46729523 0.45372048 0.4834168  0.50890076\n",
            " 0.48725203 0.46294156 0.48673055 0.47699246 0.5425007  0.50419164\n",
            " 0.5277587  0.4818674  0.5091307  0.46783447 0.52481693 0.5272496\n",
            " 0.4765001  0.52035487 0.48318923 0.51402575 0.55812645 0.52924025\n",
            " 0.4918862  0.49643648 0.52673125 0.55996543 0.5026139  0.47402534\n",
            " 0.5193506  0.58076906 0.51237756 0.52035034 0.47622278 0.53181046\n",
            " 0.5604853  0.5421439  0.53309274 0.54655284 0.51327544 0.48062757\n",
            " 0.5108245  0.4900756  0.47438335 0.5032174  0.5513269  0.52265084\n",
            " 0.51686096 0.55113703 0.5030003  0.52963316 0.4658147  0.481511\n",
            " 0.5178722  0.47391117 0.45896015 0.51715994 0.48497325 0.56407666\n",
            " 0.4917181  0.49754435 0.4700032  0.47455233 0.4501817  0.47930786\n",
            " 0.5609567  0.49925965 0.56731683 0.5047218  0.5204315  0.4534223\n",
            " 0.5071953 ]\n",
            "[0.45908699 0.42204996 0.50301464 0.42291128 0.58570198 0.56072351\n",
            " 0.57622739 0.60723514 0.43755383 0.58914729 0.48492679 0.38501292\n",
            " 0.46080965 0.54608096 0.37898363 0.35400517 0.5374677  0.59431525\n",
            " 0.41946598 0.44444444 0.43583118 0.58484065 0.5374677  0.48664944\n",
            " 0.54263566 0.54780362 0.37726098 0.61068045 0.54780362 0.48837209\n",
            " 0.46339363 0.53057709 0.61843239 0.54952627 0.53057709 0.6124031\n",
            " 0.47631352 0.39879414 0.56158484 0.56416882 0.48062016 0.57450474\n",
            " 0.38587425 0.57019811 0.63652024 0.51679587 0.43066322 0.50990525\n",
            " 0.55211025 0.57708872 0.60292851 0.31438415 0.44358312 0.42894057\n",
            " 0.66322136 0.56847545 0.5503876  0.39534884 0.54435831 0.49956934\n",
            " 0.28682171 0.48751077 0.57881137 0.55813953 0.66063738 0.60637382\n",
            " 0.583118   0.48406546 0.4754522  0.43496985 0.62015504 0.51765719\n",
            " 0.56330749 0.53316107 0.65374677 0.60378984 0.53919035 0.51937984\n",
            " 0.44702842 0.46942291 0.44530577 0.64857881 0.5211025  0.33419466\n",
            " 0.48923342 0.4754522  0.60120586 0.55211025 0.46683893 0.58742463\n",
            " 0.44702842 0.7166236  0.43927649 0.49267873 0.54091301 0.59345392\n",
            " 0.63393626 0.69250646 0.44444444 0.44875108 0.46770026 0.56847545\n",
            " 0.58828596 0.62704565 0.53229974 0.43496985 0.37639966 0.62618432\n",
            " 0.55297158 0.60034453 0.48492679 0.5538329  0.50904393 0.48234281\n",
            " 0.42204996 0.60292851 0.48406546 0.43410853 0.40482343 0.42549526\n",
            " 0.53919035 0.46511628 0.5796727  0.49009475 0.55297158 0.59259259\n",
            " 0.51507321 0.60809647 0.49095607 0.47459087 0.45908699 0.57019811\n",
            " 0.44272179 0.50645995 0.52713178 0.46167097 0.60637382 0.42377261\n",
            " 0.52024117 0.41860465 0.60292851 0.55900086 0.53316107 0.34022394\n",
            " 0.43066322 0.61498708 0.58828596 0.41429802 0.47286822 0.43238587\n",
            " 0.57450474 0.53660637 0.52885444 0.52024117 0.62101637 0.62704565\n",
            " 0.53229974 0.56158484 0.40913006 0.36950904 0.54435831 0.51593454\n",
            " 0.52799311 0.52971576 0.45133506 0.59173127 0.56761413 0.56933678\n",
            " 0.52799311 0.67011197 0.50301464 0.45908699 0.63996555 0.52713178\n",
            " 0.65374677 0.54866494 0.48751077 0.55986219 0.50301464 0.72437554\n",
            " 0.53143842 0.46770026 0.51593454 0.55555556 0.49784668 0.4039621\n",
            " 0.68303187 0.5374677  0.44099914 0.36089578 0.56847545 0.37812231\n",
            " 0.41946598 0.54349699 0.43841516 0.52024117 0.51335056 0.53229974\n",
            " 0.44702842 0.51593454 0.57278208 0.38156761 0.45908699 0.59431525\n",
            " 0.3453919  0.49095607 0.36606374 0.54952627 0.59776055 0.50990525\n",
            " 0.37295435 0.46942291 0.50904393 0.44702842 0.4918174  0.48062016\n",
            " 0.59086994 0.54263566 0.58914729 0.57278208 0.57019811 0.43496985\n",
            " 0.59259259 0.55555556 0.38845823 0.45047373 0.44186047 0.52540913\n",
            " 0.5667528  0.41343669 0.5211025  0.55986219 0.58656331 0.46080965\n",
            " 0.57105943 0.47286822 0.46856158 0.56158484 0.39965547 0.52971576\n",
            " 0.36175711 0.52024117 0.86046512 0.52196382 0.63307494 0.5994832\n",
            " 0.54349699 0.48751077 0.53143842 0.5081826  0.55555556 0.52713178\n",
            " 0.51162791 0.54091301 0.62790698 0.48923342 0.66149871 0.53488372\n",
            " 0.80878553 0.43496985 0.22739018 0.5211025  0.57622739 0.55641688\n",
            " 0.53488372 0.59776055 0.53488372 0.46167097 0.52540913 0.52971576\n",
            " 0.64254953 0.43066322 0.44875108 0.66666667 0.51507321 0.4005168\n",
            " 0.5047373  0.54866494 0.44013781 0.37984496 0.35486649 0.36950904\n",
            " 0.54694229 0.4203273  0.62015504 0.47975883 0.55813953 0.76055125\n",
            " 0.6089578  0.36089578 0.52885444 0.33936262 0.5667528  0.69853575\n",
            " 0.38845823 0.47717485 0.45994832 0.54952627 0.66925065 0.44186047\n",
            " 0.55727821 0.50215332 0.49784668 0.54780362 0.55986219 0.63652024\n",
            " 0.37639966 0.66236003 0.45908699 0.47803618 0.50129199 0.38931955\n",
            " 0.56072351 0.54608096 0.51937984 0.55211025 0.59862188 0.45305771\n",
            " 0.48406546 0.46942291 0.50732127 0.44186047 0.43583118 0.64685616\n",
            " 0.61498708 0.51765719 0.40137812 0.4625323  0.46080965 0.50559862\n",
            " 0.56503015 0.38329027 0.55986219 0.51851852 0.5211025  0.60292851\n",
            " 0.51765719 0.56158484 0.49784668 0.53143842 0.56933678 0.48320413\n",
            " 0.46511628 0.54177433 0.41774332 0.52885444 0.58053402 0.52713178\n",
            " 0.46856158 0.46339363 0.47631352 0.45478036 0.58656331 0.33505599\n",
            " 0.56847545 0.42377261 0.56761413 0.56072351 0.59862188 0.40740741\n",
            " 0.4918174  0.37209302 0.51421189 0.58742463 0.60465116 0.54866494\n",
            " 0.61412575 0.73815676 0.62962963 0.64857881 0.4332472  0.34453058\n",
            " 0.37553833 0.49009475 0.41085271 0.54263566 0.51507321 0.6416882\n",
            " 0.74677003 0.54608096 0.59259259 0.5047373  0.32816537 0.58225668\n",
            " 0.62446167 0.37898363 0.56330749 0.54349699 0.59086994 0.4005168\n",
            " 0.6089578  0.57450474 0.6089578  0.41343669 0.60206718 0.45305771\n",
            " 0.44702842 0.46942291 0.63049096 0.36864772 0.46339363 0.50732127\n",
            " 0.43152455 0.40826873 0.4332472  0.65202412 0.5374677  0.47631352\n",
            " 0.54349699 0.53057709 0.53143842 0.52540913 0.45047373 0.60809647\n",
            " 0.41257537 0.59259259 0.55986219 0.52713178 0.35917313 0.44530577\n",
            " 0.55900086 0.54694229 0.50732127 0.58484065 0.47028424 0.56503015\n",
            " 0.36520241 0.39190353 0.61154177 0.52799311 0.41429802 0.44358312\n",
            " 0.56933678 0.58570198 0.71576227 0.43669251 0.56330749 0.45564169\n",
            " 0.49267873 0.49354005 0.40137812 0.47717485 0.56589147 0.46683893\n",
            " 0.34366925 0.40654608 0.48406546 0.42463394 0.57364341 0.47372954\n",
            " 0.53574505 0.48923342 0.30577089 0.57364341 0.61498708 0.4952627\n",
            " 0.44530577 0.53229974 0.52627046 0.69939707 0.4754522  0.40913006\n",
            " 0.4788975  0.66838932 0.59345392 0.53057709 0.52627046 0.47200689\n",
            " 0.60206718 0.33763997 0.56761413 0.64771748 0.45305771 0.47631352\n",
            " 0.69595177 0.59259259 0.63910422 0.61584841 0.59086994 0.44013781\n",
            " 0.67355728 0.50215332 0.36606374 0.46597761 0.67011197 0.48148148\n",
            " 0.48492679 0.56589147 0.49698536 0.46511628 0.45650301 0.4461671\n",
            " 0.52713178 0.46425495 0.50387597 0.5994832  0.4788975  0.46942291\n",
            " 0.44099914 0.65891473 0.40913006 0.43583118 0.42980189 0.43583118\n",
            " 0.57364341 0.58225668 0.34453058 0.67183463 0.64341085 0.36692506\n",
            " 0.56244617]\n",
            "The trained model has an aproximate error rate of 8.476213275511437 which equates to 1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE for the dewp model is slightly lower in comparison to the model produced for precipitation. As the RMSE is lower than the RMSE of the mean, it shows that the model has a higher level of accuracy in comparison to the using the mean."
      ],
      "metadata": {
        "id": "k_jNEZ_dS62M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visibility (visib)\n",
        "A relationship was also uncovered between visibility and the number of collisions. This is a negative linear relationship where the visibility increases the number of collisions decrease. \n",
        "\n",
        "The process to produce the model follows the same process as above."
      ],
      "metadata": {
        "id": "XfOkQa04Wgr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_visib = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/coldata.csv', index_col=0, )\n",
        "print(df_visib[:6])"
      ],
      "metadata": {
        "id": "tOsAfHzhWgr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a29c94-b4b7-4ee9-8943-bb9465a599eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_visib = df_visib.drop(columns=['collision_date', 'temp', 'prcp', 'slp','dewp','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_visib = df_visib.loc[df_visib[\"year\"] != 2012]\n",
        "df_visib = df_visib.loc[df_visib[\"year\"] < 2020]\n",
        "cols = df_visib['NUM_COLLISIONS']\n",
        "df_visib = df_visib.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move target to end\n",
        "df_visib.insert(loc=5, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_visib[:6])\n",
        "df_visib.describe()"
      ],
      "metadata": {
        "id": "pAaWfrlBWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "cca8fa9f-ea68-4526-dc0b-8773e37b8db8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  visib  NUM_COLLISIONS\n",
            "49    4  2016   1  28   10.0             681\n",
            "51    5  2014   1  17    6.7             589\n",
            "54    1  2016   1  25   10.0             658\n",
            "55    5  2016   1  29   10.0             645\n",
            "58    5  2017   1  20   10.0             605\n",
            "59    7  2013   1  13    4.3             373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day    year           mo           da        visib  \\\n",
              "count  2556.000000  2556.0  2556.000000  2556.000000  2556.000000   \n",
              "mean      3.999218  2016.0     6.524257    15.725743     8.295618   \n",
              "std       2.000391     2.0     3.449013     8.800168     2.207870   \n",
              "min       1.000000  2013.0     1.000000     1.000000     0.200000   \n",
              "25%       2.000000  2014.0     4.000000     8.000000     7.100000   \n",
              "50%       4.000000  2016.0     7.000000    16.000000     9.400000   \n",
              "75%       6.000000  2018.0    10.000000    23.000000    10.000000   \n",
              "max       7.000000  2019.0    12.000000    31.000000    10.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2556.000000  \n",
              "mean       599.118936  \n",
              "std        100.258581  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e281b3c6-59fe-496d-ad17-b9f0078cf755\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>visib</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.0</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.999218</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.524257</td>\n",
              "      <td>15.725743</td>\n",
              "      <td>8.295618</td>\n",
              "      <td>599.118936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000391</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.449013</td>\n",
              "      <td>8.800168</td>\n",
              "      <td>2.207870</td>\n",
              "      <td>100.258581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e281b3c6-59fe-496d-ad17-b9f0078cf755')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e281b3c6-59fe-496d-ad17-b9f0078cf755 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e281b3c6-59fe-496d-ad17-b9f0078cf755');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data\n",
        "shuffle = df_visib.iloc[np.random.permutation(len(df_visib))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "9VOgsgFJWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1c85c8-ab56-4dc0-f0e5-07077b4d296f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  visib\n",
            "2696    2  2014   9  30    6.7\n",
            "79      6  2019   1  19    9.8\n",
            "3422    6  2015  12   5   10.0\n",
            "3356    3  2014  11  26    6.7\n",
            "3559    3  2013  12  11    9.9\n",
            "2840    7  2016  10   2    4.4\n",
            "      day  year  mo  da  visib  NUM_COLLISIONS\n",
            "2696    2  2014   9  30    6.7             589\n",
            "79      6  2019   1  19    9.8             479\n",
            "3422    6  2015  12   5   10.0             629\n",
            "3356    3  2014  11  26    6.7             742\n",
            "3559    3  2013  12  11    9.9             605\n",
            "2840    7  2016  10   2    4.4             486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "dx2bYy6zWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013a610b-f30e-4bfe-ecd8-aa3ea26d85be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2696    589\n",
            "79      479\n",
            "3422    629\n",
            "3356    742\n",
            "3559    605\n",
            "2840    486\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 5\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "TKLeYNUiWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a668deed-5c82-4b51-996a-7866b7ca63e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2044\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_visib', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "J24fhLeNWgr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65c4ea3-fca0-435e-f386-f43a96ae77d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6989623290>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_visib/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.2742073, step = 1\n",
            "INFO:tensorflow:global_step/sec: 719.248\n",
            "INFO:tensorflow:loss = 0.0070698485, step = 101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 832.79\n",
            "INFO:tensorflow:loss = 0.0074536, step = 201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.445\n",
            "INFO:tensorflow:loss = 0.007559098, step = 301 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.918\n",
            "INFO:tensorflow:loss = 0.00721395, step = 401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.991\n",
            "INFO:tensorflow:loss = 0.0056845434, step = 501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.265\n",
            "INFO:tensorflow:loss = 0.007107227, step = 601 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.801\n",
            "INFO:tensorflow:loss = 0.0079799695, step = 701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.696\n",
            "INFO:tensorflow:loss = 0.006806819, step = 801 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 883.983\n",
            "INFO:tensorflow:loss = 0.0066309636, step = 901 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 875.789\n",
            "INFO:tensorflow:loss = 0.006481124, step = 1001 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.342\n",
            "INFO:tensorflow:loss = 0.00620313, step = 1101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.892\n",
            "INFO:tensorflow:loss = 0.0062970025, step = 1201 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.344\n",
            "INFO:tensorflow:loss = 0.00789602, step = 1301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.116\n",
            "INFO:tensorflow:loss = 0.005477175, step = 1401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.106\n",
            "INFO:tensorflow:loss = 0.005544059, step = 1501 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.287\n",
            "INFO:tensorflow:loss = 0.0069000106, step = 1601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.273\n",
            "INFO:tensorflow:loss = 0.006795683, step = 1701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.19\n",
            "INFO:tensorflow:loss = 0.0067590824, step = 1801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.177\n",
            "INFO:tensorflow:loss = 0.007099447, step = 1901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.879\n",
            "INFO:tensorflow:loss = 0.0060922205, step = 2001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.023\n",
            "INFO:tensorflow:loss = 0.0068088197, step = 2101 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.245\n",
            "INFO:tensorflow:loss = 0.006943872, step = 2201 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.596\n",
            "INFO:tensorflow:loss = 0.0057138233, step = 2301 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 898.746\n",
            "INFO:tensorflow:loss = 0.0067655486, step = 2401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 880.341\n",
            "INFO:tensorflow:loss = 0.0074641546, step = 2501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.358\n",
            "INFO:tensorflow:loss = 0.0055614137, step = 2601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.788\n",
            "INFO:tensorflow:loss = 0.005255047, step = 2701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 812.001\n",
            "INFO:tensorflow:loss = 0.0059166485, step = 2801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.855\n",
            "INFO:tensorflow:loss = 0.0060975375, step = 2901 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.153\n",
            "INFO:tensorflow:loss = 0.005584787, step = 3001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.707\n",
            "INFO:tensorflow:loss = 0.0058711963, step = 3101 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.748\n",
            "INFO:tensorflow:loss = 0.005522025, step = 3201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.573\n",
            "INFO:tensorflow:loss = 0.0077481857, step = 3301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.485\n",
            "INFO:tensorflow:loss = 0.0064316094, step = 3401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.658\n",
            "INFO:tensorflow:loss = 0.005340373, step = 3501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.518\n",
            "INFO:tensorflow:loss = 0.0073160282, step = 3601 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.861\n",
            "INFO:tensorflow:loss = 0.0056967717, step = 3701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.675\n",
            "INFO:tensorflow:loss = 0.0051842732, step = 3801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 792.786\n",
            "INFO:tensorflow:loss = 0.009078836, step = 3901 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.69\n",
            "INFO:tensorflow:loss = 0.0061716195, step = 4001 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 870.522\n",
            "INFO:tensorflow:loss = 0.0064639812, step = 4101 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.735\n",
            "INFO:tensorflow:loss = 0.008527743, step = 4201 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.983\n",
            "INFO:tensorflow:loss = 0.006289015, step = 4301 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.536\n",
            "INFO:tensorflow:loss = 0.008184409, step = 4401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 912.245\n",
            "INFO:tensorflow:loss = 0.0052609425, step = 4501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.1\n",
            "INFO:tensorflow:loss = 0.0071991356, step = 4601 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.657\n",
            "INFO:tensorflow:loss = 0.0074240705, step = 4701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.404\n",
            "INFO:tensorflow:loss = 0.007924622, step = 4801 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.302\n",
            "INFO:tensorflow:loss = 0.0068665473, step = 4901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.884\n",
            "INFO:tensorflow:loss = 0.007243348, step = 5001 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.153\n",
            "INFO:tensorflow:loss = 0.005363368, step = 5101 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.345\n",
            "INFO:tensorflow:loss = 0.0072254604, step = 5201 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.919\n",
            "INFO:tensorflow:loss = 0.006425761, step = 5301 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.115\n",
            "INFO:tensorflow:loss = 0.006767284, step = 5401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.153\n",
            "INFO:tensorflow:loss = 0.0056139096, step = 5501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.898\n",
            "INFO:tensorflow:loss = 0.008042929, step = 5601 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.61\n",
            "INFO:tensorflow:loss = 0.0060619516, step = 5701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.655\n",
            "INFO:tensorflow:loss = 0.006449268, step = 5801 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.992\n",
            "INFO:tensorflow:loss = 0.007488051, step = 5901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 863.141\n",
            "INFO:tensorflow:loss = 0.008689268, step = 6001 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.868\n",
            "INFO:tensorflow:loss = 0.008975643, step = 6101 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 895.633\n",
            "INFO:tensorflow:loss = 0.0057927985, step = 6201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 912.575\n",
            "INFO:tensorflow:loss = 0.0047943126, step = 6301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.389\n",
            "INFO:tensorflow:loss = 0.008591156, step = 6401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.03\n",
            "INFO:tensorflow:loss = 0.004881666, step = 6501 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.158\n",
            "INFO:tensorflow:loss = 0.0065110256, step = 6601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.566\n",
            "INFO:tensorflow:loss = 0.007843862, step = 6701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 870.287\n",
            "INFO:tensorflow:loss = 0.007493952, step = 6801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.08\n",
            "INFO:tensorflow:loss = 0.006673309, step = 6901 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.383\n",
            "INFO:tensorflow:loss = 0.006724393, step = 7001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 911.255\n",
            "INFO:tensorflow:loss = 0.0064259376, step = 7101 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.713\n",
            "INFO:tensorflow:loss = 0.0058816765, step = 7201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.299\n",
            "INFO:tensorflow:loss = 0.005825527, step = 7301 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 804.243\n",
            "INFO:tensorflow:loss = 0.005772459, step = 7401 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 882.363\n",
            "INFO:tensorflow:loss = 0.0061104023, step = 7501 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.579\n",
            "INFO:tensorflow:loss = 0.00708934, step = 7601 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.286\n",
            "INFO:tensorflow:loss = 0.008813263, step = 7701 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 912.68\n",
            "INFO:tensorflow:loss = 0.00625867, step = 7801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.656\n",
            "INFO:tensorflow:loss = 0.006547516, step = 7901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.155\n",
            "INFO:tensorflow:loss = 0.0064019663, step = 8001 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.633\n",
            "INFO:tensorflow:loss = 0.010461932, step = 8101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.734\n",
            "INFO:tensorflow:loss = 0.00739247, step = 8201 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.398\n",
            "INFO:tensorflow:loss = 0.010412923, step = 8301 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.448\n",
            "INFO:tensorflow:loss = 0.008272611, step = 8401 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.785\n",
            "INFO:tensorflow:loss = 0.00782836, step = 8501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 898.167\n",
            "INFO:tensorflow:loss = 0.0072348537, step = 8601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.171\n",
            "INFO:tensorflow:loss = 0.005373339, step = 8701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.238\n",
            "INFO:tensorflow:loss = 0.0057515055, step = 8801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.326\n",
            "INFO:tensorflow:loss = 0.0059489524, step = 8901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.872\n",
            "INFO:tensorflow:loss = 0.0059268638, step = 9001 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.497\n",
            "INFO:tensorflow:loss = 0.008164733, step = 9101 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 791.026\n",
            "INFO:tensorflow:loss = 0.0070690396, step = 9201 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 893.86\n",
            "INFO:tensorflow:loss = 0.006368111, step = 9301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.123\n",
            "INFO:tensorflow:loss = 0.00656804, step = 9401 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.428\n",
            "INFO:tensorflow:loss = 0.009049902, step = 9501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.203\n",
            "INFO:tensorflow:loss = 0.0053865965, step = 9601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 790.025\n",
            "INFO:tensorflow:loss = 0.007625414, step = 9701 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.339\n",
            "INFO:tensorflow:loss = 0.0061924094, step = 9801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.124\n",
            "INFO:tensorflow:loss = 0.0055639083, step = 9901 (0.109 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_visib/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.008244002.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 95.02490044046145\n",
            "Just using average = 600.2005870841488 has RMSE of 100.99356537020641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#testd = pd.DataFrame.from_records(predictors[trainsize:].values,columns=['day','year','month','da','prcp','fog','rain','snow','hail'])\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "0ZA56JV3Wgr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7594a8-62e6-43a3-9563-3982a81df480"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698966e610>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "512\n",
            "[0.4930513  0.48964942 0.52658933 0.55354035 0.48071313 0.46926457\n",
            " 0.5534737  0.4741751  0.5334721  0.5372914  0.4900828  0.5430065\n",
            " 0.55380553 0.44292232 0.48949558 0.5133777  0.5397377  0.55587566\n",
            " 0.54923576 0.52314264 0.51653457 0.5000549  0.50659853 0.48151675\n",
            " 0.46897262 0.5132227  0.4974867  0.46730012 0.51012564 0.49101174\n",
            " 0.5452201  0.55843276 0.5268288  0.45996836 0.49134487 0.5584993\n",
            " 0.47613788 0.50463563 0.48416352 0.49086615 0.473387   0.47687387\n",
            " 0.4995968  0.4614625  0.48358625 0.51483506 0.5620351  0.5460287\n",
            " 0.45416307 0.46849984 0.50902444 0.505555   0.48494315 0.4584965\n",
            " 0.47581074 0.5041938  0.5553458  0.46635842 0.52336776 0.49803078\n",
            " 0.56080973 0.51679945 0.5542693  0.5102459  0.53552014 0.5602274\n",
            " 0.4648863  0.5065072  0.5001049  0.5005762  0.52159077 0.5018685\n",
            " 0.5522017  0.47006923 0.49449837 0.4955241  0.5276064  0.5023916\n",
            " 0.5328224  0.49324125 0.51787317 0.47525185 0.5009696  0.54844546\n",
            " 0.5153221  0.508546   0.5347954  0.5349317  0.50299925 0.48232725\n",
            " 0.5115755  0.45409277 0.55336916 0.45373967 0.5130862  0.46916938\n",
            " 0.4696701  0.45813397 0.47902805 0.45520782 0.52911603 0.45896566\n",
            " 0.50734466 0.5037846  0.47415698 0.5181982  0.50913984 0.5031864\n",
            " 0.48479366 0.5218818  0.5051534  0.51497877 0.4492526  0.49333203\n",
            " 0.48361185 0.47978556 0.53394705 0.5254635  0.46695387 0.52572244\n",
            " 0.5305606  0.51136965 0.5275628  0.55021757 0.4903928  0.54257554\n",
            " 0.50995475 0.5014691  0.53363633 0.5260476  0.5058717  0.4869828\n",
            " 0.5266389  0.50073886 0.549441   0.5083154  0.49711645 0.48814887\n",
            " 0.5361012  0.5133454  0.5215846  0.51342815 0.47967    0.5019942\n",
            " 0.46836573 0.46684197 0.5139909  0.52288485 0.47633755 0.4839611\n",
            " 0.46152902 0.48644343 0.4675963  0.48977387 0.47216856 0.47847927\n",
            " 0.4817593  0.5371238  0.5281112  0.48885643 0.5171208  0.51366305\n",
            " 0.45296162 0.47397107 0.45356247 0.5044095  0.4861356  0.50720096\n",
            " 0.47270793 0.49164304 0.45424643 0.5369853  0.53582126 0.54750764\n",
            " 0.48112562 0.58551586 0.49044204 0.49635214 0.48658958 0.54132754\n",
            " 0.5225764  0.5139026  0.48840874 0.48169398 0.46546566 0.49837786\n",
            " 0.46239555 0.5103125  0.51294    0.5371841  0.53239    0.49224943\n",
            " 0.5104118  0.52831393 0.49457794 0.5278549  0.5415282  0.47788835\n",
            " 0.47962445 0.5066687  0.48659015 0.49043328 0.53843695 0.5046586\n",
            " 0.5196866  0.54970324 0.50140685 0.45960438 0.5498639  0.46390656\n",
            " 0.4929853  0.54807746 0.47982848 0.5008185  0.53297967 0.49372447\n",
            " 0.5531755  0.49592814 0.48510087 0.5236897  0.47921354 0.44871542\n",
            " 0.50798905 0.45691288 0.50181574 0.49870005 0.473998   0.53386045\n",
            " 0.51102495 0.53979    0.5019014  0.51322454 0.53077763 0.5296162\n",
            " 0.5069807  0.46497095 0.50921726 0.5486168  0.49271315 0.54461557\n",
            " 0.45123357 0.5321996  0.50181055 0.4953561  0.5423285  0.54143155\n",
            " 0.54621476 0.4539466  0.5313507  0.46337628 0.48139265 0.5389623\n",
            " 0.48149195 0.53318435 0.4871962  0.52622074 0.4864964  0.45905265\n",
            " 0.45851332 0.47455332 0.48758423 0.5005839  0.5460328  0.5324926\n",
            " 0.50636166 0.5198277  0.5349615  0.5332756  0.5340335  0.5274566\n",
            " 0.5197471  0.5279829  0.5006522  0.5574566  0.46645573 0.47728866\n",
            " 0.4695691  0.47644645 0.5236284  0.46298972 0.51746947 0.5103965\n",
            " 0.50597644 0.5020645  0.5136584  0.4985038  0.525418   0.5456596\n",
            " 0.52745056 0.5361695  0.49027723 0.48597115 0.50723326 0.44419253\n",
            " 0.50527394 0.48243546 0.54368573 0.50800514 0.4900175  0.53257096\n",
            " 0.50469434 0.5449137  0.53407544 0.52623194 0.50897664 0.49058604\n",
            " 0.56784534 0.5123761  0.46309507 0.45899275 0.5308887  0.5324728\n",
            " 0.5613103  0.5484133  0.4987255  0.53874767 0.5192586  0.4991528\n",
            " 0.5538072  0.5315134  0.5465327  0.46365964 0.46994603 0.5585484\n",
            " 0.49894235 0.56451327 0.531432   0.5281246  0.5101432  0.52284193\n",
            " 0.522982   0.5124579  0.50708354 0.50036144 0.5023707  0.4866712\n",
            " 0.50508505 0.50248736 0.5111432  0.5100063  0.56086063 0.5463112\n",
            " 0.5253024  0.5905252  0.4975284  0.5098634  0.5223547  0.56968933\n",
            " 0.5726727  0.5295669  0.5144923  0.5607709  0.47960514 0.53082615\n",
            " 0.53143376 0.4952884  0.5657957  0.50413084 0.5015189  0.48863804\n",
            " 0.51401603 0.55425435 0.5470816  0.53780615 0.52008766 0.5616292\n",
            " 0.5692041  0.48831588 0.49047238 0.4851594  0.5134697  0.50825423\n",
            " 0.5479493  0.5378791  0.50577307 0.5017544  0.49450958 0.506364\n",
            " 0.5010999  0.5252158  0.52694386 0.53603804 0.526483   0.5389887\n",
            " 0.45722792 0.5594463  0.518591   0.55545795 0.54239887 0.5243788\n",
            " 0.55816567 0.50645024 0.4999828  0.5386805  0.50416875 0.5086947\n",
            " 0.5646746  0.53855443 0.5001016  0.5433602  0.5254823  0.54851764\n",
            " 0.5464739  0.4904232  0.53787833 0.46817243 0.54657125 0.5540323\n",
            " 0.5216939  0.49851656 0.47659987 0.512434   0.5394216  0.48410758\n",
            " 0.47972032 0.48480347 0.51733404 0.5483664  0.507266   0.49640405\n",
            " 0.55054015 0.4607807  0.5550646  0.5573283  0.49621263 0.5598787\n",
            " 0.53148586 0.4991184  0.48345488 0.514417   0.54002804 0.5106663\n",
            " 0.515808   0.49552542 0.5483824  0.53223014 0.49911702 0.5346645\n",
            " 0.50675774 0.5572079  0.50368106 0.5021586  0.45244643 0.5346054\n",
            " 0.49118313 0.5157247  0.47402486 0.47205573 0.55960846 0.54865265\n",
            " 0.52238554 0.48886994 0.48299724 0.50106657 0.50139    0.4984857\n",
            " 0.49725538 0.56351066 0.5365593  0.5183676  0.51341856 0.4461246\n",
            " 0.52063495 0.46133542 0.5418178  0.5360857  0.46141684 0.50602216\n",
            " 0.52602    0.52423114 0.4805408  0.4892345  0.46618515 0.53700876\n",
            " 0.45879945 0.48954844 0.49059254 0.48683846 0.5023803  0.5454494\n",
            " 0.49520314 0.45644298 0.49428624 0.5514278  0.52617013 0.45086563\n",
            " 0.48135504 0.5424722  0.51329845 0.47531497 0.5081877  0.47957265\n",
            " 0.4853506  0.5025353  0.54125917 0.54153264 0.50098425 0.52397794\n",
            " 0.5303359  0.46287298 0.49261534 0.49916402 0.4827329  0.49492443\n",
            " 0.5271     0.5508745  0.5509638  0.5065947  0.46822923 0.4664216\n",
            " 0.52841914 0.5138092 ]\n",
            "[0.46942291 0.39276486 0.55727821 0.56503015 0.51851852 0.46080965\n",
            " 0.53143842 0.64685616 0.48578811 0.47975883 0.53574505 0.58914729\n",
            " 0.55986219 0.4005168  0.34797588 0.54780362 0.59862188 0.54694229\n",
            " 0.52540913 0.4918174  0.58828596 0.6287683  0.59086994 0.35228252\n",
            " 0.42807924 0.59259259 0.56330749 0.50215332 0.54866494 0.45564169\n",
            " 0.45047373 0.5503876  0.54952627 0.45305771 0.40913006 0.52971576\n",
            " 0.39793282 0.4625323  0.43238587 0.55986219 0.51851852 0.41343669\n",
            " 0.50215332 0.51593454 0.30749354 0.59259259 0.49870801 0.56072351\n",
            " 0.26614987 0.44702842 0.56847545 0.48062016 0.48320413 0.42635659\n",
            " 0.3910422  0.43410853 0.35400517 0.49009475 0.5994832  0.68130922\n",
            " 0.58570198 0.54694229 0.55211025 0.54177433 0.55986219 0.53832903\n",
            " 0.48148148 0.36434109 0.48406546 0.60120586 0.62015504 0.56072351\n",
            " 0.41774332 0.48492679 0.46770026 0.52540913 0.48923342 0.62962963\n",
            " 0.51765719 0.48234281 0.6580534  0.46942291 0.55641688 0.46770026\n",
            " 0.36864772 0.57536606 0.53488372 0.51679587 0.5667528  0.51937984\n",
            " 0.61584841 0.40654608 0.51937984 0.48923342 0.51765719 0.46167097\n",
            " 0.48148148 0.43669251 0.55986219 0.43238587 0.51248923 0.44186047\n",
            " 0.5667528  0.68044789 0.39879414 0.59086994 0.5374677  0.56933678\n",
            " 0.49267873 0.30577089 0.54349699 0.51421189 0.37726098 0.48234281\n",
            " 0.48492679 0.5374677  0.42291128 0.50301464 0.41515935 0.62015504\n",
            " 0.52971576 0.53919035 0.60206718 0.52885444 0.48406546 0.55297158\n",
            " 0.53660637 0.50043066 0.55727821 0.374677   0.53488372 0.40999139\n",
            " 0.42291128 0.45994832 0.60551249 0.61929371 0.61584841 0.59086994\n",
            " 0.55469423 0.42291128 0.54005168 0.56761413 0.39190353 0.56933678\n",
            " 0.44099914 0.45908699 0.66494401 0.49009475 0.39018088 0.3712317\n",
            " 0.5081826  0.45822567 0.49784668 0.42894057 0.44358312 0.5245478\n",
            " 0.44358312 0.48751077 0.62273902 0.54694229 0.58139535 0.48234281\n",
            " 0.31093885 0.53488372 0.41774332 0.58570198 0.5245478  0.63824289\n",
            " 0.45478036 0.54177433 0.40568475 0.5503876  0.44444444 0.5374677\n",
            " 0.55900086 0.49956934 0.55297158 0.54263566 0.49354005 0.47286822\n",
            " 0.57622739 0.61498708 0.56589147 0.40223945 0.43841516 0.56244617\n",
            " 0.47372954 0.65546942 0.59086994 0.62962963 0.53402239 0.59000861\n",
            " 0.41085271 0.53057709 0.5374677  0.53229974 0.4332472  0.64857881\n",
            " 0.43066322 0.68561585 0.39190353 0.625323   0.50990525 0.6546081\n",
            " 0.31007752 0.48751077 0.60378984 0.43927649 0.5994832  0.47803618\n",
            " 0.5994832  0.53402239 0.46167097 0.46339363 0.61068045 0.51937984\n",
            " 0.62360034 0.57278208 0.36434109 0.53574505 0.49095607 0.39534884\n",
            " 0.60551249 0.39965547 0.51765719 0.49870801 0.42118863 0.64513351\n",
            " 0.60378984 0.55555556 0.5211025  0.63221361 0.32213609 0.64599483\n",
            " 0.54435831 0.44444444 0.66925065 0.49095607 0.43755383 0.58570198\n",
            " 0.36434109 0.53229974 0.57795004 0.49009475 0.5796727  0.49095607\n",
            " 0.4754522  0.36950904 0.46339363 0.39276486 0.47459087 0.5667528\n",
            " 0.52024117 0.56158484 0.43496985 0.4496124  0.43755383 0.41946598\n",
            " 0.47114556 0.45908699 0.64341085 0.59345392 0.50990525 0.55813953\n",
            " 0.51507321 0.54349699 0.53832903 0.44186047 0.5667528  0.51421189\n",
            " 0.36864772 0.44875108 0.70887166 0.55211025 0.47372954 0.46425495\n",
            " 0.35400517 0.44530577 0.57881137 0.38673557 0.5667528  0.44530577\n",
            " 0.55297158 0.51937984 0.49095607 0.53919035 0.44702842 0.47028424\n",
            " 0.4952627  0.54349699 0.51421189 0.4005168  0.54694229 0.43841516\n",
            " 0.59000861 0.39362618 0.54866494 0.62015504 0.63393626 0.59259259\n",
            " 0.53660637 0.58742463 0.5374677  0.56330749 0.57536606 0.45822567\n",
            " 0.57364341 0.42291128 0.47803618 0.2962963  0.52024117 0.47631352\n",
            " 0.53660637 0.62962963 0.68303187 0.56072351 0.91731266 0.52799311\n",
            " 0.50990525 0.44272179 0.52885444 0.44875108 0.41429802 0.50215332\n",
            " 0.47459087 0.60206718 0.43152455 0.59086994 0.63479759 0.43927649\n",
            " 0.64254953 0.51248923 0.53488372 0.4788975  0.59431525 0.47286822\n",
            " 0.60034453 0.58484065 0.54091301 0.6287683  0.60206718 0.50215332\n",
            " 0.57364341 0.60034453 0.49870801 0.50645995 0.60809647 0.57536606\n",
            " 0.5503876  0.416882   0.55900086 0.44702842 0.54866494 0.54866494\n",
            " 0.61412575 0.42377261 0.56416882 0.48923342 0.43238587 0.55124892\n",
            " 0.58656331 0.56416882 0.46339363 0.54952627 0.54952627 0.62618432\n",
            " 0.53402239 0.45822567 0.49698536 0.52971576 0.56330749 0.54521964\n",
            " 0.55555556 0.16192937 0.48837209 0.4754522  0.4496124  0.56847545\n",
            " 0.61068045 0.61929371 0.63479759 0.49698536 0.27648579 0.58225668\n",
            " 0.37812231 0.7166236  0.51679587 0.53574505 0.47286822 0.5211025\n",
            " 0.50732127 0.48148148 0.47028424 0.55297158 0.59689922 0.60981912\n",
            " 0.34453058 0.56158484 0.38501292 0.51765719 0.55986219 0.52196382\n",
            " 0.44702842 0.51421189 0.55641688 0.35917313 0.60809647 0.56416882\n",
            " 0.50301464 0.49612403 0.45650301 0.5538329  0.74677003 0.44358312\n",
            " 0.3910422  0.40568475 0.54091301 0.5667528  0.78466839 0.47631352\n",
            " 0.5538329  0.34366925 0.43496985 0.54952627 0.30577089 0.46425495\n",
            " 0.2213609  0.52885444 0.63824289 0.63307494 0.5994832  0.5503876\n",
            " 0.54608096 0.53057709 0.52885444 0.36175711 0.56158484 0.54263566\n",
            " 0.41085271 0.45908699 0.72782084 0.62704565 0.3875969  0.47975883\n",
            " 0.47372954 0.52799311 0.52024117 0.57364341 0.5667528  0.4918174\n",
            " 0.5374677  0.44186047 0.59259259 0.56503015 0.52713178 0.51421189\n",
            " 0.65977606 0.50732127 0.51507321 0.50129199 0.70542636 0.29371232\n",
            " 0.60465116 0.33419466 0.63652024 0.37726098 0.34969854 0.43066322\n",
            " 0.34280792 0.52368648 0.47114556 0.55211025 0.47200689 0.50043066\n",
            " 0.50129199 0.51593454 0.46167097 0.41257537 0.66063738 0.51248923\n",
            " 0.46511628 0.39965547 0.58053402 0.63307494 0.45305771 0.36692506\n",
            " 0.53057709 0.51679587 0.54780362 0.44444444 0.60120586 0.47372954\n",
            " 0.53316107 0.53488372 0.59086994 0.50559862 0.49956934 0.60809647\n",
            " 0.45564169 0.43927649 0.48148148 0.56416882 0.52713178 0.50387597\n",
            " 0.45305771 0.53057709 0.54435831 0.72782084 0.41860465 0.45219638\n",
            " 0.46339363 0.54694229]\n",
            "The trained model has an aproximate error rate of 3.6515270024538027 which equates to 1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the difference RMSE between the mean and the model is less, it is arguable that the model is not as accurate.\n",
        "\n",
        "Although the RMSE value indicates a weaker model, the error rate is lower indicating that there is a significant error increasing the RMSE."
      ],
      "metadata": {
        "id": "ntCQ4Pkefi3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Neural Network (DNN)\n",
        "Although the primary outcome of assignment 1 was uncovering linear relationships, more complex relationships which cannot be predicted using a linear regressor were uncovered. In this case a Deep Learning Neural Network (DNN) can be used.\n",
        "\n",
        "A Deep Learning Neural Network (DNN) is a form of unsupervised learning, where a number of hidden layers are used to uncover non-linear relationships. Karhunen, Raiko and Cho (2015) infer that deep learning neural networks work in a similar way to the human brain. This is where both the relationship between the input and output data is explored, as well as the relationship between the underlying data."
      ],
      "metadata": {
        "id": "xIvme6cXJF9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precipitation (prcp)\n",
        "The process for training a DNN follows a similar process followed above for a Linear Regressor. The data cleansed and one hot encoded as part of assignment 1 is loaded from GitHub."
      ],
      "metadata": {
        "id": "cixnwflQxNZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean_dnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "F9YrBdhTYhyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e601a66-9ee6-4321-aa06-2b16321f2143"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_prcp_dnn = df.drop(columns=['temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp_dnn = df_prcp_dnn.loc[df_prcp_dnn[\"year\"] != 2012]\n",
        "df_prcp_dnn = df_prcp_dnn.loc[df_prcp_dnn[\"year\"] < 2020]\n",
        "#Move target to the end\n",
        "cols = df_prcp_dnn['NUM_COLLISIONS']\n",
        "df_prcp_dnn = df_prcp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_prcp_dnn.insert(loc=25, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp_dnn[:6])\n",
        "df_prcp_dnn.describe()"
      ],
      "metadata": {
        "id": "jw5elr-LbRBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "5490c3e4-8a44-4d85-e28b-4df676ebc0ac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  Apr  Aug  Dec  \\\n",
            "49  2016  28  0.09    0             0                 0     0    0    0    0   \n",
            "51  2014  17  0.00    1             0                 0     0    0    0    0   \n",
            "54  2016  25  0.02    0             0                 0     0    0    0    0   \n",
            "55  2016  29  0.00    0             0                 0     0    0    0    0   \n",
            "58  2017  20  0.00    0             0                 0     0    0    0    0   \n",
            "59  2013  13  0.01    1             0                 0     0    0    0    0   \n",
            "\n",
            "    ...  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49  ...    0    0    0    0    0    0    0    0    1             681  \n",
            "51  ...    0    0    0    0    0    0    1    0    0             589  \n",
            "54  ...    0    0    0    0    0    1    0    0    0             658  \n",
            "55  ...    0    0    0    0    0    0    1    0    0             645  \n",
            "58  ...    0    0    0    0    0    0    1    0    0             605  \n",
            "59  ...    0    0    0    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 26 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da         prcp          fog  rain_drizzle  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000   2539.000000   \n",
              "mean   2015.989366    15.745569     0.122588     0.253249      0.375345   \n",
              "std       1.996126     8.803199     0.329143     0.434958      0.484307   \n",
              "min    2013.000000     1.000000     0.000000     0.000000      0.000000   \n",
              "25%    2014.000000     8.000000     0.000000     0.000000      0.000000   \n",
              "50%    2016.000000    16.000000     0.000000     0.000000      0.000000   \n",
              "75%    2018.000000    23.000000     0.060000     1.000000      1.000000   \n",
              "max    2019.000000    31.000000     3.760000     1.000000      1.000000   \n",
              "\n",
              "       snow_ice_pellets         hail          Apr          Aug          Dec  \\\n",
              "count       2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean           0.085467     0.000394     0.082316     0.083497     0.085467   \n",
              "std            0.279630     0.019846     0.274899     0.276687     0.279630   \n",
              "min            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max            1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "       ...          Nov          Oct          Sep          Mon          Sat  \\\n",
              "count  ...  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean   ...     0.082710     0.085467     0.079953     0.142970     0.143364   \n",
              "std    ...     0.275497     0.279630     0.271273     0.350111     0.350512   \n",
              "min    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max    ...     1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000     2539.000000  \n",
              "mean      0.143757     0.142182     0.142576     0.142182      599.135093  \n",
              "std       0.350913     0.349305     0.349709     0.349305      100.299164  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6d6c1ec-0a77-4ee9-9857-059c1cd3ffed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.989366</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.082316</td>\n",
              "      <td>0.083497</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082710</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.079953</td>\n",
              "      <td>0.142970</td>\n",
              "      <td>0.143364</td>\n",
              "      <td>0.143757</td>\n",
              "      <td>0.142182</td>\n",
              "      <td>0.142576</td>\n",
              "      <td>0.142182</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.996126</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>0.274899</td>\n",
              "      <td>0.276687</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275497</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.271273</td>\n",
              "      <td>0.350111</td>\n",
              "      <td>0.350512</td>\n",
              "      <td>0.350913</td>\n",
              "      <td>0.349305</td>\n",
              "      <td>0.349709</td>\n",
              "      <td>0.349305</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6d6c1ec-0a77-4ee9-9857-059c1cd3ffed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6d6c1ec-0a77-4ee9-9857-059c1cd3ffed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6d6c1ec-0a77-4ee9-9857-059c1cd3ffed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "shuffle = df_prcp_dnn.iloc[np.random.permutation(len(df_prcp_dnn))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "rpJi3P_8YcIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac943c58-fb83-4662-e812-d2f007423a1c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  Apr  Aug  \\\n",
            "3019  2013   9  0.03    0             0                 0     0    0    0   \n",
            "3561  2017  29  0.00    0             0                 1     0    0    0   \n",
            "2027  2015  23  0.00    0             0                 0     0    0    0   \n",
            "807   2015  23  0.00    0             0                 0     0    0    0   \n",
            "506   2016   9  0.06    0             0                 1     0    0    0   \n",
            "208   2015  17  0.00    0             0                 0     0    0    0   \n",
            "\n",
            "      Dec  ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "3019    0  ...    0    0    1    0    0    0    0    0    1    0  \n",
            "3561    1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2027    0  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "807     0  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "506     0  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "208     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select target as last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "a_A0EFvxZpeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a847a7c5-6685-45c6-c20b-3fe858ca1b8e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3019    529\n",
            "3561    598\n",
            "2027    623\n",
            "807     586\n",
            "506     571\n",
            "208     495\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "noutputs = 1\n",
        "# calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "bdO_kvOZZuii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10348394-044a-4ffa-87da-fb1ea0fa2402"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between the training of a DNN and linear regression model, is the addition of hidden layers. In order to optimise the trained model, the number of hidden layers, the number of nodes within each layer and the learning rate were all modified."
      ],
      "metadata": {
        "id": "XTeNjj2Rp1Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_prcp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#Test model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "GaTuIaPRfMxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411ffc70-a4fc-435e-dd27-b803cb11aeab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6985608850>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:loss = 5797.1284, step = 1\n",
            "INFO:tensorflow:global_step/sec: 484.233\n",
            "INFO:tensorflow:loss = 0.093114644, step = 101 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.315\n",
            "INFO:tensorflow:loss = 0.072762355, step = 201 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.974\n",
            "INFO:tensorflow:loss = 0.059431594, step = 301 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.296\n",
            "INFO:tensorflow:loss = 0.04294809, step = 401 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.568\n",
            "INFO:tensorflow:loss = 0.030806527, step = 501 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.412\n",
            "INFO:tensorflow:loss = 0.027688656, step = 601 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.06\n",
            "INFO:tensorflow:loss = 0.017032456, step = 701 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.787\n",
            "INFO:tensorflow:loss = 0.015034626, step = 801 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.764\n",
            "INFO:tensorflow:loss = 0.00983266, step = 901 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.384\n",
            "INFO:tensorflow:loss = 0.010421025, step = 1001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.21\n",
            "INFO:tensorflow:loss = 0.010032205, step = 1101 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.08\n",
            "INFO:tensorflow:loss = 0.006972007, step = 1201 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.996\n",
            "INFO:tensorflow:loss = 0.004265459, step = 1301 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.953\n",
            "INFO:tensorflow:loss = 0.009138774, step = 1401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.244\n",
            "INFO:tensorflow:loss = 0.0079052355, step = 1501 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.938\n",
            "INFO:tensorflow:loss = 0.0074243695, step = 1601 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.704\n",
            "INFO:tensorflow:loss = 0.0043768743, step = 1701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 592.149\n",
            "INFO:tensorflow:loss = 0.004666277, step = 1801 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.823\n",
            "INFO:tensorflow:loss = 0.007092751, step = 1901 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.612\n",
            "INFO:tensorflow:loss = 0.015192382, step = 2001 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.722\n",
            "INFO:tensorflow:loss = 0.010853673, step = 2101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.315\n",
            "INFO:tensorflow:loss = 0.011909703, step = 2201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.275\n",
            "INFO:tensorflow:loss = 0.009476259, step = 2301 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.54\n",
            "INFO:tensorflow:loss = 0.0044105677, step = 2401 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.451\n",
            "INFO:tensorflow:loss = 0.007826717, step = 2501 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.528\n",
            "INFO:tensorflow:loss = 0.026463319, step = 2601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.893\n",
            "INFO:tensorflow:loss = 0.008689595, step = 2701 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.056\n",
            "INFO:tensorflow:loss = 0.01747716, step = 2801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.454\n",
            "INFO:tensorflow:loss = 0.012103003, step = 2901 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.88\n",
            "INFO:tensorflow:loss = 0.054968268, step = 3001 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 590.335\n",
            "INFO:tensorflow:loss = 0.011429055, step = 3101 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.943\n",
            "INFO:tensorflow:loss = 0.038396075, step = 3201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.283\n",
            "INFO:tensorflow:loss = 0.80222195, step = 3301 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.474\n",
            "INFO:tensorflow:loss = 0.030557849, step = 3401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.284\n",
            "INFO:tensorflow:loss = 0.0079412665, step = 3501 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.337\n",
            "INFO:tensorflow:loss = 0.043250963, step = 3601 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.677\n",
            "INFO:tensorflow:loss = 0.111257076, step = 3701 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.536\n",
            "INFO:tensorflow:loss = 0.012919851, step = 3801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.164\n",
            "INFO:tensorflow:loss = 0.008194476, step = 3901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.628\n",
            "INFO:tensorflow:loss = 0.007981923, step = 4001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.799\n",
            "INFO:tensorflow:loss = 0.009938971, step = 4101 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.378\n",
            "INFO:tensorflow:loss = 0.0063550994, step = 4201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.75\n",
            "INFO:tensorflow:loss = 0.007077812, step = 4301 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.122\n",
            "INFO:tensorflow:loss = 0.0074097975, step = 4401 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.618\n",
            "INFO:tensorflow:loss = 0.0066155293, step = 4501 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.83\n",
            "INFO:tensorflow:loss = 0.0060730283, step = 4601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.641\n",
            "INFO:tensorflow:loss = 0.0054307263, step = 4701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.385\n",
            "INFO:tensorflow:loss = 0.004553036, step = 4801 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.175\n",
            "INFO:tensorflow:loss = 0.005541401, step = 4901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.554\n",
            "INFO:tensorflow:loss = 0.0066030836, step = 5001 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.333\n",
            "INFO:tensorflow:loss = 0.005262059, step = 5101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.368\n",
            "INFO:tensorflow:loss = 0.004993926, step = 5201 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.548\n",
            "INFO:tensorflow:loss = 0.0050549526, step = 5301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.708\n",
            "INFO:tensorflow:loss = 0.0047236527, step = 5401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.387\n",
            "INFO:tensorflow:loss = 0.003998686, step = 5501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.83\n",
            "INFO:tensorflow:loss = 0.0036772992, step = 5601 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.383\n",
            "INFO:tensorflow:loss = 0.0039592036, step = 5701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.783\n",
            "INFO:tensorflow:loss = 0.0051010246, step = 5801 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.545\n",
            "INFO:tensorflow:loss = 0.006584345, step = 5901 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.29\n",
            "INFO:tensorflow:loss = 0.006385672, step = 6001 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.711\n",
            "INFO:tensorflow:loss = 0.006294091, step = 6101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.766\n",
            "INFO:tensorflow:loss = 0.005213547, step = 6201 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.009\n",
            "INFO:tensorflow:loss = 0.0060556442, step = 6301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.84\n",
            "INFO:tensorflow:loss = 0.0059631285, step = 6401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.966\n",
            "INFO:tensorflow:loss = 0.0051577445, step = 6501 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.534\n",
            "INFO:tensorflow:loss = 0.006216661, step = 6601 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.774\n",
            "INFO:tensorflow:loss = 0.0046400893, step = 6701 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.803\n",
            "INFO:tensorflow:loss = 0.0070573045, step = 6801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.349\n",
            "INFO:tensorflow:loss = 0.003967573, step = 6901 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.742\n",
            "INFO:tensorflow:loss = 0.0050812187, step = 7001 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.767\n",
            "INFO:tensorflow:loss = 0.0058313673, step = 7101 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.343\n",
            "INFO:tensorflow:loss = 0.0049517904, step = 7201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.713\n",
            "INFO:tensorflow:loss = 0.0043604868, step = 7301 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.576\n",
            "INFO:tensorflow:loss = 0.0038547576, step = 7401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.862\n",
            "INFO:tensorflow:loss = 0.0059966585, step = 7501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.636\n",
            "INFO:tensorflow:loss = 0.004090486, step = 7601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.47\n",
            "INFO:tensorflow:loss = 0.003554929, step = 7701 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.204\n",
            "INFO:tensorflow:loss = 0.0059706145, step = 7801 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.665\n",
            "INFO:tensorflow:loss = 0.0042463955, step = 7901 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.399\n",
            "INFO:tensorflow:loss = 0.0041839173, step = 8001 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.259\n",
            "INFO:tensorflow:loss = 0.004393393, step = 8101 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.756\n",
            "INFO:tensorflow:loss = 0.0049368497, step = 8201 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.346\n",
            "INFO:tensorflow:loss = 0.00425689, step = 8301 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.089\n",
            "INFO:tensorflow:loss = 0.005300365, step = 8401 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.34\n",
            "INFO:tensorflow:loss = 0.005553464, step = 8501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.93\n",
            "INFO:tensorflow:loss = 0.0039579263, step = 8601 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.631\n",
            "INFO:tensorflow:loss = 0.0048985393, step = 8701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.786\n",
            "INFO:tensorflow:loss = 0.0056280904, step = 8801 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.095\n",
            "INFO:tensorflow:loss = 0.0042081154, step = 8901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.493\n",
            "INFO:tensorflow:loss = 0.0037187731, step = 9001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.207\n",
            "INFO:tensorflow:loss = 0.00395486, step = 9101 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.24\n",
            "INFO:tensorflow:loss = 0.005141047, step = 9201 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.834\n",
            "INFO:tensorflow:loss = 0.0031090488, step = 9301 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.206\n",
            "INFO:tensorflow:loss = 0.0051115872, step = 9401 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.419\n",
            "INFO:tensorflow:loss = 0.008043904, step = 9501 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.452\n",
            "INFO:tensorflow:loss = 0.0044392776, step = 9601 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.868\n",
            "INFO:tensorflow:loss = 0.004265591, step = 9701 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.165\n",
            "INFO:tensorflow:loss = 0.0069769844, step = 9801 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.479\n",
            "INFO:tensorflow:loss = 0.009114586, step = 9901 (0.162 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0054714605.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 77.11229799272591\n",
            "Just using average = 599.723289020187 has RMSE of 98.31506286288999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "#Ensure hidden layers match the model trained above\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "Ld6baV60hPOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1071f3a-7c77-40e8-f0a2-6d1c94f8b172"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69892dca10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5063163  0.54900837 0.5241063  0.4464979  0.41719916 0.3804229\n",
            " 0.5627806  0.5216837  0.5723269  0.5345738  0.4760729  0.48885325\n",
            " 0.46499184 0.46727848 0.56145835 0.562441   0.54951066 0.48909315\n",
            " 0.5473968  0.5864883  0.55957127 0.58954227 0.59036994 0.5918138\n",
            " 0.54280305 0.55159426 0.5442295  0.50568104 0.53995234 0.39843637\n",
            " 0.58585703 0.5603374  0.5768122  0.5341629  0.49730456 0.5600103\n",
            " 0.5656823  0.5426327  0.49772337 0.54801536 0.452973   0.57085854\n",
            " 0.3779933  0.5636091  0.5153109  0.5246148  0.49161074 0.57500076\n",
            " 0.5608868  0.5649049  0.5348468  0.4999415  0.5269826  0.46126568\n",
            " 0.48901182 0.44556057 0.5270839  0.47129714 0.3719187  0.41603413\n",
            " 0.42897987 0.5321904  0.55687034 0.4006964  0.49625728 0.5583056\n",
            " 0.5591398  0.5199641  0.52011514 0.55865824 0.42880937 0.59242123\n",
            " 0.4510392  0.53094155 0.48752865 0.5337252  0.588908   0.5142597\n",
            " 0.51020217 0.5866565  0.41077453 0.53864133 0.52015203 0.5624\n",
            " 0.56370866 0.5177094  0.5984142  0.53709704 0.5633903  0.544704\n",
            " 0.47536337 0.5111876  0.56085134 0.38479248 0.4684423  0.41570488\n",
            " 0.48147672 0.524956   0.5386416  0.5900235  0.49319407 0.5280195\n",
            " 0.49624974 0.5830905  0.44227055 0.556599   0.37243927 0.5734476\n",
            " 0.60266733 0.56814134 0.48926288 0.3810804  0.5471817  0.54142076\n",
            " 0.5179732  0.4109358  0.5154832  0.5822065  0.5462152  0.49446255\n",
            " 0.5050963  0.5002153  0.37551388 0.39991304 0.55549735 0.53191876\n",
            " 0.49915665 0.54652077 0.48998377 0.5353644  0.437932   0.5267936\n",
            " 0.5540811  0.4682923  0.54091656 0.59107095 0.49248806 0.5174807\n",
            " 0.42626837 0.5091322  0.5348031  0.54222643 0.51015294 0.56140155\n",
            " 0.4797682  0.56854725 0.429555   0.5218189  0.5776728  0.52680403\n",
            " 0.5349144  0.49366012 0.39150292 0.48433286 0.58700424 0.47623137\n",
            " 0.51127136 0.5457053  0.49720287 0.3854537  0.5834829  0.5287249\n",
            " 0.5168935  0.53097427 0.5579679  0.5420815  0.53093016 0.4862217\n",
            " 0.5687167  0.5397805  0.4894185  0.5519557  0.53989816 0.5930867\n",
            " 0.4375512  0.5753271  0.5448086  0.55430365 0.5490061  0.53924745\n",
            " 0.5317072  0.5917163  0.54594344 0.51896954 0.51081526 0.5257586\n",
            " 0.5466941  0.5587206  0.55066335 0.4956282  0.5243031  0.40740356\n",
            " 0.51015085 0.59207195 0.4701805  0.593751   0.47437546 0.56285954\n",
            " 0.55032325 0.50958586 0.6188912  0.5533743  0.5029659  0.53453887\n",
            " 0.50880045 0.5214338  0.5026175  0.53560436 0.509786   0.51415884\n",
            " 0.545177   0.54278296 0.52839124 0.59473926 0.5636099  0.6057659\n",
            " 0.42690796 0.56662047 0.46814615 0.57589424 0.4957114  0.50125754\n",
            " 0.4177712  0.44336963 0.5491949  0.5655999  0.49191153 0.49144137\n",
            " 0.44811723 0.54490185 0.44906127 0.59359825 0.41597277 0.6011986\n",
            " 0.49408287 0.556567   0.42589206 0.51365316 0.52433705 0.5404321\n",
            " 0.5526742  0.5557813  0.552759   0.5706149  0.5256283  0.53319323\n",
            " 0.4949474  0.57993114 0.5679034  0.5341593  0.49418238 0.58059466\n",
            " 0.45669943 0.58875084 0.48174247 0.42441133 0.5598439  0.5425813\n",
            " 0.5178547  0.5499004  0.55867845 0.40216252 0.50195384 0.61261606\n",
            " 0.43376505 0.47924256 0.5395793  0.52975786 0.37081715 0.5514062\n",
            " 0.48163027 0.44625518 0.46941888 0.45379022 0.5555097  0.5512695\n",
            " 0.5373567  0.53960097 0.46907002 0.36495447 0.5525867  0.5652404\n",
            " 0.5369968  0.540893   0.4468745  0.43553615 0.52087593 0.39188212\n",
            " 0.55537343 0.5734453  0.43553793 0.5320956  0.5232097  0.41843304\n",
            " 0.5023713  0.57103485 0.5063218  0.5368659  0.4409737  0.4592474\n",
            " 0.41837355 0.57211757 0.48031992 0.5432674  0.54919094 0.40225375\n",
            " 0.50947154 0.5508144  0.5196264  0.39937192 0.55204177 0.51314086\n",
            " 0.5483886  0.5296482  0.54630256 0.5163858  0.57131374 0.50850976\n",
            " 0.526477   0.49969098 0.58218    0.42860326 0.5571843  0.55639064\n",
            " 0.41911602 0.3678721  0.57257783 0.5801096  0.5166118  0.57866645\n",
            " 0.52399236 0.42531857 0.58577824 0.55239916 0.56211233 0.50841236\n",
            " 0.5233201  0.56623673 0.5861536  0.43541184 0.5353155  0.59259456\n",
            " 0.45702404 0.51849484 0.5597557  0.51091635 0.5034507  0.5188867\n",
            " 0.41786098 0.488582   0.5321454  0.5732298  0.49451324 0.43908995\n",
            " 0.5003673  0.61327755 0.5467937  0.41186154 0.50808734 0.5095128\n",
            " 0.45493346 0.4576866  0.433048   0.5506741  0.5273783  0.48612255\n",
            " 0.52499115 0.5026271  0.48758236 0.54495394 0.4985089  0.4813139\n",
            " 0.41088337 0.35494417 0.5310441  0.5529809  0.5431814  0.51423466\n",
            " 0.50604236 0.53653806 0.50520444 0.5400574  0.5802069  0.42658386\n",
            " 0.5729827  0.4821197  0.42441577 0.47843614 0.40965712 0.5304198\n",
            " 0.57285905 0.48775724 0.5343491  0.5457573  0.5449672  0.40606752\n",
            " 0.47000238 0.55033326 0.5049294  0.5154947  0.5746735  0.54112834\n",
            " 0.47743902 0.48517027 0.50068766 0.5688769  0.5604569  0.52043146\n",
            " 0.5609095  0.5551213  0.5234866  0.39353222 0.5511539  0.4920399\n",
            " 0.54774916 0.5390004  0.44663846 0.4813755  0.38422412 0.5660832\n",
            " 0.5375449  0.5907828  0.42831936 0.5036244  0.4897031  0.52825236\n",
            " 0.58158547 0.51807904 0.50261843 0.50039786 0.48571894 0.56829625\n",
            " 0.5077082  0.54524004 0.52769613 0.4301813  0.6078937  0.37138748\n",
            " 0.58590233 0.56715405 0.5589551  0.52225864 0.5024702  0.45245767\n",
            " 0.57795554 0.39220697 0.5601082  0.5412916  0.48384714 0.5448332\n",
            " 0.5751127  0.54578346 0.45731577 0.49997106 0.54999995 0.49729025\n",
            " 0.49379864 0.49073705 0.5481404  0.5204555  0.550696   0.48635527\n",
            " 0.58522165 0.4008377  0.43470195 0.540266   0.536237   0.56187904\n",
            " 0.5342883  0.49015093 0.55967396 0.52596486 0.38226822 0.47456616\n",
            " 0.52685595 0.5024753  0.56521004 0.59982914 0.55432534 0.56095064\n",
            " 0.48286334 0.5149857  0.54846317 0.52394307 0.5486731  0.53201115\n",
            " 0.4200407  0.46549678 0.35835016 0.57918835 0.5420446  0.50643337\n",
            " 0.5634829  0.56378853 0.41494498 0.4058805  0.5656333  0.5454662\n",
            " 0.5600176  0.49375463 0.47689646 0.51159155 0.5195633  0.59526324\n",
            " 0.4699791  0.5070542  0.556214   0.54066896]\n",
            "[0.56847545 0.5667528  0.5047373  0.42721792 0.40740741 0.34366925\n",
            " 0.55555556 0.4754522  0.45478036 0.5503876  0.59173127 0.45736434\n",
            " 0.48837209 0.49784668 0.57881137 0.56330749 0.61757106 0.51421189\n",
            " 0.44702842 0.55297158 0.66666667 0.63738157 0.52799311 0.53057709\n",
            " 0.5211025  0.54005168 0.59259259 0.55211025 0.64254953 0.35486649\n",
            " 0.69853575 0.64857881 0.5960379  0.62187769 0.40913006 0.36606374\n",
            " 0.51593454 0.52885444 0.57192076 0.63824289 0.38673557 0.54521964\n",
            " 0.32730405 0.53143842 0.52368648 0.52799311 0.44875108 0.62790698\n",
            " 0.60120586 0.59689922 0.49440138 0.47631352 0.58828596 0.49354005\n",
            " 0.36434109 0.38673557 0.43755383 0.31007752 0.36003445 0.41343669\n",
            " 0.52024117 0.64427218 0.50990525 0.44702842 0.4754522  0.5994832\n",
            " 0.61584841 0.49440138 0.54177433 0.32213609 0.46942291 0.57105943\n",
            " 0.40913006 0.55469423 0.49698536 0.46683893 0.583118   0.54005168\n",
            " 0.54177433 0.62360034 0.39276486 0.51593454 0.50301464 0.54091301\n",
            " 0.58225668 0.54177433 0.66063738 0.51248923 0.53919035 0.60206718\n",
            " 0.50043066 0.48923342 0.59345392 0.36692506 0.41343669 0.44875108\n",
            " 0.43410853 0.54263566 0.53660637 0.53143842 0.50043066 0.40826873\n",
            " 0.38845823 0.56761413 0.50301464 0.55727821 0.26614987 0.63221361\n",
            " 0.63049096 0.56330749 0.37037037 0.35400517 0.50559862 0.51162791\n",
            " 0.5047373  0.39534884 0.50301464 0.46683893 0.52799311 0.52368648\n",
            " 0.53402239 0.44702842 0.33936262 0.44530577 0.75107666 0.51679587\n",
            " 0.48148148 0.60292851 0.43066322 0.47631352 0.39879414 0.53316107\n",
            " 0.60120586 0.40137812 0.57795004 0.70887166 0.44788975 0.61412575\n",
            " 0.43496985 0.45736434 0.56072351 0.61929371 0.4625323  0.52282515\n",
            " 0.4625323  0.52799311 0.49354005 0.52713178 0.59173127 0.54005168\n",
            " 0.61154177 0.56933678 0.4332472  0.44272179 0.55211025 0.43669251\n",
            " 0.46856158 0.54177433 0.48062016 0.38329027 0.56158484 0.50904393\n",
            " 0.44358312 0.62187769 0.57105943 0.48148148 0.47459087 0.34969854\n",
            " 0.47459087 0.63738157 0.5374677  0.46942291 0.49956934 0.66838932\n",
            " 0.41860465 0.59862188 0.60120586 0.54263566 0.49267873 0.51335056\n",
            " 0.56503015 0.60809647 0.42291128 0.30749354 0.45822567 0.50129199\n",
            " 0.53574505 0.52971576 0.5503876  0.54952627 0.50215332 0.36692506\n",
            " 0.4005168  0.61068045 0.55555556 0.67183463 0.42463394 0.52368648\n",
            " 0.46942291 0.5047373  0.59689922 0.59345392 0.54263566 0.5994832\n",
            " 0.4203273  0.48492679 0.4788975  0.54349699 0.43669251 0.48578811\n",
            " 0.4918174  0.57278208 0.54349699 0.67786391 0.48406546 0.56847545\n",
            " 0.40999139 0.65374677 0.55297158 0.66322136 0.54091301 0.5047373\n",
            " 0.44702842 0.50732127 0.31955211 0.48664944 0.41343669 0.52971576\n",
            " 0.77174849 0.34453058 0.43669251 0.70198105 0.39534884 0.66838932\n",
            " 0.55813953 0.63135228 0.48578811 0.57881137 0.54866494 0.583118\n",
            " 0.54694229 0.59259259 0.57536606 0.63824289 0.42204996 0.51162791\n",
            " 0.54005168 0.64254953 0.6089578  0.59689922 0.54608096 0.50129199\n",
            " 0.41946598 0.61929371 0.58570198 0.43066322 0.58139535 0.64341085\n",
            " 0.60206718 0.61584841 0.59259259 0.41257537 0.4952627  0.50301464\n",
            " 0.49698536 0.49354005 0.50904393 0.52540913 0.35917313 0.53919035\n",
            " 0.49784668 0.42635659 0.48751077 0.54521964 0.53316107 0.52196382\n",
            " 0.48837209 0.61412575 0.47114556 0.36950904 0.5245478  0.57622739\n",
            " 0.48148148 0.48751077 0.49095607 0.41774332 0.36089578 0.39965547\n",
            " 0.44186047 0.6416882  0.40913006 0.53660637 0.41860465 0.45822567\n",
            " 0.37639966 0.27648579 0.50904393 0.60465116 0.4788975  0.45305771\n",
            " 0.42894057 0.57019811 0.52971576 0.41515935 0.65030146 0.37898363\n",
            " 0.54866494 0.52024117 0.44788975 0.42980189 0.51679587 0.52627046\n",
            " 0.59259259 0.54435831 0.6287683  0.43927649 0.64513351 0.40568475\n",
            " 0.60120586 0.54177433 0.60034453 0.45391904 0.59517657 0.54349699\n",
            " 0.43238587 0.3875969  0.62962963 0.63307494 0.55986219 0.52196382\n",
            " 0.55986219 0.42807924 0.49009475 0.6089578  0.6873385  0.33936262\n",
            " 0.57278208 0.47028424 0.60292851 0.44788975 0.52627046 0.49009475\n",
            " 0.54005168 0.60723514 0.63738157 0.45391904 0.47631352 0.65374677\n",
            " 0.45478036 0.46942291 0.40999139 0.59345392 0.47459087 0.45564169\n",
            " 0.4005168  0.60120586 0.28251507 0.42204996 0.57019811 0.60034453\n",
            " 0.46339363 0.47975883 0.44358312 0.60206718 0.47631352 0.57795004\n",
            " 0.41085271 0.44186047 0.46770026 0.50990525 0.44702842 0.46339363\n",
            " 0.36692506 0.41774332 0.49956934 0.60465116 0.52282515 0.43755383\n",
            " 0.48664944 0.54005168 0.54349699 0.51507321 0.67355728 0.36347976\n",
            " 0.55727821 0.50215332 0.45908699 0.55900086 0.38845823 0.54005168\n",
            " 0.58914729 0.43583118 0.37898363 0.70801034 0.54608096 0.40137812\n",
            " 0.51593454 0.60809647 0.48837209 0.57105943 0.58742463 0.56761413\n",
            " 0.4918174  0.47372954 0.51765719 0.6089578  0.57450474 0.5538329\n",
            " 0.56503015 0.36175711 0.52713178 0.48923342 0.61498708 0.58828596\n",
            " 0.61757106 0.52368648 0.52024117 0.49009475 0.43841516 0.60551249\n",
            " 0.51076658 0.58742463 0.38242894 0.51507321 0.45908699 0.50559862\n",
            " 0.52971576 0.44530577 0.48062016 0.44099914 0.48320413 0.53488372\n",
            " 0.59689922 0.51679587 0.53229974 0.51593454 0.52196382 0.38845823\n",
            " 0.64857881 0.64082687 0.56847545 0.53574505 0.4788975  0.37209302\n",
            " 0.52885444 0.43927649 0.5245478  0.57536606 0.42291128 0.5211025\n",
            " 0.58139535 0.4039621  0.45391904 0.39448751 0.59862188 0.52713178\n",
            " 0.53660637 0.46597761 0.53057709 0.45047373 0.5211025  0.50129199\n",
            " 0.60120586 0.45305771 0.47459087 0.60378984 0.57536606 0.52282515\n",
            " 0.52885444 0.42291128 0.56761413 0.64254953 0.35400517 0.46683893\n",
            " 0.55813953 0.52196382 0.52368648 0.58225668 0.59259259 0.59173127\n",
            " 0.55641688 0.42894057 0.47200689 0.56072351 0.50215332 0.71490095\n",
            " 0.43066322 0.56072351 0.33850129 0.68819983 0.6416882  0.55555556\n",
            " 0.65030146 0.38587425 0.42291128 0.42980189 0.64341085 0.63652024\n",
            " 0.51851852 0.48923342 0.5081826  0.46167097 0.60809647 0.52971576\n",
            " 0.46511628 0.50559862 0.57019811 0.54952627]\n",
            "The trained model has an aproximate error rate of -0.4591365072905534 which equates to 0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE value is very similar to that of the linear regression model, indicating that both models are accurate predictors. The error rate of the DNN is higher, indicating the there is a higher number of errors, but the margin of error is lower."
      ],
      "metadata": {
        "id": "HAhdrU04ttZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dew Point (dewp)\n",
        "As with the linear regressor the process of training each model follows a very similar process, with the number of hidden layers, the number of nodes within each layer and the learning rate changing dependant on the dataset."
      ],
      "metadata": {
        "id": "yT91LA7Xx77W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_dewp_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/dewp_clean_dnn.csv', index_col=0, )\n",
        "print(df_dewp_dnn[:6])"
      ],
      "metadata": {
        "id": "zQAH_kVzyAOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960199a4-d433-4256-fcd5-9cb2e9ae79a3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_dewp_dnn = df_dewp_dnn.drop(columns=['temp', 'prcp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_dewp_dnn = df_dewp_dnn.loc[df_dewp_dnn[\"year\"] != 2012]\n",
        "df_dewp_dnn = df_dewp_dnn.loc[df_dewp_dnn[\"year\"] < 2020]\n",
        "#Move target to end\n",
        "cols = df_dewp_dnn['NUM_COLLISIONS']\n",
        "df_dewp_dnn = df_dewp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_dewp_dnn.insert(loc=21, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_dewp_dnn[:6])\n",
        "df_dewp_dnn.describe()"
      ],
      "metadata": {
        "id": "_qzGppAwyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "fccecaee-7f8b-41dd-cb2a-d671e9c49a08"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  dewp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "49  2016  28  24.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17  35.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25  21.2    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29  36.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20  32.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13  44.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da         dewp          Apr          Aug  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean   2015.999217    15.723679    44.163170     0.082192     0.084932   \n",
              "std       2.000000     8.801271    16.995303     0.274710     0.278834   \n",
              "min    2013.000000     1.000000    -6.700000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000    32.150000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000    45.300000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000    58.500000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000    74.100000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000  ...   \n",
              "mean      0.084932     0.077104     0.084932     0.084540     0.082192  ...   \n",
              "std       0.278834     0.266808     0.278834     0.278251     0.274710  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Nov          Oct          Sep          Mon          Sat  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      0.082192     0.084932     0.082192     0.143249     0.142857   \n",
              "std       0.274710     0.278834     0.274710     0.350395     0.349996   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000     2555.000000  \n",
              "mean      0.142857     0.142857     0.142857     0.142857      599.109980  \n",
              "std       0.349996     0.349996     0.349996     0.349996      100.277185  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5f50379-b1aa-49ff-ba6b-b022c95cf1fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>dewp</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.999217</td>\n",
              "      <td>15.723679</td>\n",
              "      <td>44.163170</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.077104</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084540</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.143249</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>599.109980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.801271</td>\n",
              "      <td>16.995303</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.266808</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278251</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.350395</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>100.277185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5f50379-b1aa-49ff-ba6b-b022c95cf1fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5f50379-b1aa-49ff-ba6b-b022c95cf1fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5f50379-b1aa-49ff-ba6b-b022c95cf1fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle Data\n",
        "shuffle = df_dewp_dnn.iloc[np.random.permutation(len(df_dewp_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "z5-eCTxByAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056c7e84-ed5f-447d-c65a-5ab2b1db5863"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  dewp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  May  Nov  Oct  \\\n",
            "1980  2019  30  71.1    0    0    0    0    0    1    0  ...    0    0    0   \n",
            "2182  2014  10  61.4    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "525   2018  17  24.8    0    0    0    1    0    0    0  ...    0    0    0   \n",
            "131   2019  17  15.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "1656  2017   1  53.8    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "306   2014   3  20.2    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "      Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1980    0    1    0    0    0    0    0  \n",
            "2182    0    0    1    0    0    0    0  \n",
            "525     0    0    0    0    0    0    0  \n",
            "131     0    0    0    0    0    0    1  \n",
            "1656    0    0    0    0    0    0    1  \n",
            "306     0    0    0    0    1    0    0  \n",
            "\n",
            "[6 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "BbrOrPfQyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713fe962-f22d-4956-f37d-011699c59191"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1980    638\n",
            "2182    512\n",
            "525     604\n",
            "131     586\n",
            "1656    654\n",
            "306     423\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "#Calculate number of outputs\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "T2v7BylMyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41de26de-506c-47da-e3a0-fdf1880ff462"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_dewp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[21,17,9], optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "#Train model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "HMGFsHtkyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54babcad-7759-4577-89a5-d1eb7fd15dc1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6984fd60d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:loss = 2885.8882, step = 1\n",
            "INFO:tensorflow:global_step/sec: 452.294\n",
            "INFO:tensorflow:loss = 0.6163688, step = 101 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.605\n",
            "INFO:tensorflow:loss = 0.43207002, step = 201 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.559\n",
            "INFO:tensorflow:loss = 0.45611447, step = 301 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.565\n",
            "INFO:tensorflow:loss = 0.2883045, step = 401 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.957\n",
            "INFO:tensorflow:loss = 0.44561958, step = 501 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.541\n",
            "INFO:tensorflow:loss = 0.37659773, step = 601 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.147\n",
            "INFO:tensorflow:loss = 0.3675207, step = 701 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.969\n",
            "INFO:tensorflow:loss = 0.26099503, step = 801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.796\n",
            "INFO:tensorflow:loss = 0.3165444, step = 901 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.938\n",
            "INFO:tensorflow:loss = 0.280748, step = 1001 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.917\n",
            "INFO:tensorflow:loss = 0.31326616, step = 1101 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.817\n",
            "INFO:tensorflow:loss = 0.26480836, step = 1201 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.999\n",
            "INFO:tensorflow:loss = 0.2861905, step = 1301 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.986\n",
            "INFO:tensorflow:loss = 0.2964838, step = 1401 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.618\n",
            "INFO:tensorflow:loss = 0.1953747, step = 1501 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.186\n",
            "INFO:tensorflow:loss = 0.24093029, step = 1601 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.375\n",
            "INFO:tensorflow:loss = 0.22428265, step = 1701 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 578.081\n",
            "INFO:tensorflow:loss = 0.24397016, step = 1801 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.215\n",
            "INFO:tensorflow:loss = 0.24746117, step = 1901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.215\n",
            "INFO:tensorflow:loss = 0.18583095, step = 2001 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.698\n",
            "INFO:tensorflow:loss = 0.19471224, step = 2101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.512\n",
            "INFO:tensorflow:loss = 0.18934034, step = 2201 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.115\n",
            "INFO:tensorflow:loss = 0.20267247, step = 2301 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.343\n",
            "INFO:tensorflow:loss = 0.1895351, step = 2401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.356\n",
            "INFO:tensorflow:loss = 0.1437392, step = 2501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 578.234\n",
            "INFO:tensorflow:loss = 0.1246032, step = 2601 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.585\n",
            "INFO:tensorflow:loss = 0.13338295, step = 2701 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.981\n",
            "INFO:tensorflow:loss = 0.13141958, step = 2801 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.435\n",
            "INFO:tensorflow:loss = 0.103879504, step = 2901 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.718\n",
            "INFO:tensorflow:loss = 0.09979824, step = 3001 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.671\n",
            "INFO:tensorflow:loss = 0.08019295, step = 3101 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.562\n",
            "INFO:tensorflow:loss = 0.100788936, step = 3201 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.966\n",
            "INFO:tensorflow:loss = 0.09364969, step = 3301 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.223\n",
            "INFO:tensorflow:loss = 0.08948563, step = 3401 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.194\n",
            "INFO:tensorflow:loss = 0.0751047, step = 3501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 595\n",
            "INFO:tensorflow:loss = 0.049469676, step = 3601 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.792\n",
            "INFO:tensorflow:loss = 0.056877516, step = 3701 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.221\n",
            "INFO:tensorflow:loss = 0.04751162, step = 3801 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.668\n",
            "INFO:tensorflow:loss = 0.040080387, step = 3901 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.926\n",
            "INFO:tensorflow:loss = 0.0371836, step = 4001 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.936\n",
            "INFO:tensorflow:loss = 0.036958084, step = 4101 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.252\n",
            "INFO:tensorflow:loss = 0.032683015, step = 4201 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.695\n",
            "INFO:tensorflow:loss = 0.025062509, step = 4301 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.288\n",
            "INFO:tensorflow:loss = 0.02131087, step = 4401 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.104\n",
            "INFO:tensorflow:loss = 0.022367857, step = 4501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.661\n",
            "INFO:tensorflow:loss = 0.02076692, step = 4601 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.89\n",
            "INFO:tensorflow:loss = 0.020089535, step = 4701 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.1\n",
            "INFO:tensorflow:loss = 0.018688047, step = 4801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.136\n",
            "INFO:tensorflow:loss = 0.01495573, step = 4901 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.142\n",
            "INFO:tensorflow:loss = 0.01619701, step = 5001 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.431\n",
            "INFO:tensorflow:loss = 0.012545241, step = 5101 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.784\n",
            "INFO:tensorflow:loss = 0.011841854, step = 5201 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.189\n",
            "INFO:tensorflow:loss = 0.011034601, step = 5301 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.982\n",
            "INFO:tensorflow:loss = 0.015668986, step = 5401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.988\n",
            "INFO:tensorflow:loss = 0.011496762, step = 5501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.659\n",
            "INFO:tensorflow:loss = 0.011110781, step = 5601 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.897\n",
            "INFO:tensorflow:loss = 0.009660709, step = 5701 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.594\n",
            "INFO:tensorflow:loss = 0.010759312, step = 5801 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.313\n",
            "INFO:tensorflow:loss = 0.0071270056, step = 5901 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.923\n",
            "INFO:tensorflow:loss = 0.008318721, step = 6001 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.326\n",
            "INFO:tensorflow:loss = 0.007822504, step = 6101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.594\n",
            "INFO:tensorflow:loss = 0.009212837, step = 6201 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.604\n",
            "INFO:tensorflow:loss = 0.011687482, step = 6301 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 598.293\n",
            "INFO:tensorflow:loss = 0.0097148735, step = 6401 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.207\n",
            "INFO:tensorflow:loss = 0.0067458265, step = 6501 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.776\n",
            "INFO:tensorflow:loss = 0.0064633004, step = 6601 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.997\n",
            "INFO:tensorflow:loss = 0.0088412855, step = 6701 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.904\n",
            "INFO:tensorflow:loss = 0.006243903, step = 6801 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.632\n",
            "INFO:tensorflow:loss = 0.008086015, step = 6901 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.466\n",
            "INFO:tensorflow:loss = 0.006839916, step = 7001 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.626\n",
            "INFO:tensorflow:loss = 0.006814601, step = 7101 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.62\n",
            "INFO:tensorflow:loss = 0.008447204, step = 7201 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.629\n",
            "INFO:tensorflow:loss = 0.00593016, step = 7301 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.265\n",
            "INFO:tensorflow:loss = 0.0062152133, step = 7401 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.963\n",
            "INFO:tensorflow:loss = 0.00529558, step = 7501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.619\n",
            "INFO:tensorflow:loss = 0.0069405544, step = 7601 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.984\n",
            "INFO:tensorflow:loss = 0.0067238086, step = 7701 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.371\n",
            "INFO:tensorflow:loss = 0.006669309, step = 7801 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.429\n",
            "INFO:tensorflow:loss = 0.006317313, step = 7901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.259\n",
            "INFO:tensorflow:loss = 0.007176641, step = 8001 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.837\n",
            "INFO:tensorflow:loss = 0.004267804, step = 8101 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.646\n",
            "INFO:tensorflow:loss = 0.0065559605, step = 8201 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.783\n",
            "INFO:tensorflow:loss = 0.005412938, step = 8301 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.884\n",
            "INFO:tensorflow:loss = 0.005890118, step = 8401 (0.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.823\n",
            "INFO:tensorflow:loss = 0.0049490826, step = 8501 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.004\n",
            "INFO:tensorflow:loss = 0.005315614, step = 8601 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.809\n",
            "INFO:tensorflow:loss = 0.0063520954, step = 8701 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.797\n",
            "INFO:tensorflow:loss = 0.0055041863, step = 8801 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.493\n",
            "INFO:tensorflow:loss = 0.0046108807, step = 8901 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.573\n",
            "INFO:tensorflow:loss = 0.004247753, step = 9001 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.327\n",
            "INFO:tensorflow:loss = 0.0036440222, step = 9101 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.411\n",
            "INFO:tensorflow:loss = 0.004004861, step = 9201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.153\n",
            "INFO:tensorflow:loss = 0.004238299, step = 9301 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 578.336\n",
            "INFO:tensorflow:loss = 0.0054886853, step = 9401 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.606\n",
            "INFO:tensorflow:loss = 0.0047295485, step = 9501 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.284\n",
            "INFO:tensorflow:loss = 0.005793737, step = 9601 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.385\n",
            "INFO:tensorflow:loss = 0.0061616693, step = 9701 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.535\n",
            "INFO:tensorflow:loss = 0.004955454, step = 9801 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.895\n",
            "INFO:tensorflow:loss = 0.0063214777, step = 9901 (0.172 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0063576316.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 96.59943561948128\n",
            "Just using average = 598.2734833659491 has RMSE of 101.31319535932884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "# Ensure number of hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[21,17,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NCz6izVhyAOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003a37b5-761d-4b79-b4e3-cb123fd89784"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6984e5b810>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4818532  0.51460123 0.31911603 0.45461652 0.512521   0.50714093\n",
            " 0.4920572  0.53636235 0.50577813 0.47075906 0.47199425 0.5076965\n",
            " 0.51449645 0.5595216  0.5128036  0.5276331  0.54849154 0.49425277\n",
            " 0.48258165 0.49075547 0.5062065  0.4773247  0.5223157  0.48422638\n",
            " 0.49502268 0.48024714 0.5085339  0.49631643 0.49778122 0.49048793\n",
            " 0.39905182 0.567484   0.50202125 0.5045959  0.5104677  0.5532324\n",
            " 0.49237752 0.47260496 0.49752718 0.50108325 0.452891   0.50552005\n",
            " 0.5038974  0.5033033  0.4542569  0.3608052  0.49467486 0.50112534\n",
            " 0.5621588  0.43251032 0.45935723 0.49433625 0.5368627  0.41053864\n",
            " 0.5106945  0.43314728 0.5073223  0.44676185 0.5020465  0.47161767\n",
            " 0.5382461  0.48666313 0.5174236  0.4902932  0.49441513 0.5227637\n",
            " 0.4980762  0.4040285  0.33408618 0.47766992 0.4334986  0.47165924\n",
            " 0.39555758 0.39627087 0.5014044  0.4531174  0.4120762  0.5423504\n",
            " 0.51209754 0.49326056 0.46020252 0.48183224 0.5203091  0.38524652\n",
            " 0.5550864  0.50632936 0.47430155 0.52269053 0.526151   0.55424213\n",
            " 0.4232233  0.5292862  0.4880126  0.53775537 0.5451205  0.479969\n",
            " 0.52793574 0.4957515  0.506433   0.47012958 0.4791556  0.45512643\n",
            " 0.4952166  0.48855153 0.41085586 0.47346056 0.50988126 0.40475363\n",
            " 0.463523   0.43411252 0.50393593 0.42132702 0.43590233 0.50237715\n",
            " 0.5055555  0.4938519  0.3299487  0.39689913 0.54941666 0.42626822\n",
            " 0.49899745 0.4330852  0.45656696 0.49745202 0.5397736  0.45125294\n",
            " 0.5549896  0.5540413  0.51421547 0.51015526 0.44037867 0.45206022\n",
            " 0.470261   0.51642364 0.49339426 0.55942446 0.4119955  0.5571251\n",
            " 0.47094664 0.48800078 0.502238   0.50535375 0.54878426 0.49789912\n",
            " 0.44555342 0.52654666 0.512607   0.51665115 0.4634751  0.49714255\n",
            " 0.4677225  0.40822804 0.5591752  0.59031147 0.5078451  0.50273037\n",
            " 0.49613285 0.5238385  0.460778   0.47719416 0.50973165 0.5236742\n",
            " 0.55900526 0.43553048 0.50463694 0.5402894  0.510416   0.46008724\n",
            " 0.5276338  0.50627416 0.48710883 0.48703462 0.31960633 0.5284267\n",
            " 0.48680678 0.5240088  0.40330413 0.4709296  0.45523894 0.51452714\n",
            " 0.4820985  0.53931606 0.4735119  0.54012215 0.48585996 0.464735\n",
            " 0.51658714 0.32948908 0.41231498 0.37152398 0.49640137 0.39400476\n",
            " 0.4171236  0.4308138  0.46972585 0.5410012  0.54354286 0.50436455\n",
            " 0.45061663 0.5333555  0.40161872 0.40665844 0.5036777  0.4516057\n",
            " 0.45909005 0.38283622 0.50284404 0.3211918  0.49399874 0.5046821\n",
            " 0.410722   0.5517045  0.4857679  0.5053807  0.46600848 0.4596743\n",
            " 0.47329766 0.5347581  0.48312178 0.5179376  0.45468983 0.49411777\n",
            " 0.4380814  0.51821095 0.48292032 0.49142677 0.50987446 0.53822136\n",
            " 0.48148608 0.37897378 0.49222842 0.50583994 0.50167197 0.5127259\n",
            " 0.53614765 0.5009514  0.54126835 0.502453   0.44819182 0.51732373\n",
            " 0.49614632 0.47885048 0.44926554 0.48377997 0.40430412 0.4850026\n",
            " 0.5127496  0.44703972 0.48841757 0.3840386  0.47253245 0.4999001\n",
            " 0.45000696 0.5610577  0.34388053 0.48659632 0.5039502  0.5086619\n",
            " 0.41376972 0.53259027 0.51885355 0.5321398  0.46026152 0.4962024\n",
            " 0.4316034  0.49278814 0.530464   0.44309616 0.46510783 0.44588703\n",
            " 0.5176629  0.5056597  0.44111586 0.48408434 0.5489933  0.50941515\n",
            " 0.44159845 0.52324104 0.40693253 0.51731706 0.4955807  0.4807754\n",
            " 0.44795728 0.36393112 0.52004445 0.55239534 0.48720467 0.49651867\n",
            " 0.50084144 0.51976174 0.5025452  0.49457702 0.3860397  0.37172717\n",
            " 0.4897359  0.4046003  0.36344332 0.5073026  0.36474743 0.3960461\n",
            " 0.41952154 0.51017445 0.49731654 0.50591916 0.5473018  0.5030607\n",
            " 0.36959696 0.44823372 0.5538028  0.493259   0.54036665 0.5284679\n",
            " 0.5143388  0.43934742 0.47710025 0.49728966 0.45212597 0.49128863\n",
            " 0.40594694 0.5059567  0.3967062  0.5202807  0.3917337  0.5071849\n",
            " 0.37143314 0.4194549  0.5288528  0.49074775 0.5619926  0.42691994\n",
            " 0.38600823 0.5033209  0.5507445  0.39534935 0.4391138  0.5380931\n",
            " 0.47366542 0.5957974  0.53806424 0.55145746 0.49856764 0.4754398\n",
            " 0.46504936 0.55428135 0.3201598  0.5261787  0.40229645 0.49091977\n",
            " 0.49470407 0.49469748 0.36402014 0.49168524 0.4390041  0.5123097\n",
            " 0.5108875  0.3437682  0.42439035 0.45349428 0.5584747  0.5140763\n",
            " 0.40111473 0.49559084 0.42826223 0.53692335 0.55009544 0.4659081\n",
            " 0.4596563  0.464642   0.33325866 0.49698102 0.5062037  0.49943495\n",
            " 0.48665148 0.4845843  0.41637263 0.489789   0.44073787 0.4888656\n",
            " 0.5694361  0.4953582  0.34886426 0.54602313 0.5584778  0.397281\n",
            " 0.51042986 0.5625438  0.46863872 0.5933237  0.5276774  0.5310262\n",
            " 0.55830777 0.45975658 0.5121904  0.45552447 0.4920507  0.5143061\n",
            " 0.5135962  0.44966915 0.4549192  0.42515504 0.42481104 0.39500788\n",
            " 0.47370422 0.40469894 0.4461886  0.502256   0.5048439  0.49022803\n",
            " 0.5258744  0.46425602 0.516481   0.34453982 0.420233   0.44675392\n",
            " 0.45129663 0.47282138 0.38495472 0.32082894 0.48401886 0.49148443\n",
            " 0.50162727 0.53423256 0.48587108 0.43206245 0.4319303  0.5179187\n",
            " 0.45394963 0.51901656 0.4749752  0.5514236  0.46131954 0.5025389\n",
            " 0.5182512  0.4402128  0.45287862 0.48486114 0.4996462  0.46196467\n",
            " 0.5356844  0.47389314 0.48005468 0.44746476 0.5962395  0.5371605\n",
            " 0.46135646 0.493722   0.4283845  0.40563968 0.50318605 0.48899147\n",
            " 0.55023605 0.5069956  0.50997806 0.42290565 0.4441811  0.43767908\n",
            " 0.5499689  0.5495223  0.44325387 0.51653653 0.55858827 0.50704336\n",
            " 0.5142302  0.35370314 0.41818348 0.34762165 0.45863047 0.4440068\n",
            " 0.52152777 0.49731326 0.52680606 0.51124704 0.50561446 0.48334658\n",
            " 0.39916474 0.47149786 0.4763275  0.48570964 0.4847675  0.51820874\n",
            " 0.40325353 0.48937282 0.44590005 0.5563494  0.4548371  0.55016875\n",
            " 0.46505255 0.5518193  0.46517122 0.5042057  0.4244538  0.54949576\n",
            " 0.5171535  0.41540304 0.4323767  0.487818   0.48721316 0.5062264\n",
            " 0.5265693  0.58791006 0.4012455  0.55722296 0.50714236 0.4656521\n",
            " 0.5448647  0.4823906  0.5113007  0.49383667 0.48819172 0.494783\n",
            " 0.493911  ]\n",
            "[0.5960379  0.60292851 0.33850129 0.48406546 0.27648579 0.49698536\n",
            " 0.53229974 0.58914729 0.42894057 0.53660637 0.5796727  0.46511628\n",
            " 0.56416882 0.67355728 0.51593454 0.48664944 0.74677003 0.63221361\n",
            " 0.60809647 0.41257537 0.52713178 0.46425495 0.5211025  0.46511628\n",
            " 0.5503876  0.56847545 0.45305771 0.3712317  0.45564169 0.43755383\n",
            " 0.41085271 0.59689922 0.56589147 0.50732127 0.55641688 0.56244617\n",
            " 0.42549526 0.60206718 0.57881137 0.52885444 0.4203273  0.5245478\n",
            " 0.6744186  0.57622739 0.36606374 0.44530577 0.50129199 0.41860465\n",
            " 0.60120586 0.5081826  0.54091301 0.36175711 0.53919035 0.37984496\n",
            " 0.45305771 0.44444444 0.57105943 0.4625323  0.56761413 0.62446167\n",
            " 0.57278208 0.49784668 0.58914729 0.47028424 0.5960379  0.46167097\n",
            " 0.5667528  0.49784668 0.39793282 0.58225668 0.56330749 0.47975883\n",
            " 0.47803618 0.39362618 0.56330749 0.43410853 0.40223945 0.60809647\n",
            " 0.5994832  0.53660637 0.56158484 0.62187769 0.56933678 0.3712317\n",
            " 0.61584841 0.55813953 0.5503876  0.49612403 0.42463394 0.42204996\n",
            " 0.39190353 0.48837209 0.42377261 0.54349699 0.69939707 0.51335056\n",
            " 0.69595177 0.50215332 0.5538329  0.38931955 0.50990525 0.54005168\n",
            " 0.60551249 0.63910422 0.4461671  0.46339363 0.57536606 0.46770026\n",
            " 0.49698536 0.50990525 0.51593454 0.58570198 0.49095607 0.52282515\n",
            " 0.57881137 0.58914729 0.38587425 0.42721792 0.5538329  0.51765719\n",
            " 0.56416882 0.50301464 0.59173127 0.38845823 0.60120586 0.59086994\n",
            " 0.55986219 0.63910422 0.80878553 0.47975883 1.         0.49698536\n",
            " 0.51851852 0.61068045 0.56416882 0.55297158 0.44013781 0.83893196\n",
            " 0.57278208 0.52282515 0.5503876  0.46856158 0.55813953 0.53919035\n",
            " 0.49870801 0.62962963 0.60206718 0.61584841 0.47717485 0.57019811\n",
            " 0.5503876  0.39793282 0.6089578  0.38845823 0.63738157 0.4203273\n",
            " 0.55813953 0.65374677 0.34022394 0.63996555 0.66149871 0.59345392\n",
            " 0.56761413 0.42635659 0.43583118 0.45047373 0.51679587 0.54866494\n",
            " 0.52885444 0.58656331 0.48320413 0.56158484 0.35400517 0.4754522\n",
            " 0.49956934 0.66666667 0.51421189 0.45305771 0.53229974 0.54263566\n",
            " 0.52627046 0.54521964 0.54521964 0.56761413 0.5211025  0.53057709\n",
            " 0.45047373 0.36692506 0.53229974 0.34366925 0.56244617 0.47372954\n",
            " 0.40913006 0.44875108 0.57795004 0.66838932 0.68217054 0.64513351\n",
            " 0.58828596 0.41343669 0.44099914 0.39190353 0.50215332 0.37898363\n",
            " 0.46425495 0.48148148 0.61154177 0.39793282 0.51937984 0.54521964\n",
            " 0.50301464 0.51593454 0.60292851 0.59259259 0.43755383 0.60206718\n",
            " 0.45822567 0.67011197 0.54694229 0.48751077 0.56158484 0.52885444\n",
            " 0.43841516 0.5994832  0.45391904 0.45478036 0.59345392 0.52713178\n",
            " 0.45650301 0.43066322 0.54866494 0.51851852 0.51162791 0.58656331\n",
            " 0.54608096 0.47028424 0.49956934 0.5047373  0.40310078 0.53402239\n",
            " 0.61757106 0.59431525 0.47803618 0.61068045 0.34797588 0.44530577\n",
            " 0.60034453 0.44358312 0.46942291 0.46339363 0.5374677  0.51765719\n",
            " 0.49095607 0.45994832 0.3910422  0.53057709 0.55211025 0.52282515\n",
            " 0.44272179 0.5374677  0.63652024 0.51937984 0.47803618 0.52368648\n",
            " 0.48148148 0.50043066 0.55297158 0.57881137 0.51162791 0.4332472\n",
            " 0.5211025  0.63479759 0.64599483 0.43410853 0.63393626 0.52196382\n",
            " 0.39018088 0.61757106 0.40740741 0.51162791 0.48837209 0.54866494\n",
            " 0.4496124  0.59689922 0.59862188 0.54349699 0.47200689 0.51765719\n",
            " 0.63652024 0.42291128 0.59000861 0.61843239 0.42204996 0.43927649\n",
            " 0.45736434 0.42807924 0.30060293 0.55641688 0.40654608 0.41774332\n",
            " 0.53057709 0.33505599 0.49698536 0.54263566 0.62101637 0.41343669\n",
            " 0.38156761 0.55986219 0.65202412 0.34453058 0.61154177 0.54091301\n",
            " 0.56761413 0.46856158 0.4952627  0.4754522  0.39276486 0.5538329\n",
            " 0.45994832 0.53919035 0.44099914 0.46942291 0.46511628 0.55813953\n",
            " 0.31438415 0.48923342 0.51248923 0.6124031  0.54608096 0.38673557\n",
            " 0.35228252 0.52368648 0.53143842 0.45478036 0.58570198 0.53057709\n",
            " 0.41343669 0.63996555 0.50301464 0.61068045 0.52024117 0.50732127\n",
            " 0.49956934 0.57364341 0.35400517 0.65202412 0.43927649 0.48148148\n",
            " 0.54005168 0.55986219 0.38587425 0.46511628 0.61154177 0.54694229\n",
            " 0.47286822 0.36434109 0.52971576 0.4461671  0.61929371 0.56330749\n",
            " 0.46942291 0.64771748 0.52627046 0.56503015 0.56072351 0.49784668\n",
            " 0.45219638 0.50559862 0.41774332 0.45908699 0.6546081  0.54521964\n",
            " 0.7166236  0.41429802 0.36864772 0.60120586 0.52799311 0.5994832\n",
            " 0.60120586 0.5245478  0.34453058 0.56330749 0.63738157 0.36950904\n",
            " 0.51593454 0.64082687 0.50904393 0.59689922 0.48148148 0.59431525\n",
            " 0.55297158 0.46942291 0.55727821 0.47200689 0.51593454 0.5081826\n",
            " 0.45047373 0.50990525 0.52799311 0.49784668 0.54263566 0.35745047\n",
            " 0.44875108 0.40826873 0.32816537 0.48923342 0.73815676 0.37639966\n",
            " 0.53574505 0.6546081  0.57364341 0.39276486 0.45650301 0.49009475\n",
            " 0.56589147 0.4952627  0.49354005 0.32127476 0.44788975 0.62618432\n",
            " 0.65202412 0.5796727  0.54349699 0.49009475 0.54177433 0.63824289\n",
            " 0.57364341 0.55900086 0.48492679 0.60551249 0.28682171 0.47200689\n",
            " 0.57019811 0.42291128 0.4918174  0.46339363 0.54866494 0.50301464\n",
            " 0.46511628 0.51162791 0.51507321 0.46511628 0.63221361 0.39190353\n",
            " 0.50301464 0.44099914 0.50559862 0.40913006 0.4203273  0.60206718\n",
            " 0.55727821 0.51248923 0.47459087 0.49354005 0.53919035 0.53660637\n",
            " 0.69939707 0.57536606 0.58484065 0.60809647 0.57105943 0.67011197\n",
            " 0.54091301 0.43496985 0.416882   0.38329027 0.5374677  0.58656331\n",
            " 0.68217054 0.63393626 0.51076658 0.55727821 0.54091301 0.55727821\n",
            " 0.44358312 0.53574505 0.5211025  0.47459087 0.60378984 0.55986219\n",
            " 0.44358312 0.48751077 0.54177433 0.52799311 0.40913006 0.75107666\n",
            " 0.57278208 0.56158484 0.47459087 0.48062016 0.60551249 0.62360034\n",
            " 0.67355728 0.50732127 0.49440138 0.5667528  0.46167097 0.53316107\n",
            " 0.63049096 0.63049096 0.52024117 0.58656331 0.61068045 0.54177433\n",
            " 0.625323   0.51593454 0.45564169 0.45822567 0.55900086 0.46683893\n",
            " 0.47459087]\n",
            "The trained model has an aproximate error rate of 44.3632680311245 which equates to 7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown by the RMSE value, this model is a more efficient way to predict the number of collisions in comparison to using the mean. In comparison to the linear regression model trained, the RMSE is lower indicating the DNN makes more accurate predictions. As with the DNN for precipitation, the RMSE is lower than the linear model the error rate is higher indicating there is more errors but the margin of error is lower."
      ],
      "metadata": {
        "id": "LJTFyYeIFHwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sea Level Pressure(slp)\n",
        "Through the analysis carried out in assignment 1, no clear relationship between sea level pressure and the number of collisions was uncovered. A DNN will be used to attempt to predict the number of collisions at a given pressure point."
      ],
      "metadata": {
        "id": "eJ4eYJryNjGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_slp_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/slp_clean_dnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "mhUamxCZOTrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcfedd1-5592-46bc-bb7a-b1f797e54ee6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_slp_dnn = df_slp_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_slp_dnn = df_slp_dnn.loc[df_slp_dnn[\"year\"] != 2012]\n",
        "df_slp_dnn = df_slp_dnn.loc[df_slp_dnn[\"year\"] < 2020]\n",
        "#Move target to the end\n",
        "cols = df_slp_dnn['NUM_COLLISIONS']\n",
        "df_slp_dnn = df_slp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_slp_dnn.insert(loc=21, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_slp_dnn[:6])\n",
        "df_slp_dnn.describe()"
      ],
      "metadata": {
        "id": "P-VEj2lxOTrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "a981d580-295f-46ed-b278-00a1eb9b8ad0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da     slp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "49  2016  28  1016.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17  1014.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25  1021.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29   999.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20  1015.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13  1020.7    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da          slp          Apr          Aug  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean   2016.000391    15.719765  1016.777221     0.082192     0.084932   \n",
              "std       2.000294     8.796698     7.628429     0.274710     0.278834   \n",
              "min    2013.000000     1.000000   989.500000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000  1012.200000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000  1016.700000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000  1021.700000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000  1044.200000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000  ...   \n",
              "mean      0.084540     0.077104     0.084932     0.084932     0.082192  ...   \n",
              "std       0.278251     0.266808     0.278834     0.278834     0.274710  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Nov          Oct          Sep          Mon          Sat  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      0.082192     0.084932     0.082192     0.143249     0.142857   \n",
              "std       0.274710     0.278834     0.274710     0.350395     0.349996   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000     2555.000000  \n",
              "mean      0.142857     0.142857     0.142857     0.142466      599.147162  \n",
              "std       0.349996     0.349996     0.349996     0.349596      100.268048  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a17fb386-05d3-45d2-921b-47200223dcff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>slp</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.000391</td>\n",
              "      <td>15.719765</td>\n",
              "      <td>1016.777221</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084540</td>\n",
              "      <td>0.077104</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.143249</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142466</td>\n",
              "      <td>599.147162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000294</td>\n",
              "      <td>8.796698</td>\n",
              "      <td>7.628429</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278251</td>\n",
              "      <td>0.266808</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.350395</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349596</td>\n",
              "      <td>100.268048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1012.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1016.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1021.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>1044.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a17fb386-05d3-45d2-921b-47200223dcff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a17fb386-05d3-45d2-921b-47200223dcff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a17fb386-05d3-45d2-921b-47200223dcff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle dataset\n",
        "shuffle = df_slp_dnn.iloc[np.random.permutation(len(df_slp_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "EG2EcMoLOTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1512815c-4acb-4d6f-d85a-6f4497f2bd90"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da     slp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  May  Nov  Oct  \\\n",
            "2443  2016  17  1014.4    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "655   2014  11  1002.9    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "87    2016  15  1014.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "1625  2018   9  1018.7    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "1182  2016   5  1019.3    1    0    0    0    0    0    0  ...    0    0    0   \n",
            "1434  2013  14  1015.8    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "\n",
            "      Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "2443    0    0    0    0    0    1    0  \n",
            "655     0    1    0    0    0    0    0  \n",
            "87      0    0    0    0    1    0    0  \n",
            "1625    0    0    0    0    0    0    0  \n",
            "1182    0    1    0    0    0    0    0  \n",
            "1434    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of the targets data.\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "pd6Uk6a9OTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c559d1ff-4ae5-4d40-a5a4-ad7ce79be94d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2443    658\n",
            "655     510\n",
            "87      722\n",
            "1625    706\n",
            "1182    672\n",
            "1434    565\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "#Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "QX1fWn3jOTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8764f125-c6bf-46eb-f4ad-c5f2ad0ce876"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_slp', ignore_errors=True)\n",
        "#Setup model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[19,15,11], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "C9uL6bF7OTrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910f87f9-af77-4f74-c420-dafaab37cc5f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698953fb10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_slp/model.ckpt.\n",
            "INFO:tensorflow:loss = 9936.371, step = 1\n",
            "INFO:tensorflow:global_step/sec: 464.988\n",
            "INFO:tensorflow:loss = 1.244927, step = 101 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.381\n",
            "INFO:tensorflow:loss = 0.36806673, step = 201 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.612\n",
            "INFO:tensorflow:loss = 0.11767705, step = 301 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.415\n",
            "INFO:tensorflow:loss = 0.031092502, step = 401 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 592.056\n",
            "INFO:tensorflow:loss = 0.01956394, step = 501 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.81\n",
            "INFO:tensorflow:loss = 0.01150495, step = 601 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.142\n",
            "INFO:tensorflow:loss = 0.015598632, step = 701 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.749\n",
            "INFO:tensorflow:loss = 0.019599762, step = 801 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.826\n",
            "INFO:tensorflow:loss = 0.067787364, step = 901 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.606\n",
            "INFO:tensorflow:loss = 0.074903235, step = 1001 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.115\n",
            "INFO:tensorflow:loss = 0.08188678, step = 1101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.199\n",
            "INFO:tensorflow:loss = 0.16620055, step = 1201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.436\n",
            "INFO:tensorflow:loss = 0.03673705, step = 1301 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.244\n",
            "INFO:tensorflow:loss = 0.0679972, step = 1401 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.516\n",
            "INFO:tensorflow:loss = 0.12125584, step = 1501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.499\n",
            "INFO:tensorflow:loss = 0.017205473, step = 1601 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.871\n",
            "INFO:tensorflow:loss = 0.12226853, step = 1701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.915\n",
            "INFO:tensorflow:loss = 0.13766217, step = 1801 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.256\n",
            "INFO:tensorflow:loss = 0.015410181, step = 1901 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.647\n",
            "INFO:tensorflow:loss = 0.3961166, step = 2001 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.27\n",
            "INFO:tensorflow:loss = 0.09686513, step = 2101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.228\n",
            "INFO:tensorflow:loss = 0.11879088, step = 2201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.107\n",
            "INFO:tensorflow:loss = 0.0139584355, step = 2301 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.358\n",
            "INFO:tensorflow:loss = 0.005259696, step = 2401 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.901\n",
            "INFO:tensorflow:loss = 0.067591354, step = 2501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.375\n",
            "INFO:tensorflow:loss = 0.021616416, step = 2601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.672\n",
            "INFO:tensorflow:loss = 0.03695868, step = 2701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.689\n",
            "INFO:tensorflow:loss = 0.046684295, step = 2801 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.262\n",
            "INFO:tensorflow:loss = 0.008623694, step = 2901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.043\n",
            "INFO:tensorflow:loss = 0.024274403, step = 3001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.23\n",
            "INFO:tensorflow:loss = 0.0062662438, step = 3101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.503\n",
            "INFO:tensorflow:loss = 0.004972642, step = 3201 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.756\n",
            "INFO:tensorflow:loss = 0.04920961, step = 3301 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.134\n",
            "INFO:tensorflow:loss = 0.07015737, step = 3401 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.444\n",
            "INFO:tensorflow:loss = 0.006814013, step = 3501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.287\n",
            "INFO:tensorflow:loss = 0.051525623, step = 3601 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.428\n",
            "INFO:tensorflow:loss = 0.020839965, step = 3701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.392\n",
            "INFO:tensorflow:loss = 0.03976199, step = 3801 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.248\n",
            "INFO:tensorflow:loss = 0.008787338, step = 3901 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.472\n",
            "INFO:tensorflow:loss = 0.07327832, step = 4001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.598\n",
            "INFO:tensorflow:loss = 0.004358078, step = 4101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.958\n",
            "INFO:tensorflow:loss = 0.009279288, step = 4201 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.142\n",
            "INFO:tensorflow:loss = 0.37736356, step = 4301 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.355\n",
            "INFO:tensorflow:loss = 0.14386517, step = 4401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.37\n",
            "INFO:tensorflow:loss = 0.0126389675, step = 4501 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.464\n",
            "INFO:tensorflow:loss = 0.00905118, step = 4601 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.573\n",
            "INFO:tensorflow:loss = 0.022495031, step = 4701 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.837\n",
            "INFO:tensorflow:loss = 0.011220958, step = 4801 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.509\n",
            "INFO:tensorflow:loss = 0.062246345, step = 4901 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.753\n",
            "INFO:tensorflow:loss = 0.025419544, step = 5001 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.511\n",
            "INFO:tensorflow:loss = 0.049021535, step = 5101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.258\n",
            "INFO:tensorflow:loss = 0.067768194, step = 5201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.608\n",
            "INFO:tensorflow:loss = 0.016793398, step = 5301 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.275\n",
            "INFO:tensorflow:loss = 0.061631553, step = 5401 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.145\n",
            "INFO:tensorflow:loss = 0.03160869, step = 5501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.135\n",
            "INFO:tensorflow:loss = 0.013611589, step = 5601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.162\n",
            "INFO:tensorflow:loss = 0.2830364, step = 5701 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.232\n",
            "INFO:tensorflow:loss = 0.025465429, step = 5801 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.726\n",
            "INFO:tensorflow:loss = 0.010276843, step = 5901 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.574\n",
            "INFO:tensorflow:loss = 0.009664162, step = 6001 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.123\n",
            "INFO:tensorflow:loss = 0.0074826106, step = 6101 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.832\n",
            "INFO:tensorflow:loss = 0.014985196, step = 6201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.662\n",
            "INFO:tensorflow:loss = 0.09383865, step = 6301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.184\n",
            "INFO:tensorflow:loss = 0.20089811, step = 6401 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.618\n",
            "INFO:tensorflow:loss = 0.01977013, step = 6501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.254\n",
            "INFO:tensorflow:loss = 0.0068261237, step = 6601 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.394\n",
            "INFO:tensorflow:loss = 0.017029785, step = 6701 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.979\n",
            "INFO:tensorflow:loss = 0.0061556944, step = 6801 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.87\n",
            "INFO:tensorflow:loss = 0.015860077, step = 6901 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.708\n",
            "INFO:tensorflow:loss = 0.013724596, step = 7001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.877\n",
            "INFO:tensorflow:loss = 0.025731247, step = 7101 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.973\n",
            "INFO:tensorflow:loss = 0.0045682415, step = 7201 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 578.491\n",
            "INFO:tensorflow:loss = 0.07414594, step = 7301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.681\n",
            "INFO:tensorflow:loss = 0.003904047, step = 7401 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.431\n",
            "INFO:tensorflow:loss = 0.0041206465, step = 7501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.511\n",
            "INFO:tensorflow:loss = 0.006867011, step = 7601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.733\n",
            "INFO:tensorflow:loss = 0.008340819, step = 7701 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.035\n",
            "INFO:tensorflow:loss = 0.0149806, step = 7801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.173\n",
            "INFO:tensorflow:loss = 0.009338067, step = 7901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.357\n",
            "INFO:tensorflow:loss = 0.005140249, step = 8001 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.779\n",
            "INFO:tensorflow:loss = 0.0098592285, step = 8101 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.721\n",
            "INFO:tensorflow:loss = 0.006321912, step = 8201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.239\n",
            "INFO:tensorflow:loss = 0.013616322, step = 8301 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.871\n",
            "INFO:tensorflow:loss = 0.0047322554, step = 8401 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.95\n",
            "INFO:tensorflow:loss = 0.0055274824, step = 8501 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.252\n",
            "INFO:tensorflow:loss = 0.010504527, step = 8601 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.241\n",
            "INFO:tensorflow:loss = 0.0052006813, step = 8701 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.921\n",
            "INFO:tensorflow:loss = 0.010119285, step = 8801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.822\n",
            "INFO:tensorflow:loss = 0.010303834, step = 8901 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.318\n",
            "INFO:tensorflow:loss = 0.0045520323, step = 9001 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.607\n",
            "INFO:tensorflow:loss = 0.0043898746, step = 9101 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.642\n",
            "INFO:tensorflow:loss = 0.022576015, step = 9201 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.193\n",
            "INFO:tensorflow:loss = 0.0056006974, step = 9301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.354\n",
            "INFO:tensorflow:loss = 0.011445709, step = 9401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.959\n",
            "INFO:tensorflow:loss = 0.011458334, step = 9501 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.942\n",
            "INFO:tensorflow:loss = 0.012908995, step = 9601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.12\n",
            "INFO:tensorflow:loss = 0.0075913453, step = 9701 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.87\n",
            "INFO:tensorflow:loss = 0.0045329244, step = 9801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.007\n",
            "INFO:tensorflow:loss = 0.0031566885, step = 9901 (0.173 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_slp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0063736564.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 79.70311085693434\n",
            "Just using average = 598.7788649706458 has RMSE of 98.45554082087295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#Ensure hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[19,15,11], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "mTPv83i1OTrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a9ff89-f802-41ab-ec0c-1baa2068857a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698571cc90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54682606 0.5556914  0.5329282  0.521293   0.55673933 0.5291626\n",
            " 0.5033573  0.53117627 0.45112374 0.5126334  0.45786372 0.5461756\n",
            " 0.5115131  0.58452356 0.55373687 0.537376   0.5745998  0.4934062\n",
            " 0.5258286  0.58835816 0.56955415 0.5131042  0.5125766  0.5403559\n",
            " 0.44633624 0.5540217  0.56178236 0.441593   0.57178134 0.4244301\n",
            " 0.5319812  0.5297657  0.5033051  0.50895125 0.5455781  0.55492324\n",
            " 0.5583681  0.56263155 0.58475876 0.5472646  0.619179   0.5005402\n",
            " 0.5434918  0.429134   0.4075162  0.5589485  0.50904137 0.3876207\n",
            " 0.51352364 0.5555644  0.5077263  0.5411454  0.53805083 0.50603956\n",
            " 0.578005   0.57618684 0.54920924 0.5644084  0.49727663 0.43904588\n",
            " 0.53781617 0.550493   0.5566992  0.46487942 0.51258147 0.52088666\n",
            " 0.5262752  0.596177   0.43721464 0.50537044 0.55371463 0.5162443\n",
            " 0.53503406 0.5887415  0.4353313  0.42495155 0.55601346 0.47680178\n",
            " 0.52018225 0.5546715  0.58957124 0.55052394 0.51438355 0.51643646\n",
            " 0.57406884 0.4989576  0.47414768 0.5258431  0.49450502 0.5760749\n",
            " 0.5440518  0.5325917  0.5663811  0.5133504  0.4410489  0.5135836\n",
            " 0.55170715 0.39995694 0.5184403  0.5393868  0.45845827 0.5192682\n",
            " 0.50559783 0.54382116 0.44625938 0.5471421  0.45356277 0.5950353\n",
            " 0.55676055 0.52062446 0.49726126 0.54204804 0.47800735 0.4744073\n",
            " 0.5336264  0.52482414 0.5294417  0.5661645  0.5334364  0.49801347\n",
            " 0.5530924  0.51309884 0.57624567 0.54964316 0.5220971  0.55116266\n",
            " 0.56469566 0.4344075  0.46126962 0.5111301  0.43736425 0.62146574\n",
            " 0.43796885 0.5061344  0.56788844 0.5097315  0.4831616  0.5387065\n",
            " 0.56480664 0.6021642  0.554583   0.53543097 0.5405319  0.5601802\n",
            " 0.47355872 0.54194    0.4806703  0.5827367  0.5512504  0.54265463\n",
            " 0.54186046 0.4832764  0.52456045 0.49122202 0.5424476  0.5117636\n",
            " 0.41925615 0.51273316 0.5177311  0.5381749  0.5197493  0.5173127\n",
            " 0.515402   0.45962664 0.48241624 0.5572794  0.4250894  0.5321605\n",
            " 0.5472795  0.53874326 0.56404823 0.5619147  0.4790378  0.48361146\n",
            " 0.5459807  0.5192014  0.58204615 0.5530482  0.6153216  0.5290736\n",
            " 0.46425647 0.48139894 0.5484355  0.4522942  0.5509483  0.52116513\n",
            " 0.46311682 0.5373851  0.536474   0.574174   0.52402157 0.5131911\n",
            " 0.59104264 0.49083    0.44192937 0.5073444  0.47137812 0.5298175\n",
            " 0.5874485  0.53391165 0.5553779  0.5301708  0.52530783 0.5156866\n",
            " 0.4455365  0.6111589  0.53598094 0.54018277 0.5494115  0.5657644\n",
            " 0.52099067 0.4551049  0.41353893 0.42307854 0.40032834 0.54990816\n",
            " 0.51733786 0.49906966 0.528685   0.5018751  0.54079145 0.5062748\n",
            " 0.4933704  0.5313039  0.53748834 0.54233587 0.5441199  0.5868\n",
            " 0.572027   0.557424   0.54216635 0.56275594 0.5845127  0.5842152\n",
            " 0.5377683  0.45800182 0.54779583 0.5953399  0.5486633  0.40578872\n",
            " 0.5548252  0.44209534 0.591019   0.555133   0.5384664  0.55587286\n",
            " 0.55869025 0.54682505 0.53648293 0.47315133 0.50676405 0.53204334\n",
            " 0.46877733 0.43591383 0.5254659  0.496664   0.51654416 0.4411062\n",
            " 0.50694644 0.5863138  0.5391897  0.5791052  0.48213378 0.50127554\n",
            " 0.52984136 0.54527414 0.5428601  0.49926904 0.508818   0.62257713\n",
            " 0.41194808 0.53763926 0.53847903 0.53456575 0.5915719  0.5794149\n",
            " 0.53189    0.5398366  0.4442669  0.42409876 0.58819956 0.5250922\n",
            " 0.53444654 0.44173923 0.44302446 0.47576746 0.5830086  0.4959083\n",
            " 0.52754587 0.5107937  0.5143599  0.5729773  0.52551496 0.45214152\n",
            " 0.55849767 0.5573842  0.5259501  0.54157805 0.44271654 0.49409536\n",
            " 0.54677564 0.5277868  0.5221543  0.5227488  0.54864216 0.5934082\n",
            " 0.5064039  0.48234606 0.43305233 0.57284313 0.51214284 0.5157331\n",
            " 0.52208066 0.61901134 0.5431957  0.5261876  0.46771744 0.5235291\n",
            " 0.54326636 0.49511325 0.47821072 0.5345221  0.547087   0.5352774\n",
            " 0.5302979  0.5647498  0.5624932  0.53420657 0.5178077  0.4703685\n",
            " 0.4612641  0.39397424 0.5345     0.50922644 0.49563867 0.4986156\n",
            " 0.5544471  0.5464287  0.5992294  0.46214956 0.53652585 0.542609\n",
            " 0.41527358 0.4869682  0.4852081  0.42875108 0.47504485 0.48436052\n",
            " 0.5299584  0.54437137 0.43304363 0.53007376 0.52937955 0.5687479\n",
            " 0.524506   0.5128826  0.5168442  0.5082963  0.5213964  0.55554414\n",
            " 0.50534964 0.45136443 0.4442121  0.4978502  0.5180393  0.4766609\n",
            " 0.52159667 0.44492304 0.5898738  0.5163147  0.4381491  0.49772292\n",
            " 0.58854026 0.53995353 0.414861   0.5627862  0.5448982  0.4381427\n",
            " 0.55226076 0.5439065  0.54011554 0.4388515  0.62340546 0.528992\n",
            " 0.49802968 0.47915524 0.53734803 0.5278435  0.534466   0.46939766\n",
            " 0.48310617 0.5773232  0.50160146 0.5258008  0.5142296  0.40997228\n",
            " 0.52382547 0.50089335 0.3829619  0.4130606  0.5204289  0.5485515\n",
            " 0.56928176 0.48896977 0.4823331  0.46123615 0.5489761  0.524933\n",
            " 0.5931577  0.5407978  0.49262506 0.5634877  0.58259624 0.4860526\n",
            " 0.5647442  0.50652975 0.503375   0.5222308  0.50088716 0.5510859\n",
            " 0.54672325 0.5745665  0.39395416 0.5236339  0.5872398  0.45009133\n",
            " 0.5799654  0.49826282 0.5626772  0.547328   0.55463606 0.40333807\n",
            " 0.5372553  0.52100086 0.58616674 0.598368   0.48106328 0.5616435\n",
            " 0.52228874 0.51076996 0.5609115  0.4547273  0.53676236 0.5588103\n",
            " 0.5449316  0.4672857  0.5281698  0.54066086 0.5577819  0.50467527\n",
            " 0.5546639  0.48622742 0.4857119  0.5337145  0.5321896  0.5027606\n",
            " 0.41629615 0.49457064 0.55810356 0.5385389  0.49208352 0.58612484\n",
            " 0.41316137 0.54732937 0.564907   0.41491556 0.5046477  0.452688\n",
            " 0.5145435  0.5367514  0.58504236 0.5517757  0.5652638  0.3930245\n",
            " 0.5779655  0.50860834 0.43644953 0.52462727 0.50714296 0.50897485\n",
            " 0.41164485 0.5522246  0.45049256 0.59282327 0.55994505 0.5436596\n",
            " 0.5332829  0.5098451  0.5630531  0.5903606  0.5334615  0.54942834\n",
            " 0.5833849  0.58637744 0.43080753 0.52333874 0.4801832  0.53607124\n",
            " 0.49029535 0.56552035 0.44031522 0.5228746  0.5357141  0.54160064\n",
            " 0.5463079  0.47584572 0.5438964  0.5801029  0.48481596 0.5250464\n",
            " 0.62686586]\n",
            "[0.59000861 0.57364341 0.58570198 0.54866494 0.47028424 0.48837209\n",
            " 0.47803618 0.48751077 0.45650301 0.62273902 0.36003445 0.47200689\n",
            " 0.52799311 0.63910422 0.49095607 0.59259259 0.64857881 0.47372954\n",
            " 0.54694229 0.55813953 0.45478036 0.38501292 0.42549526 0.45305771\n",
            " 0.4788975  0.59086994 0.60120586 0.45994832 0.68217054 0.2962963\n",
            " 0.49267873 0.6546081  0.52885444 0.48062016 0.50215332 0.48148148\n",
            " 0.62704565 0.5796727  0.58656331 0.52971576 0.62704565 0.46167097\n",
            " 0.56503015 0.37812231 0.44530577 0.53057709 0.43238587 0.42549526\n",
            " 0.57019811 0.59086994 0.45908699 0.48234281 0.60292851 0.50387597\n",
            " 0.63135228 0.65288544 0.51765719 0.49612403 0.60809647 0.4788975\n",
            " 0.51248923 0.60981912 0.55900086 0.46080965 0.47028424 0.44702842\n",
            " 0.45564169 0.62618432 0.49267873 0.45305771 0.55211025 0.49956934\n",
            " 0.4203273  0.58225668 0.49440138 0.4754522  0.44358312 0.39534884\n",
            " 0.50559862 0.65719208 0.45994832 0.53143842 0.39534884 0.51765719\n",
            " 0.59000861 0.44186047 0.47459087 0.69336779 0.54091301 0.63996555\n",
            " 0.5503876  0.63393626 0.4754522  0.4461671  0.46080965 0.33936262\n",
            " 0.59259259 0.34453058 0.54091301 0.52627046 0.39276486 0.60809647\n",
            " 0.40310078 0.59086994 0.48062016 0.56158484 0.48492679 0.68819983\n",
            " 0.56158484 0.44702842 0.51765719 0.51076658 0.4918174  0.45219638\n",
            " 0.56589147 0.46511628 0.53402239 0.51076658 0.53057709 0.66925065\n",
            " 0.6124031  0.43583118 0.60378984 0.55813953 0.52196382 0.5503876\n",
            " 0.56244617 0.46942291 0.44272179 0.44358312 0.45822567 0.70456503\n",
            " 0.40482343 0.60206718 0.5960379  0.45564169 0.44875108 0.60292851\n",
            " 0.70542636 0.60120586 0.46942291 0.53402239 0.69422911 0.61670973\n",
            " 0.54005168 0.36175711 0.60551249 0.53143842 0.32988803 0.58570198\n",
            " 0.45822567 0.43238587 0.52885444 0.45908699 0.57881137 0.6124031\n",
            " 0.35745047 0.51851852 0.51248923 0.36434109 0.54952627 0.58828596\n",
            " 0.49095607 0.37812231 0.54263566 0.63738157 0.4332472  0.5211025\n",
            " 0.57881137 0.54694229 0.57278208 0.50387597 0.4203273  0.48406546\n",
            " 0.46425495 0.44702842 0.63479759 0.68475452 0.65891473 0.64513351\n",
            " 0.44444444 0.45219638 0.63738157 0.46856158 0.68647717 0.57536606\n",
            " 0.38673557 0.47200689 0.46080965 0.58914729 0.2213609  0.56503015\n",
            " 0.55986219 0.49870801 0.40826873 0.53143842 0.48148148 0.63049096\n",
            " 0.60034453 0.49095607 0.53402239 0.5796727  0.44530577 0.54091301\n",
            " 0.43238587 0.56847545 0.54521964 0.60637382 0.52282515 0.66322136\n",
            " 0.55900086 0.41429802 0.40137812 0.38070629 0.37812231 0.58397933\n",
            " 0.43669251 0.46597761 0.46511628 0.53660637 0.31955211 0.56416882\n",
            " 0.44702842 0.61929371 0.50559862 0.50301464 0.57622739 0.70887166\n",
            " 0.64857881 0.64857881 0.58914729 0.62962963 0.5538329  0.66494401\n",
            " 0.52282515 0.47286822 0.5374677  0.56847545 0.66666667 0.31093885\n",
            " 0.46080965 0.42204996 0.45133506 0.69681309 0.50559862 0.54866494\n",
            " 0.56158484 0.63565891 0.46770026 0.41085271 0.58484065 0.53229974\n",
            " 0.43496985 0.40568475 0.44702842 0.38845823 0.51248923 0.38845823\n",
            " 0.51937984 0.70198105 0.54521964 0.43238587 0.57622739 0.32816537\n",
            " 0.51593454 0.53919035 0.68044789 0.39879414 0.53919035 0.66322136\n",
            " 0.41515935 0.26098191 0.53832903 0.56761413 0.46597761 0.57450474\n",
            " 0.57450474 0.63910422 0.41171404 0.43496985 0.6287683  0.47114556\n",
            " 0.61068045 0.5047373  0.40654608 0.44444444 0.65374677 0.47717485\n",
            " 0.54866494 0.50301464 0.57192076 0.5538329  0.52368648 0.53229974\n",
            " 0.50732127 0.45047373 0.50732127 0.60206718 0.45478036 0.45564169\n",
            " 0.4952627  0.60637382 0.48664944 0.52627046 0.54780362 0.59689922\n",
            " 0.42894057 0.41343669 0.38845823 0.59086994 0.50559862 0.53488372\n",
            " 0.51248923 0.59689922 0.50129199 0.58053402 0.46511628 0.51851852\n",
            " 0.61929371 0.51507321 0.48148148 0.4039621  0.60206718 0.46683893\n",
            " 0.49440138 0.54521964 0.58742463 0.48234281 0.50645995 0.45994832\n",
            " 0.47803618 0.3453919  0.62962963 0.4203273  0.54866494 0.55124892\n",
            " 0.62790698 0.53316107 0.62273902 0.47803618 0.61929371 0.33763997\n",
            " 0.46597761 0.60292851 0.42894057 0.52196382 0.49009475 0.50301464\n",
            " 0.51162791 0.54694229 0.46511628 0.5538329  0.45822567 0.6416882\n",
            " 0.53402239 0.48923342 0.48492679 0.33505599 0.48406546 0.55555556\n",
            " 0.5047373  0.38587425 0.4625323  0.58570198 0.55124892 0.60465116\n",
            " 0.48148148 0.44702842 0.5667528  0.41860465 0.42807924 0.50990525\n",
            " 0.58225668 0.52282515 0.41257537 0.63824289 0.43669251 0.45564169\n",
            " 0.71576227 0.64427218 0.43152455 0.50387597 0.63996555 0.60034453\n",
            " 0.4754522  0.47372954 0.5667528  0.51851852 0.52540913 0.44530577\n",
            " 0.57708872 0.60723514 0.51421189 0.4039621  0.4918174  0.48923342\n",
            " 0.50732127 0.5047373  0.44530577 0.36778639 0.55986219 0.5667528\n",
            " 0.56761413 0.42291128 0.43927649 0.42635659 0.51248923 0.47975883\n",
            " 0.66063738 0.52627046 0.46770026 0.6416882  0.5667528  0.49009475\n",
            " 0.51507321 0.59173127 0.54177433 0.54435831 0.57795004 0.54177433\n",
            " 0.53660637 0.60120586 0.44702842 0.54435831 0.58742463 0.45478036\n",
            " 0.583118   0.54091301 0.42980189 0.53229974 0.67011197 0.40482343\n",
            " 0.65374677 0.59000861 0.58139535 0.83893196 0.51335056 0.54349699\n",
            " 0.52713178 0.53919035 0.59345392 0.44788975 0.52540913 0.51851852\n",
            " 0.34969854 0.49009475 0.54866494 0.53402239 0.33936262 0.45564169\n",
            " 0.49440138 0.47200689 0.51421189 0.4952627  0.53143842 0.55900086\n",
            " 0.42635659 0.58656331 0.52024117 0.57364341 0.59173127 0.56330749\n",
            " 0.39362618 0.46511628 0.40999139 0.38845823 0.47114556 0.4918174\n",
            " 0.53229974 0.51679587 0.52713178 0.58484065 0.45908699 0.38587425\n",
            " 0.60034453 0.49612403 0.44358312 0.44272179 0.53660637 0.49440138\n",
            " 0.40654608 0.5211025  0.46167097 0.56847545 0.3910422  0.5667528\n",
            " 0.60637382 0.49095607 0.52971576 0.54608096 0.42807924 0.49440138\n",
            " 0.70111972 0.7329888  0.39276486 0.43755383 0.48923342 0.48320413\n",
            " 0.34625323 0.61498708 0.40913006 0.4625323  0.49784668 0.50129199\n",
            " 0.63824289 0.5211025  0.5211025  0.57536606 0.53832903 0.47459087\n",
            " 0.64685616]\n",
            "The trained model has an aproximate error rate of -3.0212278548635405 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although no linear relationship was uncovered, it can be argued there is a relationship present due to the RMSE value which is lower than the mean value. This relationship is also shown in the error rate which is comparative to the other models produced."
      ],
      "metadata": {
        "id": "rYGXd0opI-i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gust\n",
        "As with sea level pressure, no linear relationship between the maximum gust and the number of collisions was uncovered."
      ],
      "metadata": {
        "id": "lHX1HoDlQwJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data\n",
        "df_gust_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/gust_clean_dnn.csv', index_col=0, )\n",
        "print(df_gust_dnn[:6])"
      ],
      "metadata": {
        "id": "Tf_wMIWXQ7zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6990a270-ce5b-4279-a2fc-da8ab9b3c14d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd  gust  \\\n",
            "3   2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0  20.0   \n",
            "11  2020  15             508  43.9  38.3  1019.4    8.2   5.4   14.0  15.0   \n",
            "12  2021   1             257  39.6  29.3  1029.3   10.0   7.6   14.0  20.0   \n",
            "14  2022  25             235  41.6  31.8  1013.2   10.0   9.6   15.0  19.0   \n",
            "18  2021   3             186  41.1  32.3  1018.0   10.0  10.3   19.0  27.0   \n",
            "19  2020   2             413  39.6  28.9  1011.8   10.0  13.0   19.0  26.0   \n",
            "\n",
            "    ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "3   ...    0    0    0    0    0    0    0    1    0    0  \n",
            "11  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "12  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "14  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "18  ...    0    0    0    0    0    1    0    0    0    0  \n",
            "19  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_gust_dnn = df_gust_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','mxpsd','slp','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_gust_dnn = df_gust_dnn.loc[df_gust_dnn[\"year\"] != 2012]\n",
        "df_gust_dnn = df_gust_dnn.loc[df_gust_dnn[\"year\"] < 2020]\n",
        "#Move target col to end\n",
        "cols = df_gust_dnn['NUM_COLLISIONS']\n",
        "df_gust_dnn = df_gust_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_gust_dnn.insert(loc=21, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_gust_dnn[:6])\n",
        "df_gust_dnn.describe()"
      ],
      "metadata": {
        "id": "oTbpzolhQ7zh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "59378154-74f0-460f-d22c-f0a0cfc47ec5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  gust  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "74  2016  17  18.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "76  2014   9  20.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "79  2019  19  21.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "80  2015  11  17.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "83  2015  29  20.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "85  2019  13  15.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "74    0    1    0    0    0    0             451  \n",
            "76    0    0    0    0    0    1             561  \n",
            "79    0    0    0    0    0    0             479  \n",
            "80    0    1    0    0    0    0             341  \n",
            "83    0    0    0    0    0    1             519  \n",
            "85    0    1    0    0    0    0             374  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             year           da         gust          Apr          Aug  \\\n",
              "count  1629.00000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean   2015.91283    15.702885    27.511602     0.095764     0.042357   \n",
              "std       2.01341     8.667634     7.366770     0.294358     0.201465   \n",
              "min    2013.00000     1.000000    14.000000     0.000000     0.000000   \n",
              "25%    2014.00000     8.000000    22.000000     0.000000     0.000000   \n",
              "50%    2016.00000    16.000000    26.000000     0.000000     0.000000   \n",
              "75%    2018.00000    23.000000    31.100000     0.000000     0.000000   \n",
              "max    2019.00000    31.000000    71.100000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000  ...   \n",
              "mean      0.104359     0.095150     0.108656     0.046041     0.061387  ...   \n",
              "std       0.305819     0.293513     0.311302     0.209637     0.240113  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Nov          Oct          Sep          Mon          Sat  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean      0.096378     0.087784     0.071209     0.139963     0.141191   \n",
              "std       0.295200     0.283067     0.257253     0.347055     0.348325   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000     1629.000000  \n",
              "mean      0.139963     0.151627     0.138122     0.145488      596.513198  \n",
              "std       0.347055     0.358769     0.345133     0.352700      104.479660  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      526.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      597.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      663.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f177ea9-5d1a-4d10-864e-578bb70be610\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>gust</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1629.00000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.91283</td>\n",
              "      <td>15.702885</td>\n",
              "      <td>27.511602</td>\n",
              "      <td>0.095764</td>\n",
              "      <td>0.042357</td>\n",
              "      <td>0.104359</td>\n",
              "      <td>0.095150</td>\n",
              "      <td>0.108656</td>\n",
              "      <td>0.046041</td>\n",
              "      <td>0.061387</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096378</td>\n",
              "      <td>0.087784</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.151627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>596.513198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.01341</td>\n",
              "      <td>8.667634</td>\n",
              "      <td>7.366770</td>\n",
              "      <td>0.294358</td>\n",
              "      <td>0.201465</td>\n",
              "      <td>0.305819</td>\n",
              "      <td>0.293513</td>\n",
              "      <td>0.311302</td>\n",
              "      <td>0.209637</td>\n",
              "      <td>0.240113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295200</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.257253</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.348325</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.358769</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>104.479660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>526.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>597.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.00000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>663.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.00000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f177ea9-5d1a-4d10-864e-578bb70be610')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f177ea9-5d1a-4d10-864e-578bb70be610 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f177ea9-5d1a-4d10-864e-578bb70be610');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "shuffle = df_gust_dnn.iloc[np.random.permutation(len(df_gust_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "a_4bidEbQ7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc67f10-6af6-4741-b793-ec457e567499"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  gust  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  May  Nov  Oct  \\\n",
            "106   2017  29  22.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "3631  2016  17  32.1    0    0    1    0    0    0    0  ...    0    0    0   \n",
            "795   2015  14  28.0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "1436  2019   8  22.0    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "1110  2019  21  28.0    1    0    0    0    0    0    0  ...    0    0    0   \n",
            "1129  2017   8  28.9    1    0    0    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "106     0    0    1    0    0    0    0  \n",
            "3631    0    0    0    0    0    0    0  \n",
            "795     0    0    0    0    0    0    0  \n",
            "1436    0    0    0    0    0    1    0  \n",
            "1110    0    0    1    0    0    0    0  \n",
            "1129    0    0    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select last col as a target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "l4TDr10XQ7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3a9c5c-9414-46f5-ded6-811d5c459340"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106     428\n",
            "3631    623\n",
            "795     507\n",
            "1436    649\n",
            "1110    398\n",
            "1129    627\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "75AKCrz7Q7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6176e6e2-b9b0-49e8-e370-7cf5530d73a4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_gust', ignore_errors=True)\n",
        "\n",
        "#Setup model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_gust', hidden_units=[23,19,11], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "v4av8KXMQ7zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3902d5c5-ee70-4f87-9899-0895f16e1ed1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69857ab410>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_gust', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_gust/model.ckpt.\n",
            "INFO:tensorflow:loss = 80768.34, step = 1\n",
            "INFO:tensorflow:global_step/sec: 462.411\n",
            "INFO:tensorflow:loss = 0.14845058, step = 101 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.979\n",
            "INFO:tensorflow:loss = 0.013256403, step = 201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.743\n",
            "INFO:tensorflow:loss = 0.010560701, step = 301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.141\n",
            "INFO:tensorflow:loss = 0.011680349, step = 401 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.015\n",
            "INFO:tensorflow:loss = 0.011477644, step = 501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.758\n",
            "INFO:tensorflow:loss = 0.009742392, step = 601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.415\n",
            "INFO:tensorflow:loss = 0.012344847, step = 701 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.501\n",
            "INFO:tensorflow:loss = 0.011326384, step = 801 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.303\n",
            "INFO:tensorflow:loss = 0.010977415, step = 901 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 598.933\n",
            "INFO:tensorflow:loss = 0.01097892, step = 1001 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.365\n",
            "INFO:tensorflow:loss = 0.013371682, step = 1101 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.716\n",
            "INFO:tensorflow:loss = 0.010961301, step = 1201 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.918\n",
            "INFO:tensorflow:loss = 0.0121825, step = 1301 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.304\n",
            "INFO:tensorflow:loss = 0.011841167, step = 1401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.621\n",
            "INFO:tensorflow:loss = 0.011930962, step = 1501 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.545\n",
            "INFO:tensorflow:loss = 0.011435971, step = 1601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.535\n",
            "INFO:tensorflow:loss = 0.015132578, step = 1701 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.783\n",
            "INFO:tensorflow:loss = 0.013821645, step = 1801 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.546\n",
            "INFO:tensorflow:loss = 0.011896125, step = 1901 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.483\n",
            "INFO:tensorflow:loss = 0.010136688, step = 2001 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.159\n",
            "INFO:tensorflow:loss = 0.025185255, step = 2101 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.642\n",
            "INFO:tensorflow:loss = 0.011553546, step = 2201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.268\n",
            "INFO:tensorflow:loss = 0.008718792, step = 2301 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.158\n",
            "INFO:tensorflow:loss = 0.012085124, step = 2401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.036\n",
            "INFO:tensorflow:loss = 0.011211732, step = 2501 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.764\n",
            "INFO:tensorflow:loss = 0.010221833, step = 2601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.577\n",
            "INFO:tensorflow:loss = 0.012151783, step = 2701 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.555\n",
            "INFO:tensorflow:loss = 0.009521419, step = 2801 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.303\n",
            "INFO:tensorflow:loss = 0.009983805, step = 2901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.013\n",
            "INFO:tensorflow:loss = 0.009989971, step = 3001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.309\n",
            "INFO:tensorflow:loss = 0.012453659, step = 3101 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.127\n",
            "INFO:tensorflow:loss = 0.00917103, step = 3201 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.146\n",
            "INFO:tensorflow:loss = 0.0119279865, step = 3301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.698\n",
            "INFO:tensorflow:loss = 0.013358465, step = 3401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.435\n",
            "INFO:tensorflow:loss = 0.011262799, step = 3501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.512\n",
            "INFO:tensorflow:loss = 0.01304538, step = 3601 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.53\n",
            "INFO:tensorflow:loss = 0.014085329, step = 3701 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.349\n",
            "INFO:tensorflow:loss = 0.009322668, step = 3801 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.494\n",
            "INFO:tensorflow:loss = 0.0076435143, step = 3901 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.815\n",
            "INFO:tensorflow:loss = 0.011489248, step = 4001 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.837\n",
            "INFO:tensorflow:loss = 0.011212563, step = 4101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 598.26\n",
            "INFO:tensorflow:loss = 0.0131738745, step = 4201 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.732\n",
            "INFO:tensorflow:loss = 0.0071588964, step = 4301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.3\n",
            "INFO:tensorflow:loss = 0.011124368, step = 4401 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.718\n",
            "INFO:tensorflow:loss = 0.011989281, step = 4501 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.654\n",
            "INFO:tensorflow:loss = 0.0095483, step = 4601 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.541\n",
            "INFO:tensorflow:loss = 0.010951068, step = 4701 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.402\n",
            "INFO:tensorflow:loss = 0.012041777, step = 4801 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.12\n",
            "INFO:tensorflow:loss = 0.010769568, step = 4901 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.114\n",
            "INFO:tensorflow:loss = 0.009557059, step = 5001 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.373\n",
            "INFO:tensorflow:loss = 0.0106976945, step = 5101 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.195\n",
            "INFO:tensorflow:loss = 0.0067817066, step = 5201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.166\n",
            "INFO:tensorflow:loss = 0.009718088, step = 5301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.132\n",
            "INFO:tensorflow:loss = 0.0070850123, step = 5401 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.147\n",
            "INFO:tensorflow:loss = 0.011531153, step = 5501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.173\n",
            "INFO:tensorflow:loss = 0.014164686, step = 5601 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.159\n",
            "INFO:tensorflow:loss = 0.012992175, step = 5701 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.286\n",
            "INFO:tensorflow:loss = 0.012967651, step = 5801 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.603\n",
            "INFO:tensorflow:loss = 0.009239786, step = 5901 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.898\n",
            "INFO:tensorflow:loss = 0.009419093, step = 6001 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.7\n",
            "INFO:tensorflow:loss = 0.009163123, step = 6101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.232\n",
            "INFO:tensorflow:loss = 0.012290778, step = 6201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.219\n",
            "INFO:tensorflow:loss = 0.007820251, step = 6301 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.071\n",
            "INFO:tensorflow:loss = 0.010394617, step = 6401 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.974\n",
            "INFO:tensorflow:loss = 0.0049357517, step = 6501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.294\n",
            "INFO:tensorflow:loss = 0.010505224, step = 6601 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.428\n",
            "INFO:tensorflow:loss = 0.011013864, step = 6701 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.683\n",
            "INFO:tensorflow:loss = 0.009543528, step = 6801 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.8\n",
            "INFO:tensorflow:loss = 0.008085152, step = 6901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.185\n",
            "INFO:tensorflow:loss = 0.010180879, step = 7001 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.969\n",
            "INFO:tensorflow:loss = 0.010225211, step = 7101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.494\n",
            "INFO:tensorflow:loss = 0.010032302, step = 7201 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.079\n",
            "INFO:tensorflow:loss = 0.011484802, step = 7301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.018\n",
            "INFO:tensorflow:loss = 0.0083662355, step = 7401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.337\n",
            "INFO:tensorflow:loss = 0.013222782, step = 7501 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.536\n",
            "INFO:tensorflow:loss = 0.0066402466, step = 7601 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.628\n",
            "INFO:tensorflow:loss = 0.011982547, step = 7701 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.648\n",
            "INFO:tensorflow:loss = 0.008988941, step = 7801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.938\n",
            "INFO:tensorflow:loss = 0.009743037, step = 7901 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.321\n",
            "INFO:tensorflow:loss = 0.007896513, step = 8001 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.183\n",
            "INFO:tensorflow:loss = 0.0064293593, step = 8101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.498\n",
            "INFO:tensorflow:loss = 0.008437246, step = 8201 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.835\n",
            "INFO:tensorflow:loss = 0.007980317, step = 8301 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.095\n",
            "INFO:tensorflow:loss = 0.0070666173, step = 8401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.348\n",
            "INFO:tensorflow:loss = 0.008066744, step = 8501 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.028\n",
            "INFO:tensorflow:loss = 0.007473968, step = 8601 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.261\n",
            "INFO:tensorflow:loss = 0.0050972207, step = 8701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.982\n",
            "INFO:tensorflow:loss = 0.0074066008, step = 8801 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.884\n",
            "INFO:tensorflow:loss = 0.0070953676, step = 8901 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.678\n",
            "INFO:tensorflow:loss = 0.005555786, step = 9001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.779\n",
            "INFO:tensorflow:loss = 0.007072972, step = 9101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.611\n",
            "INFO:tensorflow:loss = 0.007780399, step = 9201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.614\n",
            "INFO:tensorflow:loss = 0.008587238, step = 9301 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.221\n",
            "INFO:tensorflow:loss = 0.011361698, step = 9401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.68\n",
            "INFO:tensorflow:loss = 0.0066426145, step = 9501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.81\n",
            "INFO:tensorflow:loss = 0.006233334, step = 9601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.629\n",
            "INFO:tensorflow:loss = 0.007824311, step = 9701 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.04\n",
            "INFO:tensorflow:loss = 0.0108188875, step = 9801 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.062\n",
            "INFO:tensorflow:loss = 0.007377206, step = 9901 (0.155 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_gust/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.009556636.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_gust/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 91.9706605886673\n",
            "Just using average = 596.3514965464313 has RMSE of 103.55154233421264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_gust', hidden_units=[23,19,11], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NdhxllohQ7zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085e629e-bcbd-4ac4-80fd-164056558751"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6988f14110>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_gust', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326\n",
            "326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_gust/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5070013  0.5516282  0.54840076 0.48284504 0.5207979  0.4892027\n",
            " 0.5289301  0.45238695 0.5339557  0.54814994 0.5378042  0.5288331\n",
            " 0.4753481  0.5448718  0.5343888  0.48902097 0.5220012  0.476482\n",
            " 0.5201158  0.5258397  0.5349783  0.52133596 0.53429604 0.44876382\n",
            " 0.49566755 0.517786   0.5320708  0.5278579  0.4761928  0.48006633\n",
            " 0.48181656 0.5433951  0.47660324 0.4932333  0.48243734 0.52154386\n",
            " 0.5300238  0.504466   0.5196644  0.47444794 0.44301754 0.4863446\n",
            " 0.5309394  0.4940553  0.52281845 0.5372747  0.519419   0.50254434\n",
            " 0.51200944 0.5301151  0.49654493 0.48933753 0.50977385 0.4938307\n",
            " 0.47847065 0.518213   0.51581264 0.5212314  0.4857166  0.54374003\n",
            " 0.472257   0.4842331  0.47952327 0.526529   0.48776135 0.54902506\n",
            " 0.48996368 0.5085628  0.52305144 0.47757563 0.4970931  0.54709417\n",
            " 0.5188292  0.489786   0.5137935  0.5151523  0.5020509  0.5507229\n",
            " 0.487788   0.54538196 0.5262925  0.52487224 0.5264717  0.45700836\n",
            " 0.52436674 0.49740377 0.48234782 0.5311031  0.4758903  0.5149297\n",
            " 0.51279444 0.51248676 0.52641076 0.4549394  0.48112378 0.52324367\n",
            " 0.48228237 0.49624214 0.5229265  0.53502315 0.48422024 0.5243246\n",
            " 0.4472281  0.52224255 0.48698553 0.52297217 0.44162837 0.54524076\n",
            " 0.47857442 0.528726   0.51167285 0.48798874 0.44242957 0.530982\n",
            " 0.46888387 0.5144181  0.5091799  0.44463727 0.45898682 0.41913074\n",
            " 0.52477074 0.5198531  0.52934164 0.50219476 0.49116978 0.50079745\n",
            " 0.5210905  0.45514894 0.4929509  0.48355362 0.5257903  0.5330666\n",
            " 0.42654696 0.5214811  0.49548844 0.4917681  0.48755965 0.4641685\n",
            " 0.48529533 0.47246686 0.5438556  0.48889318 0.5266468  0.51628625\n",
            " 0.4955435  0.47677425 0.50094634 0.4817808  0.4583656  0.52234787\n",
            " 0.5514042  0.51948595 0.42122114 0.452941   0.48220834 0.5241869\n",
            " 0.5337019  0.5271097  0.48392448 0.5557777  0.5558502  0.5503913\n",
            " 0.5005646  0.5302272  0.54431266 0.5259004  0.45483893 0.49876425\n",
            " 0.5425806  0.47811905 0.5324443  0.5188058  0.4578145  0.4831381\n",
            " 0.49552533 0.5218138  0.48791376 0.52255255 0.5302794  0.51136345\n",
            " 0.5217989  0.5048288  0.5228189  0.44872472 0.4450392  0.5200201\n",
            " 0.4911931  0.46702608 0.49036905 0.4711825  0.5176772  0.5206467\n",
            " 0.48410925 0.51276416 0.49093083 0.5348597  0.5059401  0.5245458\n",
            " 0.47160545 0.52344924 0.49882486 0.48858264 0.50564575 0.48697838\n",
            " 0.52604127 0.5230575  0.49477133 0.50570256 0.5206065  0.52183384\n",
            " 0.4865776  0.47881857 0.5250675  0.48276767 0.43928027 0.4852647\n",
            " 0.5247385  0.53808534 0.4959207  0.52804273 0.50329554 0.51628923\n",
            " 0.52535105 0.52998227 0.44312727 0.53165865 0.4872106  0.5582667\n",
            " 0.4764749  0.50793093 0.49583563 0.5146622  0.49901822 0.52091575\n",
            " 0.48673722 0.55534786 0.51549846 0.53894544 0.52195334 0.54604924\n",
            " 0.51733404 0.48397037 0.524117   0.44233966 0.50816494 0.5472639\n",
            " 0.54179204 0.49515256 0.52263397 0.44361094 0.5268451  0.53011256\n",
            " 0.48913446 0.48318312 0.4888052  0.50046545 0.52370363 0.4606308\n",
            " 0.5173593  0.53386194 0.5354696  0.52250177 0.5126593  0.5343817\n",
            " 0.4925702  0.5179169  0.49456152 0.47490665 0.5113637  0.4426383\n",
            " 0.44255912 0.52361333 0.44943768 0.5055663  0.5234811  0.5005263\n",
            " 0.5177565  0.49929574 0.5142283  0.54239225 0.4963474  0.51245266\n",
            " 0.5076451  0.543907   0.4478502  0.52831095 0.49919322 0.47205654\n",
            " 0.49563387 0.52904063 0.50887144 0.52216256 0.5202837  0.5338487\n",
            " 0.5207023  0.509863   0.5004719  0.47058246 0.51847893 0.48672494\n",
            " 0.51895076 0.5150579  0.50698864 0.48106083 0.5206973  0.5206472\n",
            " 0.5169143  0.504254   0.47447345 0.5314924  0.5082546  0.55133235\n",
            " 0.50523657 0.53137153 0.46526107 0.51161826 0.5247899  0.52419984\n",
            " 0.54584795 0.50523007 0.54329246 0.5103214  0.53535056 0.49772397\n",
            " 0.46923563 0.48703334]\n",
            "[0.60292851 0.6287683  0.50387597 0.39793282 0.51421189 0.62187769\n",
            " 0.53919035 0.43496985 0.60809647 0.6873385  0.59862188 0.53574505\n",
            " 0.38242894 0.58053402 0.60034453 0.52799311 0.60034453 0.41515935\n",
            " 0.45478036 0.53660637 0.47631352 0.44702842 0.47028424 0.41774332\n",
            " 0.48751077 0.74677003 0.46942291 0.46339363 0.49267873 0.51507321\n",
            " 0.41429802 0.60292851 0.38501292 0.54091301 0.54952627 0.48923342\n",
            " 0.50990525 0.56158484 0.69853575 0.52971576 0.48923342 0.416882\n",
            " 0.64685616 0.33505599 0.60809647 0.4952627  0.4918174  0.4918174\n",
            " 0.43669251 0.45564169 0.51335056 0.51765719 0.62790698 0.28682171\n",
            " 0.4461671  0.63393626 0.55211025 0.52024117 0.45650301 0.53057709\n",
            " 0.34625323 0.53057709 0.3712317  0.53057709 0.56330749 0.49612403\n",
            " 0.61412575 0.36950904 0.59345392 0.40654608 0.39276486 0.55211025\n",
            " 0.6089578  0.59173127 0.46339363 0.40826873 0.51421189 0.5667528\n",
            " 0.52368648 0.66063738 0.4918174  0.47459087 0.60378984 0.374677\n",
            " 0.5211025  0.4203273  0.45391904 0.59689922 0.57019811 0.54952627\n",
            " 0.68044789 0.52713178 0.42463394 0.29371232 0.45822567 0.46167097\n",
            " 0.47717485 0.45650301 0.48837209 0.45305771 0.43152455 0.51937984\n",
            " 0.44530577 0.42291128 0.41171404 0.56244617 0.44272179 0.58570198\n",
            " 0.48492679 0.51937984 0.41860465 0.5667528  0.416882   0.6873385\n",
            " 0.57708872 0.35486649 0.63135228 0.34022394 0.4005168  0.38501292\n",
            " 0.46339363 0.51765719 0.49956934 0.54780362 0.44530577 0.5081826\n",
            " 0.91731266 0.45994832 0.45219638 0.54349699 0.56416882 0.51076658\n",
            " 0.50387597 0.5374677  0.64685616 0.54091301 0.45736434 0.39190353\n",
            " 0.43410853 0.50990525 0.63996555 0.47114556 0.58914729 0.61843239\n",
            " 0.50043066 0.37984496 0.58139535 0.52885444 0.34797588 0.60809647\n",
            " 0.66063738 0.59259259 0.44530577 0.33850129 0.56158484 0.53574505\n",
            " 0.54608096 0.54521964 0.47286822 0.5796727  0.53488372 0.40999139\n",
            " 0.5994832  0.61498708 0.52713178 0.52885444 0.35745047 0.49956934\n",
            " 0.59259259 0.44186047 0.62704565 0.55727821 0.36692506 0.45478036\n",
            " 0.44272179 0.47975883 0.56589147 0.51421189 0.45736434 0.45219638\n",
            " 0.55641688 0.63910422 0.52971576 0.38329027 0.46597761 0.54952627\n",
            " 0.47114556 0.34625323 0.52799311 0.41774332 0.49267873 0.57450474\n",
            " 0.46511628 0.56761413 0.4496124  0.49698536 0.56244617 0.68475452\n",
            " 0.4332472  0.47372954 0.44702842 0.48664944 0.43238587 0.50990525\n",
            " 0.54694229 0.64082687 0.46511628 0.66063738 0.64857881 0.51076658\n",
            " 0.51248923 0.55124892 0.52627046 0.63824289 0.42635659 0.42894057\n",
            " 0.64857881 0.59345392 0.37898363 0.65719208 0.54177433 0.47631352\n",
            " 0.53057709 0.5211025  0.45822567 0.44702842 0.42204996 0.63738157\n",
            " 0.43238587 0.48492679 0.41085271 0.49870801 0.41429802 0.50387597\n",
            " 0.57364341 0.46597761 0.59431525 0.56589147 0.52713178 0.68130922\n",
            " 0.66149871 0.44444444 0.47286822 0.44702842 0.43410853 0.55727821\n",
            " 0.66322136 0.52540913 0.44444444 0.44875108 0.43496985 0.60292851\n",
            " 0.45650301 0.49009475 0.4005168  0.45219638 0.56503015 0.48492679\n",
            " 0.5503876  0.47803618 0.53229974 0.56330749 0.54608096 0.51162791\n",
            " 0.43669251 0.48234281 0.45736434 0.42721792 0.48923342 0.42204996\n",
            " 0.40482343 0.4005168  0.38329027 0.44186047 0.47717485 0.46425495\n",
            " 0.52799311 0.52282515 0.60637382 0.7037037  0.44875108 0.67011197\n",
            " 0.4918174  0.69336779 0.40310078 0.54091301 0.82687339 0.48578811\n",
            " 0.54435831 0.60378984 0.583118   0.58139535 0.59000861 0.62446167\n",
            " 0.52885444 0.63910422 0.4788975  0.50387597 0.55641688 0.49870801\n",
            " 0.57278208 0.71748493 0.51593454 0.45564169 0.5211025  0.63824289\n",
            " 0.44099914 0.52971576 0.47975883 0.64082687 0.55900086 0.61326443\n",
            " 0.54091301 0.58139535 0.4918174  0.46425495 0.6089578  0.53488372\n",
            " 0.68303187 0.49440138 0.66236003 0.53229974 0.31007752 0.47372954\n",
            " 0.44358312 0.57622739]\n",
            "The trained model has an aproximate error rate of 10.634377890203629 which equates to 2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model shows there is no relationship between gust and the number of collisions.\n",
        "\n",
        "The RMSE value is over 4 times the mean value indicating the model is unable to make accurate predictions. This is also reflected in the very high error rate."
      ],
      "metadata": {
        "id": "iCLt9ZygKrGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Maximum Sustained Wind Speed (mxpsd)\n",
        "In an attempt to predict the number of collisions given the maximum sustained wind speed a DNN will be used as no linear relationship was uncovered within assignment 1."
      ],
      "metadata": {
        "id": "tKaVpVT8T55I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "df_mxpsd_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/mxpsd_clean_dnn.csv', index_col=0, )\n",
        "print(df_mxpsd_dnn[:6])"
      ],
      "metadata": {
        "id": "_LbHDT1WUbJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7afaf7f-3f00-4929-e28e-f931745d5e8c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the cols not required\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','gust','slp','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.loc[df_mxpsd_dnn[\"year\"] != 2012]\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.loc[df_mxpsd_dnn[\"year\"] < 2020]\n",
        "#Move the target to the end\n",
        "cols = df_mxpsd_dnn['NUM_COLLISIONS']\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_mxpsd_dnn.insert(loc=21, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_mxpsd_dnn[:6])\n",
        "df_mxpsd_dnn.describe()"
      ],
      "metadata": {
        "id": "OoJSkkKHUbJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "eb2ea6dc-fb6b-4d8b-b00d-0f5f3212d457"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  mxpsd  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "49  2016  28    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da        mxpsd          Apr          Aug  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
              "mean   2016.001567    15.737172    17.240110     0.082256     0.084998   \n",
              "std       2.000587     8.797367     5.858333     0.274808     0.278933   \n",
              "min    2013.000000     1.000000     5.100000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000    13.000000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000    15.900000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000    20.000000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000    49.000000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000  ...   \n",
              "mean      0.084998     0.077164     0.084998     0.084998     0.082256  ...   \n",
              "std       0.278933     0.266904     0.278933     0.278933     0.274808  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Nov          Oct          Sep          Mon          Sat  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
              "mean      0.081864     0.084998     0.081473     0.143361     0.142969   \n",
              "std       0.274212     0.278933     0.273613     0.350509     0.350110   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000     2553.000000  \n",
              "mean      0.142969     0.142969     0.142577     0.142186      599.033686  \n",
              "std       0.350110     0.350110     0.349710     0.349309      100.284761  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c91f58db-456d-4b94-8389-2ccccd04b072\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.001567</td>\n",
              "      <td>15.737172</td>\n",
              "      <td>17.240110</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.077164</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>...</td>\n",
              "      <td>0.081864</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.081473</td>\n",
              "      <td>0.143361</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142577</td>\n",
              "      <td>0.142186</td>\n",
              "      <td>599.033686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000587</td>\n",
              "      <td>8.797367</td>\n",
              "      <td>5.858333</td>\n",
              "      <td>0.274808</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.266904</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.274808</td>\n",
              "      <td>...</td>\n",
              "      <td>0.274212</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.273613</td>\n",
              "      <td>0.350509</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.349710</td>\n",
              "      <td>0.349309</td>\n",
              "      <td>100.284761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c91f58db-456d-4b94-8389-2ccccd04b072')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c91f58db-456d-4b94-8389-2ccccd04b072 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c91f58db-456d-4b94-8389-2ccccd04b072');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the data\n",
        "shuffle = df_mxpsd_dnn.iloc[np.random.permutation(len(df_mxpsd_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "z1Ut5LCiUbJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a7b52d-3a59-46b9-eb3d-368321e15a74"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  mxpsd  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  May  Nov  Oct  \\\n",
            "1116  2017  29   21.0    1    0    0    0    0    0    0  ...    0    0    0   \n",
            "187   2014  23   19.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "1407  2017  12   17.1    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "2282  2014  27   12.0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "2321  2017  18   13.0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "3359  2018  10   32.1    0    0    0    0    0    0    0  ...    0    1    0   \n",
            "\n",
            "      Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1116    0    0    0    0    0    0    0  \n",
            "187     0    0    0    0    0    0    1  \n",
            "1407    0    0    0    0    1    0    0  \n",
            "2282    0    0    0    0    0    1    0  \n",
            "2321    0    0    0    0    1    0    0  \n",
            "3359    0    0    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the target as the last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "QibQoUleUbJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6a42b7-8b40-450c-8a06-99889f3f5b3e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1116    661\n",
            "187     612\n",
            "1407    817\n",
            "2282    538\n",
            "2321    612\n",
            "3359    606\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "-C_tqkmUUbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9d2d9d-af65-48b3-be31-22bb8d1b78a6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_mxpsd', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[17,13,7], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "# Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "C3O7xWeMUbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10eb23b6-9eea-415a-e4ac-0520fc10ea86"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698b847e50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_mxpsd/model.ckpt.\n",
            "INFO:tensorflow:loss = 7281.42, step = 1\n",
            "INFO:tensorflow:global_step/sec: 470.374\n",
            "INFO:tensorflow:loss = 0.32891485, step = 101 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.899\n",
            "INFO:tensorflow:loss = 0.2024329, step = 201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.004\n",
            "INFO:tensorflow:loss = 0.09926839, step = 301 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.791\n",
            "INFO:tensorflow:loss = 0.16393805, step = 401 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.382\n",
            "INFO:tensorflow:loss = 0.14116764, step = 501 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.36\n",
            "INFO:tensorflow:loss = 0.13836263, step = 601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.732\n",
            "INFO:tensorflow:loss = 0.1368792, step = 701 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.152\n",
            "INFO:tensorflow:loss = 0.12653972, step = 801 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.236\n",
            "INFO:tensorflow:loss = 0.116124794, step = 901 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.843\n",
            "INFO:tensorflow:loss = 0.10579385, step = 1001 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.514\n",
            "INFO:tensorflow:loss = 0.07985973, step = 1101 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.708\n",
            "INFO:tensorflow:loss = 0.07688497, step = 1201 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.36\n",
            "INFO:tensorflow:loss = 0.08717409, step = 1301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.225\n",
            "INFO:tensorflow:loss = 0.075919256, step = 1401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.542\n",
            "INFO:tensorflow:loss = 0.057759292, step = 1501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.413\n",
            "INFO:tensorflow:loss = 0.04370399, step = 1601 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.391\n",
            "INFO:tensorflow:loss = 0.05783355, step = 1701 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.908\n",
            "INFO:tensorflow:loss = 0.050538994, step = 1801 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.065\n",
            "INFO:tensorflow:loss = 0.03700517, step = 1901 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.43\n",
            "INFO:tensorflow:loss = 0.040578134, step = 2001 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.523\n",
            "INFO:tensorflow:loss = 0.026292836, step = 2101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.741\n",
            "INFO:tensorflow:loss = 0.023655765, step = 2201 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.318\n",
            "INFO:tensorflow:loss = 0.02062385, step = 2301 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.601\n",
            "INFO:tensorflow:loss = 0.022107273, step = 2401 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.204\n",
            "INFO:tensorflow:loss = 0.021865554, step = 2501 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.798\n",
            "INFO:tensorflow:loss = 0.016258419, step = 2601 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.292\n",
            "INFO:tensorflow:loss = 0.017194727, step = 2701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.982\n",
            "INFO:tensorflow:loss = 0.014789077, step = 2801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.703\n",
            "INFO:tensorflow:loss = 0.013684278, step = 2901 (0.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.034\n",
            "INFO:tensorflow:loss = 0.013059581, step = 3001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.727\n",
            "INFO:tensorflow:loss = 0.011507006, step = 3101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.837\n",
            "INFO:tensorflow:loss = 0.0117543675, step = 3201 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.656\n",
            "INFO:tensorflow:loss = 0.008915719, step = 3301 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.659\n",
            "INFO:tensorflow:loss = 0.008579596, step = 3401 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.471\n",
            "INFO:tensorflow:loss = 0.0061581726, step = 3501 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.02\n",
            "INFO:tensorflow:loss = 0.0070652645, step = 3601 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.711\n",
            "INFO:tensorflow:loss = 0.007262112, step = 3701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.91\n",
            "INFO:tensorflow:loss = 0.007794056, step = 3801 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.063\n",
            "INFO:tensorflow:loss = 0.006006611, step = 3901 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.757\n",
            "INFO:tensorflow:loss = 0.0065242704, step = 4001 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.099\n",
            "INFO:tensorflow:loss = 0.0056087645, step = 4101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.843\n",
            "INFO:tensorflow:loss = 0.0057595326, step = 4201 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.698\n",
            "INFO:tensorflow:loss = 0.005761439, step = 4301 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.115\n",
            "INFO:tensorflow:loss = 0.0050848904, step = 4401 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.825\n",
            "INFO:tensorflow:loss = 0.005631431, step = 4501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.975\n",
            "INFO:tensorflow:loss = 0.004748445, step = 4601 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.016\n",
            "INFO:tensorflow:loss = 0.0047585582, step = 4701 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.091\n",
            "INFO:tensorflow:loss = 0.0085611865, step = 4801 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.226\n",
            "INFO:tensorflow:loss = 0.008824082, step = 4901 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.063\n",
            "INFO:tensorflow:loss = 0.0052316855, step = 5001 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.517\n",
            "INFO:tensorflow:loss = 0.004857464, step = 5101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.844\n",
            "INFO:tensorflow:loss = 0.005378098, step = 5201 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.929\n",
            "INFO:tensorflow:loss = 0.0055783945, step = 5301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.842\n",
            "INFO:tensorflow:loss = 0.0052810865, step = 5401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.604\n",
            "INFO:tensorflow:loss = 0.0073525007, step = 5501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.475\n",
            "INFO:tensorflow:loss = 0.008811884, step = 5601 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.549\n",
            "INFO:tensorflow:loss = 0.06971255, step = 5701 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.318\n",
            "INFO:tensorflow:loss = 0.018288277, step = 5801 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.4\n",
            "INFO:tensorflow:loss = 0.07250796, step = 5901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.466\n",
            "INFO:tensorflow:loss = 0.02589463, step = 6001 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.922\n",
            "INFO:tensorflow:loss = 0.01678037, step = 6101 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.352\n",
            "INFO:tensorflow:loss = 0.22447062, step = 6201 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.421\n",
            "INFO:tensorflow:loss = 0.10703646, step = 6301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.562\n",
            "INFO:tensorflow:loss = 0.026942924, step = 6401 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.997\n",
            "INFO:tensorflow:loss = 0.019585514, step = 6501 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.215\n",
            "INFO:tensorflow:loss = 0.038765877, step = 6601 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.577\n",
            "INFO:tensorflow:loss = 0.02272116, step = 6701 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.316\n",
            "INFO:tensorflow:loss = 0.004655405, step = 6801 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.526\n",
            "INFO:tensorflow:loss = 0.0048098457, step = 6901 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.654\n",
            "INFO:tensorflow:loss = 0.021382514, step = 7001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.43\n",
            "INFO:tensorflow:loss = 0.034671728, step = 7101 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.279\n",
            "INFO:tensorflow:loss = 0.0035794782, step = 7201 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.951\n",
            "INFO:tensorflow:loss = 0.25912935, step = 7301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.575\n",
            "INFO:tensorflow:loss = 0.040896166, step = 7401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.177\n",
            "INFO:tensorflow:loss = 0.053932913, step = 7501 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.629\n",
            "INFO:tensorflow:loss = 0.0983691, step = 7601 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.061\n",
            "INFO:tensorflow:loss = 0.17348833, step = 7701 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.876\n",
            "INFO:tensorflow:loss = 0.0062510837, step = 7801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.706\n",
            "INFO:tensorflow:loss = 0.050340895, step = 7901 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.996\n",
            "INFO:tensorflow:loss = 0.5322609, step = 8001 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.532\n",
            "INFO:tensorflow:loss = 0.006245707, step = 8101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.791\n",
            "INFO:tensorflow:loss = 0.047735527, step = 8201 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.535\n",
            "INFO:tensorflow:loss = 0.048962012, step = 8301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.048\n",
            "INFO:tensorflow:loss = 0.03267171, step = 8401 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.128\n",
            "INFO:tensorflow:loss = 0.0093777105, step = 8501 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.665\n",
            "INFO:tensorflow:loss = 0.04291606, step = 8601 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 598.742\n",
            "INFO:tensorflow:loss = 0.2364601, step = 8701 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.377\n",
            "INFO:tensorflow:loss = 0.034920607, step = 8801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 592.177\n",
            "INFO:tensorflow:loss = 0.21941192, step = 8901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.827\n",
            "INFO:tensorflow:loss = 0.007306693, step = 9001 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.831\n",
            "INFO:tensorflow:loss = 0.08439543, step = 9101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.833\n",
            "INFO:tensorflow:loss = 0.06758453, step = 9201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 592.678\n",
            "INFO:tensorflow:loss = 0.12781903, step = 9301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.23\n",
            "INFO:tensorflow:loss = 0.016072929, step = 9401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.729\n",
            "INFO:tensorflow:loss = 0.007532751, step = 9501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.955\n",
            "INFO:tensorflow:loss = 0.18145207, step = 9601 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.506\n",
            "INFO:tensorflow:loss = 0.018902313, step = 9701 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.575\n",
            "INFO:tensorflow:loss = 0.03572589, step = 9801 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.616\n",
            "INFO:tensorflow:loss = 0.16839471, step = 9901 (0.163 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_mxpsd/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.035796635.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 92.59173675913111\n",
            "Just using average = 599.0034280117532 has RMSE of 98.76589237104777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "# Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[17,13,7], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NoIPNaT3UbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31bd298-7008-4908-c9f0-9bb5adfb336e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69895ce110>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6197088  0.61292255 0.45971116 0.562188   0.5749753  0.627877\n",
            " 0.5536151  0.5251169  0.4734179  0.52584887 0.56128913 0.60150003\n",
            " 0.6132801  0.43617    0.5261491  0.6402318  0.65793586 0.4947307\n",
            " 0.45797455 0.596325   0.577111   0.5916977  0.5878715  0.6005496\n",
            " 0.5269165  0.5387591  0.61788464 0.62090635 0.587026   0.58937526\n",
            " 0.48686    0.59996444 0.5799774  0.66578424 0.6190591  0.4180082\n",
            " 0.5760781  0.5900259  0.6349804  0.5417632  0.5991643  0.575372\n",
            " 0.5377871  0.5978111  0.6126435  0.60970896 0.6198152  0.58549166\n",
            " 0.55941916 0.5315228  0.4642753  0.62802327 0.48908383 0.46225625\n",
            " 0.46850598 0.5347105  0.5813071  0.6387332  0.5002119  0.46419138\n",
            " 0.5395841  0.5191006  0.5754804  0.51653206 0.6023753  0.579029\n",
            " 0.5869737  0.5156487  0.61550295 0.5507567  0.5576838  0.47351295\n",
            " 0.5469168  0.5206457  0.61585724 0.5760814  0.5976771  0.52899027\n",
            " 0.5580237  0.52622396 0.5708613  0.64892906 0.51670724 0.568297\n",
            " 0.48287004 0.54368407 0.5934662  0.5935642  0.45962042 0.54199564\n",
            " 0.6761283  0.60486203 0.57638055 0.5729406  0.4300404  0.63802886\n",
            " 0.601334   0.5919779  0.59077114 0.5817921  0.5944105  0.592639\n",
            " 0.61638814 0.5827984  0.57243794 0.5477646  0.5181431  0.54455054\n",
            " 0.5578062  0.538284   0.6361028  0.5979605  0.6285094  0.56671196\n",
            " 0.5705146  0.5463268  0.48156092 0.4558485  0.42257193 0.5774182\n",
            " 0.579666   0.59395874 0.5958748  0.5752936  0.61763203 0.5896783\n",
            " 0.5566859  0.6132465  0.42411956 0.46035373 0.55128306 0.55756336\n",
            " 0.560598   0.5449056  0.5007959  0.6171286  0.54684454 0.5738121\n",
            " 0.62970865 0.50318295 0.5980866  0.59212184 0.49622482 0.53714263\n",
            " 0.54560244 0.5254345  0.44172227 0.5188828  0.5771316  0.57394224\n",
            " 0.5695175  0.535215   0.5539826  0.5868022  0.57836884 0.5365495\n",
            " 0.45623803 0.6284078  0.5978787  0.5476604  0.54768854 0.5441166\n",
            " 0.5589313  0.5134664  0.50008315 0.59946954 0.6448488  0.45744246\n",
            " 0.5321098  0.58214366 0.62088    0.44700527 0.57943094 0.5740832\n",
            " 0.6515527  0.499891   0.51977175 0.5920646  0.5481679  0.5821466\n",
            " 0.51175374 0.6196604  0.4628162  0.61832714 0.5574738  0.5527389\n",
            " 0.56141424 0.59816486 0.53002846 0.559081   0.47316915 0.57424986\n",
            " 0.52528286 0.5767277  0.6010901  0.5498526  0.5787126  0.5353889\n",
            " 0.5798664  0.55201006 0.57661366 0.60540664 0.6097909  0.5633347\n",
            " 0.44504485 0.53153044 0.5482504  0.607659   0.5474551  0.4807722\n",
            " 0.5421757  0.43917936 0.5222896  0.5603001  0.5456151  0.49795625\n",
            " 0.6194796  0.63001037 0.5379036  0.6369377  0.6121893  0.48000208\n",
            " 0.5094559  0.6272301  0.61507255 0.61534387 0.46145687 0.46081388\n",
            " 0.66835386 0.61358005 0.5674859  0.5803896  0.63685286 0.6313916\n",
            " 0.44690192 0.55397725 0.62348354 0.5470913  0.63544786 0.47827145\n",
            " 0.57359254 0.5444786  0.4978563  0.56734484 0.5846552  0.5409789\n",
            " 0.61764055 0.58513546 0.61374825 0.55755705 0.48361868 0.51360077\n",
            " 0.5862131  0.41864896 0.6218323  0.6134437  0.5804142  0.43553954\n",
            " 0.42374134 0.61069673 0.49791843 0.6334173  0.57462204 0.58597976\n",
            " 0.52012795 0.63263464 0.51235414 0.586446   0.5122936  0.572863\n",
            " 0.4752425  0.6041842  0.4961449  0.66754967 0.50744265 0.51089823\n",
            " 0.56386334 0.5203688  0.53411174 0.59960634 0.4616184  0.5391688\n",
            " 0.5393223  0.5380191  0.51938105 0.5586915  0.617174   0.56997544\n",
            " 0.57701916 0.6173995  0.5633421  0.5548499  0.513515   0.6680682\n",
            " 0.58330154 0.546697   0.5547001  0.5982928  0.424678   0.48785552\n",
            " 0.56780833 0.5717506  0.52375096 0.54408425 0.6275655  0.5728748\n",
            " 0.55952775 0.43723884 0.4435139  0.56463856 0.6326515  0.5586432\n",
            " 0.6097879  0.5788606  0.5961824  0.5537287  0.49857152 0.5741148\n",
            " 0.48179412 0.55499476 0.5376535  0.5370345  0.56307125 0.4749207\n",
            " 0.5812904  0.4749906  0.61799246 0.56467265 0.55921006 0.5562736\n",
            " 0.5930629  0.577817   0.623156   0.56137884 0.5079809  0.5543529\n",
            " 0.59475905 0.57896245 0.57516503 0.55777305 0.5260128  0.58199966\n",
            " 0.63012683 0.45959276 0.59122074 0.5908875  0.6027749  0.600181\n",
            " 0.5689088  0.53614926 0.47869974 0.59453183 0.51885176 0.6180004\n",
            " 0.5974717  0.55189526 0.6061448  0.57918364 0.56525975 0.5794051\n",
            " 0.5129835  0.4446614  0.6075918  0.5600788  0.58517736 0.55466473\n",
            " 0.58257645 0.5007193  0.61220175 0.56473476 0.64922607 0.58545476\n",
            " 0.4570429  0.44475263 0.63677436 0.6142444  0.61532474 0.57786816\n",
            " 0.5784111  0.57213366 0.53617245 0.4970787  0.5109854  0.6317688\n",
            " 0.6743556  0.53595245 0.5602265  0.6177171  0.57529265 0.5882164\n",
            " 0.5141405  0.536763   0.57813025 0.5713507  0.59044087 0.42162523\n",
            " 0.43505865 0.60378504 0.42377004 0.5759048  0.53599167 0.668842\n",
            " 0.530092   0.60428864 0.5383458  0.5869297  0.4598737  0.46800506\n",
            " 0.458973   0.56864613 0.46590894 0.48300543 0.59318024 0.61416155\n",
            " 0.63523304 0.6776527  0.5965458  0.60983276 0.45778647 0.56948036\n",
            " 0.5906576  0.61185366 0.5391394  0.5566088  0.5546281  0.5800661\n",
            " 0.5759764  0.61127883 0.59063244 0.5317962  0.5347776  0.5806006\n",
            " 0.59917486 0.59700906 0.5115969  0.6141484  0.63445467 0.53075427\n",
            " 0.55241704 0.4469424  0.51762486 0.58275765 0.63846576 0.5946947\n",
            " 0.5901955  0.5711088  0.5691273  0.5704357  0.5638765  0.5739316\n",
            " 0.58756846 0.6676624  0.61717165 0.61002666 0.6264895  0.6150884\n",
            " 0.5978485  0.56611526 0.5794329  0.60153717 0.45629907 0.62637454\n",
            " 0.53609484 0.56802547 0.572814   0.5110401  0.5741505  0.6328751\n",
            " 0.59360296 0.44017202 0.56950295 0.51870733 0.6052366  0.584263\n",
            " 0.5947688  0.59219116 0.56241286 0.5789944  0.5382326  0.57979494\n",
            " 0.42614245 0.6082326  0.567737   0.57373315 0.5147645  0.54137903\n",
            " 0.47028401 0.52919096 0.54188484 0.5877009  0.60948986 0.6184492\n",
            " 0.58173543 0.6210213  0.5842711  0.63241565 0.60896313 0.5876542\n",
            " 0.5288238  0.43234354 0.5744193  0.6093174  0.5971742  0.55076176\n",
            " 0.56029755 0.5602043  0.6003214  0.5636549  0.5273354  0.5782002\n",
            " 0.56253266]\n",
            "[0.59517657 0.49009475 0.4005168  0.45219638 0.62187769 0.64254953\n",
            " 0.62015504 0.31007752 0.44530577 0.55900086 0.52713178 0.38070629\n",
            " 0.68217054 0.41085271 0.42635659 0.54608096 0.55297158 0.47631352\n",
            " 0.39276486 0.55813953 0.49095607 0.48148148 0.59086994 0.56158484\n",
            " 0.42204996 0.34625323 0.63910422 0.49612403 0.4788975  0.58225668\n",
            " 0.51593454 0.70801034 0.51765719 0.59431525 0.67011197 0.36864772\n",
            " 0.60551249 0.55727821 0.61757106 0.54177433 0.52024117 0.52885444\n",
            " 0.44186047 0.65977606 0.58225668 0.62790698 0.61068045 0.76055125\n",
            " 0.54177433 0.47114556 0.40482343 0.52971576 0.52024117 0.39879414\n",
            " 0.40137812 0.34366925 0.50387597 0.60034453 0.49956934 0.42807924\n",
            " 0.53143842 0.5374677  0.38845823 0.49870801 0.54952627 0.50387597\n",
            " 0.56072351 0.51076658 0.52971576 0.49956934 0.51076658 0.43066322\n",
            " 0.51937984 0.44875108 0.63910422 0.46425495 0.61757106 0.50215332\n",
            " 0.5245478  0.374677   0.64341085 0.71490095 0.49784668 0.50732127\n",
            " 0.43496985 0.49440138 0.52971576 0.64944014 0.41774332 0.58914729\n",
            " 0.56589147 0.49612403 0.5667528  0.625323   0.38329027 0.49009475\n",
            " 0.53316107 0.65030146 0.53402239 0.48492679 0.44702842 0.60034453\n",
            " 0.66666667 0.5960379  0.46683893 0.42291128 0.5211025  0.53402239\n",
            " 0.49095607 0.46597761 0.55813953 0.49267873 0.54349699 0.46339363\n",
            " 0.56847545 0.43927649 0.45478036 0.34797588 0.27562446 0.56072351\n",
            " 0.5211025  0.52971576 0.65202412 0.4039621  0.62790698 0.55727821\n",
            " 0.50990525 0.55986219 0.4005168  0.44875108 0.45219638 0.52196382\n",
            " 0.38931955 0.4918174  0.47286822 0.59086994 0.4788975  0.28251507\n",
            " 0.57278208 0.37209302 0.62704565 0.52799311 0.42807924 0.52713178\n",
            " 0.54005168 0.49698536 0.34022394 0.46683893 0.3712317  0.51593454\n",
            " 0.56847545 0.56589147 0.38501292 0.49870801 0.51507321 0.34280792\n",
            " 0.47286822 0.57105943 0.54349699 0.5503876  0.60206718 0.54349699\n",
            " 0.61929371 0.48923342 0.39190353 0.5211025  0.68561585 0.4754522\n",
            " 0.44099914 0.4952627  0.60120586 0.48923342 0.58397933 0.5796727\n",
            " 0.60120586 0.44272179 0.48062016 0.5503876  0.50990525 0.50904393\n",
            " 0.30577089 0.56761413 0.40568475 0.56244617 0.53229974 0.35400517\n",
            " 0.40913006 0.54091301 0.43238587 0.52540913 0.51335056 0.5667528\n",
            " 0.5245478  0.57622739 0.55469423 0.48923342 0.51421189 0.45219638\n",
            " 0.54952627 0.56847545 0.61068045 0.51937984 0.56416882 0.43755383\n",
            " 0.39965547 0.48923342 0.49009475 0.59086994 0.55986219 0.43238587\n",
            " 0.49956934 0.59689922 0.53919035 0.48234281 0.65202412 0.44444444\n",
            " 0.59086994 0.6546081  0.53660637 0.7002584  0.45047373 0.34797588\n",
            " 0.43927649 0.55211025 0.46080965 0.55727821 0.43496985 0.49440138\n",
            " 0.62704565 0.6089578  0.42807924 0.60206718 0.52971576 0.69939707\n",
            " 0.34366925 0.48406546 0.63996555 0.49956934 0.58225668 0.40740741\n",
            " 0.61498708 0.42894057 0.46511628 0.46942291 0.57450474 0.4754522\n",
            " 0.52368648 0.57622739 0.7329888  0.55469423 0.4332472  0.48664944\n",
            " 0.56158484 0.32213609 0.65288544 0.63393626 0.5211025  0.43496985\n",
            " 0.34969854 0.58828596 0.49009475 0.58656331 0.54349699 0.55727821\n",
            " 0.40137812 0.45133506 0.51162791 0.38156761 0.50129199 0.56589147\n",
            " 0.5047373  0.64685616 0.47975883 0.61154177 0.58484065 0.4754522\n",
            " 0.47286822 0.54952627 0.52368648 0.35228252 0.43755383 0.4625323\n",
            " 0.43927649 0.48664944 0.50559862 0.41257537 0.60378984 0.52024117\n",
            " 0.42204996 0.48492679 0.51679587 0.57881137 0.49870801 0.5960379\n",
            " 0.55641688 0.5047373  0.58828596 0.44444444 0.35658915 0.34625323\n",
            " 0.43152455 0.60292851 0.46167097 0.40310078 0.62360034 0.47631352\n",
            " 0.47028424 0.31093885 0.43496985 0.37639966 0.56847545 0.47459087\n",
            " 0.56416882 0.57278208 0.53574505 0.4461671  0.44702842 0.53402239\n",
            " 0.43152455 0.54005168 0.44358312 0.44013781 0.47975883 0.36606374\n",
            " 0.51593454 0.45478036 0.63307494 0.52799311 0.57019811 0.55900086\n",
            " 0.40999139 0.56330749 0.58053402 0.52540913 0.46167097 0.4918174\n",
            " 0.59259259 0.52540913 0.60206718 0.45822567 0.50301464 0.55986219\n",
            " 0.583118   0.47114556 0.56847545 0.36950904 0.66149871 0.59862188\n",
            " 0.51335056 0.5994832  0.50387597 0.5081826  0.43841516 0.58914729\n",
            " 0.49095607 0.45391904 0.60206718 0.50215332 0.53402239 0.62962963\n",
            " 0.45908699 0.38587425 0.62790698 0.50301464 0.42894057 0.54866494\n",
            " 0.53402239 0.44875108 0.61498708 0.45391904 0.63393626 0.58570198\n",
            " 0.40999139 0.37639966 0.64341085 0.59776055 0.5538329  0.43927649\n",
            " 0.63652024 0.54349699 0.5047373  0.42635659 0.55297158 0.60034453\n",
            " 0.64513351 0.54521964 0.48406546 0.78466839 0.50301464 0.47200689\n",
            " 0.45908699 0.57795004 0.52627046 0.60120586 0.63479759 0.42549526\n",
            " 0.46597761 0.63824289 0.3875969  0.51937984 0.42291128 0.66666667\n",
            " 0.52799311 0.63135228 0.46339363 0.4952627  0.48492679 0.3712317\n",
            " 0.48578811 0.60551249 0.4625323  0.40913006 0.64685616 0.58570198\n",
            " 0.47631352 0.66322136 0.54608096 0.55211025 0.43927649 0.5211025\n",
            " 0.46511628 0.62015504 0.54177433 0.49956934 0.54521964 0.45908699\n",
            " 0.54694229 0.51765719 0.5374677  0.55211025 0.53919035 0.51507321\n",
            " 0.54177433 0.45908699 0.41343669 0.56761413 0.57795004 0.53057709\n",
            " 0.44272179 0.43927649 0.52024117 0.46425495 0.61929371 0.61670973\n",
            " 0.91731266 0.55986219 0.583118   0.51679587 0.42549526 0.54263566\n",
            " 0.61154177 0.64427218 0.41343669 0.5374677  0.583118   0.59862188\n",
            " 0.5245478  0.47631352 0.58914729 0.57019811 0.48148148 0.64082687\n",
            " 0.48923342 0.59431525 0.49440138 0.54005168 0.60292851 0.58914729\n",
            " 0.3255814  0.40568475 0.52368648 0.42894057 0.55641688 0.5994832\n",
            " 0.49440138 0.69853575 0.54177433 0.56933678 0.47975883 0.61757106\n",
            " 0.36434109 0.5994832  0.52799311 0.60637382 0.49009475 0.41602067\n",
            " 0.39362618 0.4005168  0.51421189 0.5994832  0.59776055 0.51593454\n",
            " 0.47200689 0.55641688 0.48062016 0.59259259 0.5245478  0.49612403\n",
            " 0.51937984 0.44702842 0.4496124  0.38587425 0.50732127 0.43583118\n",
            " 0.5081826  0.50559862 0.50732127 0.52627046 0.57708872 0.5667528\n",
            " 0.39707149]\n",
            "The trained model has an aproximate error rate of -50.9704351639211 which equates to -9%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low RMSE value suggests that a relationship between the maximum sustained wind speed and the number of collisions exist. The model produced can be used to predict the number of collisions with a degree of accuracy. As with the other DNN models produced the error rate is higher."
      ],
      "metadata": {
        "id": "6ugiuzBKuNne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Whole Dataset\n",
        "As the purpose of this assignment is to accurately predict the number of collisions given the weather condition**s**, all available weather conditions are used as input variables to train a DNN model."
      ],
      "metadata": {
        "id": "Dzn0MDJwVdg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/datadnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "r3AhZB1bVybn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439878f2-aab5-4e6a-b4bb-97877d3467c7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the whole dataset contains the error values for Dew Point, Sea Level Pressure, Maximum Sustained Wind Speed and Gust; these must be removed."
      ],
      "metadata": {
        "id": "ZhkTk0XMApB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean the data\n",
        "dnn = df.loc[df[\"year\"] != 2012]\n",
        "dnn = dnn.loc[dnn[\"year\"] < 2020]\n",
        "dnn = dnn.loc[dnn[\"dewp\"] != 9999]\n",
        "dnn = dnn.loc[dnn[\"slp\"] != 9999]\n",
        "dnn = dnn.loc[dnn[\"mxpsd\"] != 999.9]\n",
        "dnn = dnn.loc[dnn[\"gust\"] != 999.9]\n",
        "#Move the target to the end\n",
        "cols = dnn['NUM_COLLISIONS']\n",
        "dnn = dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "dnn.insert(loc=37, column='NUM_COLLISIONS', value=cols)\n",
        "print(dnn[:6])\n",
        "dnn.describe()"
      ],
      "metadata": {
        "id": "izyExLEIVybo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "c3ff4f9b-4679-498a-fbf4-098171c2a2e9"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  temp  dewp     slp  visib  wdsp  mxpsd  gust   max  ...  Nov  \\\n",
            "74  2016  17  40.2  32.3  1007.3    9.2   7.7   12.0  18.1  51.1  ...    0   \n",
            "76  2014   9  23.5   8.3  1034.2   10.0   7.9   12.0  20.0  28.9  ...    0   \n",
            "79  2019  19  34.5  29.7  1022.0    9.8   6.9   13.0  21.0  39.9  ...    0   \n",
            "80  2015  11  27.1  12.1  1035.5   10.0   8.8   13.0  17.1  37.0  ...    0   \n",
            "83  2015  29  29.2  20.9  1022.9   10.0   8.5   13.0  20.0  36.0  ...    0   \n",
            "85  2019  13  26.0  12.8  1030.5   10.0   8.0   13.0  15.9  30.9  ...    0   \n",
            "\n",
            "    Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "74    0    0    0    1    0    0    0    0             451  \n",
            "76    0    0    0    0    0    0    0    1             561  \n",
            "79    0    0    0    0    0    0    0    0             479  \n",
            "80    0    0    0    1    0    0    0    0             341  \n",
            "83    0    0    0    0    0    0    0    1             519  \n",
            "85    0    0    0    1    0    0    0    0             374  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             year           da         temp         dewp          slp  \\\n",
              "count  1629.00000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean   2015.91283    15.702885    47.909638    45.903254  1015.632904   \n",
              "std       2.01341     8.667634    13.746339   247.352840     8.134237   \n",
              "min    2013.00000     1.000000     5.800000    -6.700000   989.500000   \n",
              "25%    2014.00000     8.000000    38.100000    28.200000  1010.600000   \n",
              "50%    2016.00000    16.000000    47.000000    40.200000  1015.400000   \n",
              "75%    2018.00000    23.000000    58.800000    52.800000  1021.100000   \n",
              "max    2019.00000    31.000000    77.500000  9999.900000  1039.100000   \n",
              "\n",
              "             visib         wdsp        mxpsd         gust         max  ...  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.00000  ...   \n",
              "mean      8.225599    12.602087    20.060896    27.511602    55.73407  ...   \n",
              "std       2.227285     3.986056     5.294117     7.366770    13.52726  ...   \n",
              "min       0.600000     4.500000     8.900000    14.000000    18.00000  ...   \n",
              "25%       7.000000    10.000000    15.900000    22.000000    46.00000  ...   \n",
              "50%       9.300000    12.000000    19.000000    26.000000    55.00000  ...   \n",
              "75%      10.000000    14.400000    22.900000    31.100000    66.00000  ...   \n",
              "max      10.000000    39.300000    49.000000    71.100000    87.10000  ...   \n",
              "\n",
              "               Nov          Oct          Sep          Mon          Sat  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean      0.096378     0.087784     0.071209     0.139963     0.141191   \n",
              "std       0.295200     0.283067     0.257253     0.347055     0.348325   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000     1629.000000  \n",
              "mean      0.139963     0.151627     0.138122     0.145488      596.513198  \n",
              "std       0.347055     0.358769     0.345133     0.352700      104.479660  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      526.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      597.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      663.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b3e7fa0-7f2a-4a48-85ab-332d45664d38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>gust</th>\n",
              "      <th>max</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1629.00000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.91283</td>\n",
              "      <td>15.702885</td>\n",
              "      <td>47.909638</td>\n",
              "      <td>45.903254</td>\n",
              "      <td>1015.632904</td>\n",
              "      <td>8.225599</td>\n",
              "      <td>12.602087</td>\n",
              "      <td>20.060896</td>\n",
              "      <td>27.511602</td>\n",
              "      <td>55.73407</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096378</td>\n",
              "      <td>0.087784</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.151627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>596.513198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.01341</td>\n",
              "      <td>8.667634</td>\n",
              "      <td>13.746339</td>\n",
              "      <td>247.352840</td>\n",
              "      <td>8.134237</td>\n",
              "      <td>2.227285</td>\n",
              "      <td>3.986056</td>\n",
              "      <td>5.294117</td>\n",
              "      <td>7.366770</td>\n",
              "      <td>13.52726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295200</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.257253</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.348325</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.358769</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>104.479660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.100000</td>\n",
              "      <td>28.200000</td>\n",
              "      <td>1010.600000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>46.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>526.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>40.200000</td>\n",
              "      <td>1015.400000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>55.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>597.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.00000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.800000</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>1021.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>66.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>663.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.00000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>9999.900000</td>\n",
              "      <td>1039.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>39.300000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b3e7fa0-7f2a-4a48-85ab-332d45664d38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b3e7fa0-7f2a-4a48-85ab-332d45664d38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b3e7fa0-7f2a-4a48-85ab-332d45664d38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle = dnn.iloc[np.random.permutation(len(dnn))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "pOJhsz3dVybo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1654cd8-cedd-4ee9-d33d-84d508b99b98"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  temp  dewp     slp  visib  wdsp  mxpsd  gust   max  ...  May  \\\n",
            "2924  2015  24  51.5  38.3  1027.1   10.0   9.4   17.1  26.0  63.0  ...    0   \n",
            "389   2014   7  28.1  15.7  1023.2   10.0   9.0   14.0  19.0  32.0  ...    0   \n",
            "1800  2017  16  59.8  52.9  1018.9    9.9  15.5   22.0  32.1  66.0  ...    0   \n",
            "1318  2015  21  54.8  41.1  1014.1   10.0   7.7   14.0  19.0  64.9  ...    1   \n",
            "2639  2014  13  59.9  53.2  1022.2    9.6   7.6   15.0  21.0  70.0  ...    0   \n",
            "3005  2017  10  68.8  65.6  1015.0    5.9  11.0   21.0  28.9  77.0  ...    0   \n",
            "\n",
            "      Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "2924    0    1    0    0    0    0    0    0    0  \n",
            "389     0    0    0    0    0    0    1    0    0  \n",
            "1800    0    0    0    0    0    0    1    0    0  \n",
            "1318    0    0    0    0    0    0    0    0    1  \n",
            "2639    0    0    1    0    0    0    0    0    0  \n",
            "3005    0    1    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select the target as the last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "iOF3gP_XVybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec4c548-d479-4e0a-dc19-3fe7028f9157"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2924    519\n",
            "389     675\n",
            "1800    657\n",
            "1318    615\n",
            "2639    558\n",
            "3005    768\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)\n"
      ],
      "metadata": {
        "id": "7XAEry6uVybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a822ee-60ba-400a-a400-2b0846e59d63"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,9,5,3], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "sb-ehJ2tVybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf9a20e-c3d5-44bc-cfd0-3654d223f782"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69856419d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 78.1907, step = 1\n",
            "INFO:tensorflow:global_step/sec: 478.049\n",
            "INFO:tensorflow:loss = 0.38407242, step = 101 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.525\n",
            "INFO:tensorflow:loss = 0.13543814, step = 201 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.951\n",
            "INFO:tensorflow:loss = 0.012446139, step = 301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.194\n",
            "INFO:tensorflow:loss = 0.0113518, step = 401 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.676\n",
            "INFO:tensorflow:loss = 0.008229288, step = 501 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.682\n",
            "INFO:tensorflow:loss = 0.0087835565, step = 601 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.349\n",
            "INFO:tensorflow:loss = 0.0086564915, step = 701 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.859\n",
            "INFO:tensorflow:loss = 0.008201921, step = 801 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.081\n",
            "INFO:tensorflow:loss = 0.008002378, step = 901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.036\n",
            "INFO:tensorflow:loss = 0.009290235, step = 1001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.1\n",
            "INFO:tensorflow:loss = 0.0085836705, step = 1101 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.807\n",
            "INFO:tensorflow:loss = 0.008333299, step = 1201 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.065\n",
            "INFO:tensorflow:loss = 0.008867618, step = 1301 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.012\n",
            "INFO:tensorflow:loss = 0.008909109, step = 1401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.529\n",
            "INFO:tensorflow:loss = 0.006764479, step = 1501 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.178\n",
            "INFO:tensorflow:loss = 0.0087426305, step = 1601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.296\n",
            "INFO:tensorflow:loss = 0.00802566, step = 1701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.223\n",
            "INFO:tensorflow:loss = 0.008049862, step = 1801 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.435\n",
            "INFO:tensorflow:loss = 0.008594351, step = 1901 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.871\n",
            "INFO:tensorflow:loss = 0.006908525, step = 2001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.942\n",
            "INFO:tensorflow:loss = 0.0042486093, step = 2101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.549\n",
            "INFO:tensorflow:loss = 0.007810843, step = 2201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.118\n",
            "INFO:tensorflow:loss = 0.0068638427, step = 2301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.974\n",
            "INFO:tensorflow:loss = 0.006634713, step = 2401 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.577\n",
            "INFO:tensorflow:loss = 0.010975828, step = 2501 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.582\n",
            "INFO:tensorflow:loss = 0.007376559, step = 2601 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.723\n",
            "INFO:tensorflow:loss = 0.0064015593, step = 2701 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.272\n",
            "INFO:tensorflow:loss = 0.0075526903, step = 2801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.774\n",
            "INFO:tensorflow:loss = 0.006775598, step = 2901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.424\n",
            "INFO:tensorflow:loss = 0.00622648, step = 3001 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.271\n",
            "INFO:tensorflow:loss = 0.009612172, step = 3101 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.071\n",
            "INFO:tensorflow:loss = 0.007589756, step = 3201 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.607\n",
            "INFO:tensorflow:loss = 0.00993995, step = 3301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.042\n",
            "INFO:tensorflow:loss = 0.009263923, step = 3401 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.864\n",
            "INFO:tensorflow:loss = 0.009729342, step = 3501 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.197\n",
            "INFO:tensorflow:loss = 0.007168281, step = 3601 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.344\n",
            "INFO:tensorflow:loss = 0.008648766, step = 3701 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.109\n",
            "INFO:tensorflow:loss = 0.007456427, step = 3801 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.996\n",
            "INFO:tensorflow:loss = 0.009627863, step = 3901 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.477\n",
            "INFO:tensorflow:loss = 0.011635053, step = 4001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.442\n",
            "INFO:tensorflow:loss = 0.00705521, step = 4101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.301\n",
            "INFO:tensorflow:loss = 0.0072083236, step = 4201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.552\n",
            "INFO:tensorflow:loss = 0.010418906, step = 4301 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.35\n",
            "INFO:tensorflow:loss = 0.010596245, step = 4401 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.67\n",
            "INFO:tensorflow:loss = 0.005970246, step = 4501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.516\n",
            "INFO:tensorflow:loss = 0.0077405963, step = 4601 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.852\n",
            "INFO:tensorflow:loss = 0.006918639, step = 4701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.414\n",
            "INFO:tensorflow:loss = 0.007846314, step = 4801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.717\n",
            "INFO:tensorflow:loss = 0.00664465, step = 4901 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 598.913\n",
            "INFO:tensorflow:loss = 0.007849376, step = 5001 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.868\n",
            "INFO:tensorflow:loss = 0.008471973, step = 5101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.224\n",
            "INFO:tensorflow:loss = 0.0072194086, step = 5201 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.117\n",
            "INFO:tensorflow:loss = 0.008599617, step = 5301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.962\n",
            "INFO:tensorflow:loss = 0.010300001, step = 5401 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.288\n",
            "INFO:tensorflow:loss = 0.0061300127, step = 5501 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.543\n",
            "INFO:tensorflow:loss = 0.0072243423, step = 5601 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.333\n",
            "INFO:tensorflow:loss = 0.008478237, step = 5701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.58\n",
            "INFO:tensorflow:loss = 0.00878606, step = 5801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.48\n",
            "INFO:tensorflow:loss = 0.009754186, step = 5901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.42\n",
            "INFO:tensorflow:loss = 0.008324154, step = 6001 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.536\n",
            "INFO:tensorflow:loss = 0.0087805325, step = 6101 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.465\n",
            "INFO:tensorflow:loss = 0.006865769, step = 6201 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.357\n",
            "INFO:tensorflow:loss = 0.0069190036, step = 6301 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.995\n",
            "INFO:tensorflow:loss = 0.009899722, step = 6401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.762\n",
            "INFO:tensorflow:loss = 0.008744188, step = 6501 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.073\n",
            "INFO:tensorflow:loss = 0.008746995, step = 6601 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.788\n",
            "INFO:tensorflow:loss = 0.006328808, step = 6701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.513\n",
            "INFO:tensorflow:loss = 0.0073538013, step = 6801 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.944\n",
            "INFO:tensorflow:loss = 0.00855669, step = 6901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.766\n",
            "INFO:tensorflow:loss = 0.0066536125, step = 7001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.299\n",
            "INFO:tensorflow:loss = 0.0069874553, step = 7101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.425\n",
            "INFO:tensorflow:loss = 0.007487374, step = 7201 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.208\n",
            "INFO:tensorflow:loss = 0.007949365, step = 7301 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.221\n",
            "INFO:tensorflow:loss = 0.006472528, step = 7401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.986\n",
            "INFO:tensorflow:loss = 0.004797459, step = 7501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.618\n",
            "INFO:tensorflow:loss = 0.0049514556, step = 7601 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.071\n",
            "INFO:tensorflow:loss = 0.006948457, step = 7701 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.991\n",
            "INFO:tensorflow:loss = 0.0063540726, step = 7801 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.557\n",
            "INFO:tensorflow:loss = 0.006245502, step = 7901 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.656\n",
            "INFO:tensorflow:loss = 0.00571197, step = 8001 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.199\n",
            "INFO:tensorflow:loss = 0.0072351713, step = 8101 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.075\n",
            "INFO:tensorflow:loss = 0.005226965, step = 8201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.447\n",
            "INFO:tensorflow:loss = 0.0069550243, step = 8301 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.806\n",
            "INFO:tensorflow:loss = 0.007814028, step = 8401 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.485\n",
            "INFO:tensorflow:loss = 0.008781832, step = 8501 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.563\n",
            "INFO:tensorflow:loss = 0.010200553, step = 8601 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.818\n",
            "INFO:tensorflow:loss = 0.010117747, step = 8701 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 635.451\n",
            "INFO:tensorflow:loss = 0.0072183507, step = 8801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.761\n",
            "INFO:tensorflow:loss = 0.0062817484, step = 8901 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.587\n",
            "INFO:tensorflow:loss = 0.0070706923, step = 9001 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.909\n",
            "INFO:tensorflow:loss = 0.0058285333, step = 9101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.931\n",
            "INFO:tensorflow:loss = 0.005600314, step = 9201 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.992\n",
            "INFO:tensorflow:loss = 0.00604768, step = 9301 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.746\n",
            "INFO:tensorflow:loss = 0.006155558, step = 9401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.585\n",
            "INFO:tensorflow:loss = 0.007515249, step = 9501 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.737\n",
            "INFO:tensorflow:loss = 0.0036422526, step = 9601 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.352\n",
            "INFO:tensorflow:loss = 0.004578309, step = 9701 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.217\n",
            "INFO:tensorflow:loss = 0.01199167, step = 9801 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 589.743\n",
            "INFO:tensorflow:loss = 0.007016464, step = 9901 (0.170 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0064476887.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 84.60673873963464\n",
            "Just using average = 596.55871066769 has RMSE of 104.57564089372552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictors[trainsize:].values)\n",
        "\n",
        "#Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,9,5,3], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "ssTSefyuVybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60713803-7923-42d9-a267-dca2c19b0374"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69893db4d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.018e+03 5.000e+00 4.750e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.013e+03 1.900e+01 3.590e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.016e+03 1.400e+01 5.800e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " ...\n",
            " [2.013e+03 2.600e+01 5.020e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.014e+03 1.000e+01 6.940e+01 ... 0.000e+00 0.000e+00 1.000e+00]\n",
            " [2.018e+03 1.500e+01 4.610e+01 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4960399  0.4456477  0.39058387 0.5475331  0.54891425 0.5210385\n",
            " 0.5318333  0.5486218  0.41578734 0.38593492 0.59302896 0.50176954\n",
            " 0.5217861  0.46751556 0.5236506  0.54228014 0.5886998  0.56803644\n",
            " 0.56422985 0.4773662  0.5200675  0.55904335 0.59088856 0.54373586\n",
            " 0.56062186 0.5190677  0.56101006 0.5286563  0.5246736  0.53569335\n",
            " 0.5160985  0.48941115 0.49363893 0.5549494  0.5891978  0.5680552\n",
            " 0.45636275 0.58715254 0.47624832 0.568396   0.5348954  0.5475349\n",
            " 0.41068873 0.4827219  0.49168992 0.5611435  0.397279   0.5111623\n",
            " 0.5135496  0.46726406 0.549048   0.42037567 0.48997295 0.58580214\n",
            " 0.52456826 0.5401323  0.5751318  0.53076124 0.47012526 0.49686134\n",
            " 0.44280255 0.40975973 0.4380358  0.5734564  0.53073186 0.53820854\n",
            " 0.5045014  0.5365789  0.45125043 0.5774837  0.47968945 0.5253165\n",
            " 0.5349813  0.51444614 0.532233   0.59344107 0.48791525 0.42087618\n",
            " 0.60464257 0.4592435  0.5429901  0.53882694 0.54601926 0.51798946\n",
            " 0.6072702  0.4912275  0.5297626  0.520552   0.57103544 0.5064908\n",
            " 0.5163507  0.5163541  0.54993314 0.5039344  0.5379063  0.44613048\n",
            " 0.5312905  0.50337887 0.48643965 0.6089017  0.5419579  0.4660951\n",
            " 0.5357798  0.5041688  0.5311856  0.58232963 0.5972467  0.4903969\n",
            " 0.40253705 0.536396   0.48593983 0.4876709  0.518851   0.52166027\n",
            " 0.59130853 0.50761306 0.43769714 0.55693007 0.52266675 0.46983454\n",
            " 0.3965851  0.5547546  0.48100272 0.50486153 0.48268107 0.54791135\n",
            " 0.47701395 0.49677038 0.52281666 0.5152336  0.50417536 0.46461847\n",
            " 0.5843816  0.5061281  0.565089   0.5293764  0.5205861  0.39786318\n",
            " 0.5478523  0.517976   0.48938563 0.5161315  0.5362534  0.5247443\n",
            " 0.50562376 0.49802628 0.47305104 0.5602638  0.5475359  0.5034952\n",
            " 0.6022107  0.56951237 0.5067824  0.5731251  0.54881394 0.5212709\n",
            " 0.49099195 0.45412308 0.45152932 0.6000008  0.5216459  0.5590391\n",
            " 0.5288568  0.41615483 0.54400563 0.5081572  0.43014598 0.5076696\n",
            " 0.53176636 0.53007    0.49401742 0.5780451  0.56975126 0.49688533\n",
            " 0.5677306  0.5566464  0.48610598 0.5027563  0.52436954 0.5026218\n",
            " 0.4331107  0.5109809  0.5259564  0.60020274 0.5445397  0.5740071\n",
            " 0.4141136  0.53875005 0.5197561  0.5529606  0.5459232  0.5566233\n",
            " 0.5256929  0.50324166 0.48989272 0.55054957 0.54568    0.5659077\n",
            " 0.48181227 0.5209306  0.47015435 0.4897568  0.5046288  0.4916967\n",
            " 0.48634183 0.39689213 0.53010243 0.5026066  0.48341146 0.5552367\n",
            " 0.5534961  0.5150228  0.52785575 0.5257697  0.48386943 0.5317113\n",
            " 0.42259088 0.5236596  0.53297096 0.5677416  0.54291236 0.5758226\n",
            " 0.49006188 0.53828514 0.487412   0.4160408  0.5100961  0.5921548\n",
            " 0.6010206  0.50866836 0.5583889  0.5760042  0.5851238  0.59764034\n",
            " 0.47904685 0.57032347 0.55967176 0.39517394 0.51228446 0.54073346\n",
            " 0.47479194 0.52976674 0.41363132 0.5764642  0.5093997  0.5706865\n",
            " 0.54854625 0.5361154  0.49888173 0.4695555  0.5127109  0.5468042\n",
            " 0.49879077 0.48844683 0.58593637 0.50079995 0.45205823 0.48434016\n",
            " 0.57133293 0.53701895 0.36259222 0.5697957  0.45178232 0.5543554\n",
            " 0.49403077 0.52489156 0.4366653  0.52678496 0.48034784 0.53644484\n",
            " 0.48812833 0.52845895 0.42383412 0.5886343  0.5241353  0.41606015\n",
            " 0.6008013  0.5455069  0.5169417  0.4812684  0.49935746 0.51243544\n",
            " 0.5249371  0.48761356 0.54950166 0.5494211  0.55197865 0.57696897\n",
            " 0.4411794  0.5812844  0.5186718  0.5442319  0.57164735 0.5455719\n",
            " 0.54393935 0.5149208  0.5951891  0.54883987 0.55173427 0.55421746\n",
            " 0.4570977  0.49544454 0.5237533  0.4891234  0.52818316 0.57483846\n",
            " 0.5126868  0.55661374 0.4931116  0.48608255 0.4730031  0.42769906\n",
            " 0.5515602  0.49596205 0.56983596 0.599746   0.54717094 0.52856535\n",
            " 0.39865908 0.5267187  0.49187973 0.5662977  0.43964744 0.4578303\n",
            " 0.5214329  0.47827813]\n",
            "[0.65374677 0.416882   0.26614987 0.59086994 0.52368648 0.61670973\n",
            " 0.58656331 0.49784668 0.37812231 0.40654608 0.53488372 0.44272179\n",
            " 0.42894057 0.45564169 0.53574505 0.57105943 0.36606374 0.57105943\n",
            " 0.44788975 0.52024117 0.44272179 0.49095607 0.59345392 0.5667528\n",
            " 0.86046512 0.43669251 0.63738157 0.55900086 0.51593454 0.46167097\n",
            " 0.30749354 0.45736434 0.56933678 0.60465116 0.50215332 0.47631352\n",
            " 0.49698536 0.66063738 0.48664944 0.63910422 0.47717485 0.50559862\n",
            " 0.32730405 0.51765719 0.46339363 0.63479759 0.45822567 0.50732127\n",
            " 0.42807924 0.50301464 0.45305771 0.36692506 0.58484065 0.52885444\n",
            " 0.51765719 0.60034453 0.64082687 0.69509044 0.41343669 0.42204996\n",
            " 0.40999139 0.40137812 0.44099914 0.50129199 0.54349699 0.57881137\n",
            " 0.4788975  0.59862188 0.4788975  0.63996555 0.44013781 0.4005168\n",
            " 0.66666667 0.54263566 0.63479759 0.64857881 0.47372954 0.38329027\n",
            " 0.65719208 0.43927649 0.60465116 0.43496985 0.55727821 0.43669251\n",
            " 0.71490095 0.59086994 0.54349699 0.57622739 0.6416882  0.4203273\n",
            " 0.42894057 0.53143842 0.40568475 0.41085271 0.33763997 0.44444444\n",
            " 0.52627046 0.49870801 0.42291128 0.583118   0.56244617 0.42549526\n",
            " 0.44358312 0.51248923 0.36864772 0.49009475 0.63738157 0.47286822\n",
            " 0.41774332 0.63135228 0.4461671  0.49009475 0.54694229 0.5667528\n",
            " 0.5538329  0.5081826  0.49267873 0.43496985 0.6089578  0.4005168\n",
            " 0.4005168  0.59345392 0.46167097 0.52627046 0.44186047 0.60637382\n",
            " 0.49870801 0.42204996 0.41860465 0.57881137 0.50904393 0.43669251\n",
            " 0.50904393 0.58828596 0.58139535 0.49095607 0.57019811 0.37812231\n",
            " 0.51679587 0.48234281 0.44099914 0.46942291 0.63652024 0.52540913\n",
            " 0.51765719 0.4625323  0.44358312 0.5245478  0.56330749 0.54263566\n",
            " 0.61757106 0.6089578  0.46080965 0.58570198 0.43066322 0.45219638\n",
            " 0.46080965 0.48664944 0.42635659 0.57795004 0.5374677  0.49870801\n",
            " 0.56158484 0.33850129 0.40568475 0.82687339 0.36347976 0.4918174\n",
            " 0.65030146 0.63996555 0.58397933 0.62790698 0.52713178 0.65202412\n",
            " 0.67011197 0.53143842 0.42291128 0.4788975  0.6546081  0.48406546\n",
            " 0.38501292 0.68130922 0.50387597 0.583118   0.60378984 0.67786391\n",
            " 0.34280792 0.48578811 0.60206718 0.36434109 0.60206718 0.56158484\n",
            " 0.60809647 0.63479759 0.56330749 0.55813953 0.53229974 0.58484065\n",
            " 0.51335056 0.50904393 0.36520241 0.53660637 0.64513351 0.5374677\n",
            " 0.51335056 0.33850129 0.58828596 0.47459087 0.58139535 0.53919035\n",
            " 0.63307494 0.45305771 0.4754522  0.48492679 0.47114556 0.53316107\n",
            " 0.4005168  0.44186047 0.37726098 0.4496124  0.50990525 0.64685616\n",
            " 0.47803618 0.5667528  0.36347976 0.40482343 0.49870801 0.60378984\n",
            " 0.66063738 0.44702842 0.56503015 0.63738157 0.61068045 0.56847545\n",
            " 0.45994832 0.49440138 0.48148148 0.47372954 0.43238587 0.4203273\n",
            " 0.40913006 0.43152455 0.39362618 0.59259259 0.56416882 0.6873385\n",
            " 0.55986219 0.51593454 0.53919035 0.50732127 0.44788975 0.54263566\n",
            " 0.54435831 0.47803618 0.55555556 0.52713178 0.45736434 0.45650301\n",
            " 0.54952627 0.5503876  0.32213609 0.47459087 0.39276486 0.54349699\n",
            " 0.43410853 0.50559862 0.4461671  0.5047373  0.42894057 0.51937984\n",
            " 0.43755383 0.55124892 0.36950904 0.57536606 0.42635659 0.34022394\n",
            " 0.63824289 0.70801034 0.51507321 0.49956934 0.50990525 0.58225668\n",
            " 0.35228252 0.50990525 0.59862188 0.44272179 0.63738157 0.58225668\n",
            " 0.44186047 0.53574505 0.53057709 0.51851852 0.6089578  0.65719208\n",
            " 0.41774332 0.60723514 0.59259259 0.55469423 0.51765719 0.4039621\n",
            " 0.49784668 0.47631352 0.41257537 0.56933678 0.64771748 0.61068045\n",
            " 0.5538329  0.5374677  0.60551249 0.53660637 0.55297158 0.35400517\n",
            " 0.56589147 0.52799311 0.52282515 0.58225668 0.57450474 0.52196382\n",
            " 0.31093885 0.47975883 0.58053402 0.63824289 0.4461671  0.39190353\n",
            " 0.50301464 0.54091301]\n",
            "The trained model has an aproximate error rate of -3.8737458771357494 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low RMSE and the low percentage error rate suggest that using the whole cleaned dataset is an accurate predictor of the number of collisions."
      ],
      "metadata": {
        "id": "pdkBGr4CCjzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Location\n",
        "As identified in assignment 1, as the location tends towards the centre of New York there is stronger linear relationships. This suggests there is a link between the number of collisions, location and the observed weather conditions. A DNN will be trained to attempt to predict the number of collisions given the location, day and weather conditions."
      ],
      "metadata": {
        "id": "kHVsefPtZOYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data and extract from the zip\n",
        "#Reference - (geeksforgeeks.org 2021)\n",
        "df_loc = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/locdnn.zip', index_col=0,compression='zip' )\n",
        "print(df_loc[:6])"
      ],
      "metadata": {
        "id": "d4VkDncof2uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdc3e8c-9c32-4060-d7fb-6381b52adf9f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS   latitude  longitude  temp  dewp     slp  visib  \\\n",
            "1  2018   2               1  40.681750 -73.967480  14.7   2.0  1024.9   10.0   \n",
            "2  2018   2               1  40.645370 -73.945110  14.7   2.0  1024.9   10.0   \n",
            "3  2018   2               1  40.614830 -73.998380  14.7   2.0  1024.9   10.0   \n",
            "4  2018   2               1  40.592190 -74.087395  14.7   2.0  1024.9   10.0   \n",
            "5  2018   2               1  40.769817 -73.782370  14.7   2.0  1024.9   10.0   \n",
            "6  2018   2               1  40.660175 -73.928200  14.7   2.0  1024.9   10.0   \n",
            "\n",
            "   wdsp  ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "2  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "4  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "5  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 40 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove unrequired cols\n",
        "df_loc_dnn = df_loc.drop(columns=['thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "#Clean data\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"year\"] != 2012]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"year\"] < 2020]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"dewp\"] != 9999]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"slp\"] != 9999]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"mxpsd\"] != 999.9]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"gust\"] != 999.9]\n",
        "#Move the target to the end\n",
        "cols = df_loc_dnn['NUM_COLLISIONS']\n",
        "df_loc_dnn = df_loc_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_loc_dnn.insert(loc=33, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_loc_dnn[:6])\n",
        "df_loc_dnn.describe()"
      ],
      "metadata": {
        "id": "hl2pF-yuf2u0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "f935ae57-3dd7-4eae-80d3-7fdcf4dceb10"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da   latitude  longitude  temp  dewp     slp  visib  wdsp  mxpsd  \\\n",
            "1  2018   2  40.681750 -73.967480  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "2  2018   2  40.645370 -73.945110  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "3  2018   2  40.614830 -73.998380  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "4  2018   2  40.592190 -74.087395  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "5  2018   2  40.769817 -73.782370  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "6  2018   2  40.660175 -73.928200  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "1  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "2  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "3  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "4  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "5  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "6  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "\n",
            "[6 rows x 34 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                year             da       latitude      longitude  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean     2016.070154      15.638823      40.723907     -73.920916   \n",
              "std         1.991298       8.613159       0.078454       0.086634   \n",
              "min      2013.000000       1.000000      40.498949     -74.253006   \n",
              "25%      2014.000000       8.000000      40.668860     -73.976715   \n",
              "50%      2016.000000      16.000000      40.722470     -73.929210   \n",
              "75%      2018.000000      23.000000      40.768165     -73.866650   \n",
              "max      2019.000000      31.000000      40.912884     -73.663010   \n",
              "\n",
              "                temp           dewp            slp          visib  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean       48.419836      47.274900    1015.556656       8.199143   \n",
              "std        13.750834     261.636367       8.136580       2.230079   \n",
              "min         5.800000      -6.700000     989.500000       0.600000   \n",
              "25%        38.400000      28.800000    1010.700000       6.900000   \n",
              "50%        47.800000      41.300000    1015.300000       9.300000   \n",
              "75%        59.500000      53.400000    1021.000000      10.000000   \n",
              "max        77.500000    9999.900000    1039.100000      10.000000   \n",
              "\n",
              "                wdsp          mxpsd  ...            Nov            Oct  \\\n",
              "count  830297.000000  830297.000000  ...  830297.000000  830297.000000   \n",
              "mean       12.598551      20.021545  ...       0.102479       0.093866   \n",
              "std         3.921832       5.219745  ...       0.303277       0.291643   \n",
              "min         4.500000       8.900000  ...       0.000000       0.000000   \n",
              "25%        10.000000      15.900000  ...       0.000000       0.000000   \n",
              "50%        12.000000      19.000000  ...       0.000000       0.000000   \n",
              "75%        14.400000      22.900000  ...       0.000000       0.000000   \n",
              "max        39.300000      49.000000  ...       1.000000       1.000000   \n",
              "\n",
              "                 Sep            Mon            Sat            Sun  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean        0.074335       0.146763       0.114698       0.142687   \n",
              "std         0.262315       0.353870       0.318657       0.349754   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 Thu            Tue            Wed  NUM_COLLISIONS  \n",
              "count  830297.000000  830297.000000  830297.000000   830297.000000  \n",
              "mean        0.170187       0.141897       0.150735        1.027090  \n",
              "std         0.375797       0.348945       0.357791        0.180994  \n",
              "min         0.000000       0.000000       0.000000        1.000000  \n",
              "25%         0.000000       0.000000       0.000000        1.000000  \n",
              "50%         0.000000       0.000000       0.000000        1.000000  \n",
              "75%         0.000000       0.000000       0.000000        1.000000  \n",
              "max         1.000000       1.000000       1.000000       11.000000  \n",
              "\n",
              "[8 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b40f6f84-e9b1-4edb-b2af-0ba91d3424fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>...</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.070154</td>\n",
              "      <td>15.638823</td>\n",
              "      <td>40.723907</td>\n",
              "      <td>-73.920916</td>\n",
              "      <td>48.419836</td>\n",
              "      <td>47.274900</td>\n",
              "      <td>1015.556656</td>\n",
              "      <td>8.199143</td>\n",
              "      <td>12.598551</td>\n",
              "      <td>20.021545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102479</td>\n",
              "      <td>0.093866</td>\n",
              "      <td>0.074335</td>\n",
              "      <td>0.146763</td>\n",
              "      <td>0.114698</td>\n",
              "      <td>0.142687</td>\n",
              "      <td>0.170187</td>\n",
              "      <td>0.141897</td>\n",
              "      <td>0.150735</td>\n",
              "      <td>1.027090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.991298</td>\n",
              "      <td>8.613159</td>\n",
              "      <td>0.078454</td>\n",
              "      <td>0.086634</td>\n",
              "      <td>13.750834</td>\n",
              "      <td>261.636367</td>\n",
              "      <td>8.136580</td>\n",
              "      <td>2.230079</td>\n",
              "      <td>3.921832</td>\n",
              "      <td>5.219745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303277</td>\n",
              "      <td>0.291643</td>\n",
              "      <td>0.262315</td>\n",
              "      <td>0.353870</td>\n",
              "      <td>0.318657</td>\n",
              "      <td>0.349754</td>\n",
              "      <td>0.375797</td>\n",
              "      <td>0.348945</td>\n",
              "      <td>0.357791</td>\n",
              "      <td>0.180994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.498949</td>\n",
              "      <td>-74.253006</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>40.668860</td>\n",
              "      <td>-73.976715</td>\n",
              "      <td>38.400000</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>1010.700000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>40.722470</td>\n",
              "      <td>-73.929210</td>\n",
              "      <td>47.800000</td>\n",
              "      <td>41.300000</td>\n",
              "      <td>1015.300000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>40.768165</td>\n",
              "      <td>-73.866650</td>\n",
              "      <td>59.500000</td>\n",
              "      <td>53.400000</td>\n",
              "      <td>1021.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>40.912884</td>\n",
              "      <td>-73.663010</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>9999.900000</td>\n",
              "      <td>1039.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>39.300000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b40f6f84-e9b1-4edb-b2af-0ba91d3424fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b40f6f84-e9b1-4edb-b2af-0ba91d3424fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b40f6f84-e9b1-4edb-b2af-0ba91d3424fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the scale to the maximum value\n",
        "SCALE_LOC=11\n",
        "# Shuffle data\n",
        "shuffle = df_loc_dnn.iloc[np.random.permutation(len(df_loc_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "cPhXM4DJf2u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e25a01c-0c30-4b3e-9fbb-f889008eccd6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         year  da   latitude  longitude  temp  dewp     slp  visib  wdsp  \\\n",
            "857719   2015  20  40.783248 -73.944723  58.2  45.6  1022.8    9.7  21.3   \n",
            "1212490  2016  15  40.777092 -73.982110  64.5  53.4  1022.0   10.0  14.4   \n",
            "462091   2019  16  40.759575 -73.777030  39.7  24.5  1026.2   10.0  18.4   \n",
            "418980   2019  28  40.787390 -73.938225  65.4  61.6  1015.1    9.2   7.7   \n",
            "673714   2016  21  40.699680 -73.798640  64.6  62.1  1010.7    6.0  12.9   \n",
            "195999   2016  17  40.732348 -73.984939  41.5  35.8  1011.9    6.2  12.0   \n",
            "\n",
            "         mxpsd  ...  May  Nov  Oct  Sep  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "857719    26.0  ...    0    0    1    0    1    0    0    0    0    0  \n",
            "1212490   22.9  ...    0    0    0    1    0    0    0    0    0    1  \n",
            "462091    28.0  ...    0    1    0    0    0    0    0    0    0    0  \n",
            "418980    20.0  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "673714    18.1  ...    0    0    1    0    0    0    0    1    0    0  \n",
            "195999    17.1  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "\n",
            "[6 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "sol3wzXcf2u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebaca64-ebc6-44f0-b426-3ea28a17f717"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "857719     2\n",
            "1212490    1\n",
            "462091     1\n",
            "418980     1\n",
            "673714     1\n",
            "195999     1\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "_fZ3mPt-f2u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23f102e-711f-4626-fda4-a4a67bae03c4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_loc', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_loc', hidden_units=[19,15,11,7], optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model.\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_LOC, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_LOC\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "FEMInwLGf2u3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7550b9-407b-4c56-b922-8d122cf786e7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f69856e5250>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_loc', '_session_creation_timeout_secs': 7200}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_loc/model.ckpt.\n",
            "INFO:tensorflow:loss = 39883.492, step = 1\n",
            "INFO:tensorflow:global_step/sec: 428.494\n",
            "INFO:tensorflow:loss = 0.030600436, step = 101 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.126\n",
            "INFO:tensorflow:loss = 0.0028584637, step = 201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.49\n",
            "INFO:tensorflow:loss = 0.00018860513, step = 301 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.579\n",
            "INFO:tensorflow:loss = 7.167452e-05, step = 401 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.306\n",
            "INFO:tensorflow:loss = 0.00012837196, step = 501 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.867\n",
            "INFO:tensorflow:loss = 0.0002505085, step = 601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.261\n",
            "INFO:tensorflow:loss = 0.00025046951, step = 701 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.2\n",
            "INFO:tensorflow:loss = 0.00037224934, step = 801 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.409\n",
            "INFO:tensorflow:loss = 6.491667e-06, step = 901 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.896\n",
            "INFO:tensorflow:loss = 0.0001893749, step = 1001 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.437\n",
            "INFO:tensorflow:loss = 0.0005628726, step = 1101 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.019\n",
            "INFO:tensorflow:loss = 0.0003795244, step = 1201 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.131\n",
            "INFO:tensorflow:loss = 0.00012781483, step = 1301 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.158\n",
            "INFO:tensorflow:loss = 6.6549954e-05, step = 1401 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.217\n",
            "INFO:tensorflow:loss = 0.00025030115, step = 1501 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.327\n",
            "INFO:tensorflow:loss = 0.00018962723, step = 1601 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.817\n",
            "INFO:tensorflow:loss = 0.00037196057, step = 1701 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.423\n",
            "INFO:tensorflow:loss = 0.00025668045, step = 1801 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.521\n",
            "INFO:tensorflow:loss = 0.00012742307, step = 1901 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.596\n",
            "INFO:tensorflow:loss = 6.5377266e-05, step = 2001 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.912\n",
            "INFO:tensorflow:loss = 0.00018929427, step = 2101 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.85\n",
            "INFO:tensorflow:loss = 0.00025019763, step = 2201 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.571\n",
            "INFO:tensorflow:loss = 0.00025725388, step = 2301 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.986\n",
            "INFO:tensorflow:loss = 0.000189932, step = 2401 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.505\n",
            "INFO:tensorflow:loss = 0.0007423167, step = 2501 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.469\n",
            "INFO:tensorflow:loss = 0.00025115616, step = 2601 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.176\n",
            "INFO:tensorflow:loss = 0.00012962749, step = 2701 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.281\n",
            "INFO:tensorflow:loss = 6.8321104e-05, step = 2801 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.325\n",
            "INFO:tensorflow:loss = 0.00012982424, step = 2901 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.991\n",
            "INFO:tensorflow:loss = 6.9819704e-05, step = 3001 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.584\n",
            "INFO:tensorflow:loss = 6.657493e-05, step = 3101 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.28\n",
            "INFO:tensorflow:loss = 0.00025062548, step = 3201 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.106\n",
            "INFO:tensorflow:loss = 6.643546e-05, step = 3301 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.203\n",
            "INFO:tensorflow:loss = 0.00018919946, step = 3401 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.763\n",
            "INFO:tensorflow:loss = 6.508212e-05, step = 3501 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.902\n",
            "INFO:tensorflow:loss = 6.8552275e-05, step = 3601 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.497\n",
            "INFO:tensorflow:loss = 0.00031247427, step = 3701 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.41\n",
            "INFO:tensorflow:loss = 0.0003797657, step = 3801 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.478\n",
            "INFO:tensorflow:loss = 0.00031841022, step = 3901 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.964\n",
            "INFO:tensorflow:loss = 0.0002507624, step = 4001 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.5\n",
            "INFO:tensorflow:loss = 0.00025073485, step = 4101 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.598\n",
            "INFO:tensorflow:loss = 0.00018943165, step = 4201 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.703\n",
            "INFO:tensorflow:loss = 0.0001894782, step = 4301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.127\n",
            "INFO:tensorflow:loss = 0.00012767964, step = 4401 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.371\n",
            "INFO:tensorflow:loss = 0.00025029026, step = 4501 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.149\n",
            "INFO:tensorflow:loss = 0.000561914, step = 4601 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.013\n",
            "INFO:tensorflow:loss = 6.6420005e-05, step = 4701 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.404\n",
            "INFO:tensorflow:loss = 0.00012784993, step = 4801 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.862\n",
            "INFO:tensorflow:loss = 6.604696e-05, step = 4901 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.113\n",
            "INFO:tensorflow:loss = 0.0006153665, step = 5001 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.543\n",
            "INFO:tensorflow:loss = 0.00025083616, step = 5101 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.34\n",
            "INFO:tensorflow:loss = 0.00043985376, step = 5201 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.323\n",
            "INFO:tensorflow:loss = 6.72145e-05, step = 5301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.908\n",
            "INFO:tensorflow:loss = 0.00031037888, step = 5401 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.685\n",
            "INFO:tensorflow:loss = 6.784822e-05, step = 5501 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.106\n",
            "INFO:tensorflow:loss = 5.0981043e-06, step = 5601 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.822\n",
            "INFO:tensorflow:loss = 0.0002510748, step = 5701 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.722\n",
            "INFO:tensorflow:loss = 0.0003732222, step = 5801 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.941\n",
            "INFO:tensorflow:loss = 0.00012795898, step = 5901 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.394\n",
            "INFO:tensorflow:loss = 0.0005645855, step = 6001 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.195\n",
            "INFO:tensorflow:loss = 0.0001302649, step = 6101 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.555\n",
            "INFO:tensorflow:loss = 0.00025020295, step = 6201 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.787\n",
            "INFO:tensorflow:loss = 0.00019014277, step = 6301 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.904\n",
            "INFO:tensorflow:loss = 0.00044001473, step = 6401 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.714\n",
            "INFO:tensorflow:loss = 0.00012786374, step = 6501 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.16\n",
            "INFO:tensorflow:loss = 0.00018938858, step = 6601 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.317\n",
            "INFO:tensorflow:loss = 0.0011152821, step = 6701 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.513\n",
            "INFO:tensorflow:loss = 0.0001895756, step = 6801 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.932\n",
            "INFO:tensorflow:loss = 0.00013245203, step = 6901 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 574.715\n",
            "INFO:tensorflow:loss = 0.00018917251, step = 7001 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.32\n",
            "INFO:tensorflow:loss = 0.00031044698, step = 7101 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.974\n",
            "INFO:tensorflow:loss = 0.0004410835, step = 7201 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.109\n",
            "INFO:tensorflow:loss = 0.00012891163, step = 7301 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.662\n",
            "INFO:tensorflow:loss = 0.00031159085, step = 7401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.733\n",
            "INFO:tensorflow:loss = 0.00031038254, step = 7501 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.712\n",
            "INFO:tensorflow:loss = 0.00025071343, step = 7601 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.265\n",
            "INFO:tensorflow:loss = 0.00025080174, step = 7701 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.252\n",
            "INFO:tensorflow:loss = 7.8613775e-05, step = 7801 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.545\n",
            "INFO:tensorflow:loss = 0.0002515539, step = 7901 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.001\n",
            "INFO:tensorflow:loss = 6.4256295e-05, step = 8001 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.28\n",
            "INFO:tensorflow:loss = 0.0001907355, step = 8101 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.333\n",
            "INFO:tensorflow:loss = 6.765536e-05, step = 8201 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.758\n",
            "INFO:tensorflow:loss = 0.00019776498, step = 8301 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.261\n",
            "INFO:tensorflow:loss = 0.00031146294, step = 8401 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.253\n",
            "INFO:tensorflow:loss = 8.793188e-12, step = 8501 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.834\n",
            "INFO:tensorflow:loss = 0.00012719996, step = 8601 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.615\n",
            "INFO:tensorflow:loss = 0.00012858563, step = 8701 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.071\n",
            "INFO:tensorflow:loss = 6.8876354e-05, step = 8801 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.417\n",
            "INFO:tensorflow:loss = 0.0001276102, step = 8901 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.012\n",
            "INFO:tensorflow:loss = 0.00012756925, step = 9001 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.286\n",
            "INFO:tensorflow:loss = 0.00013580115, step = 9101 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.27\n",
            "INFO:tensorflow:loss = 0.0003263702, step = 9201 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.274\n",
            "INFO:tensorflow:loss = 0.00013167011, step = 9301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 564.634\n",
            "INFO:tensorflow:loss = 2.5575582e-07, step = 9401 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.088\n",
            "INFO:tensorflow:loss = 0.00020411506, step = 9501 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.576\n",
            "INFO:tensorflow:loss = 2.8958256e-08, step = 9601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.882\n",
            "INFO:tensorflow:loss = 0.00033205835, step = 9701 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.942\n",
            "INFO:tensorflow:loss = 0.00031084055, step = 9801 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.854\n",
            "INFO:tensorflow:loss = 0.0004414486, step = 9901 (0.176 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_loc/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.4652638e-06.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_loc/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 0.18250732634269354\n",
            "Just using average = 1.0270219816119848 has RMSE of 0.18125579252895552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictors[trainsize:].values)\n",
        "#Ensure the number of hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_loc', hidden_units=[19,15,11,7], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_LOC\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "UoS_IOAwf2u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3ba684-eb34-49f2-caf9-07e6342cde9c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f698953ccd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_loc', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.01300000e+03 7.00000000e+00 4.07984710e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01300000e+03 5.00000000e+00 4.07529363e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01800000e+03 1.20000000e+01 4.06017340e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [2.01400000e+03 9.00000000e+00 4.06777741e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [2.01700000e+03 7.00000000e+00 4.08226170e+01 ... 0.00000000e+00\n",
            "  1.00000000e+00 0.00000000e+00]\n",
            " [2.01700000e+03 1.40000000e+01 4.08964960e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_loc/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09145673 0.09145673 0.09145673 ... 0.09145673 0.09145673 0.09145673]\n",
            "[0.00086133 0.00086133 0.00086133 ... 0.00086133 0.00086133 0.00086133]\n",
            "The trained model has an aproximate error rate of 2.2522994060669705 which equates to 219%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite extensive training, the model is not accurately able to predict the number of collisions. This is inferred by the RMSE which is close to that of the mean RMSE. "
      ],
      "metadata": {
        "id": "Oir_cOA3ccIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "As shown above the given weather conditions for a particular day within New York, the number of collisions can be accurately predicted.\n",
        "\n",
        "Arguments can be made for both models; the linear regression models appear to be less efficient due to the higher RMSE values in comparison to the DNN models. In contrast the error rate is lower for the linear regression models. This suggests that although the DNN models produce more errors, but the margin of error is lower, due to the RMSE placing a larger weighting on larger errors.\n",
        "\n",
        "In hindsight the way location has been encoded does not allow for accurate predictions to be made as the number of collisions always tends towards 1 for a given location.\n",
        "\n",
        "It is clear that the models produced above can accurately predict the number of collisions as set out in the specification of the assignment.\n"
      ],
      "metadata": {
        "id": "qBaLwNJocvpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#References\n",
        "geeksforgeeks.org (2021) Read a zipped file as a Pandas DataFrame [online]. Available from <<https://www.geeksforgeeks.org/read-a-zipped-file-as-a-pandas-dataframe/>? [12 November 2022] \n",
        "\n",
        "IBM (n.d.) What is linear regression? [online]. Available from <<https://www.ibm.com/uk-en/topics/linear-regression>> [17 November 2022] \n",
        "\n",
        "Karhunen, J., Raiko, T. and Cho, K. (2015) 'Chapter 7 - Unsupervised deep learning: A short review.' In Advances in Independent Component Analysis and Learning Machines. Academic Press. Ch. 7. 135-142.\n",
        "\n",
        "Zhang, Z. (2019) Understand Data Normalization in Machine Learning [online]. Available from <<https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0>> [17 November 2022] \n",
        "\n",
        "Zulkifli, H. (2018) Understanding Learning Rates and How It Improves Performance in Deep Learning [online]. Available from <<https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10>> [17 November 2022] \n",
        "\n"
      ],
      "metadata": {
        "id": "iDBndm4x6xGv"
      }
    }
  ]
}