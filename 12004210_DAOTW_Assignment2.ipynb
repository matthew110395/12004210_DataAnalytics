{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthew110395/12004210_DataAnalytics/blob/main/12004210_DAOTW_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "This assignment builds on the New York taxi problem identified in assignment 1, where the City of New York is looking for a way to accurately predict the number of collisions on a particular day of the week. Within this document two different types of machine learning models will be utilised to predict the number of collisions. The linear relationships identified in assignment 1 will be used to create linear regression models. Deep Learning Neural Network (DNN) models will be used to predict the number of collisions where the relationship is not linear. "
      ],
      "metadata": {
        "id": "-MIIDzFYc6Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports\n",
        "To prepare data for machine learning the pandas package has been used, alongside the numpy package which has been used to aid with mathematical functions.\n",
        "\n",
        "As within part 1 of this assignment, the data file containing location data exceeds the size limit for hosting within github. To overcome this the file was zipped. To extract the data the zipfile package has been used.\n",
        "\n",
        "Within this document, TensorFlow is used for machine learning, with both linear regression models and a Deep Neural Network models. TensorFlow version 1 is unsupported within Google Colab, therefore must be installed using a package manager.\n",
        "\n",
        "Shutil is also imported to allow for file management, in particular the removal of saved models."
      ],
      "metadata": {
        "id": "PP_OBRRWE3tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "!pip install tensorflow==1.15.2\n",
        "import tensorflow as tf\n",
        "import shutil  "
      ],
      "metadata": {
        "id": "J3Vp_IJAE49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40a189e-58c2-4bc3-9175-69cfccc0c7b8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.50.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.38.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.3.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.14.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (2.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regressor\n",
        "Throughout assignment 1 a number of linear relationships were uncovered within the dataset. These relationships form the basis of the linear regression models below.\n",
        "\n",
        "A linear regressor is used to predict an output variable based on one or more input variables (IBM n.d.)."
      ],
      "metadata": {
        "id": "SxU2LFGDjN9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the accuracy of the model the target values are scaled. This reduces the range of collisions from 188-1161 to 0.1619... - 1 which allows for quicker training  (Zhang 2019)."
      ],
      "metadata": {
        "id": "vKNbHovb6hXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale to maximum number of collisions\n",
        "SCALE_COLLISIONS=1161"
      ],
      "metadata": {
        "id": "k-aEMQX9EuJJ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precipitation\n",
        "As uncovered in assignment 1; as the volume of precipitation increases, the number of collisions increase. \n",
        "\n",
        "The datafile produced in assignment is imported."
      ],
      "metadata": {
        "id": "VtJ7HqhA3bIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read File\n",
        "df_prcp = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean.csv', index_col=0, )\n",
        "print(df_prcp[:6])"
      ],
      "metadata": {
        "id": "Gr0ljmfBkDwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bdf141-043a-4995-ee97-61334d0bb0e7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create the linear regression model, extra columns are removed to simplify the model with the aim of reducing error values.\n",
        "\n",
        "The incomplete years (2012 and 2022) are removed, along with the erroneous data for 2020 and 2021.\n",
        "\n",
        "To aid with the production of the model the target is moved to the end of the data table."
      ],
      "metadata": {
        "id": "NnrlNKFM0R-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_prcp = df_prcp.drop(columns=['collision_date', 'temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] != 2012]\n",
        "df_prcp = df_prcp.loc[df_prcp[\"year\"] < 2020]\n",
        "cols = df_prcp['NUM_COLLISIONS']\n",
        "df_prcp = df_prcp.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move NUM_COLLISIONS to end\n",
        "df_prcp.insert(loc=9, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp[:6])\n",
        "df_prcp.describe()"
      ],
      "metadata": {
        "id": "nRcEly727YQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "5e5fcafc-f34a-4260-bfe7-19e65462c83d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "49    4  2016   1  28  0.09    0             0                 0     0   \n",
            "51    5  2014   1  17  0.00    1             0                 0     0   \n",
            "54    1  2016   1  25  0.02    0             0                 0     0   \n",
            "55    5  2016   1  29  0.00    0             0                 0     0   \n",
            "58    5  2017   1  20  0.00    0             0                 0     0   \n",
            "59    7  2013   1  13  0.01    1             0                 0     0   \n",
            "\n",
            "    NUM_COLLISIONS  \n",
            "49             681  \n",
            "51             589  \n",
            "54             658  \n",
            "55             645  \n",
            "58             605  \n",
            "59             373  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         prcp  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean      3.998425  2015.989366     6.518708    15.745569     0.122588   \n",
              "std       2.003542     1.996126     3.455211     8.803199     0.329143   \n",
              "min       1.000000  2013.000000     1.000000     1.000000     0.000000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000     0.000000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000     0.000000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000     0.060000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000     3.760000   \n",
              "\n",
              "               fog  rain_drizzle  snow_ice_pellets         hail  \\\n",
              "count  2539.000000   2539.000000       2539.000000  2539.000000   \n",
              "mean      0.253249      0.375345          0.085467     0.000394   \n",
              "std       0.434958      0.484307          0.279630     0.019846   \n",
              "min       0.000000      0.000000          0.000000     0.000000   \n",
              "25%       0.000000      0.000000          0.000000     0.000000   \n",
              "50%       0.000000      0.000000          0.000000     0.000000   \n",
              "75%       1.000000      1.000000          0.000000     0.000000   \n",
              "max       1.000000      1.000000          1.000000     1.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2539.000000  \n",
              "mean       599.135093  \n",
              "std        100.299164  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a20ca166-aecc-44cf-a757-1a5ed994ccda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998425</td>\n",
              "      <td>2015.989366</td>\n",
              "      <td>6.518708</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.003542</td>\n",
              "      <td>1.996126</td>\n",
              "      <td>3.455211</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20ca166-aecc-44cf-a757-1a5ed994ccda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a20ca166-aecc-44cf-a757-1a5ed994ccda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a20ca166-aecc-44cf-a757-1a5ed994ccda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove any bias within the dataset, it is randomly shuffled. The data is then split into the predictors and the target."
      ],
      "metadata": {
        "id": "eBk7xJt-Ag0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle = df_prcp.iloc[np.random.permutation(len(df_prcp))]\n",
        "\n",
        "# Select all apart from last col\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "8xT4g-UZFi01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d79d5c1-c365-47a0-bcdd-a3c992bbdabf"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail\n",
            "3492    4  2015  12  31  0.00    0             1                 0     0\n",
            "1307    5  2013   5  10  0.00    1             0                 0     0\n",
            "506     2  2016   2   9  0.06    0             0                 1     0\n",
            "1716    3  2019   6   5  0.00    0             1                 0     0\n",
            "486     5  2017   2  17  0.00    0             0                 0     0\n",
            "2648    5  2018   9  28  0.10    0             1                 0     0\n",
            "      day  year  mo  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  \\\n",
            "3492    4  2015  12  31  0.00    0             1                 0     0   \n",
            "1307    5  2013   5  10  0.00    1             0                 0     0   \n",
            "506     2  2016   2   9  0.06    0             0                 1     0   \n",
            "1716    3  2019   6   5  0.00    0             1                 0     0   \n",
            "486     5  2017   2  17  0.00    0             0                 0     0   \n",
            "2648    5  2018   9  28  0.10    0             1                 0     0   \n",
            "\n",
            "      NUM_COLLISIONS  \n",
            "3492             527  \n",
            "1307             698  \n",
            "506              571  \n",
            "1716             655  \n",
            "486              680  \n",
            "2648             712  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Target (last col)\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "O_xkzkVBQjL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594dd9a4-bd21-42a4-e3f8-a3bb0c50b108"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3492    527\n",
            "1307    698\n",
            "506     571\n",
            "1716    655\n",
            "486     680\n",
            "2648    712\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 9\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "NwSG_P_nRgPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3786bb06-907b-45ca-a5eb-b2b04df0e7fd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2031\n",
            "508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_prcp', ignore_errors=True)\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "pred = format(str(predslistscale))\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "AUKI-paISKeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872fd393-5e63-4e17-81bc-c164da8da108"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184c36790>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.28435007, step = 1\n",
            "INFO:tensorflow:global_step/sec: 610.428\n",
            "INFO:tensorflow:loss = 0.006029467, step = 101 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.111\n",
            "INFO:tensorflow:loss = 0.006208708, step = 201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 763.028\n",
            "INFO:tensorflow:loss = 0.00811196, step = 301 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.671\n",
            "INFO:tensorflow:loss = 0.006580451, step = 401 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.39\n",
            "INFO:tensorflow:loss = 0.0064119017, step = 501 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.678\n",
            "INFO:tensorflow:loss = 0.006235397, step = 601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.563\n",
            "INFO:tensorflow:loss = 0.0064507676, step = 701 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.948\n",
            "INFO:tensorflow:loss = 0.0046583666, step = 801 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.994\n",
            "INFO:tensorflow:loss = 0.007425333, step = 901 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.383\n",
            "INFO:tensorflow:loss = 0.0071029505, step = 1001 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.367\n",
            "INFO:tensorflow:loss = 0.007856553, step = 1101 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.096\n",
            "INFO:tensorflow:loss = 0.008026991, step = 1201 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 762.721\n",
            "INFO:tensorflow:loss = 0.006906911, step = 1301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.059\n",
            "INFO:tensorflow:loss = 0.0066928538, step = 1401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.996\n",
            "INFO:tensorflow:loss = 0.0058590914, step = 1501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.551\n",
            "INFO:tensorflow:loss = 0.007314265, step = 1601 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.395\n",
            "INFO:tensorflow:loss = 0.0072767627, step = 1701 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.813\n",
            "INFO:tensorflow:loss = 0.0057639307, step = 1801 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.095\n",
            "INFO:tensorflow:loss = 0.0055811442, step = 1901 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.681\n",
            "INFO:tensorflow:loss = 0.0053872583, step = 2001 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.26\n",
            "INFO:tensorflow:loss = 0.0068361387, step = 2101 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.443\n",
            "INFO:tensorflow:loss = 0.007955866, step = 2201 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.374\n",
            "INFO:tensorflow:loss = 0.004962411, step = 2301 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.423\n",
            "INFO:tensorflow:loss = 0.0064429003, step = 2401 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.323\n",
            "INFO:tensorflow:loss = 0.0059308987, step = 2501 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.214\n",
            "INFO:tensorflow:loss = 0.0057227802, step = 2601 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.224\n",
            "INFO:tensorflow:loss = 0.0064573046, step = 2701 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.9\n",
            "INFO:tensorflow:loss = 0.006172032, step = 2801 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.779\n",
            "INFO:tensorflow:loss = 0.00801239, step = 2901 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.265\n",
            "INFO:tensorflow:loss = 0.008003514, step = 3001 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.754\n",
            "INFO:tensorflow:loss = 0.009353781, step = 3101 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.347\n",
            "INFO:tensorflow:loss = 0.006517724, step = 3201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.653\n",
            "INFO:tensorflow:loss = 0.007837445, step = 3301 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.529\n",
            "INFO:tensorflow:loss = 0.0060175676, step = 3401 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.454\n",
            "INFO:tensorflow:loss = 0.0052023306, step = 3501 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.995\n",
            "INFO:tensorflow:loss = 0.0067790123, step = 3601 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.629\n",
            "INFO:tensorflow:loss = 0.0049821055, step = 3701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.851\n",
            "INFO:tensorflow:loss = 0.005931261, step = 3801 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 300.947\n",
            "INFO:tensorflow:loss = 0.0065164524, step = 3901 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.278\n",
            "INFO:tensorflow:loss = 0.0061863647, step = 4001 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.157\n",
            "INFO:tensorflow:loss = 0.004513663, step = 4101 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.232\n",
            "INFO:tensorflow:loss = 0.004990297, step = 4201 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 295.958\n",
            "INFO:tensorflow:loss = 0.00699097, step = 4301 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.865\n",
            "INFO:tensorflow:loss = 0.0057783835, step = 4401 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 214.002\n",
            "INFO:tensorflow:loss = 0.005527532, step = 4501 (0.469 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.733\n",
            "INFO:tensorflow:loss = 0.0063707875, step = 4601 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.945\n",
            "INFO:tensorflow:loss = 0.0053799395, step = 4701 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.646\n",
            "INFO:tensorflow:loss = 0.005120126, step = 4801 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.405\n",
            "INFO:tensorflow:loss = 0.007896943, step = 4901 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.105\n",
            "INFO:tensorflow:loss = 0.007009151, step = 5001 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.078\n",
            "INFO:tensorflow:loss = 0.006320907, step = 5101 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.256\n",
            "INFO:tensorflow:loss = 0.006098697, step = 5201 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.675\n",
            "INFO:tensorflow:loss = 0.005452591, step = 5301 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.833\n",
            "INFO:tensorflow:loss = 0.005169979, step = 5401 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.838\n",
            "INFO:tensorflow:loss = 0.006324291, step = 5501 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.277\n",
            "INFO:tensorflow:loss = 0.010015059, step = 5601 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 400.181\n",
            "INFO:tensorflow:loss = 0.0056345817, step = 5701 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.102\n",
            "INFO:tensorflow:loss = 0.006894122, step = 5801 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.475\n",
            "INFO:tensorflow:loss = 0.005814498, step = 5901 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 366.563\n",
            "INFO:tensorflow:loss = 0.004557113, step = 6001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.664\n",
            "INFO:tensorflow:loss = 0.006159946, step = 6101 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.225\n",
            "INFO:tensorflow:loss = 0.0048111724, step = 6201 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.28\n",
            "INFO:tensorflow:loss = 0.005655454, step = 6301 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.082\n",
            "INFO:tensorflow:loss = 0.0066588065, step = 6401 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.303\n",
            "INFO:tensorflow:loss = 0.0062325764, step = 6501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.261\n",
            "INFO:tensorflow:loss = 0.009714644, step = 6601 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.986\n",
            "INFO:tensorflow:loss = 0.007375148, step = 6701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.598\n",
            "INFO:tensorflow:loss = 0.0051732343, step = 6801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.548\n",
            "INFO:tensorflow:loss = 0.004705283, step = 6901 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.076\n",
            "INFO:tensorflow:loss = 0.0058283852, step = 7001 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.791\n",
            "INFO:tensorflow:loss = 0.0055763065, step = 7101 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.224\n",
            "INFO:tensorflow:loss = 0.0061665117, step = 7201 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.868\n",
            "INFO:tensorflow:loss = 0.0064396923, step = 7301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.612\n",
            "INFO:tensorflow:loss = 0.004723952, step = 7401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.93\n",
            "INFO:tensorflow:loss = 0.0046920525, step = 7501 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 795.569\n",
            "INFO:tensorflow:loss = 0.0069446466, step = 7601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.398\n",
            "INFO:tensorflow:loss = 0.008423658, step = 7701 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 798.412\n",
            "INFO:tensorflow:loss = 0.004839075, step = 7801 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.183\n",
            "INFO:tensorflow:loss = 0.008891412, step = 7901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.26\n",
            "INFO:tensorflow:loss = 0.0059559643, step = 8001 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.923\n",
            "INFO:tensorflow:loss = 0.0057020113, step = 8101 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.114\n",
            "INFO:tensorflow:loss = 0.0053385654, step = 8201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.867\n",
            "INFO:tensorflow:loss = 0.008999255, step = 8301 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.583\n",
            "INFO:tensorflow:loss = 0.0064664492, step = 8401 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.75\n",
            "INFO:tensorflow:loss = 0.0048507582, step = 8501 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.867\n",
            "INFO:tensorflow:loss = 0.0077269245, step = 8601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.538\n",
            "INFO:tensorflow:loss = 0.0051401877, step = 8701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.379\n",
            "INFO:tensorflow:loss = 0.0045297253, step = 8801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.481\n",
            "INFO:tensorflow:loss = 0.004936953, step = 8901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.895\n",
            "INFO:tensorflow:loss = 0.004428764, step = 9001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.198\n",
            "INFO:tensorflow:loss = 0.007652574, step = 9101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.933\n",
            "INFO:tensorflow:loss = 0.0063473643, step = 9201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.678\n",
            "INFO:tensorflow:loss = 0.005982277, step = 9301 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.009\n",
            "INFO:tensorflow:loss = 0.0067656944, step = 9401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 767.691\n",
            "INFO:tensorflow:loss = 0.005355211, step = 9501 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.4\n",
            "INFO:tensorflow:loss = 0.005350487, step = 9601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.269\n",
            "INFO:tensorflow:loss = 0.007836929, step = 9701 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.61\n",
            "INFO:tensorflow:loss = 0.005872808, step = 9801 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.08\n",
            "INFO:tensorflow:loss = 0.0070758876, step = 9901 (0.124 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0057841525.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 102.05434614543951\n",
            "Just using average = 600.2299359921221 has RMSE of 105.566287878724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A number of learning rates were used to determine a suitable learning rate for the model. As the learning rate decreases the overall time to train the dataset increases (Zulkifli 2018)."
      ],
      "metadata": {
        "id": "3uYG_ScZR3yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Error Rate\n",
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "1fifEsTD98hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9599cac-c431-4e12-a48e-da6acbacc6f8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21845a0e50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n",
            "[0.5122645  0.47875375 0.52287126 0.5635435  0.46389306 0.55077493\n",
            " 0.56979203 0.47948697 0.54274005 0.5035545  0.5411757  0.54123\n",
            " 0.5133076  0.48793462 0.55686814 0.48470786 0.53721666 0.50310105\n",
            " 0.47432306 0.5792667  0.54587805 0.4638464  0.5302459  0.4894051\n",
            " 0.55784094 0.5486665  0.50999916 0.46061707 0.5070047  0.5136187\n",
            " 0.53376424 0.53320867 0.51746637 0.5568299  0.51152563 0.5712332\n",
            " 0.5349731  0.49143696 0.4980978  0.53075117 0.50611013 0.5668902\n",
            " 0.5099612  0.53449446 0.5607861  0.5116442  0.54498    0.5537348\n",
            " 0.54023683 0.5213465  0.55704856 0.49917585 0.52356577 0.55058366\n",
            " 0.489171   0.5526224  0.5368833  0.48330578 0.5391398  0.48670578\n",
            " 0.51017135 0.54889625 0.5786473  0.56032413 0.50977975 0.51447284\n",
            " 0.48049292 0.48267332 0.5532888  0.5355576  0.46934167 0.4938137\n",
            " 0.54982024 0.4537593  0.48576254 0.5497053  0.5488554  0.54657066\n",
            " 0.59345555 0.49571893 0.4655688  0.504705   0.49902675 0.5296054\n",
            " 0.48964164 0.54712546 0.50650275 0.46399084 0.5053166  0.55089676\n",
            " 0.46235624 0.5372828  0.5251164  0.4660914  0.52908725 0.54862154\n",
            " 0.5446464  0.54298717 0.5226878  0.5630963  0.5970185  0.5177022\n",
            " 0.52253884 0.5326607  0.52936214 0.4503949  0.47778085 0.48127964\n",
            " 0.5013348  0.50163186 0.49138218 0.4965117  0.5197148  0.5505\n",
            " 0.50040174 0.46084183 0.56650734 0.5365601  0.5516496  0.51640046\n",
            " 0.48224673 0.48780283 0.53373903 0.5317239  0.52661085 0.5074755\n",
            " 0.5217122  0.5301556  0.47458735 0.49838656 0.5616193  0.46442246\n",
            " 0.58647484 0.55886644 0.52957565 0.4873158  0.46163112 0.52439475\n",
            " 0.54058504 0.58119875 0.5323516  0.51428014 0.49698192 0.4919624\n",
            " 0.4929311  0.5363306  0.48507077 0.46688697 0.50894064 0.56619394\n",
            " 0.45250085 0.50100344 0.54390657 0.51163507 0.46930197 0.5777619\n",
            " 0.54952466 0.47234756 0.57156277 0.47618264 0.48777175 0.56288016\n",
            " 0.5149122  0.53586394 0.5009805  0.45968398 0.5214099  0.5526196\n",
            " 0.52386886 0.52881885 0.52016747 0.50853735 0.5504946  0.4794129\n",
            " 0.48904684 0.49764827 0.54138905 0.57680875 0.57094073 0.5285267\n",
            " 0.5296823  0.54718643 0.45920107 0.50969356 0.5193512  0.47161922\n",
            " 0.53470486 0.50967103 0.54727674 0.48910242 0.5424346  0.49741375\n",
            " 0.5182201  0.532238   0.5599094  0.47559947 0.49563494 0.524032\n",
            " 0.5561868  0.57096887 0.56266487 0.45871687 0.5192802  0.49275076\n",
            " 0.5587234  0.52423394 0.51606715 0.5243241  0.488433   0.45144847\n",
            " 0.48979348 0.494943   0.5565037  0.5428917  0.52029085 0.5496739\n",
            " 0.51477647 0.5214099  0.4745806  0.5335944  0.5150351  0.4554738\n",
            " 0.48895785 0.55799234 0.52482736 0.50132483 0.5398974  0.56345046\n",
            " 0.4833397  0.49991864 0.5790738  0.51994157 0.49629894 0.55402935\n",
            " 0.5281257  0.57542574 0.55077845 0.54435384 0.53615457 0.52103466\n",
            " 0.558417   0.50142956 0.5328526  0.48535645 0.5412814  0.4726795\n",
            " 0.5188701  0.46676064 0.47258252 0.5347077  0.5028782  0.538524\n",
            " 0.5429659  0.46491066 0.5021715  0.51130545 0.50474054 0.5504043\n",
            " 0.46985713 0.48111776 0.52381873 0.49165604 0.5608557  0.5077654\n",
            " 0.5443033  0.5656466  0.53054816 0.55976397 0.51719725 0.49924648\n",
            " 0.55092806 0.50938725 0.5695912  0.52444714 0.5490389  0.51622444\n",
            " 0.49612066 0.5406858  0.48600098 0.5580542  0.44421935 0.46809906\n",
            " 0.48343003 0.46287358 0.5208142  0.54697883 0.5726039  0.4943833\n",
            " 0.50225616 0.5556044  0.57224596 0.533523   0.5408806  0.54726136\n",
            " 0.5130413  0.46570125 0.51400995 0.49782836 0.51413417 0.570078\n",
            " 0.50342864 0.49453184 0.5024433  0.49797833 0.5627055  0.53593045\n",
            " 0.4766287  0.46287644 0.49217787 0.49320972 0.4897873  0.45804763\n",
            " 0.5667701  0.4964063  0.52636343 0.54233927 0.5088625  0.5287521\n",
            " 0.5156112  0.54272044 0.4789966  0.5570814  0.48417175 0.5117241\n",
            " 0.5138491  0.47082993 0.4719821  0.536793   0.47799405 0.56762993\n",
            " 0.482385   0.52332217 0.54491645 0.548693   0.5665342  0.5198092\n",
            " 0.51366687 0.49949944 0.5191015  0.51915693 0.5234952  0.534336\n",
            " 0.54709464 0.5621447  0.5042577  0.5471836  0.55589783 0.47603327\n",
            " 0.5647192  0.5497968  0.50846803 0.5464685  0.52860993 0.49144885\n",
            " 0.52594364 0.5566265  0.5444429  0.5216891  0.525369   0.5068545\n",
            " 0.5558995  0.5196451  0.5626611  0.5563852  0.56692684 0.54032576\n",
            " 0.55747813 0.46462232 0.5356626  0.5050976  0.48186776 0.51970124\n",
            " 0.46535835 0.54222894 0.54779637 0.4840951  0.55473256 0.5140445\n",
            " 0.49464974 0.52162313 0.55103576 0.54832995 0.49566877 0.54011256\n",
            " 0.50698847 0.49650142 0.4948962  0.5003124  0.49854922 0.4869406\n",
            " 0.5182998  0.46793994 0.45240498 0.5220663  0.5048112  0.5366269\n",
            " 0.5501726  0.4932967  0.5337558  0.5127135  0.54263395 0.50049067\n",
            " 0.49717966 0.53088135 0.534373   0.45650002 0.49917296 0.49039373\n",
            " 0.5303377  0.5448794  0.49893013 0.5316706  0.53512114 0.5687227\n",
            " 0.48179087 0.5370867  0.524235   0.48209426 0.5351609  0.50777495\n",
            " 0.49293616 0.53348327 0.5090611  0.5679194  0.52127236 0.5211361\n",
            " 0.5042392  0.53924143 0.48800966 0.5196402  0.5289949  0.49116313\n",
            " 0.5544735  0.48979482 0.55569756 0.48244098 0.4962449  0.5364042\n",
            " 0.49037963 0.51661485 0.53805953 0.55724645 0.45742872 0.5049538\n",
            " 0.5337934  0.5746904  0.5079995  0.50881577 0.53079087 0.523422\n",
            " 0.4600336  0.48317108 0.52938056 0.56937796 0.4970212  0.51073635\n",
            " 0.5090481  0.57223403 0.5195844  0.5395309  0.54545534 0.51928496\n",
            " 0.45533302 0.57098025 0.46829605 0.51008624 0.5363101  0.5062597\n",
            " 0.4990715  0.46299368 0.50423515 0.5118291  0.49189633 0.52181846\n",
            " 0.4809112  0.5510523  0.4943907  0.5467006  0.5109687  0.5424451\n",
            " 0.50735545 0.5541022  0.5429656  0.5096968  0.55854124 0.5598163\n",
            " 0.5296845  0.5215249  0.4829458  0.53439146 0.5487325  0.54311717\n",
            " 0.55487025 0.51057196 0.5101764  0.45573092 0.49855977 0.54991853\n",
            " 0.48940682 0.48446718 0.46372685 0.50686836 0.49979448 0.5545436\n",
            " 0.5218025  0.46484894 0.5023761  0.496821  ]\n",
            "[0.45994832 0.52627046 0.52799311 0.49095607 0.39534884 0.52799311\n",
            " 0.63135228 0.42980189 0.63049096 0.4788975  0.57536606 0.53402239\n",
            " 0.53229974 0.60206718 0.54866494 0.41343669 0.45305771 0.56330749\n",
            " 0.50559862 0.58484065 0.49956934 0.42980189 0.60809647 0.40826873\n",
            " 0.57450474 0.4005168  0.55813953 0.46597761 0.50215332 0.40999139\n",
            " 0.56244617 0.27648579 0.44444444 0.55727821 0.52540913 0.48234281\n",
            " 0.59776055 0.45822567 0.48923342 0.50301464 0.47803618 0.54694229\n",
            " 0.47028424 0.5374677  0.47631352 0.60034453 0.5796727  0.43583118\n",
            " 0.52282515 0.54349699 0.4461671  0.62704565 0.58053402 0.62962963\n",
            " 0.47114556 0.60034453 0.5211025  0.51851852 0.5047373  0.64857881\n",
            " 0.4754522  0.53402239 0.53143842 0.58742463 0.53832903 0.70542636\n",
            " 0.41946598 0.39018088 0.53919035 0.59173127 0.4203273  0.47803618\n",
            " 0.54694229 0.35658915 0.58139535 0.56158484 0.61843239 0.37295435\n",
            " 0.58742463 0.63996555 0.38587425 0.43066322 0.51162791 0.41257537\n",
            " 0.44358312 0.63824289 0.61584841 0.39362618 0.52540913 0.45736434\n",
            " 0.39190353 0.48062016 0.32988803 0.42635659 0.55727821 0.49698536\n",
            " 0.53229974 0.48062016 0.47631352 0.60120586 0.47286822 0.50732127\n",
            " 0.64685616 0.25064599 0.57795004 0.36003445 0.48492679 0.47028424\n",
            " 0.5960379  0.54091301 0.57364341 0.4754522  0.63135228 0.62790698\n",
            " 0.54177433 0.40568475 0.45822567 0.34280792 0.53574505 0.43410853\n",
            " 0.49956934 0.4461671  0.4918174  0.45391904 0.63221361 0.67183463\n",
            " 0.46511628 0.60292851 0.32816537 0.66838932 0.47028424 0.46597761\n",
            " 0.3712317  0.64944014 0.5667528  0.33074935 0.48751077 0.56416882\n",
            " 0.5211025  0.57881137 0.57536606 0.59086994 0.4788975  0.4496124\n",
            " 0.49698536 0.44875108 0.41343669 0.45564169 0.65891473 0.37898363\n",
            " 0.39534884 0.42807924 0.22739018 0.66063738 0.49009475 0.60206718\n",
            " 0.55469423 0.39793282 0.63996555 0.41257537 0.51421189 0.54435831\n",
            " 0.68561585 0.49612403 0.54780362 0.42204996 0.61584841 0.6089578\n",
            " 0.45391904 0.50559862 0.55986219 0.64341085 0.58570198 0.48923342\n",
            " 0.7002584  0.46511628 0.54091301 0.62446167 0.42204996 0.45219638\n",
            " 0.44272179 0.49267873 0.31093885 0.45133506 0.51593454 0.50043066\n",
            " 0.41085271 0.52885444 0.45908699 0.45908699 0.51248923 0.56847545\n",
            " 0.56072351 0.54177433 0.56933678 0.44099914 0.63049096 0.69939707\n",
            " 0.45047373 0.46856158 0.44444444 0.41085271 0.50043066 0.52024117\n",
            " 0.50990525 0.65977606 0.48837209 0.32816537 0.55900086 0.33936262\n",
            " 0.35228252 0.68217054 0.6287683  0.32988803 0.55211025 0.50990525\n",
            " 0.6873385  0.60723514 0.40913006 0.54263566 0.56761413 0.40654608\n",
            " 0.43066322 0.37898363 0.46942291 0.44186047 0.4332472  0.58570198\n",
            " 0.4332472  0.52713178 0.625323   0.62790698 0.49698536 0.63652024\n",
            " 0.54694229 0.45908699 0.5994832  0.61412575 0.37639966 0.48751077\n",
            " 0.57881137 0.52627046 0.49267873 0.46080965 0.47114556 0.46597761\n",
            " 0.4461671  0.41429802 0.38587425 0.55641688 0.5374677  0.4788975\n",
            " 0.61843239 0.44013781 0.5538329  0.36606374 0.5081826  0.59000861\n",
            " 0.45391904 0.50559862 0.62790698 0.41257537 0.43583118 0.56158484\n",
            " 0.58225668 0.63824289 0.44013781 0.61068045 0.48837209 0.50215332\n",
            " 0.34969854 0.51765719 0.60034453 0.57105943 0.49870801 0.46167097\n",
            " 0.46339363 0.53057709 0.50301464 0.45650301 0.32730405 0.44358312\n",
            " 0.40137812 0.43927649 0.64857881 0.49095607 0.51593454 0.46511628\n",
            " 0.57278208 0.6744186  0.47459087 0.5994832  0.62704565 0.52368648\n",
            " 0.57536606 0.44272179 0.69336779 0.57192076 0.51507321 0.55555556\n",
            " 0.61068045 0.43755383 0.51335056 0.50904393 0.55555556 0.60981912\n",
            " 0.38587425 0.37209302 0.48320413 0.44702842 0.45305771 0.40482343\n",
            " 0.38845823 0.37984496 0.52971576 0.57019811 0.63479759 0.60034453\n",
            " 0.54349699 0.68217054 0.60551249 0.42549526 0.36434109 0.53488372\n",
            " 0.63652024 0.47717485 0.43410853 0.51248923 0.47975883 0.58570198\n",
            " 0.52024117 0.48492679 0.46683893 0.62101637 0.43927649 0.61154177\n",
            " 0.50387597 0.64857881 0.55555556 0.58225668 0.48492679 0.42721792\n",
            " 0.52282515 0.44702842 0.62790698 0.54608096 0.58914729 0.47028424\n",
            " 0.51507321 0.49009475 0.58656331 0.56158484 0.45478036 0.35745047\n",
            " 0.60292851 0.57019811 0.46597761 0.45822567 0.52799311 0.48751077\n",
            " 0.5538329  0.57019811 0.59173127 0.57536606 0.59345392 0.51507321\n",
            " 0.28251507 0.4625323  0.56330749 0.52713178 0.41602067 0.51937984\n",
            " 0.46856158 0.66666667 0.51679587 0.53402239 0.43152455 0.62704565\n",
            " 0.72265289 0.65202412 0.51851852 0.61584841 0.41257537 0.53660637\n",
            " 0.66063738 0.46080965 0.42291128 0.45047373 0.66236003 0.4918174\n",
            " 0.55124892 0.3910422  0.38329027 0.56589147 0.5047373  0.5245478\n",
            " 0.59431525 0.62273902 0.57019811 0.59776055 0.42894057 0.54263566\n",
            " 0.55469423 0.55555556 0.54694229 0.3875969  0.46167097 0.44530577\n",
            " 0.59086994 0.60292851 0.62273902 0.60809647 0.57536606 0.64427218\n",
            " 0.45478036 0.61498708 0.47286822 0.52024117 0.52368648 0.45564169\n",
            " 0.5994832  0.57622739 0.40568475 0.36778639 0.52627046 0.6287683\n",
            " 0.34797588 0.59173127 0.45650301 0.36606374 0.61757106 0.47372954\n",
            " 0.52885444 0.45564169 0.63738157 0.4788975  0.33936262 0.66063738\n",
            " 0.6416882  0.66666667 0.59776055 0.49956934 0.37812231 0.42635659\n",
            " 0.49784668 0.38156761 0.4625323  0.53919035 0.45822567 0.45047373\n",
            " 0.50387597 0.53143842 0.16192937 0.43152455 0.47286822 0.57795004\n",
            " 0.65374677 0.28682171 0.54005168 0.39018088 0.55469423 0.72437554\n",
            " 0.32385874 0.51421189 0.41085271 0.70887166 0.59345392 0.48148148\n",
            " 0.45478036 0.45908699 0.53574505 0.62704565 0.76141258 0.42807924\n",
            " 0.47975883 0.59345392 0.44358312 0.50129199 0.41343669 0.56072351\n",
            " 0.54177433 0.52885444 0.60723514 0.42291128 0.53402239 0.53660637\n",
            " 0.7329888  0.49612403 0.45994832 0.48664944 0.5667528  0.57019811\n",
            " 0.4039621  0.61068045 0.41343669 0.48062016 0.54263566 0.6709733\n",
            " 0.56158484 0.63049096 0.43669251 0.56761413 0.56761413 0.47975883\n",
            " 0.54866494 0.46339363 0.34022394 0.43755383]\n",
            "The trained model has an aproximate error rate of -7.264750952619738 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'day' : [1,1,1,10],\n",
        "         'year' : [2019,2019,2019,2020],\n",
        "         'mo' : [3,3,3,12],\n",
        "         'da' : [10,10,10,12],\n",
        "         'prcp' : [0,2.34,5.5,2.24],\n",
        "         'fog' : [0,0,1,1],\n",
        "         'rain_drizzle' : [0,1,1,1],\n",
        "         'snow_ice_pellets' : [0,0,0,0],\n",
        "         'hail' : [0,0,0,0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_prcp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRwTIlrs_nvk",
        "outputId": "5e66f5ab-8956-45bd-9268-88b913195625"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180c349d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[631.5835  628.92267 644.65247 542.87445]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two main tests have been applied to the model. The Route Mean Squared Error (RMSE) and a comparison between the target values in the testing dataset and the predicted values using the predictors in the testing dataset.\n",
        "\n",
        "Predominantly the RMSE of the model is lower than that of the average. This indicates that the model makes more accurate predictions compared to the average.\n",
        "\n",
        "Based on the relationship, the test data outputs results as expected."
      ],
      "metadata": {
        "id": "kKckcLmPVIMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dew Point (dewp)\n",
        "A relationship between dew point and the number of collisions was also uncovered in assignment 1. This linear relationship suggests that as the dew point increases the number of collisions increase. \n",
        "\n",
        "The process to produce the model follows the same process as the precipitation model."
      ],
      "metadata": {
        "id": "RB0Zq1024UmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_dewp = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/dewp_clean.csv', index_col=0, )\n",
        "print(df_dewp[:6])"
      ],
      "metadata": {
        "id": "d2NB6odM5G9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d677ac-3bf9-4ea7-bffb-688446b2cc5a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_dewp = df_dewp.drop(columns=['collision_date', 'temp', 'prcp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_dewp = df_dewp.loc[df_dewp[\"year\"] != 2012]\n",
        "df_dewp = df_dewp.loc[df_dewp[\"year\"] < 2020]\n",
        "cols = df_dewp['NUM_COLLISIONS']\n",
        "df_dewp = df_dewp.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move target to end\n",
        "df_dewp.insert(loc=5, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_dewp[:6])\n",
        "df_dewp.describe()"
      ],
      "metadata": {
        "id": "WwtmLQ6a5rHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "48221d99-452e-40f9-d4bc-18b64d9d2aac"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  dewp  NUM_COLLISIONS\n",
            "49    4  2016   1  28  24.4             681\n",
            "51    5  2014   1  17  35.8             589\n",
            "54    1  2016   1  25  21.2             658\n",
            "55    5  2016   1  29  36.8             645\n",
            "58    5  2017   1  20  32.5             605\n",
            "59    7  2013   1  13  44.9             373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day         year           mo           da         dewp  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      3.998434  2015.999217     6.524070    15.723679    44.163170   \n",
              "std       2.000391     2.000000     3.449676     8.801271    16.995303   \n",
              "min       1.000000  2013.000000     1.000000     1.000000    -6.700000   \n",
              "25%       2.000000  2014.000000     4.000000     8.000000    32.150000   \n",
              "50%       4.000000  2016.000000     7.000000    16.000000    45.300000   \n",
              "75%       6.000000  2018.000000    10.000000    23.000000    58.500000   \n",
              "max       7.000000  2019.000000    12.000000    31.000000    74.100000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2555.000000  \n",
              "mean       599.109980  \n",
              "std        100.277185  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8a28623-69c0-4d69-b01a-3093ac005d36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>dewp</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.998434</td>\n",
              "      <td>2015.999217</td>\n",
              "      <td>6.524070</td>\n",
              "      <td>15.723679</td>\n",
              "      <td>44.163170</td>\n",
              "      <td>599.109980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000391</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.449676</td>\n",
              "      <td>8.801271</td>\n",
              "      <td>16.995303</td>\n",
              "      <td>100.277185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8a28623-69c0-4d69-b01a-3093ac005d36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8a28623-69c0-4d69-b01a-3093ac005d36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8a28623-69c0-4d69-b01a-3093ac005d36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle Data\n",
        "shuffle = df_dewp.iloc[np.random.permutation(len(df_dewp))]\n",
        "#Select Predictors\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "KXbAqzNN694C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff99f739-fbda-48a5-ebff-7ba2d774dfe9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  dewp\n",
            "1587    2  2019   6  18  58.8\n",
            "2698    3  2016   9   7  66.8\n",
            "1724    5  2017   6  23  63.4\n",
            "1383    1  2018   5   7  49.7\n",
            "1877    5  2019   7  26  58.9\n",
            "2879    2  2013  10   1  51.8\n",
            "      day  year  mo  da  dewp  NUM_COLLISIONS\n",
            "1587    2  2019   6  18  58.8             721\n",
            "2698    3  2016   9   7  66.8             648\n",
            "1724    5  2017   6  23  63.4             793\n",
            "1383    1  2018   5   7  49.7             695\n",
            "1877    5  2019   7  26  58.9             650\n",
            "2879    2  2013  10   1  51.8             616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "iGbT5sAJ7KTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf311b7-e0c7-44df-a29f-ceac2ba4e86a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1587    721\n",
            "2698    648\n",
            "1724    793\n",
            "1383    695\n",
            "1877    650\n",
            "2879    616\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 5\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "vpHbBnml7PZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55f9db0-e258-48e7-cc2e-3393ae11c430"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2044\n",
            "511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_dewp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#test Model\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "j4GKf5BL7WI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25071b13-87ea-45e7-ed78-774149d5f624"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184825110>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.27910894, step = 1\n",
            "INFO:tensorflow:global_step/sec: 585.842\n",
            "INFO:tensorflow:loss = 0.0071757007, step = 101 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.49\n",
            "INFO:tensorflow:loss = 0.009145996, step = 201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.143\n",
            "INFO:tensorflow:loss = 0.006120279, step = 301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.497\n",
            "INFO:tensorflow:loss = 0.0068645384, step = 401 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.93\n",
            "INFO:tensorflow:loss = 0.0065441383, step = 501 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 718.277\n",
            "INFO:tensorflow:loss = 0.005712265, step = 601 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 756.416\n",
            "INFO:tensorflow:loss = 0.0065529943, step = 701 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 763.885\n",
            "INFO:tensorflow:loss = 0.0074291234, step = 801 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.516\n",
            "INFO:tensorflow:loss = 0.0064876494, step = 901 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.259\n",
            "INFO:tensorflow:loss = 0.0070132073, step = 1001 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 758.645\n",
            "INFO:tensorflow:loss = 0.007427176, step = 1101 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.352\n",
            "INFO:tensorflow:loss = 0.008275729, step = 1201 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.486\n",
            "INFO:tensorflow:loss = 0.008530104, step = 1301 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 377.271\n",
            "INFO:tensorflow:loss = 0.0061031026, step = 1401 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.276\n",
            "INFO:tensorflow:loss = 0.007176334, step = 1501 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.328\n",
            "INFO:tensorflow:loss = 0.0063570933, step = 1601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.481\n",
            "INFO:tensorflow:loss = 0.0072192913, step = 1701 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.851\n",
            "INFO:tensorflow:loss = 0.005751349, step = 1801 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.81\n",
            "INFO:tensorflow:loss = 0.00858137, step = 1901 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.227\n",
            "INFO:tensorflow:loss = 0.0068627414, step = 2001 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.978\n",
            "INFO:tensorflow:loss = 0.0047110915, step = 2101 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.977\n",
            "INFO:tensorflow:loss = 0.007619273, step = 2201 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.966\n",
            "INFO:tensorflow:loss = 0.0064425655, step = 2301 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.671\n",
            "INFO:tensorflow:loss = 0.006739822, step = 2401 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.782\n",
            "INFO:tensorflow:loss = 0.0068638753, step = 2501 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 399.443\n",
            "INFO:tensorflow:loss = 0.00650636, step = 2601 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.945\n",
            "INFO:tensorflow:loss = 0.006377356, step = 2701 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.298\n",
            "INFO:tensorflow:loss = 0.007627611, step = 2801 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.008\n",
            "INFO:tensorflow:loss = 0.0075903423, step = 2901 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.037\n",
            "INFO:tensorflow:loss = 0.008274168, step = 3001 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.169\n",
            "INFO:tensorflow:loss = 0.0057349103, step = 3101 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.107\n",
            "INFO:tensorflow:loss = 0.006691985, step = 3201 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.857\n",
            "INFO:tensorflow:loss = 0.0054842513, step = 3301 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.512\n",
            "INFO:tensorflow:loss = 0.0063920356, step = 3401 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.371\n",
            "INFO:tensorflow:loss = 0.006456484, step = 3501 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.174\n",
            "INFO:tensorflow:loss = 0.006904257, step = 3601 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.62\n",
            "INFO:tensorflow:loss = 0.0061804852, step = 3701 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.217\n",
            "INFO:tensorflow:loss = 0.005532725, step = 3801 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.91\n",
            "INFO:tensorflow:loss = 0.00870128, step = 3901 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.159\n",
            "INFO:tensorflow:loss = 0.005885532, step = 4001 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.723\n",
            "INFO:tensorflow:loss = 0.0061193057, step = 4101 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.281\n",
            "INFO:tensorflow:loss = 0.0062840246, step = 4201 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.34\n",
            "INFO:tensorflow:loss = 0.0058887666, step = 4301 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.889\n",
            "INFO:tensorflow:loss = 0.006267621, step = 4401 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.201\n",
            "INFO:tensorflow:loss = 0.0077075316, step = 4501 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.271\n",
            "INFO:tensorflow:loss = 0.0069782697, step = 4601 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 407.38\n",
            "INFO:tensorflow:loss = 0.0061693573, step = 4701 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.399\n",
            "INFO:tensorflow:loss = 0.0051371753, step = 4801 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.123\n",
            "INFO:tensorflow:loss = 0.0062765065, step = 4901 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.007\n",
            "INFO:tensorflow:loss = 0.0073586637, step = 5001 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.257\n",
            "INFO:tensorflow:loss = 0.006521263, step = 5101 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.876\n",
            "INFO:tensorflow:loss = 0.0051808357, step = 5201 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.35\n",
            "INFO:tensorflow:loss = 0.0064858664, step = 5301 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.698\n",
            "INFO:tensorflow:loss = 0.005778677, step = 5401 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.922\n",
            "INFO:tensorflow:loss = 0.006358114, step = 5501 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.448\n",
            "INFO:tensorflow:loss = 0.005667003, step = 5601 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.797\n",
            "INFO:tensorflow:loss = 0.006210869, step = 5701 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.214\n",
            "INFO:tensorflow:loss = 0.004809019, step = 5801 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.381\n",
            "INFO:tensorflow:loss = 0.006987954, step = 5901 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 294.482\n",
            "INFO:tensorflow:loss = 0.0070811426, step = 6001 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 369.968\n",
            "INFO:tensorflow:loss = 0.009145645, step = 6101 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 172.48\n",
            "INFO:tensorflow:loss = 0.005567722, step = 6201 (0.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.918\n",
            "INFO:tensorflow:loss = 0.0060405647, step = 6301 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.737\n",
            "INFO:tensorflow:loss = 0.0055036265, step = 6401 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.878\n",
            "INFO:tensorflow:loss = 0.005654744, step = 6501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.056\n",
            "INFO:tensorflow:loss = 0.008668926, step = 6601 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.518\n",
            "INFO:tensorflow:loss = 0.006052752, step = 6701 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.426\n",
            "INFO:tensorflow:loss = 0.0073277927, step = 6801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.715\n",
            "INFO:tensorflow:loss = 0.005175301, step = 6901 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.917\n",
            "INFO:tensorflow:loss = 0.0058476683, step = 7001 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.516\n",
            "INFO:tensorflow:loss = 0.007243996, step = 7101 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.561\n",
            "INFO:tensorflow:loss = 0.005623378, step = 7201 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.589\n",
            "INFO:tensorflow:loss = 0.006515202, step = 7301 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.93\n",
            "INFO:tensorflow:loss = 0.006132504, step = 7401 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.022\n",
            "INFO:tensorflow:loss = 0.005530668, step = 7501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.629\n",
            "INFO:tensorflow:loss = 0.00521371, step = 7601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.023\n",
            "INFO:tensorflow:loss = 0.0067268144, step = 7701 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.026\n",
            "INFO:tensorflow:loss = 0.0057989266, step = 7801 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.526\n",
            "INFO:tensorflow:loss = 0.007417523, step = 7901 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.6\n",
            "INFO:tensorflow:loss = 0.0070543485, step = 8001 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.967\n",
            "INFO:tensorflow:loss = 0.005738203, step = 8101 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.118\n",
            "INFO:tensorflow:loss = 0.006946933, step = 8201 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.124\n",
            "INFO:tensorflow:loss = 0.005553347, step = 8301 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 757.93\n",
            "INFO:tensorflow:loss = 0.0056874603, step = 8401 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.901\n",
            "INFO:tensorflow:loss = 0.0059882808, step = 8501 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.968\n",
            "INFO:tensorflow:loss = 0.0059762653, step = 8601 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 741.14\n",
            "INFO:tensorflow:loss = 0.007290546, step = 8701 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.976\n",
            "INFO:tensorflow:loss = 0.0073462366, step = 8801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.105\n",
            "INFO:tensorflow:loss = 0.0063031493, step = 8901 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 796.867\n",
            "INFO:tensorflow:loss = 0.005898542, step = 9001 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 805.876\n",
            "INFO:tensorflow:loss = 0.0066786343, step = 9101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.946\n",
            "INFO:tensorflow:loss = 0.007888571, step = 9201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.385\n",
            "INFO:tensorflow:loss = 0.0076215817, step = 9301 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.5\n",
            "INFO:tensorflow:loss = 0.005833526, step = 9401 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.404\n",
            "INFO:tensorflow:loss = 0.0068534315, step = 9501 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 757.781\n",
            "INFO:tensorflow:loss = 0.0060513746, step = 9601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 761.612\n",
            "INFO:tensorflow:loss = 0.0056732455, step = 9701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 710.521\n",
            "INFO:tensorflow:loss = 0.007188744, step = 9801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.487\n",
            "INFO:tensorflow:loss = 0.006826111, step = 9901 (0.118 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0069436403.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 93.96416755097607\n",
            "Just using average = 598.9432485322897 has RMSE of 102.3375683663379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "CmqqgLT09593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348a6751-fe91-45ba-f49b-3693ae4a37dc"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2193f8d590>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n",
            "[0.54108864 0.5150208  0.51542944 0.51455796 0.47583237 0.5577232\n",
            " 0.56107754 0.52491874 0.5058224  0.5312116  0.57578826 0.4976822\n",
            " 0.5146251  0.47125548 0.54165584 0.5187817  0.54353875 0.48916832\n",
            " 0.5086365  0.51474327 0.4938765  0.47406805 0.54567677 0.57583743\n",
            " 0.53132784 0.5793128  0.5340886  0.5401705  0.53567487 0.56672806\n",
            " 0.507975   0.5596787  0.53980374 0.52301604 0.47560015 0.49049875\n",
            " 0.52553046 0.48754847 0.5383884  0.49556622 0.5098874  0.529255\n",
            " 0.56506574 0.49334618 0.5572748  0.5790375  0.55949205 0.4743112\n",
            " 0.5073691  0.53109753 0.46992546 0.5120298  0.5085686  0.57224846\n",
            " 0.5523468  0.50943124 0.53462005 0.48818082 0.51841134 0.5310553\n",
            " 0.5350835  0.580653   0.5600857  0.5329062  0.5573527  0.5525702\n",
            " 0.5150917  0.518853   0.49951407 0.5492718  0.5072489  0.548728\n",
            " 0.51278436 0.48733842 0.48348555 0.5607031  0.46873987 0.5772446\n",
            " 0.54728687 0.5182029  0.47003058 0.48797196 0.58404195 0.5136731\n",
            " 0.5490102  0.44753367 0.5624638  0.5363252  0.5077698  0.5223185\n",
            " 0.5647131  0.53296053 0.5311435  0.45915756 0.5383896  0.52778465\n",
            " 0.50772107 0.48073635 0.46005115 0.5643885  0.52050877 0.53915364\n",
            " 0.47376418 0.5291812  0.5316149  0.57221764 0.50233936 0.5749045\n",
            " 0.5195794  0.58106124 0.5015247  0.52341264 0.5791856  0.54169655\n",
            " 0.5179704  0.49738026 0.58506763 0.562683   0.5014503  0.5359829\n",
            " 0.49600577 0.5417481  0.51964784 0.4918763  0.5395946  0.5456967\n",
            " 0.5258083  0.4615731  0.5589868  0.57399124 0.5266814  0.5556721\n",
            " 0.5204989  0.51010114 0.5629906  0.5677934  0.5099794  0.5101632\n",
            " 0.46556857 0.5130429  0.5088091  0.5477641  0.533126   0.5244356\n",
            " 0.4880653  0.51941603 0.5629181  0.5027197  0.5748539  0.53744197\n",
            " 0.4911248  0.55418473 0.5099713  0.5438294  0.5291913  0.51656616\n",
            " 0.5043808  0.49378875 0.5658045  0.5742666  0.5115534  0.5255683\n",
            " 0.5408959  0.5192384  0.52800554 0.4907549  0.5201664  0.5022712\n",
            " 0.52749896 0.49686885 0.5379528  0.4929482  0.49575558 0.5091372\n",
            " 0.52279586 0.4886876  0.479897   0.50207    0.5362723  0.46801957\n",
            " 0.5206949  0.51806706 0.54768634 0.5036697  0.5434192  0.4803427\n",
            " 0.49922448 0.550738   0.499836   0.5142034  0.5452298  0.48413566\n",
            " 0.55458874 0.47859424 0.50596595 0.5498642  0.5685965  0.47783923\n",
            " 0.5002379  0.4992798  0.5333279  0.4976158  0.48554757 0.55075973\n",
            " 0.48538044 0.52437603 0.50453764 0.48055372 0.5248616  0.49792236\n",
            " 0.52434886 0.5134821  0.55376095 0.53997666 0.5119878  0.52128774\n",
            " 0.54187113 0.54070324 0.523219   0.5140302  0.5822087  0.49417746\n",
            " 0.5053261  0.5448133  0.50911653 0.513521   0.4999316  0.5382092\n",
            " 0.5151459  0.5505595  0.5429388  0.4778663  0.5239519  0.51999915\n",
            " 0.56870246 0.5558545  0.5410267  0.54752064 0.55876815 0.5264027\n",
            " 0.55601645 0.5222852  0.49241278 0.5613162  0.5164091  0.567348\n",
            " 0.5418663  0.5409191  0.45717958 0.5568921  0.4891582  0.47621858\n",
            " 0.51051927 0.55769926 0.53311014 0.57283217 0.540937   0.5171946\n",
            " 0.5206638  0.55404264 0.5410526  0.53414035 0.53172547 0.57925946\n",
            " 0.5108401  0.5395705  0.55371046 0.45959055 0.5172581  0.543899\n",
            " 0.5540535  0.48851457 0.4640204  0.55025214 0.5303824  0.57901204\n",
            " 0.53455913 0.53971565 0.4788242  0.4715443  0.52637124 0.47154385\n",
            " 0.5630304  0.5567627  0.48489612 0.5056705  0.5084416  0.50329655\n",
            " 0.53464884 0.5233374  0.46753234 0.51766855 0.5644074  0.51348555\n",
            " 0.5140848  0.5589446  0.50416434 0.5675617  0.4962442  0.5457608\n",
            " 0.55659807 0.5254398  0.5732695  0.49685046 0.55320305 0.530385\n",
            " 0.529313   0.4881646  0.5098324  0.5423858  0.56070584 0.53553724\n",
            " 0.5166824  0.5069935  0.50816876 0.5695718  0.5595358  0.5234725\n",
            " 0.5594523  0.52237004 0.51563996 0.53060746 0.5079491  0.57450044\n",
            " 0.5430948  0.5135061  0.51167035 0.5339886  0.49223828 0.5103185\n",
            " 0.5102206  0.4854121  0.47086793 0.5418512  0.5783348  0.5213529\n",
            " 0.5813127  0.5075146  0.47741216 0.48958746 0.56194764 0.5175923\n",
            " 0.4644613  0.58068794 0.5542987  0.5444137  0.49073932 0.5381133\n",
            " 0.4745168  0.5213706  0.55103105 0.52668697 0.5738027  0.55382997\n",
            " 0.49778694 0.5263539  0.5095734  0.5291051  0.57043386 0.45855048\n",
            " 0.49511877 0.55450445 0.4908795  0.48974425 0.5609539  0.53970325\n",
            " 0.48845464 0.54853857 0.51469666 0.5511472  0.5042448  0.53032047\n",
            " 0.5183261  0.5024437  0.49122676 0.54270077 0.49579433 0.47879753\n",
            " 0.5648128  0.5349496  0.5063429  0.48789123 0.547935   0.46537974\n",
            " 0.5245902  0.5083281  0.5257869  0.535143   0.54618734 0.5672864\n",
            " 0.4815183  0.51203954 0.4788181  0.5242893  0.5639166  0.46593848\n",
            " 0.50493115 0.5047898  0.5403574  0.50033826 0.48278597 0.4537321\n",
            " 0.55885434 0.53192544 0.51250017 0.51003206 0.4967232  0.5751745\n",
            " 0.50074774 0.5264961  0.53491265 0.5035847  0.5333813  0.47456107\n",
            " 0.48825306 0.53684956 0.5042847  0.5111529  0.5397072  0.50899994\n",
            " 0.512863   0.5717247  0.4668577  0.53421354 0.5186316  0.50372183\n",
            " 0.5779205  0.49999714 0.54701155 0.48963317 0.5165203  0.5317221\n",
            " 0.5297121  0.47898808 0.48183885 0.4977342  0.5360973  0.49959457\n",
            " 0.55645806 0.528866   0.4522385  0.5559241  0.5109132  0.53523386\n",
            " 0.57489276 0.5703531  0.5460177  0.51864666 0.5199364  0.5047125\n",
            " 0.54501015 0.5124917  0.5206937  0.5671324  0.5209091  0.5401893\n",
            " 0.5630166  0.5206738  0.5197941  0.5517631  0.5457354  0.5360193\n",
            " 0.4801066  0.4926353  0.5575767  0.56088686 0.53406847 0.5528147\n",
            " 0.51076263 0.5361917  0.49752912 0.55641687 0.52756524 0.5296206\n",
            " 0.4913484  0.50925815 0.5321994  0.51275694 0.5121953  0.49233717\n",
            " 0.4713706  0.5205171  0.5384881  0.55368763 0.49089685 0.52918386\n",
            " 0.4834323  0.49148476 0.5431942  0.5091376  0.45677802 0.5164526\n",
            " 0.56503344 0.47267884 0.54127246 0.51009476 0.5562523  0.50759655\n",
            " 0.47628433 0.5593053  0.519566   0.53316087 0.46996322 0.50838274\n",
            " 0.57078654 0.5092215  0.57673067 0.5446872  0.4878115  0.5409762\n",
            " 0.4992038 ]\n",
            "[0.53574505 0.42721792 0.60120586 0.46856158 0.35917313 0.47631352\n",
            " 0.7002584  0.61154177 0.60206718 0.45822567 0.5047373  0.5081826\n",
            " 0.40913006 0.41085271 0.52627046 0.63479759 0.63652024 0.44099914\n",
            " 0.56158484 0.43496985 0.42635659 0.37898363 0.58914729 0.52627046\n",
            " 0.63135228 0.43152455 0.56761413 0.62273902 0.51507321 0.52713178\n",
            " 1.         0.46511628 0.60034453 0.49267873 0.39362618 0.45305771\n",
            " 0.63910422 0.47286822 0.26098191 0.46770026 0.4754522  0.70542636\n",
            " 0.52971576 0.44444444 0.52971576 0.48837209 0.5503876  0.43410853\n",
            " 0.42291128 0.46339363 0.4203273  0.39276486 0.46511628 0.51248923\n",
            " 0.33936262 0.43238587 0.64771748 0.46425495 0.49095607 0.4005168\n",
            " 0.57622739 0.5047373  0.59345392 0.52971576 0.49009475 0.65633075\n",
            " 0.58225668 0.44875108 0.46080965 0.64254953 0.48062016 0.45908699\n",
            " 0.5047373  0.40482343 0.4918174  0.56158484 0.36434109 0.52799311\n",
            " 0.61412575 0.55641688 0.49784668 0.38242894 0.53229974 0.40310078\n",
            " 0.47803618 0.4005168  0.51593454 0.41257537 0.47114556 0.49870801\n",
            " 0.65202412 0.54263566 0.54780362 0.56416882 0.49095607 0.61326443\n",
            " 0.54005168 0.40999139 0.36692506 0.56589147 0.46683893 0.54349699\n",
            " 0.52713178 0.6124031  0.52799311 0.57364341 0.40137812 0.51248923\n",
            " 0.74677003 0.54521964 0.48751077 0.41343669 0.51937984 0.51851852\n",
            " 0.49956934 0.41602067 0.4952627  0.66149871 0.53402239 0.65891473\n",
            " 0.42463394 0.60809647 0.39190353 0.53660637 0.48837209 0.55124892\n",
            " 0.50043066 0.43066322 0.56330749 0.5960379  0.59259259 0.5667528\n",
            " 0.55813953 0.43066322 0.56761413 0.62618432 0.46339363 0.53660637\n",
            " 0.36520241 0.42377261 0.57278208 0.57450474 0.60292851 0.4754522\n",
            " 0.55900086 0.51593454 0.63824289 0.47631352 0.57536606 0.45305771\n",
            " 0.45564169 0.58914729 0.38501292 0.65202412 0.54263566 0.44099914\n",
            " 0.5374677  0.50990525 0.61843239 0.63738157 0.49440138 0.53488372\n",
            " 0.60378984 0.49698536 0.44444444 0.53832903 0.57019811 0.52627046\n",
            " 0.46167097 0.48148148 0.51937984 0.50904393 0.4625323  0.46080965\n",
            " 0.48664944 0.49267873 0.49440138 0.44358312 0.49354005 0.33936262\n",
            " 0.58914729 0.57536606 0.47372954 0.54780362 0.6089578  0.4918174\n",
            " 0.47803618 0.43755383 0.43496985 0.59259259 0.48320413 0.40826873\n",
            " 0.50904393 0.58139535 0.60378984 0.54608096 0.3910422  0.44272179\n",
            " 0.51162791 0.56589147 0.36864772 0.56933678 0.45908699 0.68044789\n",
            " 0.5047373  0.66408269 0.41429802 0.51851852 0.56416882 0.30060293\n",
            " 0.48148148 0.91731266 0.52282515 0.63910422 0.57708872 0.4952627\n",
            " 0.45305771 0.5796727  0.75107666 0.51076658 0.53143842 0.53143842\n",
            " 0.42118863 0.4332472  0.76141258 0.70456503 0.38587425 0.56158484\n",
            " 0.55900086 0.62704565 0.61068045 0.58570198 0.47459087 0.42980189\n",
            " 0.52885444 0.47717485 0.82687339 0.63393626 0.5667528  0.5667528\n",
            " 0.58828596 0.64082687 0.4754522  0.56589147 0.47286822 0.4918174\n",
            " 0.51507321 0.56158484 0.60723514 0.47459087 0.60551249 0.44444444\n",
            " 0.39793282 0.52627046 0.44186047 0.47286822 0.57364341 0.53316107\n",
            " 0.5245478  0.64254953 0.47975883 0.52713178 0.58225668 0.5667528\n",
            " 0.63738157 0.64254953 0.57881137 0.38845823 0.49784668 0.62101637\n",
            " 0.57364341 0.39362618 0.36950904 0.55900086 0.53919035 0.54005168\n",
            " 0.58828596 0.49267873 0.47372954 0.33419466 0.56761413 0.38845823\n",
            " 0.49440138 0.57019811 0.34366925 0.55986219 0.43238587 0.52540913\n",
            " 0.56416882 0.48923342 0.44702842 0.51593454 0.40568475 0.66838932\n",
            " 0.60809647 0.4952627  0.50990525 0.51162791 0.583118   0.5667528\n",
            " 0.5503876  0.5245478  0.6089578  0.40913006 0.55641688 0.61154177\n",
            " 0.51765719 0.47372954 0.4952627  0.61929371 0.4918174  0.61498708\n",
            " 0.36950904 0.41774332 0.43583118 0.63996555 0.60120586 0.51248923\n",
            " 0.5994832  0.39362618 0.55813953 0.66666667 0.46856158 0.53919035\n",
            " 0.53660637 0.5960379  0.51851852 0.44186047 0.45650301 0.42118863\n",
            " 0.47631352 0.40913006 0.43238587 0.4496124  0.55900086 0.54780362\n",
            " 0.55211025 0.54694229 0.44530577 0.58656331 0.59173127 0.41085271\n",
            " 0.39793282 0.51851852 0.41257537 0.52971576 0.47114556 0.47114556\n",
            " 0.44875108 0.56847545 0.64427218 0.72782084 0.47975883 0.55727821\n",
            " 0.59862188 0.54866494 0.39879414 0.58656331 0.62360034 0.37812231\n",
            " 0.33936262 0.62790698 0.47803618 0.54521964 0.56330749 0.54866494\n",
            " 0.31438415 0.57450474 0.48492679 0.50129199 0.59431525 0.58828596\n",
            " 0.44702842 0.38501292 0.50301464 0.51937984 0.45219638 0.50732127\n",
            " 0.50990525 0.48664944 0.43496985 0.64857881 0.43927649 0.49698536\n",
            " 0.47459087 0.36606374 0.51248923 0.57364341 0.63221361 0.52540913\n",
            " 0.4788975  0.53229974 0.3875969  0.625323   0.56847545 0.4005168\n",
            " 0.55211025 0.48664944 0.44788975 0.54177433 0.39276486 0.34453058\n",
            " 0.53402239 0.66063738 0.39707149 0.44358312 0.40310078 0.54866494\n",
            " 0.45822567 0.56847545 0.66063738 0.50129199 0.52971576 0.47631352\n",
            " 0.44099914 0.48148148 0.45478036 0.42204996 0.48751077 0.49095607\n",
            " 0.46339363 0.4754522  0.33850129 0.51593454 0.5374677  0.45736434\n",
            " 0.59689922 0.43927649 0.51937984 0.43410853 0.6546081  0.56158484\n",
            " 0.46770026 0.38587425 0.39793282 0.53574505 0.6416882  0.5081826\n",
            " 0.52799311 0.49870801 0.51593454 0.56072351 0.45391904 0.65546942\n",
            " 0.60378984 0.49698536 0.6416882  0.47028424 0.41343669 0.48234281\n",
            " 0.45908699 0.47975883 0.54435831 0.57622739 0.42549526 0.57364341\n",
            " 0.68130922 0.50387597 0.59431525 0.57105943 0.65719208 0.49440138\n",
            " 0.39534884 0.44272179 0.56158484 0.64944014 0.55211025 0.63824289\n",
            " 0.54694229 0.58570198 0.45564169 0.54005168 0.49784668 0.57536606\n",
            " 0.52024117 0.50990525 0.53488372 0.53057709 0.52971576 0.64685616\n",
            " 0.3453919  0.65202412 0.49870801 0.42807924 0.51507321 0.47286822\n",
            " 0.44702842 0.51851852 0.63910422 0.50990525 0.37209302 0.59689922\n",
            " 0.60206718 0.33505599 0.55900086 0.53402239 0.49870801 0.59776055\n",
            " 0.48923342 0.50215332 0.51421189 0.60809647 0.51765719 0.51765719\n",
            " 0.50215332 0.41343669 0.68475452 0.54349699 0.33074935 0.55124892\n",
            " 0.43238587]\n",
            "The trained model has an aproximate error rate of -7.645719182234686 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'day' : [1,1,1,10],\n",
        "         'year' : [2019,2019,2019,2020],\n",
        "         'mo' : [3,3,3,12],\n",
        "         'da' : [10,10,10,12],\n",
        "         'dewp' : [0,2.34,5.5,2.24],\n",
        "         \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_dewp', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567b5422-06f0-48e5-d285-1b24f14a96a8",
        "id": "SrAmbEAeHknA"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f218474e550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[596.0713  598.4295  601.614   503.96735]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE for the dewp model is slightly lower in comparison to the model produced for precipitation. As the RMSE is lower than the RMSE of the mean, it shows that the model has a higher level of accuracy in comparison to the using the mean.\n",
        "\n",
        "Based on the relationship, the test data outputs results as expected."
      ],
      "metadata": {
        "id": "k_jNEZ_dS62M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visibility (visib)\n",
        "A relationship was also uncovered between visibility and the number of collisions. This is a negative linear relationship where the visibility increases the number of collisions decrease. \n",
        "\n",
        "The process to produce the model follows the same process as above."
      ],
      "metadata": {
        "id": "XfOkQa04Wgr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_visib = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/coldata.csv', index_col=0, )\n",
        "print(df_visib[:6])"
      ],
      "metadata": {
        "id": "tOsAfHzhWgr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497890c0-f7f2-4d5b-bc99-9ef2d216680d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  year  mo  da collision_date  NUM_COLLISIONS  temp  dewp     slp  \\\n",
            "1    5  2020   1  24     2020-01-24             524  37.3  33.7  1028.5   \n",
            "2    2  2021   1  12     2021-01-12             278  37.0  29.1  1019.0   \n",
            "3    5  2021   1  22     2021-01-22             254  36.5  28.4  1003.1   \n",
            "4    3  2021   1  27     2021-01-27             262  34.6  33.8  1012.8   \n",
            "5    2  2021   1  26     2021-01-26             263  31.9  23.4  1016.9   \n",
            "6    1  2022   1  24     2022-01-24             237  34.5  23.8  1010.6   \n",
            "\n",
            "   visib  ...   max   min  prcp   sndp  fog  rain_drizzle  snow_ice_pellets  \\\n",
            "1    6.5  ...  46.0  19.9  0.00  999.9    1             0                 0   \n",
            "2   10.0  ...  44.1  21.0  0.00  999.9    0             0                 0   \n",
            "3   10.0  ...  44.1  19.9  0.00  999.9    0             0                 0   \n",
            "4    8.0  ...  41.0  28.9  0.25  999.9    1             1                 0   \n",
            "5    9.0  ...  37.9  21.0  0.00  999.9    1             0                 0   \n",
            "6    9.7  ...  39.9  25.0  0.00  999.9    1             0                 0   \n",
            "\n",
            "   hail  thunder  tornado_funnel_cloud  \n",
            "1     0        0                     0  \n",
            "2     0        0                     0  \n",
            "3     0        0                     0  \n",
            "4     0        0                 11000  \n",
            "5     0     1000                  1000  \n",
            "6     0     1000                  1000  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_visib = df_visib.drop(columns=['collision_date', 'temp', 'prcp', 'slp','dewp','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_visib = df_visib.loc[df_visib[\"year\"] != 2012]\n",
        "df_visib = df_visib.loc[df_visib[\"year\"] < 2020]\n",
        "cols = df_visib['NUM_COLLISIONS']\n",
        "df_visib = df_visib.drop(columns=['NUM_COLLISIONS'])\n",
        "#Move target to end\n",
        "df_visib.insert(loc=5, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_visib[:6])\n",
        "df_visib.describe()"
      ],
      "metadata": {
        "id": "pAaWfrlBWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "7ebcd1d2-16e3-4f36-f11f-8d1e296583dc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    day  year  mo  da  visib  NUM_COLLISIONS\n",
            "49    4  2016   1  28   10.0             681\n",
            "51    5  2014   1  17    6.7             589\n",
            "54    1  2016   1  25   10.0             658\n",
            "55    5  2016   1  29   10.0             645\n",
            "58    5  2017   1  20   10.0             605\n",
            "59    7  2013   1  13    4.3             373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               day    year           mo           da        visib  \\\n",
              "count  2556.000000  2556.0  2556.000000  2556.000000  2556.000000   \n",
              "mean      3.999218  2016.0     6.524257    15.725743     8.295618   \n",
              "std       2.000391     2.0     3.449013     8.800168     2.207870   \n",
              "min       1.000000  2013.0     1.000000     1.000000     0.200000   \n",
              "25%       2.000000  2014.0     4.000000     8.000000     7.100000   \n",
              "50%       4.000000  2016.0     7.000000    16.000000     9.400000   \n",
              "75%       6.000000  2018.0    10.000000    23.000000    10.000000   \n",
              "max       7.000000  2019.0    12.000000    31.000000    10.000000   \n",
              "\n",
              "       NUM_COLLISIONS  \n",
              "count     2556.000000  \n",
              "mean       599.118936  \n",
              "std        100.258581  \n",
              "min        188.000000  \n",
              "25%        531.000000  \n",
              "50%        602.000000  \n",
              "75%        665.000000  \n",
              "max       1161.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab434ebf-6a46-4af2-8016-b3b1c99898ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>mo</th>\n",
              "      <th>da</th>\n",
              "      <th>visib</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.0</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "      <td>2556.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.999218</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>6.524257</td>\n",
              "      <td>15.725743</td>\n",
              "      <td>8.295618</td>\n",
              "      <td>599.118936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000391</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.449013</td>\n",
              "      <td>8.800168</td>\n",
              "      <td>2.207870</td>\n",
              "      <td>100.258581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab434ebf-6a46-4af2-8016-b3b1c99898ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab434ebf-6a46-4af2-8016-b3b1c99898ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab434ebf-6a46-4af2-8016-b3b1c99898ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the data\n",
        "shuffle = df_visib.iloc[np.random.permutation(len(df_visib))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])\n",
        "print(shuffle[:6])"
      ],
      "metadata": {
        "id": "9VOgsgFJWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f41be07-b5b0-491d-c50c-9d1a12e2e1d4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day  year  mo  da  visib\n",
            "2825    4  2019  10  24   10.0\n",
            "1856    1  2019   7   8   10.0\n",
            "1021    7  2015   4  12   10.0\n",
            "2935    3  2016  10   5   10.0\n",
            "1685    6  2018   6  23    5.7\n",
            "2187    2  2016   8   9   10.0\n",
            "      day  year  mo  da  visib  NUM_COLLISIONS\n",
            "2825    4  2019  10  24   10.0             613\n",
            "1856    1  2019   7   8   10.0             592\n",
            "1021    7  2015   4  12   10.0             443\n",
            "2935    3  2016  10   5   10.0             695\n",
            "1685    6  2018   6  23    5.7             513\n",
            "2187    2  2016   8   9   10.0             650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "dx2bYy6zWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60917e28-07c9-4a47-fe7d-b21625907959"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2825    613\n",
            "1856    592\n",
            "1021    443\n",
            "2935    695\n",
            "1685    513\n",
            "2187    650\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "print(trainsize)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "print(testsize)\n",
        "nppredictors = 5\n",
        "noutputs = 1"
      ],
      "metadata": {
        "id": "TKLeYNUiWgr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c72fa7c-90d2-4fe9-92d9-9f6a9c987061"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2044\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/linear_regression_trained_model_visib', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "pred = format(str(predslistscale))\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('LinearRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "J24fhLeNWgr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138ec4ae-9f5c-4d7b-888a-30196f964678"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21848e5050>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_visib/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.27459064, step = 1\n",
            "INFO:tensorflow:global_step/sec: 657.885\n",
            "INFO:tensorflow:loss = 0.009505197, step = 101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.991\n",
            "INFO:tensorflow:loss = 0.008307781, step = 201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.181\n",
            "INFO:tensorflow:loss = 0.0071506426, step = 301 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.623\n",
            "INFO:tensorflow:loss = 0.0070540262, step = 401 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.632\n",
            "INFO:tensorflow:loss = 0.007330095, step = 501 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 797.108\n",
            "INFO:tensorflow:loss = 0.0065802094, step = 601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.471\n",
            "INFO:tensorflow:loss = 0.0069297077, step = 701 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.927\n",
            "INFO:tensorflow:loss = 0.0067370385, step = 801 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.604\n",
            "INFO:tensorflow:loss = 0.0064073256, step = 901 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 732.192\n",
            "INFO:tensorflow:loss = 0.007578803, step = 1001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.24\n",
            "INFO:tensorflow:loss = 0.00867, step = 1101 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.069\n",
            "INFO:tensorflow:loss = 0.0065758135, step = 1201 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.068\n",
            "INFO:tensorflow:loss = 0.0068451595, step = 1301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.137\n",
            "INFO:tensorflow:loss = 0.007285299, step = 1401 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.249\n",
            "INFO:tensorflow:loss = 0.0064365007, step = 1501 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 756.277\n",
            "INFO:tensorflow:loss = 0.0049128546, step = 1601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.147\n",
            "INFO:tensorflow:loss = 0.007026744, step = 1701 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.1\n",
            "INFO:tensorflow:loss = 0.0075818216, step = 1801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.645\n",
            "INFO:tensorflow:loss = 0.0066062314, step = 1901 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 749.079\n",
            "INFO:tensorflow:loss = 0.006248415, step = 2001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.685\n",
            "INFO:tensorflow:loss = 0.005182577, step = 2101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.835\n",
            "INFO:tensorflow:loss = 0.0059992033, step = 2201 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.475\n",
            "INFO:tensorflow:loss = 0.006666119, step = 2301 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.386\n",
            "INFO:tensorflow:loss = 0.008299904, step = 2401 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.026\n",
            "INFO:tensorflow:loss = 0.005268941, step = 2501 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.067\n",
            "INFO:tensorflow:loss = 0.00860627, step = 2601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.288\n",
            "INFO:tensorflow:loss = 0.007959292, step = 2701 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 734.305\n",
            "INFO:tensorflow:loss = 0.008902807, step = 2801 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 756.775\n",
            "INFO:tensorflow:loss = 0.0068417303, step = 2901 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.191\n",
            "INFO:tensorflow:loss = 0.0083650425, step = 3001 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.053\n",
            "INFO:tensorflow:loss = 0.005891314, step = 3101 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.402\n",
            "INFO:tensorflow:loss = 0.0073317527, step = 3201 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 792.494\n",
            "INFO:tensorflow:loss = 0.00620248, step = 3301 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 774.061\n",
            "INFO:tensorflow:loss = 0.0084326295, step = 3401 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.734\n",
            "INFO:tensorflow:loss = 0.009049901, step = 3501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.061\n",
            "INFO:tensorflow:loss = 0.0061233398, step = 3601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.806\n",
            "INFO:tensorflow:loss = 0.006067221, step = 3701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.475\n",
            "INFO:tensorflow:loss = 0.005854753, step = 3801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.185\n",
            "INFO:tensorflow:loss = 0.0059032897, step = 3901 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 729.141\n",
            "INFO:tensorflow:loss = 0.0068065533, step = 4001 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.401\n",
            "INFO:tensorflow:loss = 0.008008072, step = 4101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 788.449\n",
            "INFO:tensorflow:loss = 0.0051779924, step = 4201 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 790.293\n",
            "INFO:tensorflow:loss = 0.005235537, step = 4301 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.695\n",
            "INFO:tensorflow:loss = 0.0067226123, step = 4401 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 794.43\n",
            "INFO:tensorflow:loss = 0.0076974332, step = 4501 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.549\n",
            "INFO:tensorflow:loss = 0.0072712135, step = 4601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.431\n",
            "INFO:tensorflow:loss = 0.006950234, step = 4701 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 775.501\n",
            "INFO:tensorflow:loss = 0.006682454, step = 4801 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 751.537\n",
            "INFO:tensorflow:loss = 0.0075197644, step = 4901 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.714\n",
            "INFO:tensorflow:loss = 0.008675145, step = 5001 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.078\n",
            "INFO:tensorflow:loss = 0.008781816, step = 5101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.529\n",
            "INFO:tensorflow:loss = 0.007178896, step = 5201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.706\n",
            "INFO:tensorflow:loss = 0.0064572757, step = 5301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 705.533\n",
            "INFO:tensorflow:loss = 0.0048701763, step = 5401 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.061\n",
            "INFO:tensorflow:loss = 0.0056445585, step = 5501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 752.886\n",
            "INFO:tensorflow:loss = 0.004679214, step = 5601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.283\n",
            "INFO:tensorflow:loss = 0.0065129786, step = 5701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.841\n",
            "INFO:tensorflow:loss = 0.00816129, step = 5801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 789.411\n",
            "INFO:tensorflow:loss = 0.00916107, step = 5901 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.034\n",
            "INFO:tensorflow:loss = 0.006169971, step = 6001 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 785.197\n",
            "INFO:tensorflow:loss = 0.0053570108, step = 6101 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.179\n",
            "INFO:tensorflow:loss = 0.0067909528, step = 6201 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.192\n",
            "INFO:tensorflow:loss = 0.0079180105, step = 6301 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 791.059\n",
            "INFO:tensorflow:loss = 0.007313135, step = 6401 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 794.058\n",
            "INFO:tensorflow:loss = 0.008182682, step = 6501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.186\n",
            "INFO:tensorflow:loss = 0.0057457527, step = 6601 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.871\n",
            "INFO:tensorflow:loss = 0.009332962, step = 6701 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.575\n",
            "INFO:tensorflow:loss = 0.004983102, step = 6801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.042\n",
            "INFO:tensorflow:loss = 0.0070657404, step = 6901 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.467\n",
            "INFO:tensorflow:loss = 0.006353494, step = 7001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.209\n",
            "INFO:tensorflow:loss = 0.006096108, step = 7101 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 750.296\n",
            "INFO:tensorflow:loss = 0.007504399, step = 7201 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.571\n",
            "INFO:tensorflow:loss = 0.006361652, step = 7301 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 772.009\n",
            "INFO:tensorflow:loss = 0.0074365623, step = 7401 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.665\n",
            "INFO:tensorflow:loss = 0.0062454185, step = 7501 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.697\n",
            "INFO:tensorflow:loss = 0.0076758293, step = 7601 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 710.06\n",
            "INFO:tensorflow:loss = 0.0052281683, step = 7701 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 718.054\n",
            "INFO:tensorflow:loss = 0.005865478, step = 7801 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.06\n",
            "INFO:tensorflow:loss = 0.0060072597, step = 7901 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.638\n",
            "INFO:tensorflow:loss = 0.005717426, step = 8001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.988\n",
            "INFO:tensorflow:loss = 0.006591914, step = 8101 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 760.238\n",
            "INFO:tensorflow:loss = 0.0053211963, step = 8201 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.264\n",
            "INFO:tensorflow:loss = 0.006874784, step = 8301 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.04\n",
            "INFO:tensorflow:loss = 0.007064792, step = 8401 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 770.445\n",
            "INFO:tensorflow:loss = 0.006961857, step = 8501 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.164\n",
            "INFO:tensorflow:loss = 0.006254699, step = 8601 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 784.655\n",
            "INFO:tensorflow:loss = 0.0059917914, step = 8701 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 786.07\n",
            "INFO:tensorflow:loss = 0.005850648, step = 8801 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.6\n",
            "INFO:tensorflow:loss = 0.007045309, step = 8901 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.716\n",
            "INFO:tensorflow:loss = 0.0060406034, step = 9001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 836.287\n",
            "INFO:tensorflow:loss = 0.0068637263, step = 9101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 770.82\n",
            "INFO:tensorflow:loss = 0.006374861, step = 9201 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.675\n",
            "INFO:tensorflow:loss = 0.0072171343, step = 9301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.324\n",
            "INFO:tensorflow:loss = 0.0061317505, step = 9401 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.461\n",
            "INFO:tensorflow:loss = 0.0062216986, step = 9501 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.607\n",
            "INFO:tensorflow:loss = 0.006983169, step = 9601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 783.155\n",
            "INFO:tensorflow:loss = 0.0076330435, step = 9701 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.71\n",
            "INFO:tensorflow:loss = 0.0062445304, step = 9801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.485\n",
            "INFO:tensorflow:loss = 0.0074864775, step = 9901 (0.119 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_visib/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.005660077.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression has RMSE of 93.30438690969395\n",
            "Just using average = 600.527397260274 has RMSE of 97.94271362023213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#testd = pd.DataFrame.from_records(predictors[trainsize:].values,columns=['day','year','month','da','prcp','fog','rain','snow','hail'])\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "0ZA56JV3Wgr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72167a8a-32f9-49ec-90fe-fa0f322f26d7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2184612150>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "512\n",
            "[0.51203763 0.56929165 0.49971002 0.53724235 0.5331647  0.4596194\n",
            " 0.5065841  0.5196762  0.4785367  0.50867176 0.5652723  0.4853061\n",
            " 0.52714485 0.5508507  0.5110668  0.49564546 0.5065315  0.4916242\n",
            " 0.51037836 0.5458444  0.5211129  0.48834977 0.5527546  0.50391304\n",
            " 0.5037089  0.49517938 0.5110578  0.5189451  0.5335094  0.5112895\n",
            " 0.4963031  0.5103712  0.5012339  0.53205377 0.5731611  0.55361545\n",
            " 0.55337316 0.50122494 0.5149181  0.49802685 0.5079251  0.48917392\n",
            " 0.51711273 0.5218819  0.4799218  0.5363916  0.49335063 0.5628964\n",
            " 0.5526853  0.47750828 0.48871735 0.4885171  0.5009921  0.52025706\n",
            " 0.49132308 0.5235904  0.5267433  0.50128156 0.5249217  0.4807761\n",
            " 0.51871735 0.54851705 0.46648568 0.51754755 0.51672596 0.4948084\n",
            " 0.4541079  0.55862695 0.50122607 0.5371028  0.4885851  0.563091\n",
            " 0.45256427 0.5198303  0.51368785 0.50315446 0.52299356 0.55308145\n",
            " 0.49334005 0.5486676  0.45334056 0.46320236 0.51783854 0.5497701\n",
            " 0.5620634  0.5276797  0.5162332  0.5170213  0.4965934  0.53592235\n",
            " 0.5566871  0.5105881  0.563803   0.55293685 0.52336955 0.48582587\n",
            " 0.51315135 0.47224262 0.4823065  0.51875395 0.49169073 0.5514865\n",
            " 0.51816535 0.50808233 0.491865   0.55566555 0.55633783 0.51450694\n",
            " 0.50135505 0.5012591  0.49317792 0.551061   0.5658793  0.55414444\n",
            " 0.5155473  0.46498403 0.55153966 0.50015885 0.47565606 0.49800155\n",
            " 0.578818   0.53191113 0.50613534 0.5206934  0.49257863 0.53193104\n",
            " 0.46980837 0.54089    0.4871836  0.53007376 0.52011    0.48947325\n",
            " 0.49949697 0.5154014  0.5261102  0.5490378  0.51382244 0.53601146\n",
            " 0.5584137  0.48373464 0.50698495 0.4938628  0.5300925  0.49796495\n",
            " 0.49174026 0.4993398  0.4995988  0.5536746  0.5571887  0.54920846\n",
            " 0.48107013 0.55720943 0.46793702 0.53099257 0.51655924 0.5699312\n",
            " 0.50404847 0.47838575 0.4824796  0.5429521  0.4935901  0.49431852\n",
            " 0.5035002  0.53430915 0.49497446 0.46307224 0.570035   0.52547437\n",
            " 0.48468342 0.55058837 0.46326745 0.5098612  0.49552485 0.5073505\n",
            " 0.47267255 0.50138384 0.5319164  0.45051166 0.47994125 0.50012887\n",
            " 0.49941906 0.5155849  0.44074023 0.46722537 0.54359967 0.52249813\n",
            " 0.53160965 0.52940446 0.5293143  0.47087136 0.48063937 0.46867552\n",
            " 0.48740256 0.50502515 0.5681491  0.50606155 0.51032704 0.47822657\n",
            " 0.5235557  0.48232892 0.5278218  0.4640812  0.5258037  0.5198077\n",
            " 0.44836193 0.4886846  0.46314472 0.48830846 0.5425115  0.5543131\n",
            " 0.48832956 0.5145724  0.5374341  0.4797099  0.49296904 0.48360503\n",
            " 0.48214868 0.5426228  0.51071674 0.5520636  0.5221811  0.52544373\n",
            " 0.52054226 0.5372299  0.54572195 0.45395648 0.5176153  0.47973403\n",
            " 0.48807803 0.48999092 0.5213104  0.54021436 0.53049725 0.5225597\n",
            " 0.49072802 0.45141235 0.54984385 0.49504027 0.48088676 0.4486275\n",
            " 0.4779938  0.5337854  0.49110213 0.4927739  0.47270158 0.4822699\n",
            " 0.46934178 0.5466148  0.48725018 0.48122966 0.5648721  0.4724256\n",
            " 0.53544664 0.5025251  0.5232479  0.5143011  0.45641416 0.47064862\n",
            " 0.5425929  0.48407462 0.5479373  0.54259753 0.53314245 0.5113878\n",
            " 0.4489989  0.5024516  0.5442611  0.51345533 0.52938354 0.5044102\n",
            " 0.52247894 0.50150317 0.48208293 0.48723796 0.49616152 0.5014949\n",
            " 0.5245498  0.5302125  0.5191029  0.47947297 0.5296931  0.5254648\n",
            " 0.55208594 0.4973616  0.49274006 0.55382985 0.49288762 0.5239713\n",
            " 0.46678516 0.53049195 0.49822307 0.47138837 0.45245442 0.5107868\n",
            " 0.50967336 0.51412356 0.5404622  0.55086976 0.4554987  0.47619858\n",
            " 0.49403366 0.47803056 0.5430428  0.5135534  0.48211947 0.4667766\n",
            " 0.5655517  0.5336911  0.5357829  0.47171584 0.55513084 0.5526431\n",
            " 0.5576662  0.5411068  0.45632586 0.4563072  0.57327    0.5292376\n",
            " 0.5062609  0.5491694  0.4871065  0.534338   0.5081734  0.48764\n",
            " 0.48792335 0.4843757  0.47468254 0.52206737 0.5268236  0.47610208\n",
            " 0.5240242  0.5492452  0.50368404 0.48352423 0.4799802  0.49996763\n",
            " 0.46597046 0.49036238 0.5666378  0.49638444 0.5074466  0.46270415\n",
            " 0.48136112 0.4758108  0.5235155  0.49640444 0.51379    0.48140898\n",
            " 0.4676461  0.49287635 0.52218056 0.47969475 0.53724265 0.48479518\n",
            " 0.54235435 0.5286229  0.56015503 0.5640686  0.50607014 0.4864616\n",
            " 0.5415367  0.45769194 0.5406648  0.50153434 0.46600893 0.49917182\n",
            " 0.54217404 0.48631123 0.53731984 0.4965237  0.553581   0.53486574\n",
            " 0.49782687 0.46552163 0.55319905 0.4964117  0.56330854 0.4926615\n",
            " 0.51511705 0.48973575 0.4967141  0.48210993 0.51153046 0.5109704\n",
            " 0.4943364  0.5356155  0.49062067 0.4976307  0.48123565 0.5287177\n",
            " 0.49430063 0.5072946  0.4548225  0.5685027  0.5259524  0.5689447\n",
            " 0.51863515 0.4482999  0.5460699  0.55600023 0.50036025 0.4563296\n",
            " 0.51556146 0.5320023  0.48996744 0.5343272  0.5649458  0.474057\n",
            " 0.49863395 0.46554935 0.5645336  0.46571788 0.5666088  0.5789059\n",
            " 0.5401667  0.5296164  0.5146444  0.45189115 0.57826686 0.5016073\n",
            " 0.5095208  0.5079355  0.5300477  0.48728096 0.51518667 0.48901603\n",
            " 0.48796287 0.5288336  0.53894687 0.5487506  0.5612592  0.501364\n",
            " 0.51073927 0.46960196 0.556449   0.5202604  0.54774296 0.5692953\n",
            " 0.52173144 0.51299495 0.5298965  0.5051066  0.45415542 0.5001797\n",
            " 0.5121589  0.5336395  0.57799226 0.4705132  0.5320099  0.5325722\n",
            " 0.53573096 0.48033637 0.52798545 0.5199958  0.5570687  0.5090936\n",
            " 0.49672198 0.4827074  0.49782825 0.4813657  0.5661708  0.49347243\n",
            " 0.49477854 0.49764082 0.47963157 0.49664918 0.51382184 0.5185517\n",
            " 0.5445689  0.5026472  0.568777   0.5617079  0.5379524  0.4526008\n",
            " 0.5111724  0.53365076 0.49925292 0.54698473 0.5085913  0.5220064\n",
            " 0.5150931  0.48557082 0.5057786  0.48328775 0.48108152 0.51851517\n",
            " 0.4776791  0.5023244  0.52025205 0.5065323  0.50280696 0.55804324\n",
            " 0.4710859  0.4891558  0.54744977 0.4538277  0.5630176  0.4638695\n",
            " 0.46452093 0.47020063 0.552427   0.51125765 0.57834744 0.45675597\n",
            " 0.52849644 0.44996372 0.50651455 0.544172   0.48511028 0.48059615\n",
            " 0.5005361  0.48237407]\n",
            "[0.60206718 0.34453058 0.4918174  0.48148148 0.51248923 0.39793282\n",
            " 0.64341085 0.53402239 0.53660637 0.51248923 0.35400517 0.5245478\n",
            " 0.58397933 0.51507321 0.43238587 0.49009475 0.5211025  0.5960379\n",
            " 0.52540913 0.53919035 0.51765719 0.59431525 0.53660637 0.48664944\n",
            " 0.3875969  0.48751077 0.60551249 0.59431525 0.5374677  0.40568475\n",
            " 0.66838932 0.58570198 0.4005168  0.6124031  0.28682171 0.49095607\n",
            " 0.58914729 0.40913006 0.56244617 0.53574505 0.5081826  0.34797588\n",
            " 0.5503876  0.5081826  0.39793282 0.51248923 0.49354005 0.64427218\n",
            " 0.61929371 0.45478036 0.44702842 0.54349699 0.64082687 0.70801034\n",
            " 0.55124892 0.44875108 0.53660637 0.47028424 0.55727821 0.57278208\n",
            " 0.48578811 0.69250646 0.45305771 0.5667528  0.60120586 0.41343669\n",
            " 0.39362618 0.52196382 0.53919035 0.54091301 0.44444444 0.52282515\n",
            " 0.43238587 0.53919035 0.55813953 0.54263566 0.52196382 0.64771748\n",
            " 0.36175711 0.35228252 0.42118863 0.41085271 0.31007752 0.51248923\n",
            " 0.56416882 0.34625323 0.51507321 0.61412575 0.33936262 0.61670973\n",
            " 0.67700258 0.54349699 0.50387597 0.59862188 0.60809647 0.45305771\n",
            " 0.59517657 0.40999139 0.43066322 0.57795004 0.4203273  0.63996555\n",
            " 0.59431525 0.58225668 0.57536606 0.60378984 0.6089578  0.62790698\n",
            " 0.34969854 0.52885444 0.52971576 0.46942291 0.36089578 0.6287683\n",
            " 0.55555556 0.47372954 0.43927649 0.46770026 0.51851852 0.54177433\n",
            " 0.47286822 0.48062016 0.65374677 0.48148148 0.50904393 0.56330749\n",
            " 0.42635659 0.31955211 0.62618432 0.47717485 0.70542636 0.54694229\n",
            " 0.60120586 0.56158484 0.46942291 0.56761413 0.54005168 0.5503876\n",
            " 0.55986219 0.47631352 0.57019811 0.47631352 0.4625323  0.50387597\n",
            " 0.48062016 0.61068045 0.57708872 0.48837209 0.53057709 0.52799311\n",
            " 0.6089578  0.54952627 0.56847545 0.50990525 0.59862188 0.60292851\n",
            " 0.41946598 0.39879414 0.51593454 0.37898363 0.40568475 0.58053402\n",
            " 0.38845823 0.59259259 0.49870801 0.43496985 0.58914729 0.48923342\n",
            " 0.374677   0.47028424 0.50732127 0.45219638 0.625323   0.57536606\n",
            " 0.47200689 0.43238587 0.57795004 0.36950904 0.55297158 0.625323\n",
            " 0.52799311 0.46856158 0.36864772 0.45219638 0.52368648 0.60809647\n",
            " 0.46683893 0.57881137 0.57622739 0.41429802 0.51851852 0.39534884\n",
            " 0.41343669 0.50645995 0.4952627  0.45219638 0.63996555 0.44702842\n",
            " 0.59431525 0.51679587 0.57450474 0.37553833 0.47631352 0.55211025\n",
            " 0.41774332 0.59000861 0.44875108 0.4754522  0.50990525 0.60981912\n",
            " 0.36606374 0.51593454 0.63738157 0.41774332 0.49095607 0.80878553\n",
            " 0.4332472  0.58570198 0.55555556 0.43583118 0.60120586 0.56072351\n",
            " 0.52282515 0.49784668 0.56330749 0.39793282 0.53919035 0.54866494\n",
            " 0.43496985 0.30060293 0.62015504 0.55986219 0.4496124  0.41429802\n",
            " 0.4461671  0.45305771 0.5667528  0.41343669 0.46511628 0.38329027\n",
            " 0.40999139 0.5667528  0.47114556 0.65030146 0.40223945 0.40740741\n",
            " 0.57450474 0.54866494 0.43238587 0.45391904 0.45908699 0.52713178\n",
            " 0.53057709 0.55900086 0.54091301 0.46511628 0.34969854 0.48492679\n",
            " 0.59086994 0.45305771 0.63738157 0.62101637 0.44186047 0.44358312\n",
            " 0.38845823 0.52713178 0.58225668 0.57622739 0.5667528  0.55555556\n",
            " 0.52971576 0.47459087 0.47286822 0.38242894 0.43669251 0.50387597\n",
            " 0.47459087 0.53057709 0.48492679 0.4788975  0.5211025  0.43755383\n",
            " 0.52196382 0.44875108 0.47975883 0.53143842 0.34797588 0.36950904\n",
            " 0.583118   0.47631352 0.54177433 0.37639966 0.42291128 0.68561585\n",
            " 0.54177433 0.68217054 0.59862188 0.4918174  0.33936262 0.49267873\n",
            " 0.51076658 0.38501292 0.51679587 0.36606374 0.5994832  0.40310078\n",
            " 0.3712317  0.53316107 0.37295435 0.42894057 0.55727821 0.63135228\n",
            " 0.36778639 0.52799311 0.47717485 0.38845823 0.53402239 0.61757106\n",
            " 0.57364341 0.42549526 0.51421189 0.56072351 0.52713178 0.47114556\n",
            " 0.60292851 0.42549526 0.43583118 0.65719208 0.46683893 0.52282515\n",
            " 0.4039621  0.50732127 0.5211025  0.49956934 0.45908699 0.55986219\n",
            " 0.42807924 0.43496985 0.33763997 0.42377261 0.44186047 0.47803618\n",
            " 0.63135228 0.48492679 0.59345392 0.45736434 0.53488372 0.45478036\n",
            " 0.48492679 0.59776055 0.51679587 0.50387597 0.55469423 0.50990525\n",
            " 0.55641688 0.35486649 0.5503876  0.62446167 0.48837209 0.43066322\n",
            " 0.60809647 0.33419466 0.62962963 0.50387597 0.60723514 0.44013781\n",
            " 0.6709733  0.57192076 0.46683893 0.52971576 0.52885444 0.53574505\n",
            " 0.33936262 0.40826873 0.60034453 0.64857881 0.39276486 0.53316107\n",
            " 0.54091301 0.54349699 0.43238587 0.47372954 0.66925065 0.54952627\n",
            " 0.60292851 0.6124031  0.58484065 0.54521964 0.55900086 0.69853575\n",
            " 0.53057709 0.53229974 0.39965547 0.52713178 0.60809647 0.55555556\n",
            " 0.54435831 0.36434109 0.26098191 0.53402239 0.4754522  0.59689922\n",
            " 0.56416882 0.59173127 0.4918174  0.58139535 0.53832903 0.49440138\n",
            " 0.58742463 0.49784668 0.42807924 0.55555556 0.60637382 0.62187769\n",
            " 0.66063738 0.51507321 0.5503876  0.26614987 0.5503876  0.50904393\n",
            " 0.52885444 0.44530577 0.57105943 0.45822567 0.50387597 0.44358312\n",
            " 0.56158484 0.58828596 0.5667528  0.55900086 0.55727821 0.50043066\n",
            " 0.583118   0.51851852 0.55297158 0.60809647 0.55900086 0.56072351\n",
            " 0.38673557 0.57278208 0.53229974 0.56244617 0.40482343 0.45822567\n",
            " 0.51937984 0.54608096 0.55469423 0.38845823 0.48406546 0.47717485\n",
            " 0.50129199 0.60981912 0.56158484 0.52971576 0.52627046 0.72782084\n",
            " 0.50559862 0.59259259 0.59431525 0.47459087 0.53660637 0.51335056\n",
            " 0.4788975  0.47975883 0.60809647 0.53574505 0.60034453 0.6546081\n",
            " 0.56158484 0.61412575 0.56416882 0.54694229 0.55641688 0.4005168\n",
            " 0.63910422 0.45564169 0.61154177 0.57019811 0.57536606 0.49267873\n",
            " 0.55727821 0.44272179 0.57019811 0.44358312 0.41602067 0.5796727\n",
            " 0.45650301 0.41860465 0.60551249 0.63738157 0.54091301 0.45822567\n",
            " 0.44272179 0.55297158 0.43583118 0.43927649 0.53229974 0.3910422\n",
            " 0.49784668 0.60551249 0.56933678 0.54780362 0.63479759 0.416882\n",
            " 0.32213609 0.39534884 0.41085271 0.46770026 0.52024117 0.51765719\n",
            " 0.50215332 0.44358312]\n",
            "The trained model has an aproximate error rate of 0.4050294426851904 which equates to 0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'day' : [1,1,1,10],\n",
        "         'year' : [2019,2019,2019,2020],\n",
        "         'mo' : [3,3,3,12],\n",
        "         'da' : [10,10,10,12],\n",
        "         'visib' : [1,5,9.5,5],\n",
        "         \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model_visib', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3081032f-f2a7-47bd-8628-dab3cb3a43c9",
        "id": "us9wEUCuHvZj"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21848b7d90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_visib', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_visib/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[648.7901  633.99225 617.3446  546.5106 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the difference RMSE between the mean and the model is less, it is arguable that the model is not as accurate.\n",
        "\n",
        "Although the RMSE value indicates a weaker model, the error rate is lower indicating that there is a significant error increasing the RMSE.\n",
        "\n",
        "Based on the relationship, the test data outputs results as expected."
      ],
      "metadata": {
        "id": "ntCQ4Pkefi3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Neural Network (DNN)\n",
        "Although the primary outcome of assignment 1 was uncovering linear relationships, more complex relationships which cannot be predicted using a linear regressor were uncovered. In this case a Deep Learning Neural Network (DNN) can be used.\n",
        "\n",
        "A Deep Learning Neural Network (DNN) is a form of unsupervised learning, where a number of hidden layers are used to uncover non-linear relationships. Karhunen, Raiko and Cho (2015) infer that deep learning neural networks work in a similar way to the human brain. This is where both the relationship between the input and output data is explored, as well as the relationship between the underlying data."
      ],
      "metadata": {
        "id": "xIvme6cXJF9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precipitation (prcp)\n",
        "The process for training a DNN follows a similar process followed above for a Linear Regressor. The data cleansed and one hot encoded as part of assignment 1 is loaded from GitHub."
      ],
      "metadata": {
        "id": "cixnwflQxNZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/prcp_clean_dnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "F9YrBdhTYhyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d419947-fa9e-43b2-db2a-145bebf44bf3"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_prcp_dnn = df.drop(columns=['temp', 'dewp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud'])\n",
        "df_prcp_dnn = df_prcp_dnn.loc[df_prcp_dnn[\"year\"] != 2012]\n",
        "df_prcp_dnn = df_prcp_dnn.loc[df_prcp_dnn[\"year\"] < 2020]\n",
        "#Move target to the end\n",
        "cols = df_prcp_dnn['NUM_COLLISIONS']\n",
        "df_prcp_dnn = df_prcp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_prcp_dnn.insert(loc=26, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_prcp_dnn[:6])\n",
        "df_prcp_dnn.describe()"
      ],
      "metadata": {
        "id": "jw5elr-LbRBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "969b4cc2-f43d-4429-ae7a-063c858a4b99"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  Apr  Aug  Dec  \\\n",
            "49  2016  28  0.09    0             0                 0     0    0    0    0   \n",
            "51  2014  17  0.00    1             0                 0     0    0    0    0   \n",
            "54  2016  25  0.02    0             0                 0     0    0    0    0   \n",
            "55  2016  29  0.00    0             0                 0     0    0    0    0   \n",
            "58  2017  20  0.00    0             0                 0     0    0    0    0   \n",
            "59  2013  13  0.01    1             0                 0     0    0    0    0   \n",
            "\n",
            "    ...  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49  ...    0    0    0    0    0    0    0    0    1             681  \n",
            "51  ...    0    0    0    0    0    0    1    0    0             589  \n",
            "54  ...    0    0    0    0    0    1    0    0    0             658  \n",
            "55  ...    0    0    0    0    0    0    1    0    0             645  \n",
            "58  ...    0    0    0    0    0    0    1    0    0             605  \n",
            "59  ...    0    0    0    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 27 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da         prcp          fog  rain_drizzle  \\\n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000   2539.000000   \n",
              "mean   2015.989366    15.745569     0.122588     0.253249      0.375345   \n",
              "std       1.996126     8.803199     0.329143     0.434958      0.484307   \n",
              "min    2013.000000     1.000000     0.000000     0.000000      0.000000   \n",
              "25%    2014.000000     8.000000     0.000000     0.000000      0.000000   \n",
              "50%    2016.000000    16.000000     0.000000     0.000000      0.000000   \n",
              "75%    2018.000000    23.000000     0.060000     1.000000      1.000000   \n",
              "max    2019.000000    31.000000     3.760000     1.000000      1.000000   \n",
              "\n",
              "       snow_ice_pellets         hail          Apr          Aug          Dec  \\\n",
              "count       2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean           0.085467     0.000394     0.082316     0.083497     0.085467   \n",
              "std            0.279630     0.019846     0.274899     0.276687     0.279630   \n",
              "min            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%            0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max            1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "       ...          Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  ...  2539.000000  2539.000000  2539.000000  2539.000000  2539.000000   \n",
              "mean   ...     0.085467     0.079953     0.142970     0.142970     0.143364   \n",
              "std    ...     0.279630     0.271273     0.350111     0.350111     0.350512   \n",
              "min    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max    ...     1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2539.000000  2539.000000  2539.000000  2539.000000     2539.000000  \n",
              "mean      0.143757     0.142182     0.142576     0.142182      599.135093  \n",
              "std       0.350913     0.349305     0.349709     0.349305      100.299164  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9b60e9a-a99d-442e-bd55-4460b529ea39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>prcp</th>\n",
              "      <th>fog</th>\n",
              "      <th>rain_drizzle</th>\n",
              "      <th>snow_ice_pellets</th>\n",
              "      <th>hail</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "      <td>2539.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.989366</td>\n",
              "      <td>15.745569</td>\n",
              "      <td>0.122588</td>\n",
              "      <td>0.253249</td>\n",
              "      <td>0.375345</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.082316</td>\n",
              "      <td>0.083497</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085467</td>\n",
              "      <td>0.079953</td>\n",
              "      <td>0.142970</td>\n",
              "      <td>0.142970</td>\n",
              "      <td>0.143364</td>\n",
              "      <td>0.143757</td>\n",
              "      <td>0.142182</td>\n",
              "      <td>0.142576</td>\n",
              "      <td>0.142182</td>\n",
              "      <td>599.135093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.996126</td>\n",
              "      <td>8.803199</td>\n",
              "      <td>0.329143</td>\n",
              "      <td>0.434958</td>\n",
              "      <td>0.484307</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.019846</td>\n",
              "      <td>0.274899</td>\n",
              "      <td>0.276687</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.271273</td>\n",
              "      <td>0.350111</td>\n",
              "      <td>0.350111</td>\n",
              "      <td>0.350512</td>\n",
              "      <td>0.350913</td>\n",
              "      <td>0.349305</td>\n",
              "      <td>0.349709</td>\n",
              "      <td>0.349305</td>\n",
              "      <td>100.299164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.760000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9b60e9a-a99d-442e-bd55-4460b529ea39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9b60e9a-a99d-442e-bd55-4460b529ea39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9b60e9a-a99d-442e-bd55-4460b529ea39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "shuffle = df_prcp_dnn.iloc[np.random.permutation(len(df_prcp_dnn))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "rpJi3P_8YcIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebbf651-4d67-47c4-8ce0-6a573eb6b80e"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  prcp  fog  rain_drizzle  snow_ice_pellets  hail  Apr  Aug  \\\n",
            "2542  2013   2  0.00    1             1                 0     0    0    0   \n",
            "3410  2019  21  0.00    0             0                 0     0    0    0   \n",
            "220   2019   5  0.25    0             1                 0     0    0    0   \n",
            "3446  2015   6  0.00    1             0                 0     0    0    0   \n",
            "1328  2016  13  0.00    1             1                 0     0    0    0   \n",
            "2090  2015  14  0.00    0             1                 0     0    0    0   \n",
            "\n",
            "      Dec  ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "2542    0  ...    0    0    1    0    0    0    1    0    0    0  \n",
            "3410    1  ...    0    0    0    1    0    0    0    0    0    0  \n",
            "220     0  ...    0    0    0    1    0    0    0    0    0    0  \n",
            "3446    1  ...    0    0    0    0    0    1    0    0    0    0  \n",
            "1328    0  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2090    0  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select target as last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "a_A0EFvxZpeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d540ded-9ddb-4d48-a8ef-3720b9df2d93"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2542    431\n",
            "3410    520\n",
            "220     455\n",
            "3446    485\n",
            "1328    766\n",
            "2090    657\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "noutputs = 1\n",
        "# calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "bdO_kvOZZuii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6385c8ac-3866-4266-c6d1-fd4d0c7d9c10"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between the training of a DNN and linear regression model, is the addition of hidden layers. In order to optimise the trained model, the number of hidden layers, the number of nodes within each layer and the learning rate were all modified."
      ],
      "metadata": {
        "id": "XTeNjj2Rp1Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_prcp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "print(\"starting to train\");\n",
        "#Train Model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#Test model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "GaTuIaPRfMxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbae8103-098f-4270-f1d2-332b589352c8"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180bba350>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:loss = 1514.6118, step = 1\n",
            "INFO:tensorflow:global_step/sec: 346.132\n",
            "INFO:tensorflow:loss = 0.029177908, step = 101 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.571\n",
            "INFO:tensorflow:loss = 0.016058322, step = 201 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.067\n",
            "INFO:tensorflow:loss = 0.015163561, step = 301 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.908\n",
            "INFO:tensorflow:loss = 0.016746871, step = 401 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.915\n",
            "INFO:tensorflow:loss = 0.013372488, step = 501 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.683\n",
            "INFO:tensorflow:loss = 0.0124777965, step = 601 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.707\n",
            "INFO:tensorflow:loss = 0.016399944, step = 701 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.74\n",
            "INFO:tensorflow:loss = 0.011535076, step = 801 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.209\n",
            "INFO:tensorflow:loss = 0.010483248, step = 901 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.825\n",
            "INFO:tensorflow:loss = 0.013724584, step = 1001 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.524\n",
            "INFO:tensorflow:loss = 0.009215251, step = 1101 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.746\n",
            "INFO:tensorflow:loss = 0.009775566, step = 1201 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.926\n",
            "INFO:tensorflow:loss = 0.0083425045, step = 1301 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.443\n",
            "INFO:tensorflow:loss = 0.006575093, step = 1401 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.396\n",
            "INFO:tensorflow:loss = 0.0055236127, step = 1501 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.683\n",
            "INFO:tensorflow:loss = 0.008738838, step = 1601 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.888\n",
            "INFO:tensorflow:loss = 0.009320557, step = 1701 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.491\n",
            "INFO:tensorflow:loss = 0.006050408, step = 1801 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.746\n",
            "INFO:tensorflow:loss = 0.0050191423, step = 1901 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.682\n",
            "INFO:tensorflow:loss = 0.004848309, step = 2001 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.908\n",
            "INFO:tensorflow:loss = 0.0063092434, step = 2101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.96\n",
            "INFO:tensorflow:loss = 0.0052156583, step = 2201 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.442\n",
            "INFO:tensorflow:loss = 0.0050963657, step = 2301 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.983\n",
            "INFO:tensorflow:loss = 0.005437961, step = 2401 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.789\n",
            "INFO:tensorflow:loss = 0.009514207, step = 2501 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.363\n",
            "INFO:tensorflow:loss = 0.009010916, step = 2601 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.084\n",
            "INFO:tensorflow:loss = 0.014399463, step = 2701 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.766\n",
            "INFO:tensorflow:loss = 0.0049164398, step = 2801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.897\n",
            "INFO:tensorflow:loss = 0.01892249, step = 2901 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.515\n",
            "INFO:tensorflow:loss = 0.18750638, step = 3001 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.113\n",
            "INFO:tensorflow:loss = 0.020079479, step = 3101 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.29\n",
            "INFO:tensorflow:loss = 0.01156131, step = 3201 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.437\n",
            "INFO:tensorflow:loss = 0.14179371, step = 3301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.995\n",
            "INFO:tensorflow:loss = 0.0118639935, step = 3401 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.057\n",
            "INFO:tensorflow:loss = 0.013721268, step = 3501 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.876\n",
            "INFO:tensorflow:loss = 0.15806282, step = 3601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.224\n",
            "INFO:tensorflow:loss = 0.05553788, step = 3701 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.175\n",
            "INFO:tensorflow:loss = 0.06430066, step = 3801 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.219\n",
            "INFO:tensorflow:loss = 0.0066323997, step = 3901 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.845\n",
            "INFO:tensorflow:loss = 0.025036126, step = 4001 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.087\n",
            "INFO:tensorflow:loss = 0.0071939854, step = 4101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.904\n",
            "INFO:tensorflow:loss = 0.015679568, step = 4201 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.195\n",
            "INFO:tensorflow:loss = 0.0726856, step = 4301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.85\n",
            "INFO:tensorflow:loss = 0.015019229, step = 4401 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.812\n",
            "INFO:tensorflow:loss = 0.004768028, step = 4501 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.819\n",
            "INFO:tensorflow:loss = 0.004112129, step = 4601 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.383\n",
            "INFO:tensorflow:loss = 0.02896614, step = 4701 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.539\n",
            "INFO:tensorflow:loss = 0.13099411, step = 4801 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.333\n",
            "INFO:tensorflow:loss = 0.028867655, step = 4901 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.161\n",
            "INFO:tensorflow:loss = 0.009314643, step = 5001 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.024\n",
            "INFO:tensorflow:loss = 0.14616732, step = 5101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.671\n",
            "INFO:tensorflow:loss = 0.009860515, step = 5201 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.103\n",
            "INFO:tensorflow:loss = 0.008424191, step = 5301 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.151\n",
            "INFO:tensorflow:loss = 0.018145284, step = 5401 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.46\n",
            "INFO:tensorflow:loss = 0.031223293, step = 5501 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.56\n",
            "INFO:tensorflow:loss = 0.005011907, step = 5601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.58\n",
            "INFO:tensorflow:loss = 0.015467472, step = 5701 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.745\n",
            "INFO:tensorflow:loss = 0.010287999, step = 5801 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.218\n",
            "INFO:tensorflow:loss = 0.011073826, step = 5901 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.089\n",
            "INFO:tensorflow:loss = 0.03182149, step = 6001 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.038\n",
            "INFO:tensorflow:loss = 0.0054485844, step = 6101 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.143\n",
            "INFO:tensorflow:loss = 0.005300452, step = 6201 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.384\n",
            "INFO:tensorflow:loss = 0.07729699, step = 6301 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.694\n",
            "INFO:tensorflow:loss = 0.004417714, step = 6401 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.702\n",
            "INFO:tensorflow:loss = 0.20243946, step = 6501 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.513\n",
            "INFO:tensorflow:loss = 0.040653847, step = 6601 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.105\n",
            "INFO:tensorflow:loss = 0.05062607, step = 6701 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.09\n",
            "INFO:tensorflow:loss = 0.007862447, step = 6801 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.754\n",
            "INFO:tensorflow:loss = 0.016062263, step = 6901 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.285\n",
            "INFO:tensorflow:loss = 0.005071043, step = 7001 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.505\n",
            "INFO:tensorflow:loss = 0.036228456, step = 7101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.42\n",
            "INFO:tensorflow:loss = 0.0048509208, step = 7201 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.968\n",
            "INFO:tensorflow:loss = 0.08757273, step = 7301 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.766\n",
            "INFO:tensorflow:loss = 0.017843645, step = 7401 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.052\n",
            "INFO:tensorflow:loss = 0.015523685, step = 7501 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.838\n",
            "INFO:tensorflow:loss = 0.008317935, step = 7601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.363\n",
            "INFO:tensorflow:loss = 0.034012794, step = 7701 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.989\n",
            "INFO:tensorflow:loss = 0.004518575, step = 7801 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.885\n",
            "INFO:tensorflow:loss = 0.009294871, step = 7901 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.796\n",
            "INFO:tensorflow:loss = 0.01052511, step = 8001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.74\n",
            "INFO:tensorflow:loss = 0.010917718, step = 8101 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.625\n",
            "INFO:tensorflow:loss = 0.005910574, step = 8201 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.4\n",
            "INFO:tensorflow:loss = 0.0038122293, step = 8301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.702\n",
            "INFO:tensorflow:loss = 0.02235045, step = 8401 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.886\n",
            "INFO:tensorflow:loss = 0.0083654225, step = 8501 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.046\n",
            "INFO:tensorflow:loss = 0.011124741, step = 8601 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.157\n",
            "INFO:tensorflow:loss = 0.03268743, step = 8701 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.829\n",
            "INFO:tensorflow:loss = 0.015155327, step = 8801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.844\n",
            "INFO:tensorflow:loss = 0.008513825, step = 8901 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.615\n",
            "INFO:tensorflow:loss = 0.005237531, step = 9001 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.002\n",
            "INFO:tensorflow:loss = 0.0044748965, step = 9101 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.446\n",
            "INFO:tensorflow:loss = 0.015413883, step = 9201 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.452\n",
            "INFO:tensorflow:loss = 0.0040153675, step = 9301 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.7\n",
            "INFO:tensorflow:loss = 0.0051112743, step = 9401 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.394\n",
            "INFO:tensorflow:loss = 0.005287378, step = 9501 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.909\n",
            "INFO:tensorflow:loss = 0.0074687777, step = 9601 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.887\n",
            "INFO:tensorflow:loss = 0.004470391, step = 9701 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.803\n",
            "INFO:tensorflow:loss = 0.003958009, step = 9801 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.49\n",
            "INFO:tensorflow:loss = 0.0059280815, step = 9901 (0.189 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_prcp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0045371545.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 84.055815964759\n",
            "Just using average = 599.69768586903 has RMSE of 107.78744673447711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "#Ensure hidden layers match the model trained above\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "Ld6baV60hPOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30407ee0-19ac-4093-ce74-b4ee3efe8f42"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21b8005a10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508\n",
            "508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.50444597 0.44498342 0.49839872 0.5123872  0.5352444  0.52600855\n",
            " 0.569745   0.5445346  0.52861947 0.5235066  0.52895635 0.4999084\n",
            " 0.560666   0.5415916  0.54303545 0.48940796 0.4481277  0.47860855\n",
            " 0.5308289  0.5452089  0.5274996  0.5099086  0.48506683 0.42798704\n",
            " 0.48449367 0.4985029  0.53439444 0.57339257 0.5179083  0.5041413\n",
            " 0.42731422 0.48793334 0.43446678 0.5611958  0.55776614 0.488429\n",
            " 0.5438995  0.45518392 0.56067795 0.5307037  0.49741262 0.51700443\n",
            " 0.5169677  0.44484895 0.56041664 0.45509714 0.53598565 0.5090565\n",
            " 0.52829546 0.52326006 0.52145904 0.56543297 0.48814863 0.38606304\n",
            " 0.5357327  0.51590675 0.5131163  0.41825742 0.55698675 0.5412697\n",
            " 0.53855985 0.5941927  0.539051   0.52240103 0.57341546 0.51572937\n",
            " 0.5401296  0.44628114 0.51654714 0.46380728 0.5290274  0.39833015\n",
            " 0.5418796  0.4861681  0.4899754  0.43878764 0.5648858  0.5424122\n",
            " 0.5152473  0.5093693  0.52032846 0.515449   0.5158457  0.538521\n",
            " 0.5287613  0.5183181  0.58786386 0.504466   0.45372146 0.510529\n",
            " 0.5258917  0.6003074  0.5649461  0.5238852  0.4985692  0.48006696\n",
            " 0.52102417 0.44917482 0.52820724 0.5653798  0.41272157 0.4367594\n",
            " 0.48749107 0.5095684  0.49141163 0.53139156 0.39749187 0.5262298\n",
            " 0.58667225 0.5583915  0.52045006 0.5738043  0.46896976 0.5463714\n",
            " 0.5693702  0.5321993  0.5752761  0.5282609  0.5328712  0.5341458\n",
            " 0.5292842  0.49046558 0.5193395  0.5487804  0.5082235  0.43681282\n",
            " 0.42591256 0.42515367 0.520096   0.50789064 0.47518677 0.56814975\n",
            " 0.5487179  0.55964273 0.5693664  0.45017523 0.6224331  0.5137884\n",
            " 0.46717042 0.51257485 0.5168895  0.4359116  0.4695341  0.5230369\n",
            " 0.5503749  0.41350502 0.49675268 0.48619932 0.54125804 0.5752925\n",
            " 0.42531246 0.5729627  0.49652404 0.5348157  0.3855309  0.526689\n",
            " 0.5198452  0.5804822  0.53705734 0.4781403  0.56886595 0.38064617\n",
            " 0.5876345  0.56824154 0.57166284 0.46402305 0.5342962  0.51874536\n",
            " 0.57144207 0.49329537 0.5674669  0.5901317  0.55891055 0.49645847\n",
            " 0.3942005  0.46927398 0.5398883  0.527203   0.50152916 0.52460235\n",
            " 0.42012066 0.42153758 0.51793665 0.5892028  0.5647425  0.48653716\n",
            " 0.52438563 0.5638947  0.565082   0.4760663  0.54483646 0.4134311\n",
            " 0.5213458  0.5639643  0.46249646 0.53940624 0.6095943  0.49358696\n",
            " 0.38862294 0.44487613 0.48430485 0.50724214 0.5333931  0.5619697\n",
            " 0.54866356 0.45268768 0.514893   0.4657802  0.54797643 0.505227\n",
            " 0.46894497 0.5178265  0.5318684  0.43046325 0.60555404 0.50595206\n",
            " 0.38918155 0.48657697 0.546267   0.55105203 0.4879002  0.52777237\n",
            " 0.41069955 0.49004072 0.54080766 0.51130766 0.57889074 0.48876327\n",
            " 0.5320868  0.49295777 0.5666525  0.50573915 0.53865856 0.46530265\n",
            " 0.538114   0.5141062  0.54604286 0.44412154 0.47808522 0.4310779\n",
            " 0.4384498  0.41567177 0.57128805 0.51088566 0.5649454  0.5614328\n",
            " 0.57873124 0.5902409  0.54533    0.499654   0.5794286  0.5426678\n",
            " 0.54603237 0.563585   0.51170367 0.5531449  0.47655052 0.47160572\n",
            " 0.39568752 0.45032185 0.5455722  0.559359   0.45267195 0.52962226\n",
            " 0.46501082 0.5482134  0.59372944 0.6061496  0.411565   0.5286898\n",
            " 0.62281984 0.51502126 0.39099163 0.42284673 0.42709965 0.45857137\n",
            " 0.49052972 0.543868   0.5367097  0.49939507 0.53957075 0.4991941\n",
            " 0.5180883  0.41578597 0.5369753  0.5580968  0.5356068  0.50740093\n",
            " 0.52228206 0.48192614 0.56277794 0.5423531  0.55125946 0.46804088\n",
            " 0.38522142 0.52230877 0.54144853 0.5356154  0.58523935 0.50055164\n",
            " 0.48191637 0.48361582 0.48618597 0.5194146  0.50953    0.4490866\n",
            " 0.47410673 0.45792955 0.5257167  0.5434765  0.5865554  0.44287103\n",
            " 0.5217847  0.5175008  0.5026173  0.5089318  0.47208112 0.5855836\n",
            " 0.40842813 0.59567064 0.55972284 0.528459   0.53797907 0.46772307\n",
            " 0.54921    0.5509476  0.37096542 0.57015485 0.4659719  0.5013854\n",
            " 0.5326516  0.46103972 0.5206148  0.5496785  0.50405186 0.5062081\n",
            " 0.5346319  0.5155527  0.5231053  0.47719806 0.5335073  0.5052709\n",
            " 0.4955663  0.50133127 0.5321025  0.5695128  0.45610327 0.48074287\n",
            " 0.508249   0.4190578  0.53551906 0.59348434 0.5418071  0.505053\n",
            " 0.56527275 0.46210903 0.5744843  0.52577156 0.55074304 0.4759981\n",
            " 0.37541598 0.59108704 0.53028697 0.5861117  0.4611358  0.5512437\n",
            " 0.51490587 0.41511387 0.5375766  0.5536484  0.54119295 0.5147564\n",
            " 0.49364775 0.43266767 0.45427078 0.37144607 0.50786847 0.50506777\n",
            " 0.44729704 0.4241175  0.52775735 0.5623922  0.4318437  0.5385429\n",
            " 0.5306656  0.52609104 0.47566742 0.51028126 0.4362759  0.5042338\n",
            " 0.53012556 0.40816134 0.5470976  0.5439033  0.5052132  0.46781105\n",
            " 0.54736227 0.42439264 0.48495907 0.5751347  0.49208015 0.52982825\n",
            " 0.49487156 0.504368   0.5196232  0.5030531  0.48876423 0.5239698\n",
            " 0.5555963  0.3996262  0.43947595 0.57697433 0.5704426  0.42854732\n",
            " 0.41902775 0.4628839  0.50883    0.53057617 0.5118415  0.5154783\n",
            " 0.494986   0.4124512  0.51456517 0.5061626  0.5138082  0.36776918\n",
            " 0.5361089  0.6199617  0.5424432  0.5334224  0.5504765  0.5570044\n",
            " 0.5258116  0.3801841  0.48488063 0.38989586 0.5781974  0.49384922\n",
            " 0.5573148  0.49236554 0.48000163 0.47552294 0.59181255 0.6115653\n",
            " 0.43354124 0.5449869  0.5131723  0.42193192 0.48169702 0.5788514\n",
            " 0.5251743  0.5211808  0.5693764  0.5773534  0.48441118 0.5708675\n",
            " 0.5533709  0.5055961  0.5219416  0.507543   0.5375585  0.50500387\n",
            " 0.51261467 0.4817192  0.4109947  0.44637984 0.44588703 0.53414863\n",
            " 0.45868152 0.5344128  0.5621566  0.6057748  0.6261682  0.5319509\n",
            " 0.46638054 0.52670187 0.5436978  0.5689115  0.5187296  0.55502456\n",
            " 0.40253705 0.44579452 0.431302   0.5394215  0.49577707 0.49079937\n",
            " 0.51818174 0.5178146  0.48196763 0.47812122 0.5064127  0.49479812\n",
            " 0.52366346 0.56155485 0.6110191  0.49814814 0.4273576  0.4998979\n",
            " 0.48847717 0.51630086 0.54394525 0.61862034 0.55156034 0.5714821\n",
            " 0.53272575 0.5362405  0.5840787  0.43069834]\n",
            "[0.47286822 0.44788975 0.4918174  0.44788975 0.51248923 0.50732127\n",
            " 0.74677003 0.59086994 0.54952627 0.56416882 0.53402239 0.50215332\n",
            " 0.56416882 0.58914729 0.56330749 0.49698536 0.37209302 0.45908699\n",
            " 0.63738157 0.45822567 0.59345392 0.47286822 0.49870801 0.33505599\n",
            " 0.48320413 0.44875108 0.56761413 0.57536606 0.51248923 0.44702842\n",
            " 0.4918174  0.48406546 0.36950904 0.65202412 0.59345392 0.50990525\n",
            " 0.32988803 0.50559862 0.66149871 0.55297158 0.52799311 0.58053402\n",
            " 0.44444444 0.50043066 0.49095607 0.37984496 0.48492679 0.4918174\n",
            " 0.58397933 0.53229974 0.36434109 0.5081826  0.51162791 0.35400517\n",
            " 0.62618432 0.49870801 0.51076658 0.40137812 0.63910422 0.34022394\n",
            " 0.60292851 0.62618432 0.56330749 0.51593454 0.54435831 0.4005168\n",
            " 0.53832903 0.46511628 0.54780362 0.36434109 0.5796727  0.4332472\n",
            " 0.54349699 0.56847545 0.55900086 0.4496124  0.69164513 0.4918174\n",
            " 0.48234281 0.49956934 0.47114556 0.63996555 0.47459087 0.59862188\n",
            " 0.53229974 0.50215332 0.62704565 0.46942291 0.47286822 0.54694229\n",
            " 0.52024117 0.64685616 0.59517657 0.48234281 0.42894057 0.51765719\n",
            " 0.52024117 0.48148148 0.57019811 0.75107666 0.37639966 0.416882\n",
            " 0.45047373 0.47114556 0.34969854 0.6124031  0.33419466 0.51507321\n",
            " 0.60809647 0.58656331 0.36089578 0.57278208 0.5667528  0.55727821\n",
            " 0.45478036 0.54521964 0.67011197 0.74677003 0.53488372 0.52282515\n",
            " 0.5374677  0.45564169 0.54177433 0.68044789 0.48923342 0.45564169\n",
            " 0.43927649 0.39190353 0.52885444 0.38931955 0.49354005 0.59776055\n",
            " 0.54005168 0.56330749 0.58742463 0.50904393 0.56589147 0.54694229\n",
            " 0.51335056 0.53574505 0.48406546 0.4461671  0.3910422  0.54694229\n",
            " 0.58225668 0.38587425 0.44444444 0.51507321 0.50904393 0.56761413\n",
            " 0.45822567 0.5538329  0.43927649 0.4788975  0.42204996 0.61068045\n",
            " 0.6089578  0.59259259 0.49095607 0.34022394 0.64857881 0.33850129\n",
            " 0.7002584  0.63307494 0.68217054 0.34366925 0.65891473 0.53660637\n",
            " 0.53057709 0.45305771 0.60034453 0.70198105 0.47459087 0.58139535\n",
            " 0.3875969  0.5374677  0.61498708 0.41429802 0.51507321 0.52024117\n",
            " 0.41774332 0.43583118 0.46339363 0.59345392 0.58139535 0.50904393\n",
            " 0.50904393 0.59086994 0.50129199 0.31007752 0.5994832  0.40654608\n",
            " 0.48148148 0.65030146 0.50129199 0.54263566 0.53057709 0.47114556\n",
            " 0.39793282 0.44358312 0.46339363 0.54435831 0.43152455 0.49440138\n",
            " 0.5503876  0.55297158 0.51851852 0.57536606 0.58570198 0.41257537\n",
            " 0.49784668 0.57364341 0.54694229 0.41429802 0.62273902 0.56503015\n",
            " 0.29371232 0.45908699 0.50387597 0.46942291 0.47372954 0.58656331\n",
            " 0.45478036 0.50215332 0.50129199 0.33763997 0.57450474 0.42291128\n",
            " 0.54005168 0.4203273  0.56158484 0.43238587 0.48062016 0.34969854\n",
            " 0.5081826  0.4754522  0.37898363 0.39190353 0.42204996 0.36089578\n",
            " 0.46425495 0.38587425 0.48148148 0.5047373  0.59862188 0.55555556\n",
            " 0.61584841 0.52799311 0.46425495 0.47803618 0.4754522  0.45908699\n",
            " 0.54952627 0.62015504 0.55555556 0.48406546 0.54005168 0.45305771\n",
            " 0.59689922 0.39534884 0.76055125 0.49009475 0.40740741 0.60378984\n",
            " 0.30577089 0.63824289 0.54608096 0.66666667 0.34280792 0.50301464\n",
            " 0.66408269 0.62187769 0.37726098 0.41515935 0.40137812 0.54005168\n",
            " 0.42894057 0.63738157 0.68217054 0.52627046 0.59431525 0.53143842\n",
            " 0.46080965 0.45391904 0.31955211 0.66925065 0.52282515 0.43152455\n",
            " 0.60292851 0.42635659 0.55986219 0.50990525 0.64513351 0.41085271\n",
            " 0.32730405 0.51248923 0.51593454 0.55813953 0.61584841 0.48062016\n",
            " 0.37037037 0.4918174  0.39965547 0.55555556 0.68217054 0.47803618\n",
            " 0.46511628 0.45219638 0.48148148 0.59086994 0.53488372 0.40568475\n",
            " 0.52713178 0.63049096 0.50301464 0.44186047 0.54263566 0.60809647\n",
            " 0.45305771 0.71231697 0.63393626 0.57536606 0.59259259 0.41257537\n",
            " 0.53919035 0.55900086 0.45822567 0.55986219 0.45822567 0.5503876\n",
            " 0.51335056 0.46511628 0.54694229 0.5211025  0.50043066 0.58828596\n",
            " 0.54694229 0.48664944 0.54866494 0.4461671  0.76141258 0.54263566\n",
            " 0.54866494 0.50990525 0.63910422 0.61068045 0.44530577 0.58656331\n",
            " 0.45219638 0.4461671  0.57622739 0.52196382 0.45564169 0.44358312\n",
            " 0.5796727  0.42377261 0.65719208 0.52196382 0.50559862 0.35486649\n",
            " 0.4005168  0.60034453 0.51162791 0.5538329  0.46511628 0.6744186\n",
            " 0.47975883 0.39018088 0.54091301 0.60206718 0.53143842 0.60120586\n",
            " 0.57881137 0.43669251 0.51937984 0.37209302 0.33936262 0.54349699\n",
            " 0.43066322 0.44530577 0.49009475 0.52713178 0.44875108 0.35228252\n",
            " 0.5538329  0.60034453 0.60465116 0.54091301 0.4332472  0.59173127\n",
            " 0.55555556 0.33936262 0.54091301 0.59517657 0.53057709 0.48148148\n",
            " 0.49440138 0.39276486 0.43238587 0.66063738 0.44272179 0.56589147\n",
            " 0.25064599 0.56072351 0.60809647 0.39362618 0.42807924 0.7166236\n",
            " 0.68044789 0.40137812 0.4461671  0.59862188 0.52885444 0.39276486\n",
            " 0.40999139 0.41946598 0.49009475 0.55900086 0.47028424 0.44272179\n",
            " 0.55641688 0.41515935 0.4039621  0.46080965 0.56330749 0.41774332\n",
            " 0.44444444 0.64427218 0.59862188 0.59862188 0.59776055 0.52971576\n",
            " 0.43927649 0.31093885 0.48492679 0.38587425 0.59086994 0.49354005\n",
            " 0.50387597 0.60206718 0.51421189 0.48406546 0.62101637 0.64857881\n",
            " 0.46167097 0.56158484 0.54005168 0.45305771 0.47803618 0.58656331\n",
            " 0.54435831 0.45305771 0.56330749 0.6873385  0.50387597 0.58828596\n",
            " 0.63652024 0.54177433 0.6287683  0.49698536 0.60551249 0.56847545\n",
            " 0.52713178 0.45564169 0.39534884 0.40654608 0.77174849 0.33936262\n",
            " 0.46770026 0.53402239 0.56072351 0.63996555 0.60981912 0.49784668\n",
            " 0.34711456 0.69509044 0.63738157 0.56847545 0.5047373  0.57536606\n",
            " 0.40568475 0.34797588 0.51593454 0.50559862 0.43583118 0.49956934\n",
            " 0.45822567 0.47286822 0.52971576 0.47286822 0.47286822 0.45736434\n",
            " 0.43583118 0.50990525 0.70456503 1.         0.38845823 0.47459087\n",
            " 0.51421189 0.63393626 0.64427218 0.68303187 0.60120586 0.59173127\n",
            " 0.49354005 0.48837209 0.71403962 0.42980189]\n",
            "The trained model has an aproximate error rate of 4.508944327437033 which equates to 1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "            'year':[2019,2019,2019,2020],\n",
        "          'da':[10,10,10,20],\n",
        "         'prcp' : [0,2.34,5.5,2.24],\n",
        "         'fog' : [0,0,1,1],\n",
        "         'rain_drizzle' : [0,1,1,1],\n",
        "         'snow_ice_pellets' : [0,0,0,0],\n",
        "         'hail' : [0,0,0,0],\n",
        "         'Apr' : [0,0,0,0],\n",
        "         'Aug' : [1,1,1,1],\n",
        "         'Dec' : [0,0,0,0],\n",
        "         'Feb' : [0,0,0,0],\n",
        "         'Jan' : [0,0,0,0],\n",
        "         'Jul' : [0,0,0,0],\n",
        "         'Jun' : [0,0,0,0],\n",
        "         'Mar' : [0,0,0,0],\n",
        "         'May' : [0,0,0,0],\n",
        "         'Nov' : [0,0,0,0],\n",
        "         'Oct' : [0,0,0,0],\n",
        "         'Sep' : [0,0,0,0],\n",
        "         'Fri' : [0,0,0,0],\n",
        "         'Mon' : [1,1,1,1],\n",
        "         'Sat' : [0,0,0,0],\n",
        "         'Sun' : [0,0,0,0],\n",
        "         'Thu' : [0,0,0,0],\n",
        "         'Tue' : [0,0,0,0],\n",
        "         'Wed' : [0,0,0,0]\n",
        "      \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_prcp', hidden_units=[20,18,13], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b284e0-eb9f-4ed9-d042-777a309cce5d",
        "id": "4fOP899kI8XR"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2186e34810>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_prcp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_prcp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[555.3892 561.1319 568.3101 559.7017]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE value is very similar to that of the linear regression model, indicating that both models are accurate predictors. The error rate of the DNN is higher, indicating the there is a higher number of errors, but the margin of error is lower.\n",
        "\n",
        "Based on the linear relationship found, the test data outputs results as expected."
      ],
      "metadata": {
        "id": "HAhdrU04ttZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dew Point (dewp)\n",
        "As with the linear regressor the process of training each model follows a very similar process, with the number of hidden layers, the number of nodes within each layer and the learning rate changing dependant on the dataset."
      ],
      "metadata": {
        "id": "yT91LA7Xx77W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_dewp_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/dewp_clean_dnn.csv', index_col=0, )\n",
        "print(df_dewp_dnn[:6])"
      ],
      "metadata": {
        "id": "zQAH_kVzyAOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cbd473-4996-44b5-b689-ee38f229d22e"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_dewp_dnn = df_dewp_dnn.drop(columns=['temp', 'prcp', 'slp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_dewp_dnn = df_dewp_dnn.loc[df_dewp_dnn[\"year\"] != 2012]\n",
        "df_dewp_dnn = df_dewp_dnn.loc[df_dewp_dnn[\"year\"] < 2020]\n",
        "#Move target to end\n",
        "cols = df_dewp_dnn['NUM_COLLISIONS']\n",
        "df_dewp_dnn = df_dewp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_dewp_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_dewp_dnn[:6])\n",
        "df_dewp_dnn.describe()"
      ],
      "metadata": {
        "id": "_qzGppAwyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "3a25a40f-21cb-48ab-af09-457aa75c4fc4"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  dewp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "49  2016  28  24.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17  35.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25  21.2    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29  36.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20  32.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13  44.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da         dewp          Apr          Aug  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean   2015.999217    15.723679    44.163170     0.082192     0.084932   \n",
              "std       2.000000     8.801271    16.995303     0.274710     0.278834   \n",
              "min    2013.000000     1.000000    -6.700000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000    32.150000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000    45.300000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000    58.500000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000    74.100000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000  ...   \n",
              "mean      0.084932     0.077104     0.084932     0.084540     0.082192  ...   \n",
              "std       0.278834     0.266808     0.278834     0.278251     0.274710  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      0.084932     0.082192     0.142466     0.143249     0.142857   \n",
              "std       0.278834     0.274710     0.349596     0.350395     0.349996   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000     2555.000000  \n",
              "mean      0.142857     0.142857     0.142857     0.142857      599.109980  \n",
              "std       0.349996     0.349996     0.349996     0.349996      100.277185  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4c5bd07-2967-4144-bf11-ddb8d7fb6d1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>dewp</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.999217</td>\n",
              "      <td>15.723679</td>\n",
              "      <td>44.163170</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.077104</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084540</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.142466</td>\n",
              "      <td>0.143249</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>599.109980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.801271</td>\n",
              "      <td>16.995303</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.266808</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278251</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.349596</td>\n",
              "      <td>0.350395</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>100.277185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4c5bd07-2967-4144-bf11-ddb8d7fb6d1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4c5bd07-2967-4144-bf11-ddb8d7fb6d1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4c5bd07-2967-4144-bf11-ddb8d7fb6d1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle Data\n",
        "shuffle = df_dewp_dnn.iloc[np.random.permutation(len(df_dewp_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "z5-eCTxByAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0a5b21-daf2-4f2c-d0a7-613aa183a2e6"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  dewp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "264   2018   8  28.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "1431  2016  17  44.5    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "3029  2017  31  44.2    0    0    0    0    0    0    0  ...    0    1    0   \n",
            "3594  2015  21  40.8    0    0    1    0    0    0    0  ...    0    0    0   \n",
            "3222  2019  20  39.8    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "1945  2016  28  69.0    0    0    0    0    0    1    0  ...    0    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "264     0    0    0    1    0    0    0  \n",
            "1431    0    1    0    0    0    0    0  \n",
            "3029    0    1    0    0    0    0    0  \n",
            "3594    0    0    0    1    0    0    0  \n",
            "3222    0    0    0    0    0    1    0  \n",
            "1945    0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "BbrOrPfQyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd95797-2fbd-4d4b-aed8-0623fce83d91"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "264     720\n",
            "1431    624\n",
            "3029    696\n",
            "3594    612\n",
            "3222    526\n",
            "1945    709\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split to test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "#Calculate number of outputs\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "T2v7BylMyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d96aeb85-7bec-443a-eabf-825796f505a4"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_dewp', ignore_errors=True)\n",
        "\n",
        "#Setup Model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[19,17,9], optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "#Train model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "HMGFsHtkyAOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad455663-8fe8-4e3d-9d6f-a2befc15aa89"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180c8abd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:loss = 2278.502, step = 1\n",
            "INFO:tensorflow:global_step/sec: 180.808\n",
            "INFO:tensorflow:loss = 9.152033, step = 101 (0.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.81\n",
            "INFO:tensorflow:loss = 8.72504, step = 201 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.05\n",
            "INFO:tensorflow:loss = 8.032806, step = 301 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 408.298\n",
            "INFO:tensorflow:loss = 7.5503483, step = 401 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.096\n",
            "INFO:tensorflow:loss = 6.216921, step = 501 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 426.439\n",
            "INFO:tensorflow:loss = 7.2335544, step = 601 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.964\n",
            "INFO:tensorflow:loss = 5.8428593, step = 701 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.623\n",
            "INFO:tensorflow:loss = 7.3701863, step = 801 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 417.761\n",
            "INFO:tensorflow:loss = 5.447606, step = 901 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.632\n",
            "INFO:tensorflow:loss = 4.6235046, step = 1001 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.056\n",
            "INFO:tensorflow:loss = 4.9857054, step = 1101 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.804\n",
            "INFO:tensorflow:loss = 5.884767, step = 1201 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.519\n",
            "INFO:tensorflow:loss = 4.64776, step = 1301 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 423.582\n",
            "INFO:tensorflow:loss = 5.6216145, step = 1401 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 407.167\n",
            "INFO:tensorflow:loss = 4.205093, step = 1501 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.88\n",
            "INFO:tensorflow:loss = 3.9035559, step = 1601 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 213.664\n",
            "INFO:tensorflow:loss = 3.3548744, step = 1701 (0.459 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.965\n",
            "INFO:tensorflow:loss = 3.8485918, step = 1801 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 417.54\n",
            "INFO:tensorflow:loss = 3.0717525, step = 1901 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 366.802\n",
            "INFO:tensorflow:loss = 3.2040253, step = 2001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 423.232\n",
            "INFO:tensorflow:loss = 2.5672503, step = 2101 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.964\n",
            "INFO:tensorflow:loss = 2.222941, step = 2201 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.168\n",
            "INFO:tensorflow:loss = 1.8067219, step = 2301 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 372.058\n",
            "INFO:tensorflow:loss = 2.330509, step = 2401 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 407.89\n",
            "INFO:tensorflow:loss = 1.860539, step = 2501 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.708\n",
            "INFO:tensorflow:loss = 1.5883982, step = 2601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.113\n",
            "INFO:tensorflow:loss = 1.2289995, step = 2701 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 430.897\n",
            "INFO:tensorflow:loss = 1.2470559, step = 2801 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 444.262\n",
            "INFO:tensorflow:loss = 1.2218145, step = 2901 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.898\n",
            "INFO:tensorflow:loss = 0.90489364, step = 3001 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.697\n",
            "INFO:tensorflow:loss = 0.917315, step = 3101 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.791\n",
            "INFO:tensorflow:loss = 0.82133216, step = 3201 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 413.92\n",
            "INFO:tensorflow:loss = 0.59529895, step = 3301 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.437\n",
            "INFO:tensorflow:loss = 0.58014023, step = 3401 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.536\n",
            "INFO:tensorflow:loss = 0.5043685, step = 3501 (0.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.196\n",
            "INFO:tensorflow:loss = 0.4480949, step = 3601 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.727\n",
            "INFO:tensorflow:loss = 0.35006326, step = 3701 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.547\n",
            "INFO:tensorflow:loss = 0.2879406, step = 3801 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 420.704\n",
            "INFO:tensorflow:loss = 0.25831345, step = 3901 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.932\n",
            "INFO:tensorflow:loss = 0.20422009, step = 4001 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.924\n",
            "INFO:tensorflow:loss = 0.17583427, step = 4101 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 424.363\n",
            "INFO:tensorflow:loss = 0.16213232, step = 4201 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.491\n",
            "INFO:tensorflow:loss = 0.15740797, step = 4301 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.558\n",
            "INFO:tensorflow:loss = 0.13150474, step = 4401 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.512\n",
            "INFO:tensorflow:loss = 0.08886075, step = 4501 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.896\n",
            "INFO:tensorflow:loss = 0.06637546, step = 4601 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 414.913\n",
            "INFO:tensorflow:loss = 0.06356874, step = 4701 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 426.185\n",
            "INFO:tensorflow:loss = 0.051760938, step = 4801 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.379\n",
            "INFO:tensorflow:loss = 0.052674502, step = 4901 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.561\n",
            "INFO:tensorflow:loss = 0.038613804, step = 5001 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 369\n",
            "INFO:tensorflow:loss = 0.03603882, step = 5101 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.621\n",
            "INFO:tensorflow:loss = 0.02343867, step = 5201 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.852\n",
            "INFO:tensorflow:loss = 0.025896475, step = 5301 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.605\n",
            "INFO:tensorflow:loss = 0.025331063, step = 5401 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.06\n",
            "INFO:tensorflow:loss = 0.024102565, step = 5501 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.88\n",
            "INFO:tensorflow:loss = 0.018045515, step = 5601 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.37\n",
            "INFO:tensorflow:loss = 0.018005252, step = 5701 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.627\n",
            "INFO:tensorflow:loss = 0.017613806, step = 5801 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 399.498\n",
            "INFO:tensorflow:loss = 0.013600793, step = 5901 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.012\n",
            "INFO:tensorflow:loss = 0.012481279, step = 6001 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.334\n",
            "INFO:tensorflow:loss = 0.01759668, step = 6101 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.28\n",
            "INFO:tensorflow:loss = 0.016024347, step = 6201 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.396\n",
            "INFO:tensorflow:loss = 0.011805603, step = 6301 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.29\n",
            "INFO:tensorflow:loss = 0.016324777, step = 6401 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.035\n",
            "INFO:tensorflow:loss = 0.011901639, step = 6501 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.599\n",
            "INFO:tensorflow:loss = 0.012825051, step = 6601 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.154\n",
            "INFO:tensorflow:loss = 0.013938149, step = 6701 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.625\n",
            "INFO:tensorflow:loss = 0.013343608, step = 6801 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.085\n",
            "INFO:tensorflow:loss = 0.010958796, step = 6901 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.284\n",
            "INFO:tensorflow:loss = 0.010289405, step = 7001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.271\n",
            "INFO:tensorflow:loss = 0.008611732, step = 7101 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.514\n",
            "INFO:tensorflow:loss = 0.010182723, step = 7201 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.78\n",
            "INFO:tensorflow:loss = 0.017311905, step = 7301 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.845\n",
            "INFO:tensorflow:loss = 0.009519634, step = 7401 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 423.765\n",
            "INFO:tensorflow:loss = 0.009448955, step = 7501 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.364\n",
            "INFO:tensorflow:loss = 0.008817835, step = 7601 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.163\n",
            "INFO:tensorflow:loss = 0.010570915, step = 7701 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.752\n",
            "INFO:tensorflow:loss = 0.008465955, step = 7801 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.918\n",
            "INFO:tensorflow:loss = 0.008745389, step = 7901 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.592\n",
            "INFO:tensorflow:loss = 0.008196961, step = 8001 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.021\n",
            "INFO:tensorflow:loss = 0.0052418103, step = 8101 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 439.308\n",
            "INFO:tensorflow:loss = 0.009056773, step = 8201 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.317\n",
            "INFO:tensorflow:loss = 0.011226417, step = 8301 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.871\n",
            "INFO:tensorflow:loss = 0.0073549766, step = 8401 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.817\n",
            "INFO:tensorflow:loss = 0.007045714, step = 8501 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 447.667\n",
            "INFO:tensorflow:loss = 0.008090186, step = 8601 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.931\n",
            "INFO:tensorflow:loss = 0.0077278493, step = 8701 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 407.739\n",
            "INFO:tensorflow:loss = 0.005350782, step = 8801 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.628\n",
            "INFO:tensorflow:loss = 0.009235527, step = 8901 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.389\n",
            "INFO:tensorflow:loss = 0.00650141, step = 9001 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.576\n",
            "INFO:tensorflow:loss = 0.0055123353, step = 9101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.103\n",
            "INFO:tensorflow:loss = 0.0063169096, step = 9201 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.476\n",
            "INFO:tensorflow:loss = 0.0046257507, step = 9301 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 413.131\n",
            "INFO:tensorflow:loss = 0.005539341, step = 9401 (0.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.434\n",
            "INFO:tensorflow:loss = 0.005101127, step = 9501 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 410.922\n",
            "INFO:tensorflow:loss = 0.0053642937, step = 9601 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.967\n",
            "INFO:tensorflow:loss = 0.004940256, step = 9701 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.321\n",
            "INFO:tensorflow:loss = 0.007111078, step = 9801 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.64\n",
            "INFO:tensorflow:loss = 0.010624273, step = 9901 (0.206 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_dewp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.008127491.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 81.18373280690219\n",
            "Just using average = 598.4936399217221 has RMSE of 97.45723895859679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "# Ensure number of hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[19,17,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NCz6izVhyAOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3fda0c-d291-4655-9efd-cd08e2154470"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f217fa89290>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5161224  0.5144156  0.5638021  0.56961    0.50995    0.54459804\n",
            " 0.5268664  0.48013327 0.5465937  0.5828879  0.550459   0.43661296\n",
            " 0.5443691  0.5433554  0.50073284 0.5932928  0.5222144  0.52036756\n",
            " 0.6468448  0.62040687 0.416818   0.5732942  0.5902322  0.5571462\n",
            " 0.5390077  0.5489542  0.42926723 0.5936663  0.5482859  0.4821805\n",
            " 0.49113512 0.43909934 0.5138586  0.3759073  0.5293005  0.4887133\n",
            " 0.57810795 0.49117145 0.50808334 0.5481959  0.56424105 0.43003097\n",
            " 0.5633474  0.5062528  0.5125602  0.59050876 0.4751144  0.49893475\n",
            " 0.50104403 0.5693581  0.523823   0.44281793 0.569378   0.519079\n",
            " 0.4985885  0.5440442  0.5873928  0.57331705 0.46690565 0.46823338\n",
            " 0.5815407  0.41638747 0.4140756  0.5021293  0.58359385 0.5062102\n",
            " 0.5639096  0.59023625 0.5109083  0.5284078  0.5416432  0.5555529\n",
            " 0.6271585  0.5454535  0.41284668 0.4172884  0.5568577  0.5328828\n",
            " 0.5241073  0.5762602  0.5381281  0.44959676 0.5053994  0.52595794\n",
            " 0.51329064 0.58196455 0.5911612  0.59167945 0.48942715 0.5690166\n",
            " 0.544784   0.43006814 0.5263307  0.52040946 0.54878825 0.47382742\n",
            " 0.54099935 0.57656133 0.4875672  0.5305247  0.46354404 0.5651182\n",
            " 0.51620495 0.59731    0.48662028 0.52236694 0.4484805  0.5156835\n",
            " 0.4722013  0.5750794  0.62949604 0.61488557 0.47521716 0.5302344\n",
            " 0.5518419  0.5884646  0.47235125 0.5281883  0.5028699  0.5226162\n",
            " 0.5053116  0.4115344  0.5391682  0.54988843 0.5463947  0.55156857\n",
            " 0.5616131  0.52060336 0.57070136 0.5440599  0.551198   0.56986374\n",
            " 0.6014421  0.52050894 0.44746795 0.610112   0.45716494 0.48864833\n",
            " 0.5136744  0.505361   0.58286726 0.5362151  0.6162424  0.5182139\n",
            " 0.5281085  0.53175014 0.42458087 0.55956715 0.52193165 0.59515315\n",
            " 0.46178648 0.6081665  0.4325773  0.50814474 0.608996   0.5111045\n",
            " 0.5743034  0.531151   0.5677279  0.4912317  0.5414663  0.5763904\n",
            " 0.4661601  0.5104114  0.56404555 0.38568714 0.5414059  0.47641805\n",
            " 0.56398296 0.55881554 0.4130379  0.56655294 0.51948553 0.49332303\n",
            " 0.59301263 0.53702515 0.5218507  0.6054548  0.49072447 0.5246628\n",
            " 0.48244384 0.5737702  0.48161057 0.45744148 0.61097306 0.576442\n",
            " 0.489056   0.5825977  0.50679994 0.5249154  0.5399781  0.5058422\n",
            " 0.5477677  0.44842288 0.49120694 0.5240226  0.4939181  0.56006265\n",
            " 0.58234346 0.43077153 0.4503047  0.5318247  0.58606255 0.6234566\n",
            " 0.5414815  0.5444893  0.57580775 0.4850184  0.53971314 0.5390752\n",
            " 0.41922605 0.5350619  0.6074989  0.54358286 0.51079637 0.6089405\n",
            " 0.5645393  0.5192903  0.40602982 0.6127369  0.55467325 0.48916626\n",
            " 0.57580876 0.44813162 0.4708972  0.5521604  0.5489791  0.42093354\n",
            " 0.46289    0.49988985 0.5375565  0.40297985 0.54386085 0.60993826\n",
            " 0.5712138  0.57080835 0.5477247  0.46997795 0.5988955  0.43936014\n",
            " 0.48689803 0.60452783 0.5789509  0.53859204 0.53488487 0.61723727\n",
            " 0.56425136 0.4866396  0.5423602  0.5390629  0.5793699  0.5549379\n",
            " 0.55325806 0.55844253 0.5163775  0.47529575 0.49519378 0.5112529\n",
            " 0.56514317 0.4770356  0.50904816 0.5158268  0.5618149  0.41706666\n",
            " 0.4353717  0.5711056  0.56208545 0.46069816 0.48150492 0.5712329\n",
            " 0.43865737 0.5135406  0.6085835  0.64151925 0.58647645 0.5315648\n",
            " 0.5421607  0.5039584  0.5669094  0.4656307  0.5140955  0.58884335\n",
            " 0.53951657 0.41923133 0.5302901  0.56296957 0.5048572  0.5243537\n",
            " 0.4496176  0.47070843 0.44195157 0.5262404  0.5215691  0.45586616\n",
            " 0.47458678 0.49921584 0.5446199  0.5705344  0.49489242 0.55386454\n",
            " 0.56290185 0.5565915  0.51801664 0.48473284 0.59842527 0.5204818\n",
            " 0.55083656 0.52140933 0.54013395 0.5673227  0.57155997 0.4509319\n",
            " 0.5247924  0.39324754 0.47927895 0.57502526 0.5903778  0.4875065\n",
            " 0.62921214 0.4841307  0.50145394 0.48804933 0.44419342 0.55545175\n",
            " 0.4962598  0.6102328  0.5772928  0.5054691  0.57839376 0.5339691\n",
            " 0.57275057 0.5779635  0.5371769  0.4582958  0.467075   0.57883793\n",
            " 0.4937865  0.50598115 0.44975176 0.62157816 0.5382545  0.5208387\n",
            " 0.5749288  0.46023104 0.4823265  0.5298964  0.5718965  0.5440079\n",
            " 0.5633019  0.57268226 0.55701226 0.51621556 0.5544725  0.43037683\n",
            " 0.5874262  0.56905454 0.42481875 0.5624125  0.5618515  0.486314\n",
            " 0.60058343 0.52275264 0.5178213  0.5409393  0.4521977  0.5180328\n",
            " 0.5775192  0.423142   0.58664256 0.42975643 0.608636   0.5794679\n",
            " 0.6042521  0.63145226 0.51985395 0.52165455 0.51512384 0.5768085\n",
            " 0.55949444 0.51367503 0.52417135 0.6123497  0.5512163  0.5527642\n",
            " 0.51677555 0.48205376 0.58810693 0.5523278  0.5310576  0.60619843\n",
            " 0.58764976 0.56993544 0.4730075  0.49156815 0.5703806  0.6031832\n",
            " 0.54175323 0.5794812  0.41863835 0.49815714 0.5936332  0.60832214\n",
            " 0.59451467 0.5730915  0.54917455 0.44311926 0.6118622  0.6181031\n",
            " 0.5186306  0.4486136  0.5447191  0.54615444 0.56202424 0.51719713\n",
            " 0.56602556 0.55481434 0.5898689  0.55111784 0.607151   0.55166954\n",
            " 0.54856426 0.62164205 0.5268665  0.64987546 0.50813216 0.5415714\n",
            " 0.52826405 0.45844755 0.51505476 0.51061594 0.5568143  0.49637538\n",
            " 0.5355613  0.5337783  0.51106524 0.5557027  0.577352   0.48656368\n",
            " 0.5576228  0.5802074  0.54213995 0.5493073  0.5609641  0.55404234\n",
            " 0.6221517  0.5447161  0.5278683  0.5720049  0.6071727  0.41449425\n",
            " 0.54214364 0.4527297  0.43475688 0.54200023 0.4862277  0.5375509\n",
            " 0.477241   0.5054808  0.57310843 0.5900573  0.5028687  0.5143027\n",
            " 0.54079294 0.5778533  0.5059022  0.46228406 0.49856108 0.5004807\n",
            " 0.5897322  0.53798336 0.5159773  0.43201044 0.5107349  0.5989543\n",
            " 0.57963556 0.49461934 0.41656098 0.459898   0.49230477 0.547393\n",
            " 0.505542   0.53772706 0.59442335 0.48694092 0.5472683  0.53208196\n",
            " 0.5456748  0.57796884 0.44993573 0.56540227 0.45181796 0.6421211\n",
            " 0.5282945  0.4020218  0.5438677  0.5589009  0.42533258 0.4203596\n",
            " 0.49169204 0.6229047  0.49272805 0.49107707 0.4873303  0.4825075\n",
            " 0.46072766 0.46444818 0.5257667  0.4459008  0.55194926 0.570452\n",
            " 0.547711  ]\n",
            "[0.4788975  0.48837209 0.6124031  0.52627046 0.53057709 0.55469423\n",
            " 0.51248923 0.44444444 0.4918174  0.53574505 0.54349699 0.38845823\n",
            " 0.52196382 0.54263566 0.51421189 0.60723514 0.56072351 0.52540913\n",
            " 0.38845823 0.63221361 0.34969854 0.51679587 0.53143842 0.67183463\n",
            " 0.63049096 0.51421189 0.46339363 0.55986219 0.4918174  0.5374677\n",
            " 0.57364341 0.37812231 0.49095607 0.38329027 0.59431525 0.63307494\n",
            " 0.61757106 0.49784668 0.53488372 0.49095607 0.62015504 0.37553833\n",
            " 0.47372954 0.44186047 0.55124892 0.6089578  0.41774332 0.53229974\n",
            " 0.53832903 0.51162791 0.4754522  0.4203273  0.49612403 0.53919035\n",
            " 0.49009475 0.48664944 0.69853575 0.57278208 0.44530577 0.44702842\n",
            " 0.60809647 0.44788975 0.39190353 0.45305771 0.57622739 0.47803618\n",
            " 0.51593454 0.52971576 0.5374677  0.28251507 0.37984496 0.44788975\n",
            " 0.66322136 0.45822567 0.38673557 0.48664944 0.59517657 0.49956934\n",
            " 0.53143842 0.32988803 0.7166236  0.45822567 0.49612403 0.60465116\n",
            " 0.54177433 0.65116279 0.62360034 0.55469423 0.42463394 0.48234281\n",
            " 0.60378984 0.40740741 0.50301464 0.57192076 0.63652024 0.55211025\n",
            " 0.55813953 0.56589147 0.39448751 0.50387597 0.33936262 0.60206718\n",
            " 0.47631352 0.53402239 0.48923342 0.54608096 0.35228252 0.57622739\n",
            " 0.45564169 0.61584841 0.71490095 0.70198105 0.53660637 0.52799311\n",
            " 0.46683893 0.65633075 0.56589147 0.50990525 0.51162791 0.47803618\n",
            " 0.54349699 0.40913006 0.4918174  0.51507321 0.4496124  0.5503876\n",
            " 0.5796727  0.52540913 0.6546081  0.56589147 0.47803618 0.52971576\n",
            " 0.56330749 0.5503876  0.4496124  0.69939707 0.44099914 0.42377261\n",
            " 0.48062016 0.51421189 0.60809647 0.50301464 0.62618432 0.57019811\n",
            " 0.44875108 0.47028424 0.40654608 0.5503876  0.61929371 0.69939707\n",
            " 0.50043066 0.72782084 0.46425495 0.48751077 0.57795004 0.58828596\n",
            " 0.53919035 0.54091301 0.62187769 0.53488372 0.51507321 0.52540913\n",
            " 0.50129199 0.5211025  0.48234281 0.42980189 0.65202412 0.47975883\n",
            " 0.56158484 0.5667528  0.44444444 0.59259259 0.63652024 0.43496985\n",
            " 0.51851852 0.55641688 0.52885444 0.5994832  0.48751077 0.40913006\n",
            " 0.53229974 0.54694229 0.55124892 0.41171404 0.5960379  0.62962963\n",
            " 0.40568475 0.59862188 0.51421189 0.43238587 0.51162791 0.55297158\n",
            " 0.53057709 0.50387597 0.46339363 0.55900086 0.44702842 0.50387597\n",
            " 0.59345392 0.46942291 0.39018088 0.52627046 0.56847545 0.50129199\n",
            " 0.52627046 0.58914729 0.32213609 0.60465116 0.43496985 0.53143842\n",
            " 0.36950904 0.53143842 0.5538329  0.45047373 0.65719208 0.53488372\n",
            " 0.63996555 0.46942291 0.38156761 0.66838932 0.48923342 0.42291128\n",
            " 0.46080965 0.47975883 0.46856158 0.31955211 0.49870801 0.44530577\n",
            " 0.3910422  0.47717485 0.42721792 0.41515935 0.4461671  0.49009475\n",
            " 0.52799311 0.39965547 0.49612403 0.36089578 0.64685616 0.48148148\n",
            " 0.4952627  0.7037037  0.46683893 0.4754522  0.51248923 0.56847545\n",
            " 0.51937984 0.42635659 0.36606374 0.59862188 0.57364341 0.32213609\n",
            " 0.44358312 0.52024117 0.57536606 0.35745047 0.44875108 0.34969854\n",
            " 0.55727821 0.44186047 0.44875108 0.51421189 0.51248923 0.41257537\n",
            " 0.36434109 0.45047373 0.53574505 0.43496985 0.45047373 0.62015504\n",
            " 0.56158484 0.54349699 0.58742463 0.60981912 0.41860465 0.5667528\n",
            " 0.5667528  0.72265289 0.625323   0.68217054 0.51507321 0.55555556\n",
            " 0.47286822 0.40999139 0.55211025 0.43410853 0.53919035 0.4918174\n",
            " 0.41343669 0.45478036 0.39018088 0.42894057 0.52540913 0.57622739\n",
            " 0.55900086 0.50990525 0.80878553 0.58656331 0.45650301 0.65202412\n",
            " 0.71490095 0.52196382 0.51507321 0.44444444 0.4918174  0.55986219\n",
            " 0.55641688 0.47717485 0.51507321 0.53143842 0.57536606 0.3453919\n",
            " 0.48492679 0.40568475 0.41860465 0.61412575 0.60034453 0.52799311\n",
            " 0.57881137 0.41946598 0.63135228 0.48664944 0.4332472  0.53919035\n",
            " 0.54952627 0.71748493 0.53574505 0.49956934 0.57019811 0.48062016\n",
            " 0.59259259 0.57364341 0.56330749 0.38845823 0.50904393 0.55727821\n",
            " 0.48148148 0.42894057 0.37726098 0.60465116 0.52799311 0.43066322\n",
            " 0.50387597 0.33505599 0.4625323  0.49698536 0.55813953 0.53316107\n",
            " 0.59431525 0.4788975  0.53574505 0.44702842 0.58570198 0.39793282\n",
            " 0.49612403 0.4461671  0.44530577 0.53316107 0.56330749 0.44358312\n",
            " 0.63824289 0.64341085 0.44358312 0.49267873 0.45305771 0.49095607\n",
            " 0.62187769 0.40482343 0.46597761 0.38242894 0.49009475 0.50043066\n",
            " 0.58656331 0.69853575 0.51765719 0.48837209 0.51851852 0.5374677\n",
            " 0.58828596 0.48234281 0.52799311 0.6873385  0.56330749 0.53143842\n",
            " 0.4952627  0.48062016 0.59862188 0.52799311 0.45736434 0.63824289\n",
            " 0.58484065 0.42807924 0.47200689 0.50387597 0.75107666 0.59000861\n",
            " 0.59776055 0.59345392 0.46167097 0.46167097 0.65288544 0.56158484\n",
            " 0.55641688 0.52971576 0.60292851 0.39534884 0.53660637 0.51507321\n",
            " 0.63307494 0.46597761 0.5960379  0.54694229 0.65374677 0.55555556\n",
            " 0.59173127 0.52368648 0.57622739 0.86046512 0.46942291 0.61757106\n",
            " 0.51593454 0.56847545 0.58656331 0.65374677 0.44444444 0.53402239\n",
            " 0.5211025  0.52024117 0.48406546 0.53229974 0.5374677  0.46942291\n",
            " 0.55124892 0.4918174  0.54866494 0.51421189 0.54694229 0.57881137\n",
            " 0.62015504 0.57019811 0.51765719 0.48751077 0.64771748 0.54694229\n",
            " 0.58484065 0.60809647 0.50559862 0.49009475 0.45650301 0.50387597\n",
            " 0.57795004 0.47717485 0.41171404 0.44186047 0.60809647 0.56589147\n",
            " 0.416882   0.55900086 0.52713178 0.6287683  0.48406546 0.4918174\n",
            " 0.54694229 0.66666667 0.39534884 0.42204996 0.52024117 0.48664944\n",
            " 0.66063738 0.51679587 0.60034453 0.44099914 0.52282515 0.59086994\n",
            " 0.57622739 0.54866494 0.38845823 0.36175711 0.53402239 0.49784668\n",
            " 0.38673557 0.47114556 0.62790698 0.34366925 0.583118   0.43583118\n",
            " 0.54091301 0.56330749 0.44358312 0.49440138 0.45305771 0.67355728\n",
            " 0.55297158 0.45994832 0.58139535 0.53488372 0.46511628 0.38329027\n",
            " 0.49784668 0.5667528  0.58397933 0.41343669 0.39793282 0.49095607\n",
            " 0.40826873 0.43410853 0.42204996 0.47803618 0.34969854 0.54177433\n",
            " 0.625323  ]\n",
            "The trained model has an aproximate error rate of -11.795653165261573 which equates to -2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "            'year':[2019,2019,2019,2020],\n",
        "          'da':[10,10,10,20],\n",
        "         'dewp' : [0,10.5,66.1,10.5],\n",
        "         'Apr' : [0,0,0,0],\n",
        "         'Aug' : [1,1,1,1],\n",
        "         'Dec' : [0,0,0,0],\n",
        "         'Feb' : [0,0,0,0],\n",
        "         'Jan' : [0,0,0,0],\n",
        "         'Jul' : [0,0,0,0],\n",
        "         'Jun' : [0,0,0,0],\n",
        "         'Mar' : [0,0,0,0],\n",
        "         'May' : [0,0,0,0],\n",
        "         'Nov' : [0,0,0,0],\n",
        "         'Oct' : [0,0,0,0],\n",
        "         'Sep' : [0,0,0,0],\n",
        "         'Fri' : [0,0,0,0],\n",
        "         'Mon' : [1,1,1,1],\n",
        "         'Sat' : [0,0,0,0],\n",
        "         'Sun' : [0,0,0,0],\n",
        "         'Thu' : [0,0,0,0],\n",
        "         'Tue' : [0,0,0,0],\n",
        "         'Wed' : [0,0,0,0]\n",
        "      \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_dewp', hidden_units=[19,17,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LXXzHmCwJhx",
        "outputId": "eea5d342-c84c-4382-a243-75d9e70c3849"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f217f995a10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_dewp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_dewp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[428.91623 463.7521  648.1726  458.87842]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown by the RMSE value, this model is a more efficient way to predict the number of collisions in comparison to using the mean. In comparison to the linear regression model trained, the RMSE is lower indicating the DNN makes more accurate predictions. As with the DNN for precipitation, the RMSE is lower than the linear model the error rate is higher indicating there is more errors but the margin of error is lower.\n",
        "\n",
        "Based on the linear relationship found, the test data outputs results as expected."
      ],
      "metadata": {
        "id": "LJTFyYeIFHwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sea Level Pressure(slp)\n",
        "Through the analysis carried out in assignment 1, no clear relationship between sea level pressure and the number of collisions was uncovered. A DNN will be used to attempt to predict the number of collisions at a given pressure point."
      ],
      "metadata": {
        "id": "eJ4eYJryNjGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "df_slp_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/slp_clean_dnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "mhUamxCZOTrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f17840b-d293-4cca-c9ca-ea3892549e38"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_slp_dnn = df_slp_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','mxpsd','gust','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_slp_dnn = df_slp_dnn.loc[df_slp_dnn[\"year\"] != 2012]\n",
        "df_slp_dnn = df_slp_dnn.loc[df_slp_dnn[\"year\"] < 2020]\n",
        "#Move target to the end\n",
        "cols = df_slp_dnn['NUM_COLLISIONS']\n",
        "df_slp_dnn = df_slp_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_slp_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_slp_dnn[:6])\n",
        "df_slp_dnn.describe()"
      ],
      "metadata": {
        "id": "P-VEj2lxOTrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "11e60dfc-5735-4cea-e568-c5803a7d9321"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da     slp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "49  2016  28  1016.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17  1014.8    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25  1021.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29   999.4    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20  1015.5    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13  1020.7    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da          slp          Apr          Aug  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean   2016.000391    15.719765  1016.777221     0.082192     0.084932   \n",
              "std       2.000294     8.796698     7.628429     0.274710     0.278834   \n",
              "min    2013.000000     1.000000   989.500000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000  1012.200000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000  1016.700000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000  1021.700000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000  1044.200000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000  ...   \n",
              "mean      0.084540     0.077104     0.084932     0.084932     0.082192  ...   \n",
              "std       0.278251     0.266808     0.278834     0.278834     0.274710  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000  2555.000000   \n",
              "mean      0.084932     0.082192     0.142857     0.143249     0.142857   \n",
              "std       0.278834     0.274710     0.349996     0.350395     0.349996   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2555.000000  2555.000000  2555.000000  2555.000000     2555.000000  \n",
              "mean      0.142857     0.142857     0.142857     0.142466      599.147162  \n",
              "std       0.349996     0.349996     0.349996     0.349596      100.268048  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a10934d-9546-4730-8ee7-30b87e1e06da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>slp</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "      <td>2555.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.000391</td>\n",
              "      <td>15.719765</td>\n",
              "      <td>1016.777221</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084540</td>\n",
              "      <td>0.077104</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084932</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.143249</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.142466</td>\n",
              "      <td>599.147162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000294</td>\n",
              "      <td>8.796698</td>\n",
              "      <td>7.628429</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278251</td>\n",
              "      <td>0.266808</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278834</td>\n",
              "      <td>0.274710</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.350395</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349996</td>\n",
              "      <td>0.349596</td>\n",
              "      <td>100.268048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1012.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1016.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1021.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>1044.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a10934d-9546-4730-8ee7-30b87e1e06da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a10934d-9546-4730-8ee7-30b87e1e06da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a10934d-9546-4730-8ee7-30b87e1e06da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle dataset\n",
        "shuffle = df_slp_dnn.iloc[np.random.permutation(len(df_slp_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "EG2EcMoLOTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec9a893-d5d4-44cd-83e6-e58e8a33e567"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da     slp  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "774   2015   9  1020.1    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2308  2017   1  1017.1    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "3546  2013   3  1011.1    0    0    1    0    0    0    0  ...    0    0    0   \n",
            "1587  2019  18  1015.1    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "3594  2015  21  1025.2    0    0    1    0    0    0    0  ...    0    0    0   \n",
            "2965  2013   8  1019.7    0    0    0    0    0    0    0  ...    0    1    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "774     0    0    0    1    0    0    0  \n",
            "2308    0    1    0    0    0    0    0  \n",
            "3546    0    1    0    0    0    0    0  \n",
            "1587    0    1    0    0    0    0    0  \n",
            "3594    0    0    0    1    0    0    0  \n",
            "2965    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "\n",
        "# print out the first 6 rows of the targets data.\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "pd6Uk6a9OTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecc7606-cd1f-4f58-8fac-0485d6566393"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "774     661\n",
            "2308    705\n",
            "3546    553\n",
            "1587    721\n",
            "3594    612\n",
            "2965    574\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "#Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "QX1fWn3jOTrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf689af-a702-4daf-c1cf-41304677f8b3"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_slp', ignore_errors=True)\n",
        "#Setup model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[15,13,9], optimizer=tf.train.AdamOptimizer(learning_rate=0.01), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "C9uL6bF7OTrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3334504-7a86-4be8-de7e-c4bfba6b9230"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21849832d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_slp/model.ckpt.\n",
            "INFO:tensorflow:loss = 4011.2021, step = 1\n",
            "INFO:tensorflow:global_step/sec: 349.044\n",
            "INFO:tensorflow:loss = 0.0119057875, step = 101 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.932\n",
            "INFO:tensorflow:loss = 0.008684389, step = 201 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.11\n",
            "INFO:tensorflow:loss = 0.008322796, step = 301 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.541\n",
            "INFO:tensorflow:loss = 0.009944219, step = 401 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.014\n",
            "INFO:tensorflow:loss = 0.010556124, step = 501 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.38\n",
            "INFO:tensorflow:loss = 0.009488182, step = 601 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.278\n",
            "INFO:tensorflow:loss = 0.011358846, step = 701 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.597\n",
            "INFO:tensorflow:loss = 0.009957209, step = 801 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.301\n",
            "INFO:tensorflow:loss = 0.008153401, step = 901 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.687\n",
            "INFO:tensorflow:loss = 0.008179213, step = 1001 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.242\n",
            "INFO:tensorflow:loss = 0.011989607, step = 1101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.578\n",
            "INFO:tensorflow:loss = 0.010429988, step = 1201 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.091\n",
            "INFO:tensorflow:loss = 0.009281993, step = 1301 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.08\n",
            "INFO:tensorflow:loss = 0.009894081, step = 1401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.294\n",
            "INFO:tensorflow:loss = 0.008428755, step = 1501 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.062\n",
            "INFO:tensorflow:loss = 0.017054776, step = 1601 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.932\n",
            "INFO:tensorflow:loss = 0.0068691997, step = 1701 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.597\n",
            "INFO:tensorflow:loss = 0.026386099, step = 1801 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.26\n",
            "INFO:tensorflow:loss = 0.007937785, step = 1901 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.809\n",
            "INFO:tensorflow:loss = 0.008161826, step = 2001 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.19\n",
            "INFO:tensorflow:loss = 0.028485093, step = 2101 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.998\n",
            "INFO:tensorflow:loss = 0.013927475, step = 2201 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.973\n",
            "INFO:tensorflow:loss = 0.007706793, step = 2301 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.219\n",
            "INFO:tensorflow:loss = 0.008502903, step = 2401 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.058\n",
            "INFO:tensorflow:loss = 0.0061818194, step = 2501 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.986\n",
            "INFO:tensorflow:loss = 0.011676602, step = 2601 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.774\n",
            "INFO:tensorflow:loss = 0.0059706024, step = 2701 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.747\n",
            "INFO:tensorflow:loss = 0.007493782, step = 2801 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.638\n",
            "INFO:tensorflow:loss = 0.008443216, step = 2901 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.615\n",
            "INFO:tensorflow:loss = 0.0070304163, step = 3001 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.964\n",
            "INFO:tensorflow:loss = 0.007971559, step = 3101 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.961\n",
            "INFO:tensorflow:loss = 0.00679336, step = 3201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.268\n",
            "INFO:tensorflow:loss = 0.00898429, step = 3301 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.646\n",
            "INFO:tensorflow:loss = 0.010707373, step = 3401 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.076\n",
            "INFO:tensorflow:loss = 0.007760463, step = 3501 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.992\n",
            "INFO:tensorflow:loss = 0.027151901, step = 3601 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.356\n",
            "INFO:tensorflow:loss = 0.011957974, step = 3701 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.958\n",
            "INFO:tensorflow:loss = 0.0068661286, step = 3801 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.215\n",
            "INFO:tensorflow:loss = 0.005427566, step = 3901 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.745\n",
            "INFO:tensorflow:loss = 0.0078104213, step = 4001 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.493\n",
            "INFO:tensorflow:loss = 0.007897833, step = 4101 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.181\n",
            "INFO:tensorflow:loss = 0.007272872, step = 4201 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.392\n",
            "INFO:tensorflow:loss = 0.0068563404, step = 4301 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.635\n",
            "INFO:tensorflow:loss = 0.006116368, step = 4401 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.937\n",
            "INFO:tensorflow:loss = 0.0075390986, step = 4501 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.64\n",
            "INFO:tensorflow:loss = 0.006570028, step = 4601 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.468\n",
            "INFO:tensorflow:loss = 0.0076915044, step = 4701 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.195\n",
            "INFO:tensorflow:loss = 0.006611202, step = 4801 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.801\n",
            "INFO:tensorflow:loss = 0.008259395, step = 4901 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.952\n",
            "INFO:tensorflow:loss = 0.006092849, step = 5001 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.668\n",
            "INFO:tensorflow:loss = 0.0076476177, step = 5101 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.279\n",
            "INFO:tensorflow:loss = 0.0076349704, step = 5201 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.514\n",
            "INFO:tensorflow:loss = 0.0066412203, step = 5301 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.521\n",
            "INFO:tensorflow:loss = 0.006958841, step = 5401 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.024\n",
            "INFO:tensorflow:loss = 0.007868415, step = 5501 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.572\n",
            "INFO:tensorflow:loss = 0.00761644, step = 5601 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.58\n",
            "INFO:tensorflow:loss = 0.0061413674, step = 5701 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.29\n",
            "INFO:tensorflow:loss = 0.007720699, step = 5801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.7\n",
            "INFO:tensorflow:loss = 0.006646376, step = 5901 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.097\n",
            "INFO:tensorflow:loss = 0.007039325, step = 6001 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.056\n",
            "INFO:tensorflow:loss = 0.011230823, step = 6101 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.996\n",
            "INFO:tensorflow:loss = 0.008378861, step = 6201 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.563\n",
            "INFO:tensorflow:loss = 0.007713685, step = 6301 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.495\n",
            "INFO:tensorflow:loss = 0.0070141847, step = 6401 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.952\n",
            "INFO:tensorflow:loss = 0.0054853926, step = 6501 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.789\n",
            "INFO:tensorflow:loss = 0.006844149, step = 6601 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.464\n",
            "INFO:tensorflow:loss = 0.0059800176, step = 6701 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.256\n",
            "INFO:tensorflow:loss = 0.004940842, step = 6801 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.496\n",
            "INFO:tensorflow:loss = 0.0051539075, step = 6901 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.587\n",
            "INFO:tensorflow:loss = 0.003782965, step = 7001 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.869\n",
            "INFO:tensorflow:loss = 0.0064416034, step = 7101 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.307\n",
            "INFO:tensorflow:loss = 0.0058590667, step = 7201 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.051\n",
            "INFO:tensorflow:loss = 0.0042307856, step = 7301 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.051\n",
            "INFO:tensorflow:loss = 0.0076955883, step = 7401 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.193\n",
            "INFO:tensorflow:loss = 0.00799655, step = 7501 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.742\n",
            "INFO:tensorflow:loss = 0.006089962, step = 7601 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.388\n",
            "INFO:tensorflow:loss = 0.0056309174, step = 7701 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.292\n",
            "INFO:tensorflow:loss = 0.0059754006, step = 7801 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.948\n",
            "INFO:tensorflow:loss = 0.0077252784, step = 7901 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.148\n",
            "INFO:tensorflow:loss = 0.005126722, step = 8001 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.226\n",
            "INFO:tensorflow:loss = 0.0058473484, step = 8101 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.078\n",
            "INFO:tensorflow:loss = 0.0067140684, step = 8201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.307\n",
            "INFO:tensorflow:loss = 0.006231475, step = 8301 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.062\n",
            "INFO:tensorflow:loss = 0.004360796, step = 8401 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.311\n",
            "INFO:tensorflow:loss = 0.004383696, step = 8501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.889\n",
            "INFO:tensorflow:loss = 0.007627677, step = 8601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.958\n",
            "INFO:tensorflow:loss = 0.006162247, step = 8701 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.506\n",
            "INFO:tensorflow:loss = 0.007708172, step = 8801 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 422.645\n",
            "INFO:tensorflow:loss = 0.0037903606, step = 8901 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.823\n",
            "INFO:tensorflow:loss = 0.00756317, step = 9001 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.209\n",
            "INFO:tensorflow:loss = 0.0047845514, step = 9101 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.864\n",
            "INFO:tensorflow:loss = 0.0052293316, step = 9201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.291\n",
            "INFO:tensorflow:loss = 0.0049245507, step = 9301 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 449.426\n",
            "INFO:tensorflow:loss = 0.0046771453, step = 9401 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.662\n",
            "INFO:tensorflow:loss = 0.0070043043, step = 9501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.082\n",
            "INFO:tensorflow:loss = 0.004894385, step = 9601 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.489\n",
            "INFO:tensorflow:loss = 0.0058171498, step = 9701 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.1\n",
            "INFO:tensorflow:loss = 0.006195461, step = 9801 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.743\n",
            "INFO:tensorflow:loss = 0.004517312, step = 9901 (0.325 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_slp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.005011015.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 83.90977431833942\n",
            "Just using average = 600.5239726027397 has RMSE of 101.79804376051676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#Ensure hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[15,13,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "mTPv83i1OTrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01c7067-6005-4f6a-fce9-fb1580768447"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180da6910>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.52125245 0.5034854  0.41281563 0.476237   0.5458724  0.50280666\n",
            " 0.58176255 0.45544517 0.4562766  0.52456474 0.41281563 0.49613345\n",
            " 0.48526388 0.53654647 0.55378985 0.5539732  0.6000898  0.5526836\n",
            " 0.53982186 0.49123958 0.5526306  0.5224725  0.536389   0.5291162\n",
            " 0.547381   0.508787   0.46184903 0.49955156 0.5659125  0.45230004\n",
            " 0.53561115 0.57052994 0.5384188  0.49192184 0.43280986 0.4471418\n",
            " 0.5352424  0.5217596  0.57406735 0.43629843 0.547762   0.517613\n",
            " 0.5077557  0.5034744  0.48244873 0.5791251  0.5494153  0.56851065\n",
            " 0.58760595 0.53095555 0.45680854 0.47154695 0.5294121  0.5141434\n",
            " 0.48286062 0.5549488  0.5594372  0.4903386  0.5159296  0.41809854\n",
            " 0.5472297  0.53090256 0.5271747  0.41281563 0.54033655 0.52469814\n",
            " 0.44946957 0.49765342 0.52984214 0.5348796  0.46027333 0.47828263\n",
            " 0.5220268  0.5768114  0.48278582 0.56255877 0.42644298 0.52820206\n",
            " 0.5510924  0.57657695 0.54934394 0.52745605 0.55426097 0.54239506\n",
            " 0.41281563 0.48803777 0.55779743 0.5424226  0.41281563 0.51517284\n",
            " 0.5866021  0.59030724 0.548252   0.4995194  0.48559713 0.58899987\n",
            " 0.42326695 0.513286   0.5174451  0.56057537 0.5287336  0.42353165\n",
            " 0.5895796  0.5387996  0.4845028  0.51816946 0.5442956  0.46328273\n",
            " 0.5646517  0.48140472 0.5449644  0.43893135 0.5182234  0.4935799\n",
            " 0.43869582 0.56138575 0.5303792  0.5139189  0.43213055 0.55828905\n",
            " 0.4905001  0.5820962  0.499619   0.4412835  0.51712924 0.5275902\n",
            " 0.4872306  0.55291796 0.55821997 0.5503486  0.5191375  0.41558018\n",
            " 0.54174656 0.47832096 0.45565358 0.45004952 0.5487628  0.4623319\n",
            " 0.5206426  0.51044023 0.49252886 0.4470566  0.46799195 0.53681964\n",
            " 0.57209724 0.5407441  0.52250475 0.5643025  0.53471285 0.4768064\n",
            " 0.43580797 0.5800092  0.52099633 0.5307503  0.5951531  0.41281563\n",
            " 0.5635514  0.54989845 0.5346663  0.43517336 0.55666816 0.5211585\n",
            " 0.515924   0.5700346  0.4278181  0.526094   0.50358397 0.5316786\n",
            " 0.5308072  0.5524089  0.55824643 0.41281563 0.4415245  0.4480473\n",
            " 0.5364099  0.54410595 0.5489241  0.49723047 0.55659455 0.49388668\n",
            " 0.5789071  0.5259602  0.59071416 0.5356398  0.55180687 0.5705487\n",
            " 0.567153   0.50888723 0.49257618 0.5714564  0.5478474  0.51743996\n",
            " 0.53802407 0.516586   0.506198   0.5188897  0.47115558 0.43471402\n",
            " 0.58776873 0.45944116 0.5368603  0.5198036  0.50511587 0.5382352\n",
            " 0.51697165 0.48458448 0.41281563 0.53518265 0.4405048  0.50209564\n",
            " 0.525651   0.50644606 0.47674924 0.5660892  0.5599359  0.503303\n",
            " 0.5278629  0.56466544 0.4243948  0.5181185  0.43499845 0.5840257\n",
            " 0.48131397 0.48455113 0.53387547 0.53472346 0.53538024 0.5245478\n",
            " 0.5155525  0.41281563 0.5059531  0.52879304 0.52592325 0.52433175\n",
            " 0.53279555 0.4147319  0.6028169  0.4830337  0.5340629  0.5106058\n",
            " 0.5588271  0.44742903 0.5378915  0.55071014 0.41281563 0.45071194\n",
            " 0.59666795 0.54677194 0.5319852  0.43418735 0.4411526  0.43896255\n",
            " 0.48352283 0.5248352  0.5437155  0.48390976 0.5453043  0.41281563\n",
            " 0.53249025 0.5507167  0.54907984 0.4530449  0.5809377  0.5583069\n",
            " 0.58674943 0.49666378 0.5620474  0.57592034 0.4999844  0.571104\n",
            " 0.53254795 0.58074695 0.4240023  0.5461189  0.56541264 0.5079144\n",
            " 0.52037543 0.56000614 0.57858074 0.4889412  0.41281563 0.54739606\n",
            " 0.5586535  0.5833949  0.42212057 0.4813605  0.5158435  0.43125606\n",
            " 0.52127594 0.43887788 0.5251882  0.5197528  0.5807816  0.5036974\n",
            " 0.56062263 0.55176157 0.48224077 0.5440933  0.5516742  0.4197904\n",
            " 0.5565926  0.5103567  0.5434497  0.5312648  0.5267453  0.44400534\n",
            " 0.51399386 0.5486012  0.5057774  0.45076457 0.52095366 0.4901282\n",
            " 0.55699    0.5457009  0.435323   0.5139902  0.5327515  0.5152856\n",
            " 0.5574896  0.543563   0.53931284 0.5517509  0.5379275  0.57338077\n",
            " 0.4868904  0.4884947  0.53638065 0.5296067  0.51139647 0.5677931\n",
            " 0.50831485 0.6027026  0.51461434 0.5142428  0.52650714 0.47655135\n",
            " 0.5102706  0.5527228  0.495556   0.42521286 0.564948   0.54129165\n",
            " 0.49059188 0.55513364 0.5315407  0.5332752  0.5255851  0.45342407\n",
            " 0.46351287 0.4701977  0.4865468  0.4959955  0.5460048  0.5509387\n",
            " 0.49007052 0.5303936  0.5701954  0.5366932  0.55085886 0.5144625\n",
            " 0.49635053 0.5017835  0.5111962  0.5385667  0.46776223 0.55166113\n",
            " 0.55242556 0.4180384  0.5410179  0.53845143 0.45972538 0.5374116\n",
            " 0.5607425  0.5777694  0.52771395 0.5069121  0.50009114 0.42760977\n",
            " 0.50309175 0.509217   0.5397861  0.5053556  0.5138608  0.44970682\n",
            " 0.46142966 0.5903643  0.51502913 0.5574702  0.5065687  0.5648973\n",
            " 0.48584712 0.5355863  0.4550801  0.5303458  0.58245885 0.55921775\n",
            " 0.6069881  0.4478489  0.57250315 0.5942279  0.52173615 0.5239314\n",
            " 0.42387018 0.5160453  0.5314881  0.5034196  0.5806943  0.50734454\n",
            " 0.4842074  0.48543376 0.5409894  0.43945706 0.55016553 0.5586088\n",
            " 0.5549065  0.58062774 0.5831474  0.48218566 0.5437549  0.529082\n",
            " 0.5409814  0.5726682  0.48798278 0.4350047  0.43110517 0.41281563\n",
            " 0.5407571  0.5493469  0.49620926 0.5906593  0.44700304 0.5173914\n",
            " 0.54428893 0.41281563 0.6027224  0.47032115 0.44699538 0.55422187\n",
            " 0.51453376 0.53343475 0.534121   0.4968922  0.49525788 0.51413774\n",
            " 0.48111254 0.49483192 0.57111466 0.45872962 0.4962985  0.42111906\n",
            " 0.55461603 0.47607034 0.5698221  0.51470166 0.51517946 0.5244099\n",
            " 0.54044473 0.6030787  0.44379455 0.5076717  0.4447301  0.5306381\n",
            " 0.49488315 0.5418037  0.5700667  0.41281563 0.54520714 0.51620376\n",
            " 0.50306094 0.5044353  0.5236711  0.4512167  0.5762     0.43707782\n",
            " 0.58424747 0.5551038  0.53057736 0.41281563 0.5348502  0.50134456\n",
            " 0.53598726 0.49197343 0.58680767 0.41281563 0.5770272  0.5479585\n",
            " 0.5851116  0.5073181  0.55577564 0.4297655  0.547312   0.43322924\n",
            " 0.49540174 0.5289885  0.5164815  0.58242947 0.53916276 0.5058007\n",
            " 0.50015247 0.5401542  0.51817715 0.53400826 0.4960549  0.53134656\n",
            " 0.50883645 0.5113573  0.5638575  0.4726688  0.56552    0.5529187\n",
            " 0.41281563]\n",
            "[0.32213609 0.58828596 0.38329027 0.45650301 0.49956934 0.55555556\n",
            " 0.51507321 0.45650301 0.47200689 0.5538329  0.41774332 0.53660637\n",
            " 0.46511628 0.50301464 0.59862188 0.63393626 0.67355728 0.62704565\n",
            " 0.45822567 0.52196382 0.57450474 0.56503015 0.53316107 0.51765719\n",
            " 0.61068045 0.36606374 0.49698536 0.45564169 0.59431525 0.44013781\n",
            " 0.4918174  0.53919035 0.58225668 0.48923342 0.51076658 0.43066322\n",
            " 0.4203273  0.68130922 0.53143842 0.39534884 0.58656331 0.60809647\n",
            " 0.4788975  0.55641688 0.42894057 0.58742463 0.55900086 0.53402239\n",
            " 0.53143842 0.53832903 0.55900086 0.44444444 0.54435831 0.50990525\n",
            " 0.46339363 0.51937984 0.51593454 0.58656331 0.40999139 0.40137812\n",
            " 0.52282515 0.65202412 0.44530577 0.36003445 0.55641688 0.51248923\n",
            " 0.39276486 0.43066322 0.53574505 0.53919035 0.39534884 0.30577089\n",
            " 0.46683893 0.46511628 0.39448751 0.59345392 0.43496985 0.52799311\n",
            " 0.5503876  0.7329888  0.65030146 0.54005168 0.59086994 0.50387597\n",
            " 0.40654608 0.48148148 0.66666667 0.61498708 0.44702842 0.60809647\n",
            " 0.52971576 0.625323   0.36950904 0.41343669 0.4625323  0.66063738\n",
            " 0.36347976 0.45047373 0.6546081  0.45822567 0.26098191 0.41946598\n",
            " 0.5538329  0.61843239 0.60551249 0.60292851 0.51593454 0.41946598\n",
            " 0.57364341 0.49784668 0.50904393 0.3712317  0.52627046 0.48148148\n",
            " 0.45564169 0.54349699 0.39276486 0.53143842 0.42118863 0.56244617\n",
            " 0.4918174  0.54349699 0.49095607 0.44358312 0.4754522  0.5503876\n",
            " 0.50129199 0.65719208 0.5994832  0.56330749 0.52627046 0.29371232\n",
            " 0.49009475 0.48664944 0.45564169 0.47459087 0.53229974 0.374677\n",
            " 0.50215332 0.52799311 0.45994832 0.37984496 0.50559862 0.4952627\n",
            " 0.65374677 0.46770026 0.50732127 0.57622739 0.55813953 0.49267873\n",
            " 0.47286822 0.55727821 0.59000861 0.46511628 0.6873385  0.33419466\n",
            " 0.48664944 0.47286822 0.52540913 0.48062016 0.52196382 0.55297158\n",
            " 0.49009475 0.40999139 0.43152455 0.57364341 0.41343669 0.63910422\n",
            " 0.48406546 0.49870801 0.61757106 0.39793282 0.38587425 0.41257537\n",
            " 0.6089578  0.46080965 0.53229974 0.59431525 0.34969854 0.47717485\n",
            " 0.51076658 0.48492679 0.57364341 0.51507321 0.61412575 0.54608096\n",
            " 0.58656331 0.54780362 0.42894057 0.54521964 0.60809647 0.60723514\n",
            " 0.64685616 0.53574505 0.47372954 0.46511628 0.48578811 0.43066322\n",
            " 0.63221361 0.41429802 0.55641688 0.61154177 0.60206718 0.53229974\n",
            " 0.34022394 0.53832903 0.4005168  0.64513351 0.45650301 0.33505599\n",
            " 0.5503876  0.46080965 0.34625323 0.62790698 0.63910422 0.59173127\n",
            " 0.48320413 0.60206718 0.43496985 0.51851852 0.40999139 0.51076658\n",
            " 0.50043066 0.45305771 0.49440138 0.54866494 0.49698536 0.40826873\n",
            " 0.39793282 0.37812231 0.54177433 0.48837209 0.50904393 0.50215332\n",
            " 0.46080965 0.38329027 0.5211025  0.47114556 0.54263566 0.55211025\n",
            " 0.60034453 0.38845823 0.60206718 0.74677003 0.26614987 0.40223945\n",
            " 0.64944014 0.59000861 0.54091301 0.41429802 0.44358312 0.41774332\n",
            " 0.48923342 0.5245478  0.49009475 0.49095607 0.6709733  0.42549526\n",
            " 0.61154177 0.64427218 0.50990525 0.36347976 0.71231697 0.67355728\n",
            " 0.55727821 0.30749354 0.33936262 0.32988803 0.44272179 0.69164513\n",
            " 0.54694229 0.5538329  0.48923342 0.5211025  0.53919035 0.41946598\n",
            " 0.54952627 0.59862188 0.5245478  0.51335056 0.35400517 0.56589147\n",
            " 0.52713178 0.57708872 0.38156761 0.5374677  0.53143842 0.39276486\n",
            " 0.48664944 0.46942291 0.44702842 0.42118863 0.56416882 0.52540913\n",
            " 0.54694229 0.55986219 0.50990525 0.38845823 0.52540913 0.48923342\n",
            " 0.54780362 0.62790698 0.54694229 0.60206718 0.54866494 0.39793282\n",
            " 0.53488372 0.53919035 0.47114556 0.4918174  0.52196382 0.45736434\n",
            " 0.55211025 0.54694229 0.35228252 0.42549526 0.57278208 0.47286822\n",
            " 0.52971576 0.64771748 0.50904393 0.50129199 0.65030146 0.57105943\n",
            " 0.4918174  0.56503015 0.56416882 0.53229974 0.56589147 0.59776055\n",
            " 0.61068045 0.55297158 0.38931955 0.55986219 0.56416882 0.51076658\n",
            " 0.6124031  0.49095607 0.57708872 0.42204996 0.68217054 0.47028424\n",
            " 0.54866494 0.44788975 0.49956934 0.43496985 0.55469423 0.50904393\n",
            " 0.46339363 0.49612403 0.55986219 0.42894057 0.61757106 0.4918174\n",
            " 0.82687339 0.583118   0.48148148 0.57622739 0.54091301 0.53832903\n",
            " 0.52540913 0.49698536 0.68217054 0.43496985 0.36003445 0.53057709\n",
            " 0.53057709 0.40568475 0.53660637 0.51593454 0.47459087 0.4788975\n",
            " 0.52799311 0.5538329  0.4039621  0.53057709 0.54263566 0.42635659\n",
            " 0.44272179 0.4625323  0.43755383 0.4461671  0.55124892 0.41774332\n",
            " 0.39276486 0.62618432 0.47286822 0.52971576 0.51851852 0.55297158\n",
            " 0.45391904 0.59259259 0.52024117 0.47114556 0.55986219 0.5374677\n",
            " 0.50301464 0.4625323  0.49870801 0.66408269 0.50129199 0.55555556\n",
            " 0.47372954 0.62273902 0.53229974 0.50387597 0.64254953 0.45391904\n",
            " 0.48923342 0.54091301 0.63910422 0.50559862 0.66149871 0.59345392\n",
            " 0.52627046 0.50129199 0.65546942 0.46425495 0.46511628 0.62790698\n",
            " 0.51851852 0.57105943 0.5796727  0.47975883 0.45994832 0.38587425\n",
            " 0.5538329  0.56847545 0.4952627  0.66063738 0.42721792 0.44702842\n",
            " 0.60206718 0.42204996 0.60292851 0.48148148 0.35745047 0.46339363\n",
            " 0.48923342 0.44272179 0.56158484 0.56503015 0.52024117 0.5081826\n",
            " 0.50129199 0.374677   0.67011197 0.40740741 0.58484065 0.34366925\n",
            " 0.65202412 0.47975883 0.54952627 0.50645995 0.37898363 0.51421189\n",
            " 0.54349699 0.53057709 0.48578811 0.41860465 0.36606374 0.57881137\n",
            " 0.46683893 0.60206718 0.52885444 0.33850129 0.51593454 0.50904393\n",
            " 0.51851852 0.51248923 0.44186047 0.45822567 0.68044789 0.38070629\n",
            " 0.50904393 0.49440138 0.34453058 0.32730405 0.45650301 0.53574505\n",
            " 0.51679587 1.         0.45994832 0.43496985 0.58570198 0.60551249\n",
            " 0.63738157 0.5047373  0.60981912 0.37639966 0.63652024 0.50387597\n",
            " 0.4496124  0.47975883 0.51248923 0.70887166 0.46597761 0.43238587\n",
            " 0.53660637 0.54263566 0.60292851 0.53488372 0.43238587 0.48406546\n",
            " 0.57795004 0.52713178 0.61843239 0.48664944 0.38415159 0.6546081\n",
            " 0.40482343]\n",
            "The trained model has an aproximate error rate of -4.496756596691221 which equates to -1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "            'year':[2019,2019,2019,2020],\n",
        "          'da':[10,10,10,20],\n",
        "         'slp' : [990.2,1022.4,1039.0,1022.4],\n",
        "         'Apr' : [0,0,0,0],\n",
        "         'Aug' : [1,1,1,1],\n",
        "         'Dec' : [0,0,0,0],\n",
        "         'Feb' : [0,0,0,0],\n",
        "         'Jan' : [0,0,0,0],\n",
        "         'Jul' : [0,0,0,0],\n",
        "         'Jun' : [0,0,0,0],\n",
        "         'Mar' : [0,0,0,0],\n",
        "         'May' : [0,0,0,0],\n",
        "         'Nov' : [0,0,0,0],\n",
        "         'Oct' : [0,0,0,0],\n",
        "         'Sep' : [0,0,0,0],\n",
        "         'Fri' : [0,0,0,0],\n",
        "         'Mon' : [1,1,1,1],\n",
        "         'Sat' : [0,0,0,0],\n",
        "         'Sun' : [0,0,0,0],\n",
        "         'Thu' : [0,0,0,0],\n",
        "         'Tue' : [0,0,0,0],\n",
        "         'Wed' : [0,0,0,0]\n",
        "      \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_slp', hidden_units=[15,13,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqyBHs4QxtY3",
        "outputId": "06c49ab9-2bac-462e-b44d-3770d0fc62d5"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f218097e310>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_slp', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_slp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[112.89884 147.19633 164.878   141.17247]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although no linear relationship was uncovered, it can be argued there is a relationship present due to the RMSE value which is lower than the mean value. This relationship is also shown in the error rate which is comparative to the other models produced."
      ],
      "metadata": {
        "id": "rYGXd0opI-i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gust\n",
        "As with sea level pressure, no linear relationship between the maximum gust and the number of collisions was uncovered."
      ],
      "metadata": {
        "id": "lHX1HoDlQwJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data\n",
        "df_gust_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/gust_clean_dnn.csv', index_col=0, )\n",
        "print(df_gust_dnn[:6])"
      ],
      "metadata": {
        "id": "Tf_wMIWXQ7zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e45844f-f4c1-4c93-8b3b-02f0d19314af"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd  gust  \\\n",
            "3   2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0  20.0   \n",
            "11  2020  15             508  43.9  38.3  1019.4    8.2   5.4   14.0  15.0   \n",
            "12  2021   1             257  39.6  29.3  1029.3   10.0   7.6   14.0  20.0   \n",
            "14  2022  25             235  41.6  31.8  1013.2   10.0   9.6   15.0  19.0   \n",
            "18  2021   3             186  41.1  32.3  1018.0   10.0  10.3   19.0  27.0   \n",
            "19  2020   2             413  39.6  28.9  1011.8   10.0  13.0   19.0  26.0   \n",
            "\n",
            "    ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "3   ...    0    0    0    0    0    0    0    1    0    0  \n",
            "11  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "12  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "14  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "18  ...    0    0    0    0    0    1    0    0    0    0  \n",
            "19  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Cols not Required \n",
        "df_gust_dnn = df_gust_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','mxpsd','slp','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_gust_dnn = df_gust_dnn.loc[df_gust_dnn[\"year\"] != 2012]\n",
        "df_gust_dnn = df_gust_dnn.loc[df_gust_dnn[\"year\"] < 2020]\n",
        "#Move target col to end\n",
        "cols = df_gust_dnn['NUM_COLLISIONS']\n",
        "df_gust_dnn = df_gust_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_gust_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_gust_dnn[:6])\n",
        "df_gust_dnn.describe()"
      ],
      "metadata": {
        "id": "oTbpzolhQ7zh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "a1229498-1cbf-4389-e130-575b42cbd05f"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  gust  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "74  2016  17  18.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "76  2014   9  20.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "79  2019  19  21.0    0    0    0    0    1    0    0  ...    0    0    1   \n",
            "80  2015  11  17.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "83  2015  29  20.0    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "85  2019  13  15.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "74    0    1    0    0    0    0             451  \n",
            "76    0    0    0    0    0    1             561  \n",
            "79    0    0    0    0    0    0             479  \n",
            "80    0    1    0    0    0    0             341  \n",
            "83    0    0    0    0    0    1             519  \n",
            "85    0    1    0    0    0    0             374  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             year           da         gust          Apr          Aug  \\\n",
              "count  1629.00000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean   2015.91283    15.702885    27.511602     0.095764     0.042357   \n",
              "std       2.01341     8.667634     7.366770     0.294358     0.201465   \n",
              "min    2013.00000     1.000000    14.000000     0.000000     0.000000   \n",
              "25%    2014.00000     8.000000    22.000000     0.000000     0.000000   \n",
              "50%    2016.00000    16.000000    26.000000     0.000000     0.000000   \n",
              "75%    2018.00000    23.000000    31.100000     0.000000     0.000000   \n",
              "max    2019.00000    31.000000    71.100000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000  ...   \n",
              "mean      0.104359     0.095150     0.108656     0.046041     0.061387  ...   \n",
              "std       0.305819     0.293513     0.311302     0.209637     0.240113  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean      0.087784     0.071209     0.143646     0.139963     0.141191   \n",
              "std       0.283067     0.257253     0.350839     0.347055     0.348325   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000     1629.000000  \n",
              "mean      0.139963     0.151627     0.138122     0.145488      596.513198  \n",
              "std       0.347055     0.358769     0.345133     0.352700      104.479660  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      526.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      597.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      663.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49a1ecff-f0db-4745-beb9-726235c95549\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>gust</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1629.00000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.91283</td>\n",
              "      <td>15.702885</td>\n",
              "      <td>27.511602</td>\n",
              "      <td>0.095764</td>\n",
              "      <td>0.042357</td>\n",
              "      <td>0.104359</td>\n",
              "      <td>0.095150</td>\n",
              "      <td>0.108656</td>\n",
              "      <td>0.046041</td>\n",
              "      <td>0.061387</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087784</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.143646</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.151627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>596.513198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.01341</td>\n",
              "      <td>8.667634</td>\n",
              "      <td>7.366770</td>\n",
              "      <td>0.294358</td>\n",
              "      <td>0.201465</td>\n",
              "      <td>0.305819</td>\n",
              "      <td>0.293513</td>\n",
              "      <td>0.311302</td>\n",
              "      <td>0.209637</td>\n",
              "      <td>0.240113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.257253</td>\n",
              "      <td>0.350839</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.348325</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.358769</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>104.479660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>526.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>597.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.00000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>663.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.00000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49a1ecff-f0db-4745-beb9-726235c95549')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49a1ecff-f0db-4745-beb9-726235c95549 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49a1ecff-f0db-4745-beb9-726235c95549');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data\n",
        "shuffle = df_gust_dnn.iloc[np.random.permutation(len(df_gust_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "a_4bidEbQ7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f32284-6f37-48ef-f0b0-45e3867e7bc5"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  gust  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "204   2018  15  25.1    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "797   2014   5  26.0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "388   2019  20  18.1    0    0    0    1    0    0    0  ...    0    0    0   \n",
            "3265  2018   4  32.1    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "3260  2014   8  32.1    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "3264  2016  13  28.0    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "204     0    0    0    1    0    0    0  \n",
            "797     0    0    0    0    0    1    0  \n",
            "388     0    0    0    0    0    1    0  \n",
            "3265    0    0    1    0    0    0    0  \n",
            "3260    1    0    0    0    0    0    0  \n",
            "3264    0    0    1    0    0    0    0  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select last col as a target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "l4TDr10XQ7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fc3ffb-5e19-49f1-88dc-31e794e2a077"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204     523\n",
            "797     491\n",
            "388     615\n",
            "3265    502\n",
            "3260    543\n",
            "3264    518\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "75AKCrz7Q7zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962145fd-4c27-458d-afda-32bfb356adf1"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_gust', ignore_errors=True)\n",
        "\n",
        "#Setup model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_gust', hidden_units=[23,19,11], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "#Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "v4av8KXMQ7zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb86b02-0b16-4c38-cce3-a839c783f99c"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180284350>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_gust', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_gust/model.ckpt.\n",
            "INFO:tensorflow:loss = 120400.266, step = 1\n",
            "INFO:tensorflow:global_step/sec: 405.676\n",
            "INFO:tensorflow:loss = 7.0375686, step = 101 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.996\n",
            "INFO:tensorflow:loss = 5.923665, step = 201 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.858\n",
            "INFO:tensorflow:loss = 5.86942, step = 301 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.249\n",
            "INFO:tensorflow:loss = 6.0937967, step = 401 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.124\n",
            "INFO:tensorflow:loss = 4.2698884, step = 501 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.422\n",
            "INFO:tensorflow:loss = 4.467372, step = 601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.527\n",
            "INFO:tensorflow:loss = 4.017475, step = 701 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.568\n",
            "INFO:tensorflow:loss = 3.2649374, step = 801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.164\n",
            "INFO:tensorflow:loss = 2.7305653, step = 901 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.444\n",
            "INFO:tensorflow:loss = 2.3063312, step = 1001 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.664\n",
            "INFO:tensorflow:loss = 2.2919662, step = 1101 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.698\n",
            "INFO:tensorflow:loss = 1.8576, step = 1201 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.016\n",
            "INFO:tensorflow:loss = 1.4480735, step = 1301 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.739\n",
            "INFO:tensorflow:loss = 1.3023047, step = 1401 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.698\n",
            "INFO:tensorflow:loss = 1.1923356, step = 1501 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.529\n",
            "INFO:tensorflow:loss = 1.0356822, step = 1601 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.675\n",
            "INFO:tensorflow:loss = 0.81964207, step = 1701 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.622\n",
            "INFO:tensorflow:loss = 0.68120426, step = 1801 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.403\n",
            "INFO:tensorflow:loss = 0.4506585, step = 1901 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.76\n",
            "INFO:tensorflow:loss = 0.38239735, step = 2001 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.409\n",
            "INFO:tensorflow:loss = 0.41520467, step = 2101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.326\n",
            "INFO:tensorflow:loss = 0.2829373, step = 2201 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.604\n",
            "INFO:tensorflow:loss = 0.26974353, step = 2301 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 585.845\n",
            "INFO:tensorflow:loss = 0.20634069, step = 2401 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.315\n",
            "INFO:tensorflow:loss = 0.15686002, step = 2501 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.596\n",
            "INFO:tensorflow:loss = 0.088459894, step = 2601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.964\n",
            "INFO:tensorflow:loss = 0.07461629, step = 2701 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.852\n",
            "INFO:tensorflow:loss = 0.06916441, step = 2801 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.57\n",
            "INFO:tensorflow:loss = 0.07343644, step = 2901 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.195\n",
            "INFO:tensorflow:loss = 0.059603374, step = 3001 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.522\n",
            "INFO:tensorflow:loss = 0.054709367, step = 3101 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.755\n",
            "INFO:tensorflow:loss = 0.04464304, step = 3201 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.33\n",
            "INFO:tensorflow:loss = 0.03981411, step = 3301 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.772\n",
            "INFO:tensorflow:loss = 0.036022678, step = 3401 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.101\n",
            "INFO:tensorflow:loss = 0.030335888, step = 3501 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.577\n",
            "INFO:tensorflow:loss = 0.026157843, step = 3601 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.581\n",
            "INFO:tensorflow:loss = 0.020474834, step = 3701 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.967\n",
            "INFO:tensorflow:loss = 0.016550446, step = 3801 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.291\n",
            "INFO:tensorflow:loss = 0.015335739, step = 3901 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.731\n",
            "INFO:tensorflow:loss = 0.017806306, step = 4001 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.281\n",
            "INFO:tensorflow:loss = 0.010351585, step = 4101 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.007\n",
            "INFO:tensorflow:loss = 0.009618761, step = 4201 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.878\n",
            "INFO:tensorflow:loss = 0.013301925, step = 4301 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.669\n",
            "INFO:tensorflow:loss = 0.010603843, step = 4401 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.06\n",
            "INFO:tensorflow:loss = 0.010468041, step = 4501 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.144\n",
            "INFO:tensorflow:loss = 0.009557543, step = 4601 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.751\n",
            "INFO:tensorflow:loss = 0.010874076, step = 4701 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.62\n",
            "INFO:tensorflow:loss = 0.009830994, step = 4801 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.403\n",
            "INFO:tensorflow:loss = 0.0068505486, step = 4901 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.694\n",
            "INFO:tensorflow:loss = 0.0075540226, step = 5001 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.305\n",
            "INFO:tensorflow:loss = 0.008184001, step = 5101 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.301\n",
            "INFO:tensorflow:loss = 0.0049784463, step = 5201 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.59\n",
            "INFO:tensorflow:loss = 0.0042394265, step = 5301 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.84\n",
            "INFO:tensorflow:loss = 0.00928786, step = 5401 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.045\n",
            "INFO:tensorflow:loss = 0.006430416, step = 5501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.847\n",
            "INFO:tensorflow:loss = 0.004938865, step = 5601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.603\n",
            "INFO:tensorflow:loss = 0.010002337, step = 5701 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.679\n",
            "INFO:tensorflow:loss = 0.0056644827, step = 5801 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.478\n",
            "INFO:tensorflow:loss = 0.006587888, step = 5901 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.341\n",
            "INFO:tensorflow:loss = 0.0059550833, step = 6001 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.702\n",
            "INFO:tensorflow:loss = 0.0043235905, step = 6101 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.113\n",
            "INFO:tensorflow:loss = 0.011251749, step = 6201 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.895\n",
            "INFO:tensorflow:loss = 0.00819475, step = 6301 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.104\n",
            "INFO:tensorflow:loss = 0.004902296, step = 6401 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.634\n",
            "INFO:tensorflow:loss = 0.0033542197, step = 6501 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.6\n",
            "INFO:tensorflow:loss = 0.031021941, step = 6601 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.316\n",
            "INFO:tensorflow:loss = 0.005717297, step = 6701 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.942\n",
            "INFO:tensorflow:loss = 0.0071046995, step = 6801 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.233\n",
            "INFO:tensorflow:loss = 0.00588895, step = 6901 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.487\n",
            "INFO:tensorflow:loss = 0.0043601594, step = 7001 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.883\n",
            "INFO:tensorflow:loss = 0.035568044, step = 7101 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.001\n",
            "INFO:tensorflow:loss = 2.3468637, step = 7201 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.701\n",
            "INFO:tensorflow:loss = 0.0646865, step = 7301 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.979\n",
            "INFO:tensorflow:loss = 0.038446687, step = 7401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.835\n",
            "INFO:tensorflow:loss = 0.009906963, step = 7501 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.892\n",
            "INFO:tensorflow:loss = 0.017341608, step = 7601 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.715\n",
            "INFO:tensorflow:loss = 0.27565384, step = 7701 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.587\n",
            "INFO:tensorflow:loss = 0.017169379, step = 7801 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.696\n",
            "INFO:tensorflow:loss = 1.9638627, step = 7901 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.476\n",
            "INFO:tensorflow:loss = 2.4020135, step = 8001 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.377\n",
            "INFO:tensorflow:loss = 1.5349414, step = 8101 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.41\n",
            "INFO:tensorflow:loss = 0.63826257, step = 8201 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.445\n",
            "INFO:tensorflow:loss = 0.030480515, step = 8301 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.306\n",
            "INFO:tensorflow:loss = 0.14897192, step = 8401 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.944\n",
            "INFO:tensorflow:loss = 0.15895289, step = 8501 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.127\n",
            "INFO:tensorflow:loss = 0.5391966, step = 8601 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.73\n",
            "INFO:tensorflow:loss = 0.042642385, step = 8701 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.295\n",
            "INFO:tensorflow:loss = 1.3000555, step = 8801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.338\n",
            "INFO:tensorflow:loss = 0.68839735, step = 8901 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.483\n",
            "INFO:tensorflow:loss = 0.047045525, step = 9001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.579\n",
            "INFO:tensorflow:loss = 0.053349424, step = 9101 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.904\n",
            "INFO:tensorflow:loss = 0.54634297, step = 9201 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.888\n",
            "INFO:tensorflow:loss = 0.022787143, step = 9301 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.197\n",
            "INFO:tensorflow:loss = 0.5641475, step = 9401 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.116\n",
            "INFO:tensorflow:loss = 1.469424, step = 9501 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.325\n",
            "INFO:tensorflow:loss = 0.5588855, step = 9601 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.342\n",
            "INFO:tensorflow:loss = 0.009198517, step = 9701 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.468\n",
            "INFO:tensorflow:loss = 0.3662643, step = 9801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.005\n",
            "INFO:tensorflow:loss = 0.012300643, step = 9901 (0.191 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_gust/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.7641789.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_gust/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 1018.3540724737733\n",
            "Just using average = 595.6431312356101 has RMSE of 107.5373681714606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "#Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_gust', hidden_units=[23,19,11], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NdhxllohQ7zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c055bf-6627-4ff5-9358-8c120ce4bc0b"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21809540d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_gust', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326\n",
            "326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_gust/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.3049663  -0.42005202 -0.51450616 -0.29954398 -0.3548231  -0.33809265\n",
            " -0.44262335 -0.39822903 -0.38705528 -0.31102693 -0.38927925 -0.29266882\n",
            " -0.41832456 -0.38759193 -0.32961118 -0.302848   -0.3841639  -0.35516366\n",
            " -0.39627936 -0.33033198 -0.3804949  -0.4882057  -0.3625027  -0.38677642\n",
            " -0.29193735 -0.32585177 -0.2907221  -0.35136354 -0.32740298 -0.38262534\n",
            " -0.3065188  -0.28920543 -0.31905624 -0.37320375 -0.3748302  -0.39114377\n",
            " -0.3285573  -0.3862763  -0.29360756 -0.357711   -0.4675518  -0.39903703\n",
            " -0.36056608 -0.31410253 -0.30655792 -0.516221   -0.35794276 -0.34592134\n",
            " -0.29268256 -0.3290304  -0.3581174  -0.3279106  -0.44864726 -0.40452954\n",
            " -0.32755962 -0.46700737 -0.34779194 -0.43543026 -0.3385287  -0.36341026\n",
            " -0.38059017 -0.33614656 -0.30604503 -0.40815502 -0.4003447  -0.32367313\n",
            " -0.36357993 -0.28842196 -0.31632268 -0.29129422 -0.28562742 -0.4094085\n",
            " -0.35539058 -0.3862904  -0.25717908 -0.28122094 -0.28967875 -0.34104088\n",
            " -0.39588308 -0.30864412 -0.3474564  -0.3633494  -0.3288619  -0.45648095\n",
            " -0.3374553  -0.43694845 -0.32752717 -0.3376843  -0.46963874 -0.40701076\n",
            " -0.3291184  -0.324154   -0.3377853  -0.2875981  -0.40692437 -0.3510832\n",
            " -0.33076927 -0.34074327 -0.2988094  -0.3365593  -0.3578983  -0.30801553\n",
            " -0.316189   -0.27341047 -0.2778132  -0.31353554 -0.286298   -0.30219793\n",
            " -0.33557844 -0.40472072 -0.30220866 -0.2764305  -0.27054197 -0.34685823\n",
            " -0.3560058  -0.46249455 -0.44891375 -0.46626553 -0.41464308 -0.34476483\n",
            " -0.28058574 -0.35769165 -0.28821394 -0.33853135 -0.45729354 -0.32732716\n",
            " -0.29859316 -0.3544229  -0.2912184  -0.29253155 -0.34836623 -0.36592662\n",
            " -0.35024917 -0.32742393 -0.4679377  -0.37656337 -0.3889045  -0.4481428\n",
            " -0.35830238 -0.33813834 -0.35511997 -0.3514261  -0.4432095  -0.3714454\n",
            " -0.3335728  -0.3526895  -0.30429852 -0.35304418 -0.3575469  -0.3342305\n",
            " -0.43951705 -0.40949884 -0.36697656 -0.38482863 -0.38679448 -0.440766\n",
            " -0.3527593  -0.30645254 -0.35593602 -0.42548555 -0.40744188 -0.36660916\n",
            " -0.36007968 -0.24339889 -0.29149196 -0.27741605 -0.45311478 -0.3400659\n",
            " -0.3331849  -0.3435064  -0.33896777 -0.50741535 -0.32234773 -0.2952354\n",
            " -0.35402456 -0.34433952 -0.3068802  -0.31565875 -0.30267894 -0.37202764\n",
            " -0.34919193 -0.32417306 -0.26648965 -0.30105156 -0.31118843 -0.4270166\n",
            " -0.31254348 -0.36937514 -0.45360938 -0.3664762  -0.2912832  -0.36987448\n",
            " -0.35950428 -0.47495306 -0.50929666 -0.38718325 -0.3196882  -0.30480197\n",
            " -0.29922414 -0.33210114 -0.3193409  -0.37512177 -0.30875856 -0.4114902\n",
            " -0.4634279  -0.3983733  -0.3196694  -0.30636707 -0.33366448 -0.3448596\n",
            " -0.3641423  -0.3250825  -0.32495314 -0.338998   -0.35121545 -0.32902518\n",
            " -0.34895888 -0.29968217 -0.3497595  -0.3904436  -0.41302243 -0.46472618\n",
            " -0.34313488 -0.46760932 -0.34468058 -0.33969826 -0.4967302  -0.43494013\n",
            " -0.33867708 -0.33761483 -0.4898407  -0.2868138  -0.4589354  -0.32148454\n",
            " -0.3262535  -0.35636112 -0.36753026 -0.33957735 -0.3443223  -0.3074875\n",
            " -0.3414241  -0.3002013  -0.3565981  -0.43406767 -0.33692092 -0.4753413\n",
            " -0.3463974  -0.44949088 -0.32944998 -0.4606159  -0.4229091  -0.33906147\n",
            " -0.4531417  -0.33985442 -0.43101302 -0.34998375 -0.3885001  -0.32305735\n",
            " -0.465101   -0.46958134 -0.34980243 -0.44183832 -0.40856248 -0.3133036\n",
            " -0.46390995 -0.32497406 -0.37512422 -0.4059158  -0.31181753 -0.36837253\n",
            " -0.28818953 -0.2844608  -0.33858922 -0.3438776  -0.30160457 -0.34737602\n",
            " -0.33984375 -0.37135854 -0.4208764  -0.2944469  -0.28432146 -0.3310974\n",
            " -0.2910933  -0.2742032  -0.4734375  -0.4001463  -0.39732033 -0.45564395\n",
            " -0.44576636 -0.449408   -0.3413388  -0.44166136 -0.34016508 -0.3587167\n",
            " -0.47947994 -0.3559138  -0.36413133 -0.29843804 -0.34521204 -0.34150442\n",
            " -0.3124905  -0.26363623 -0.2946779  -0.37859243 -0.34677315 -0.3129632\n",
            " -0.26342216 -0.37062195 -0.34177557 -0.34154952 -0.35174555 -0.3398039\n",
            " -0.3510462  -0.3626296  -0.31147003 -0.32917708 -0.34994572 -0.35838127\n",
            " -0.3172226  -0.34490445 -0.3095523  -0.34331578 -0.32258055 -0.24797358\n",
            " -0.3122389  -0.259393  ]\n",
            "[0.52713178 0.43238587 0.36864772 0.59517657 0.52713178 0.53832903\n",
            " 0.40913006 0.54005168 0.42377261 0.62790698 0.62015504 0.60465116\n",
            " 0.4918174  0.50990525 0.91731266 0.48148148 0.49784668 0.47286822\n",
            " 0.49784668 0.69853575 0.4918174  0.37209302 0.45564169 0.4952627\n",
            " 0.65202412 0.65030146 0.5796727  0.72265289 0.53402239 0.52196382\n",
            " 0.59776055 0.71403962 0.56330749 0.4788975  0.43583118 0.46942291\n",
            " 0.49009475 0.43496985 0.60723514 0.37984496 0.33936262 0.47975883\n",
            " 0.38156761 0.64857881 0.59689922 0.45822567 0.53229974 0.56158484\n",
            " 0.55727821 0.54521964 0.51421189 0.65374677 0.3712317  0.5374677\n",
            " 0.42291128 0.47372954 0.4918174  0.40223945 0.52885444 0.35400517\n",
            " 0.66925065 0.54263566 0.59776055 0.43669251 0.51335056 0.61154177\n",
            " 0.64599483 0.53574505 0.36089578 0.61412575 0.56761413 0.45822567\n",
            " 0.43755383 0.46511628 0.61929371 0.64341085 0.59345392 0.51593454\n",
            " 0.45478036 0.53143842 0.54177433 0.50301464 0.46942291 0.38156761\n",
            " 0.45736434 0.52799311 0.63221361 0.49956934 0.34797588 0.48923342\n",
            " 0.60120586 0.52799311 0.55813953 0.57105943 0.43669251 0.26098191\n",
            " 0.49354005 0.76055125 0.59000861 0.53229974 0.57364341 0.48923342\n",
            " 0.50215332 0.54608096 0.55297158 0.51765719 0.54694229 0.37639966\n",
            " 0.47459087 0.55986219 0.63479759 0.59173127 0.57536606 0.5047373\n",
            " 0.56589147 0.39534884 0.416882   0.45305771 0.42463394 0.4496124\n",
            " 0.49612403 0.45908699 0.59431525 0.65891473 0.45908699 0.49354005\n",
            " 0.53143842 0.54694229 0.53402239 0.55900086 0.47975883 0.52885444\n",
            " 0.60809647 0.54866494 0.44530577 0.37037037 0.53660637 0.38587425\n",
            " 0.52885444 0.36864772 0.40913006 0.4754522  0.44788975 0.5667528\n",
            " 0.7166236  0.56158484 0.63996555 0.59259259 0.61584841 0.53574505\n",
            " 0.47717485 0.48664944 0.47114556 0.51765719 0.45564169 0.35228252\n",
            " 0.43152455 0.63824289 0.45047373 0.47459087 0.44013781 0.47631352\n",
            " 0.50904393 0.70456503 0.65374677 0.63910422 0.41774332 0.5667528\n",
            " 0.33850129 0.54521964 0.49354005 0.35400517 0.48751077 0.53574505\n",
            " 0.50043066 0.57105943 0.5374677  0.59086994 0.52024117 0.51765719\n",
            " 0.47114556 0.51593454 0.5538329  0.64857881 0.64857881 0.42204996\n",
            " 0.40999139 0.34366925 0.46597761 0.49698536 0.52713178 0.61154177\n",
            " 0.50215332 0.40482343 0.44530577 0.44875108 0.56158484 0.55641688\n",
            " 0.57708872 0.52282515 0.69681309 0.54177433 0.54780362 0.50301464\n",
            " 0.4039621  0.50559862 0.54435831 0.55813953 0.59689922 0.52282515\n",
            " 0.40999139 0.52024117 0.48148148 0.54263566 0.51248923 0.56072351\n",
            " 0.56330749 0.5994832  0.54349699 0.42894057 0.34797588 0.39965547\n",
            " 0.5503876  0.40654608 0.60637382 0.56589147 0.33419466 0.33505599\n",
            " 0.5047373  0.63824289 0.27562446 0.60809647 0.42204996 0.45822567\n",
            " 0.65202412 0.48751077 0.49440138 0.5245478  0.58828596 0.63135228\n",
            " 0.60292851 0.56589147 0.58053402 0.36003445 0.59862188 0.39793282\n",
            " 0.44702842 0.36347976 0.60206718 0.51335056 0.42721792 0.54521964\n",
            " 0.40310078 0.52627046 0.47803618 0.45219638 0.50301464 0.54694229\n",
            " 0.40568475 0.37209302 0.45219638 0.40913006 0.47717485 0.46425495\n",
            " 0.3910422  0.59259259 0.32816537 0.45564169 0.63910422 0.49009475\n",
            " 0.71748493 0.59259259 0.5796727  0.58225668 0.60034453 0.62962963\n",
            " 0.68130922 0.40568475 0.39534884 0.42291128 0.6089578  0.47631352\n",
            " 0.70111972 0.67786391 0.34022394 0.49784668 0.46167097 0.53574505\n",
            " 0.42463394 0.44186047 0.46080965 0.48062016 0.51851852 0.58828596\n",
            " 0.3875969  0.64857881 0.52540913 0.62790698 0.60637382 0.36950904\n",
            " 0.47028424 0.64341085 0.51593454 0.44272179 0.61154177 0.59431525\n",
            " 0.6580534  0.54177433 0.54263566 0.63738157 0.59000861 0.51765719\n",
            " 0.54952627 0.42204996 0.46339363 0.62187769 0.62446167 0.44013781\n",
            " 0.52971576 0.53057709 0.53229974 0.4918174  0.54349699 0.55297158\n",
            " 0.49440138 0.7037037 ]\n",
            "The trained model has an aproximate error rate of 1014.8983142185797 which equates to 169%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model shows there is no relationship between gust and the number of collisions.\n",
        "\n",
        "The RMSE value is over 4 times the mean value indicating the model is unable to make accurate predictions. This is also reflected in the very high error rate."
      ],
      "metadata": {
        "id": "iCLt9ZygKrGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Maximum Sustained Wind Speed (mxpsd)\n",
        "In an attempt to predict the number of collisions given the maximum sustained wind speed a DNN will be used as no linear relationship was uncovered within assignment 1."
      ],
      "metadata": {
        "id": "tKaVpVT8T55I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "df_mxpsd_dnn = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/mxpsd_clean_dnn.csv', index_col=0, )\n",
        "print(df_mxpsd_dnn[:6])"
      ],
      "metadata": {
        "id": "_LbHDT1WUbJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1107cd-e353-49a2-e5ed-ee26356bb32c"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the cols not required\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.drop(columns=['temp', 'prcp', 'dewp','visib','max','min','sndp','wdsp','gust','slp','thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.loc[df_mxpsd_dnn[\"year\"] != 2012]\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.loc[df_mxpsd_dnn[\"year\"] < 2020]\n",
        "#Move the target to the end\n",
        "cols = df_mxpsd_dnn['NUM_COLLISIONS']\n",
        "df_mxpsd_dnn = df_mxpsd_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_mxpsd_dnn.insert(loc=22, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_mxpsd_dnn[:6])\n",
        "df_mxpsd_dnn.describe()"
      ],
      "metadata": {
        "id": "OoJSkkKHUbJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "15489394-3d82-4e00-c5a7-00c56712f7cf"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  mxpsd  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Oct  Sep  Fri  \\\n",
            "49  2016  28    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "51  2014  17    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "54  2016  25    8.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "55  2016  29    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "58  2017  20    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "59  2013  13    9.9    0    0    0    0    1    0    0  ...    0    0    0   \n",
            "\n",
            "    Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "49    0    0    0    0    0    1             681  \n",
            "51    0    0    0    1    0    0             589  \n",
            "54    0    0    1    0    0    0             658  \n",
            "55    0    0    0    1    0    0             645  \n",
            "58    0    0    0    1    0    0             605  \n",
            "59    0    1    0    0    0    0             373  \n",
            "\n",
            "[6 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              year           da        mxpsd          Apr          Aug  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
              "mean   2016.001567    15.737172    17.240110     0.082256     0.084998   \n",
              "std       2.000587     8.797367     5.858333     0.274808     0.278933   \n",
              "min    2013.000000     1.000000     5.100000     0.000000     0.000000   \n",
              "25%    2014.000000     8.000000    13.000000     0.000000     0.000000   \n",
              "50%    2016.000000    16.000000    15.900000     0.000000     0.000000   \n",
              "75%    2018.000000    23.000000    20.000000     0.000000     0.000000   \n",
              "max    2019.000000    31.000000    49.000000     1.000000     1.000000   \n",
              "\n",
              "               Dec          Feb          Jan          Jul          Jun  ...  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000  ...   \n",
              "mean      0.084998     0.077164     0.084998     0.084998     0.082256  ...   \n",
              "std       0.278933     0.266904     0.278933     0.278933     0.274808  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
              "mean      0.084998     0.081473     0.142969     0.143361     0.142969   \n",
              "std       0.278933     0.273613     0.350110     0.350509     0.350110   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  2553.000000  2553.000000  2553.000000  2553.000000     2553.000000  \n",
              "mean      0.142969     0.142969     0.142577     0.142186      599.033686  \n",
              "std       0.350110     0.350110     0.349710     0.349309      100.284761  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      531.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      602.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      665.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b79dea8-a668-4cc7-b011-ae1797def286\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>Apr</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "      <td>2553.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.001567</td>\n",
              "      <td>15.737172</td>\n",
              "      <td>17.240110</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.077164</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.082256</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>0.081473</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.143361</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142969</td>\n",
              "      <td>0.142577</td>\n",
              "      <td>0.142186</td>\n",
              "      <td>599.033686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000587</td>\n",
              "      <td>8.797367</td>\n",
              "      <td>5.858333</td>\n",
              "      <td>0.274808</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.266904</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.274808</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278933</td>\n",
              "      <td>0.273613</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350509</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.350110</td>\n",
              "      <td>0.349710</td>\n",
              "      <td>0.349309</td>\n",
              "      <td>100.284761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>531.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>602.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>665.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b79dea8-a668-4cc7-b011-ae1797def286')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b79dea8-a668-4cc7-b011-ae1797def286 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b79dea8-a668-4cc7-b011-ae1797def286');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the data\n",
        "shuffle = df_mxpsd_dnn.iloc[np.random.permutation(len(df_mxpsd_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "z1Ut5LCiUbJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df920a82-52b5-4ece-ea56-1c573bfe9e11"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  mxpsd  Apr  Aug  Dec  Feb  Jan  Jul  Jun  ...  Nov  Oct  Sep  \\\n",
            "2243  2014   3    9.9    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "1415  2014  29   17.1    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "3358  2018   3   32.1    0    0    0    0    0    0    0  ...    1    0    0   \n",
            "573   2016  25   29.9    0    0    0    1    0    0    0  ...    0    0    0   \n",
            "1876  2015  25    8.9    0    0    0    0    0    1    0  ...    0    0    0   \n",
            "659   2016   8   13.0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "2243    0    0    1    0    0    0    0  \n",
            "1415    0    0    0    0    0    0    1  \n",
            "3358    1    0    0    0    0    0    0  \n",
            "573     0    0    0    0    0    0    1  \n",
            "1876    1    0    0    0    0    0    0  \n",
            "659     0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the target as the last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "QibQoUleUbJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5728fe-a56d-47dd-e00b-c1f5ed2fbe07"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2243    476\n",
            "1415    663\n",
            "3358    656\n",
            "573     663\n",
            "1876    451\n",
            "659     632\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "-C_tqkmUUbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b7b79a-ad60-4f05-f02e-ff98d66bc806"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_mxpsd', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[23,13,9], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "\n",
        "# Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "C3O7xWeMUbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46f3d11-ddfd-46f8-bb89-cf1c93774772"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2187f87450>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_mxpsd/model.ckpt.\n",
            "INFO:tensorflow:loss = 144257.9, step = 1\n",
            "INFO:tensorflow:global_step/sec: 399.379\n",
            "INFO:tensorflow:loss = 3.7238111, step = 101 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.75\n",
            "INFO:tensorflow:loss = 0.23482522, step = 201 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.828\n",
            "INFO:tensorflow:loss = 0.2148373, step = 301 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.616\n",
            "INFO:tensorflow:loss = 0.20698708, step = 401 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.841\n",
            "INFO:tensorflow:loss = 0.20983556, step = 501 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.498\n",
            "INFO:tensorflow:loss = 0.20757458, step = 601 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.111\n",
            "INFO:tensorflow:loss = 0.21551603, step = 701 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.008\n",
            "INFO:tensorflow:loss = 0.19450481, step = 801 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.942\n",
            "INFO:tensorflow:loss = 0.20758441, step = 901 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.077\n",
            "INFO:tensorflow:loss = 0.22613457, step = 1001 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.462\n",
            "INFO:tensorflow:loss = 0.19174114, step = 1101 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.009\n",
            "INFO:tensorflow:loss = 0.21985918, step = 1201 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.609\n",
            "INFO:tensorflow:loss = 0.20585462, step = 1301 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.519\n",
            "INFO:tensorflow:loss = 0.19591051, step = 1401 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.567\n",
            "INFO:tensorflow:loss = 0.19627678, step = 1501 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.214\n",
            "INFO:tensorflow:loss = 0.20114668, step = 1601 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.957\n",
            "INFO:tensorflow:loss = 0.1943756, step = 1701 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.793\n",
            "INFO:tensorflow:loss = 0.18344492, step = 1801 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.991\n",
            "INFO:tensorflow:loss = 0.183698, step = 1901 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.116\n",
            "INFO:tensorflow:loss = 0.16236633, step = 2001 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.09\n",
            "INFO:tensorflow:loss = 0.19512364, step = 2101 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.332\n",
            "INFO:tensorflow:loss = 0.19549277, step = 2201 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.022\n",
            "INFO:tensorflow:loss = 0.18464026, step = 2301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.071\n",
            "INFO:tensorflow:loss = 0.1872624, step = 2401 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.601\n",
            "INFO:tensorflow:loss = 0.17205726, step = 2501 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.251\n",
            "INFO:tensorflow:loss = 0.15159425, step = 2601 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.984\n",
            "INFO:tensorflow:loss = 0.13429396, step = 2701 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.287\n",
            "INFO:tensorflow:loss = 0.16914171, step = 2801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.153\n",
            "INFO:tensorflow:loss = 0.13638379, step = 2901 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.52\n",
            "INFO:tensorflow:loss = 0.1634561, step = 3001 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.593\n",
            "INFO:tensorflow:loss = 0.116741225, step = 3101 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.642\n",
            "INFO:tensorflow:loss = 0.13531908, step = 3201 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.992\n",
            "INFO:tensorflow:loss = 0.14854313, step = 3301 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.911\n",
            "INFO:tensorflow:loss = 0.13574775, step = 3401 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.471\n",
            "INFO:tensorflow:loss = 0.13680533, step = 3501 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.686\n",
            "INFO:tensorflow:loss = 0.10771738, step = 3601 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.699\n",
            "INFO:tensorflow:loss = 0.11641786, step = 3701 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.135\n",
            "INFO:tensorflow:loss = 0.11131799, step = 3801 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.628\n",
            "INFO:tensorflow:loss = 0.10022736, step = 3901 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.68\n",
            "INFO:tensorflow:loss = 0.09318783, step = 4001 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.499\n",
            "INFO:tensorflow:loss = 0.09773444, step = 4101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.731\n",
            "INFO:tensorflow:loss = 0.104380205, step = 4201 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.132\n",
            "INFO:tensorflow:loss = 0.06743783, step = 4301 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.149\n",
            "INFO:tensorflow:loss = 0.074298635, step = 4401 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.288\n",
            "INFO:tensorflow:loss = 0.07555889, step = 4501 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.913\n",
            "INFO:tensorflow:loss = 0.07197766, step = 4601 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.957\n",
            "INFO:tensorflow:loss = 0.06685171, step = 4701 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.051\n",
            "INFO:tensorflow:loss = 0.049154893, step = 4801 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.506\n",
            "INFO:tensorflow:loss = 0.057799675, step = 4901 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.442\n",
            "INFO:tensorflow:loss = 0.04854977, step = 5001 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.924\n",
            "INFO:tensorflow:loss = 0.047954824, step = 5101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.021\n",
            "INFO:tensorflow:loss = 0.04578811, step = 5201 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.473\n",
            "INFO:tensorflow:loss = 0.038769584, step = 5301 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.048\n",
            "INFO:tensorflow:loss = 0.037010074, step = 5401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.243\n",
            "INFO:tensorflow:loss = 0.037681375, step = 5501 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.838\n",
            "INFO:tensorflow:loss = 0.03581886, step = 5601 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.089\n",
            "INFO:tensorflow:loss = 0.032182716, step = 5701 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.762\n",
            "INFO:tensorflow:loss = 0.022288108, step = 5801 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.935\n",
            "INFO:tensorflow:loss = 0.024576034, step = 5901 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.204\n",
            "INFO:tensorflow:loss = 0.019758977, step = 6001 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.378\n",
            "INFO:tensorflow:loss = 0.017214114, step = 6101 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.222\n",
            "INFO:tensorflow:loss = 0.01665593, step = 6201 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.814\n",
            "INFO:tensorflow:loss = 0.015959071, step = 6301 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.065\n",
            "INFO:tensorflow:loss = 0.017943215, step = 6401 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.224\n",
            "INFO:tensorflow:loss = 0.013942198, step = 6501 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.967\n",
            "INFO:tensorflow:loss = 0.008870391, step = 6601 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.051\n",
            "INFO:tensorflow:loss = 0.011494735, step = 6701 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.522\n",
            "INFO:tensorflow:loss = 0.009623237, step = 6801 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.653\n",
            "INFO:tensorflow:loss = 0.008488116, step = 6901 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.525\n",
            "INFO:tensorflow:loss = 0.008720709, step = 7001 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.373\n",
            "INFO:tensorflow:loss = 0.0060421512, step = 7101 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.137\n",
            "INFO:tensorflow:loss = 0.006831727, step = 7201 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.439\n",
            "INFO:tensorflow:loss = 0.0061450517, step = 7301 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.949\n",
            "INFO:tensorflow:loss = 0.0071256747, step = 7401 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.127\n",
            "INFO:tensorflow:loss = 0.008557564, step = 7501 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.847\n",
            "INFO:tensorflow:loss = 0.006251465, step = 7601 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 484.268\n",
            "INFO:tensorflow:loss = 0.005618738, step = 7701 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.279\n",
            "INFO:tensorflow:loss = 0.0070890267, step = 7801 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.739\n",
            "INFO:tensorflow:loss = 0.0054089604, step = 7901 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.281\n",
            "INFO:tensorflow:loss = 0.0070616733, step = 8001 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.857\n",
            "INFO:tensorflow:loss = 0.0064938706, step = 8101 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.686\n",
            "INFO:tensorflow:loss = 0.006602837, step = 8201 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.553\n",
            "INFO:tensorflow:loss = 0.004920807, step = 8301 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.514\n",
            "INFO:tensorflow:loss = 0.0046090847, step = 8401 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.431\n",
            "INFO:tensorflow:loss = 0.007009329, step = 8501 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.586\n",
            "INFO:tensorflow:loss = 0.005009355, step = 8601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.886\n",
            "INFO:tensorflow:loss = 0.0065026833, step = 8701 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.356\n",
            "INFO:tensorflow:loss = 0.0064620106, step = 8801 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.116\n",
            "INFO:tensorflow:loss = 0.005229902, step = 8901 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.284\n",
            "INFO:tensorflow:loss = 0.005551329, step = 9001 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.808\n",
            "INFO:tensorflow:loss = 0.0036689434, step = 9101 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.182\n",
            "INFO:tensorflow:loss = 0.004143243, step = 9201 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.765\n",
            "INFO:tensorflow:loss = 0.0068891915, step = 9301 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.645\n",
            "INFO:tensorflow:loss = 0.0048836772, step = 9401 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.306\n",
            "INFO:tensorflow:loss = 0.0040264, step = 9501 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.765\n",
            "INFO:tensorflow:loss = 0.0033105346, step = 9601 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.519\n",
            "INFO:tensorflow:loss = 0.0054021636, step = 9701 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.818\n",
            "INFO:tensorflow:loss = 0.0040995544, step = 9801 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.464\n",
            "INFO:tensorflow:loss = 0.00726716, step = 9901 (0.202 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_mxpsd/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0034471937.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 84.23085911504302\n",
            "Just using average = 598.1993143976493 has RMSE of 104.23183328393432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictors[trainsize:].values))\n",
        "print(len(targets[trainsize:].values.reshape(testsize, noutputs)/SCALE_COLLISIONS))\n",
        "\n",
        "# Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[23,13,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "NoIPNaT3UbJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f68e61-061a-4850-b29a-30d0a5359ad9"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180284490>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511\n",
            "511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5051993  0.45869815 0.43577182 0.47302425 0.5498141  0.600767\n",
            " 0.5123404  0.53738964 0.5240153  0.52028644 0.5878581  0.5521468\n",
            " 0.42057598 0.5662631  0.4849261  0.5182208  0.51844394 0.5679873\n",
            " 0.48783863 0.55446804 0.38091075 0.54891384 0.43582904 0.455078\n",
            " 0.5394019  0.5436133  0.52703655 0.52970874 0.42868984 0.51997936\n",
            " 0.5729331  0.53062236 0.51496494 0.52057445 0.51554286 0.5385779\n",
            " 0.54045093 0.5253848  0.484537   0.54777324 0.5728167  0.56724155\n",
            " 0.43326557 0.5131911  0.508314   0.5161704  0.49952495 0.56435764\n",
            " 0.5183524  0.5124892  0.52438915 0.48305118 0.4849547  0.46947658\n",
            " 0.5106658  0.53285396 0.52265155 0.5624198  0.53384197 0.4575976\n",
            " 0.41304004 0.46495235 0.56669605 0.5417403  0.502962   0.5676383\n",
            " 0.48058116 0.37955463 0.54059017 0.5121707  0.47007358 0.42322338\n",
            " 0.58208835 0.54260814 0.42033184 0.52436626 0.42542255 0.51416194\n",
            " 0.5596732  0.56292903 0.48566806 0.5127467  0.51593006 0.5169562\n",
            " 0.46529186 0.5085639  0.53960025 0.5076922  0.4327277  0.5140475\n",
            " 0.5078887  0.5267981  0.5540122  0.50746524 0.52542865 0.50084484\n",
            " 0.54938686 0.4526099  0.50066364 0.5384463  0.5117339  0.5435313\n",
            " 0.5390166  0.46673    0.50266826 0.5587214  0.5323943  0.51869\n",
            " 0.562683   0.5411109  0.46027172 0.5589007  0.54289997 0.5117358\n",
            " 0.42856014 0.5672358  0.51805484 0.6047877  0.46925342 0.5115775\n",
            " 0.48325336 0.53571117 0.43266475 0.5279273  0.52771556 0.52107036\n",
            " 0.54276264 0.46803272 0.43692005 0.54585636 0.52495944 0.56589496\n",
            " 0.47052562 0.502386   0.53033245 0.53716457 0.5165175  0.5357894\n",
            " 0.5174998  0.50638187 0.48906314 0.5064162  0.4115981  0.51442325\n",
            " 0.42558658 0.42653263 0.5208529  0.5130881  0.5170001  0.41274822\n",
            " 0.52703846 0.5461596  0.57507503 0.5220736  0.53079975 0.42487705\n",
            " 0.5364188  0.51201236 0.5232638  0.45478237 0.537321   0.5042895\n",
            " 0.5205649  0.40370739 0.48551357 0.5729445  0.48270977 0.54518306\n",
            " 0.46895587 0.51332843 0.58219707 0.5081996  0.51571643 0.47556484\n",
            " 0.5647868  0.5410689  0.4812907  0.51325214 0.45005214 0.55844486\n",
            " 0.5508479  0.5100516  0.4439181  0.58172977 0.5482787  0.51356304\n",
            " 0.48023784 0.5284995  0.47718036 0.4796332  0.51214206 0.47335804\n",
            " 0.5126151  0.5830401  0.5499896  0.5506915  0.5273169  0.52400196\n",
            " 0.47255504 0.4230746  0.4116     0.45296657 0.5428752  0.48364818\n",
            " 0.5168189  0.47218883 0.55688846 0.5258521  0.5258311  0.5459746\n",
            " 0.4746989  0.49452007 0.5715598  0.5700644  0.43453395 0.58190906\n",
            " 0.49287593 0.5489749  0.57362735 0.5185126  0.47265422 0.5286559\n",
            " 0.5634688  0.40860736 0.4293517  0.5666121  0.54445636 0.5279082\n",
            " 0.51084507 0.54341304 0.5635928  0.40517604 0.53846157 0.55968845\n",
            " 0.514326   0.46425235 0.5265349  0.516178   0.5682448  0.4264506\n",
            " 0.40826976 0.5139407  0.4942721  0.5009402  0.55966175 0.48124874\n",
            " 0.42461765 0.51673687 0.58753574 0.4169997  0.43534458 0.48418224\n",
            " 0.5359477  0.5817832  0.5226668  0.50359714 0.41455066 0.4606818\n",
            " 0.5222682  0.5524386  0.5463351  0.5636977  0.5663756  0.5226401\n",
            " 0.5233172  0.46776378 0.5007342  0.54961956 0.52291286 0.6016463\n",
            " 0.56981075 0.41840732 0.42971218 0.38937175 0.5669688  0.55722606\n",
            " 0.5288962  0.5685824  0.4223441  0.50399005 0.50207126 0.5268229\n",
            " 0.5527686  0.4739684  0.5275191  0.5204333  0.5611476  0.55989826\n",
            " 0.5022582  0.5255488  0.5387744  0.5030688  0.48977077 0.42464817\n",
            " 0.46060932 0.537506   0.5156325  0.60352504 0.47898853 0.5171317\n",
            " 0.54177845 0.5221919  0.55683315 0.56456363 0.5345992  0.51346004\n",
            " 0.5663012  0.52021396 0.48549068 0.5143107  0.5038737  0.5447272\n",
            " 0.4128493  0.45690143 0.50437534 0.49941432 0.49594104 0.5115355\n",
            " 0.4605273  0.52706707 0.5794829  0.5354365  0.49958217 0.51912487\n",
            " 0.5512408  0.40552318 0.53910625 0.5808028  0.54753673 0.48120105\n",
            " 0.5574149  0.4688624  0.532442   0.55063426 0.5555266  0.46808803\n",
            " 0.4329146  0.54051006 0.49728954 0.59802234 0.52025974 0.5038947\n",
            " 0.47759044 0.5423316  0.55358493 0.4721259  0.5210074  0.4996432\n",
            " 0.49967563 0.51024806 0.5290297  0.44345653 0.53505313 0.47761524\n",
            " 0.5251616  0.40359676 0.5189456  0.46783626 0.40772998 0.51271045\n",
            " 0.4398402  0.52662075 0.53233516 0.51751506 0.5316962  0.5455321\n",
            " 0.5222739  0.52348125 0.44503963 0.5225123  0.4894923  0.5361651\n",
            " 0.53313434 0.42907703 0.5161952  0.60232913 0.551237   0.45576847\n",
            " 0.49685657 0.5234374  0.5590972  0.5804614  0.5222739  0.5694922\n",
            " 0.49001873 0.4536971  0.53152454 0.51564205 0.5124625  0.5218142\n",
            " 0.53619754 0.4787253  0.38835323 0.5353545  0.4823035  0.581663\n",
            " 0.5464133  0.547243   0.47912395 0.42698085 0.53936946 0.43631542\n",
            " 0.48507488 0.5215968  0.5058955  0.51805294 0.5256747  0.49670398\n",
            " 0.5064181  0.56783473 0.42467487 0.51413524 0.5537051  0.5076426\n",
            " 0.56480205 0.55171    0.5403193  0.5115813  0.5098742  0.5441493\n",
            " 0.5334166  0.5503787  0.5180415  0.5384959  0.45453823 0.47979343\n",
            " 0.5419177  0.5290202  0.51268566 0.42681873 0.52724254 0.4587897\n",
            " 0.5669898  0.5061625  0.54105556 0.52448833 0.5574626  0.4798869\n",
            " 0.56121814 0.50305545 0.53632724 0.46542537 0.5828723  0.5264815\n",
            " 0.52532566 0.51969516 0.51148784 0.46630466 0.42488277 0.53334224\n",
            " 0.45716274 0.5407847  0.55602443 0.5032309  0.55335414 0.51401126\n",
            " 0.53108585 0.49734676 0.5064219  0.5137061  0.4349612  0.52595127\n",
            " 0.50346935 0.5493754  0.4757594  0.5095328  0.5382174  0.4989394\n",
            " 0.47525012 0.4173659  0.4834994  0.49905956 0.5292262  0.5740031\n",
            " 0.56176937 0.44013393 0.5680598  0.53934276 0.53682506 0.5224017\n",
            " 0.5399569  0.50354946 0.5497111  0.5720252  0.51732624 0.42935932\n",
            " 0.51611507 0.529106   0.4718436  0.4094447  0.5696486  0.41878688\n",
            " 0.51836765 0.58756244 0.45818317 0.46889675 0.44647205 0.4732741\n",
            " 0.5158366  0.56833637 0.497074   0.4939803  0.5298556  0.5712985\n",
            " 0.5138091  0.56822    0.4694594  0.47854984 0.4796332  0.43834865\n",
            " 0.5313033 ]\n",
            "[0.53057709 0.47200689 0.4788975  0.51335056 0.65977606 0.65891473\n",
            " 0.32213609 0.55813953 0.5503876  0.55297158 0.50301464 0.61757106\n",
            " 0.42980189 0.66838932 0.51335056 0.22739018 0.60034453 0.57364341\n",
            " 0.4918174  0.55469423 0.36950904 0.57536606 0.43927649 0.45391904\n",
            " 0.47028424 0.58225668 0.65374677 0.4952627  0.44099914 0.61068045\n",
            " 0.66925065 0.63479759 0.55555556 0.4952627  0.44272179 0.49440138\n",
            " 0.52282515 0.62790698 0.53143842 0.6089578  0.6580534  0.64341085\n",
            " 0.39018088 0.52024117 0.50904393 0.54780362 0.45047373 0.65202412\n",
            " 0.4005168  0.43152455 0.56330749 0.48062016 0.47028424 0.48320413\n",
            " 0.55469423 0.52368648 0.50904393 0.66322136 0.55727821 0.49009475\n",
            " 0.3875969  0.44444444 0.50129199 0.63221361 0.53660637 0.57105943\n",
            " 1.         0.44530577 0.45047373 0.49698536 0.47631352 0.31438415\n",
            " 0.59086994 0.57105943 0.40654608 0.5503876  0.41946598 0.46770026\n",
            " 0.64685616 0.75107666 0.47631352 0.54091301 0.47459087 0.58225668\n",
            " 0.50904393 0.49956934 0.54091301 0.56416882 0.40913006 0.55986219\n",
            " 0.46339363 0.52799311 0.38415159 0.43927649 0.57450474 0.51507321\n",
            " 0.60034453 0.40654608 0.59000861 0.47200689 0.49870801 0.59173127\n",
            " 0.49440138 0.47975883 0.50732127 0.59000861 0.48751077 0.5047373\n",
            " 0.48148148 0.67700258 0.55900086 0.54608096 0.66063738 0.39362618\n",
            " 0.38845823 0.583118   0.60637382 0.63996555 0.48148148 0.56847545\n",
            " 0.47717485 0.66666667 0.44099914 0.53229974 0.52024117 0.45305771\n",
            " 0.51421189 0.57450474 0.40826873 0.58225668 0.60206718 0.58656331\n",
            " 0.48148148 0.54435831 0.54521964 0.56589147 0.50301464 0.37295435\n",
            " 0.45908699 0.42204996 0.45736434 0.53143842 0.41257537 0.57450474\n",
            " 0.46942291 0.51335056 0.57536606 0.54521964 0.64341085 0.40999139\n",
            " 0.58742463 0.55727821 0.58656331 0.5503876  0.65891473 0.43496985\n",
            " 0.6416882  0.50043066 0.36089578 0.47114556 0.6709733  0.55555556\n",
            " 0.46770026 0.38501292 0.52799311 0.63738157 0.41343669 0.50732127\n",
            " 0.30577089 0.50990525 0.66408269 0.53919035 0.54952627 0.5211025\n",
            " 0.57450474 0.59689922 0.41946598 0.5503876  0.37209302 0.65288544\n",
            " 0.5374677  0.48751077 0.41343669 0.68819983 0.63135228 0.54091301\n",
            " 0.47028424 0.52627046 0.4952627  0.51765719 0.45822567 0.42894057\n",
            " 0.54177433 0.63824289 0.62704565 0.60465116 0.5374677  0.57881137\n",
            " 0.51162791 0.39793282 0.42204996 0.5374677  0.59345392 0.56503015\n",
            " 0.51507321 0.16192937 0.58053402 0.5960379  0.55986219 0.52368648\n",
            " 0.48751077 0.25064599 0.58914729 0.62360034 0.38587425 0.52971576\n",
            " 0.42291128 0.60292851 0.64254953 0.61929371 0.58570198 0.47975883\n",
            " 0.64944014 0.26614987 0.38587425 0.55813953 0.32988803 0.45305771\n",
            " 0.55641688 0.44444444 0.6873385  0.38587425 0.66149871 0.45478036\n",
            " 0.52196382 0.48837209 0.60809647 0.59259259 0.61757106 0.4332472\n",
            " 0.40654608 0.5667528  0.40913006 0.54177433 0.56503015 0.48148148\n",
            " 0.38845823 0.53229974 0.59086994 0.40568475 0.39190353 0.5047373\n",
            " 0.48148148 0.7002584  0.47631352 0.56244617 0.42118863 0.48406546\n",
            " 0.47975883 0.65202412 0.48492679 0.60809647 0.39190353 0.50559862\n",
            " 0.55727821 0.44013781 0.54177433 0.6416882  0.56416882 0.60981912\n",
            " 0.54608096 0.39534884 0.40913006 0.32127476 0.70111972 0.6287683\n",
            " 0.52799311 0.57278208 0.39362618 0.58139535 0.4203273  0.53229974\n",
            " 0.57364341 0.62015504 0.51248923 0.49784668 0.59776055 0.625323\n",
            " 0.57795004 0.50387597 0.61929371 0.50904393 0.51765719 0.4039621\n",
            " 0.47803618 0.52971576 0.57795004 0.68130922 0.46339363 0.54263566\n",
            " 0.58656331 0.45650301 0.55727821 0.60551249 0.56244617 0.56847545\n",
            " 0.53919035 0.5374677  0.55124892 0.54866494 0.55986219 0.45822567\n",
            " 0.38329027 0.42204996 0.41085271 0.41085271 0.47114556 0.64857881\n",
            " 0.49784668 0.48234281 0.58656331 0.35658915 0.44702842 0.50301464\n",
            " 0.52713178 0.44702842 0.46339363 0.48492679 0.49095607 0.54177433\n",
            " 0.56761413 0.53574505 0.5374677  0.58828596 0.54952627 0.40826873\n",
            " 0.36175711 0.3255814  0.4754522  0.72782084 0.43496985 0.51679587\n",
            " 0.65202412 0.5374677  0.57622739 0.54091301 0.63996555 0.56503015\n",
            " 0.45219638 0.48751077 0.51937984 0.26873385 0.6124031  0.47631352\n",
            " 0.53402239 0.36692506 0.52885444 0.43669251 0.48492679 0.54349699\n",
            " 0.36089578 0.41429802 0.52540913 0.61068045 0.42204996 0.62790698\n",
            " 0.28251507 0.48148148 0.45564169 0.50645995 0.56330749 0.54177433\n",
            " 0.4918174  0.48578811 0.54521964 0.64427218 0.42463394 0.50043066\n",
            " 0.53316107 0.34969854 0.64341085 0.62704565 0.58828596 0.55813953\n",
            " 0.42204996 0.43669251 0.61584841 0.69336779 0.41257537 0.5667528\n",
            " 0.53316107 0.39879414 0.38845823 0.52282515 0.4918174  0.71748493\n",
            " 0.65719208 0.56330749 0.51679587 0.37812231 0.6089578  0.51076658\n",
            " 0.56589147 0.56330749 0.61584841 0.52627046 0.42807924 0.42291128\n",
            " 0.4461671  0.53143842 0.43238587 0.56330749 0.52368648 0.50129199\n",
            " 0.57536606 0.49612403 0.53402239 0.49956934 0.50904393 0.56933678\n",
            " 0.54694229 0.53316107 0.55727821 0.45822567 0.54952627 0.48406546\n",
            " 0.46080965 0.6089578  0.58053402 0.35228252 0.61757106 0.45650301\n",
            " 0.63049096 0.41085271 0.52799311 0.59345392 0.6873385  0.45822567\n",
            " 0.63910422 0.54349699 0.52799311 0.36434109 0.62618432 0.54694229\n",
            " 0.43755383 0.54952627 0.51248923 0.49956934 0.34625323 0.51937984\n",
            " 0.38845823 0.54349699 0.48664944 0.59086994 0.51507321 0.50559862\n",
            " 0.56761413 0.47200689 0.42894057 0.60809647 0.49267873 0.5796727\n",
            " 0.53057709 0.6124031  0.56158484 0.49956934 0.61154177 0.56933678\n",
            " 0.51765719 0.41257537 0.50215332 0.47631352 0.64771748 0.60981912\n",
            " 0.58570198 0.45478036 0.58570198 0.58570198 0.50559862 0.50129199\n",
            " 0.52196382 0.5081826  0.58484065 0.5538329  0.52196382 0.47286822\n",
            " 0.49956934 0.3712317  0.51421189 0.39534884 0.59259259 0.48923342\n",
            " 0.49956934 0.66838932 0.52885444 0.55813953 0.41860465 0.49784668\n",
            " 0.4203273  0.51076658 0.56847545 0.47028424 0.5994832  0.67355728\n",
            " 0.47028424 0.58914729 0.41085271 0.39018088 0.43583118 0.46080965\n",
            " 0.47975883]\n",
            "The trained model has an aproximate error rate of 9.56824108742455 which equates to 2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "            'year':[2019,2019,2019,2020],\n",
        "          'da':[10,10,10,20],\n",
        "         'mxpsd' : [9.2,20.5,45.2,20.5],\n",
        "         'Apr' : [0,0,0,0],\n",
        "         'Aug' : [1,1,1,1],\n",
        "         'Dec' : [0,0,0,0],\n",
        "         'Feb' : [0,0,0,0],\n",
        "         'Jan' : [0,0,0,0],\n",
        "         'Jul' : [0,0,0,0],\n",
        "         'Jun' : [0,0,0,0],\n",
        "         'Mar' : [0,0,0,0],\n",
        "         'May' : [0,0,0,0],\n",
        "         'Nov' : [0,0,0,0],\n",
        "         'Oct' : [0,0,0,0],\n",
        "         'Sep' : [0,0,0,0],\n",
        "         'Fri' : [0,0,0,0],\n",
        "         'Mon' : [1,1,1,1],\n",
        "         'Sat' : [0,0,0,0],\n",
        "         'Sun' : [0,0,0,0],\n",
        "         'Thu' : [0,0,0,0],\n",
        "         'Tue' : [0,0,0,0],\n",
        "         'Wed' : [0,0,0,0]\n",
        "      \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_mxpsd', hidden_units=[23,13,9], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcJ23lA21oRs",
        "outputId": "0f4ad708-e407-4d74-faff-07a002199405"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180da0410>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_mxpsd', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_mxpsd/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[787.65375 784.37445 777.20844 780.4174 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low RMSE value suggests that a relationship between the maximum sustained wind speed and the number of collisions exist. The model produced can be used to predict the number of collisions with a degree of accuracy. As with the other DNN models produced the error rate is higher."
      ],
      "metadata": {
        "id": "6ugiuzBKuNne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Whole Dataset\n",
        "As the purpose of this assignment is to accurately predict the number of collisions given the weather condition**s**, all available weather conditions are used as input variables to train a DNN model."
      ],
      "metadata": {
        "id": "Dzn0MDJwVdg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/datadnn.csv', index_col=0, )\n",
        "print(df[:6])"
      ],
      "metadata": {
        "id": "r3AhZB1bVybn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd062f05-a1f3-4538-da6f-55cf0ed434ca"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS  temp  dewp     slp  visib  wdsp  mxpsd   gust  \\\n",
            "1  2020  24             524  37.3  33.7  1028.5    6.5   3.3    8.0  999.9   \n",
            "2  2021  12             278  37.0  29.1  1019.0   10.0   6.5   12.0  999.9   \n",
            "3  2021  22             254  36.5  28.4  1003.1   10.0   7.8   12.0   20.0   \n",
            "4  2021  27             262  34.6  33.8  1012.8    8.0   7.8   12.0  999.9   \n",
            "5  2021  26             263  31.9  23.4  1016.9    9.0   7.4   12.0  999.9   \n",
            "6  2022  24             237  34.5  23.8  1010.6    9.7   7.4   12.0  999.9   \n",
            "\n",
            "   ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "2  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  ...    0    0    0    0    0    0    0    1    0    0  \n",
            "4  ...    0    0    0    0    0    0    0    0    1    0  \n",
            "5  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the whole dataset contains the error values for Dew Point, Sea Level Pressure, Maximum Sustained Wind Speed and Gust; these must be removed."
      ],
      "metadata": {
        "id": "ZhkTk0XMApB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean the data\n",
        "dnn = df.loc[df[\"year\"] != 2012]\n",
        "dnn = dnn.loc[dnn[\"year\"] < 2020]\n",
        "dnn = dnn.loc[dnn[\"dewp\"] != 9999]\n",
        "dnn = dnn.loc[dnn[\"slp\"] != 9999]\n",
        "dnn = dnn.loc[dnn[\"mxpsd\"] != 999.9]\n",
        "dnn = dnn.loc[dnn[\"gust\"] != 999.9]\n",
        "#Move the target to the end\n",
        "cols = dnn['NUM_COLLISIONS']\n",
        "dnn = dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "dnn.insert(loc=38, column='NUM_COLLISIONS', value=cols)\n",
        "print(dnn[:6])\n",
        "dnn.describe()"
      ],
      "metadata": {
        "id": "izyExLEIVybo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "e141b863-3918-4f19-8a01-96d8cc69001e"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    year  da  temp  dewp     slp  visib  wdsp  mxpsd  gust   max  ...  Oct  \\\n",
            "74  2016  17  40.2  32.3  1007.3    9.2   7.7   12.0  18.1  51.1  ...    0   \n",
            "76  2014   9  23.5   8.3  1034.2   10.0   7.9   12.0  20.0  28.9  ...    0   \n",
            "79  2019  19  34.5  29.7  1022.0    9.8   6.9   13.0  21.0  39.9  ...    0   \n",
            "80  2015  11  27.1  12.1  1035.5   10.0   8.8   13.0  17.1  37.0  ...    0   \n",
            "83  2015  29  29.2  20.9  1022.9   10.0   8.5   13.0  20.0  36.0  ...    0   \n",
            "85  2019  13  26.0  12.8  1030.5   10.0   8.0   13.0  15.9  30.9  ...    0   \n",
            "\n",
            "    Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "74    0    0    0    1    0    0    0    0             451  \n",
            "76    0    0    0    0    0    0    0    1             561  \n",
            "79    0    1    0    0    0    0    0    0             479  \n",
            "80    0    0    0    1    0    0    0    0             341  \n",
            "83    0    0    0    0    0    0    0    1             519  \n",
            "85    0    0    0    1    0    0    0    0             374  \n",
            "\n",
            "[6 rows x 39 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             year           da         temp         dewp          slp  \\\n",
              "count  1629.00000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean   2015.91283    15.702885    47.909638    45.903254  1015.632904   \n",
              "std       2.01341     8.667634    13.746339   247.352840     8.134237   \n",
              "min    2013.00000     1.000000     5.800000    -6.700000   989.500000   \n",
              "25%    2014.00000     8.000000    38.100000    28.200000  1010.600000   \n",
              "50%    2016.00000    16.000000    47.000000    40.200000  1015.400000   \n",
              "75%    2018.00000    23.000000    58.800000    52.800000  1021.100000   \n",
              "max    2019.00000    31.000000    77.500000  9999.900000  1039.100000   \n",
              "\n",
              "             visib         wdsp        mxpsd         gust         max  ...  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.00000  ...   \n",
              "mean      8.225599    12.602087    20.060896    27.511602    55.73407  ...   \n",
              "std       2.227285     3.986056     5.294117     7.366770    13.52726  ...   \n",
              "min       0.600000     4.500000     8.900000    14.000000    18.00000  ...   \n",
              "25%       7.000000    10.000000    15.900000    22.000000    46.00000  ...   \n",
              "50%       9.300000    12.000000    19.000000    26.000000    55.00000  ...   \n",
              "75%      10.000000    14.400000    22.900000    31.100000    66.00000  ...   \n",
              "max      10.000000    39.300000    49.000000    71.100000    87.10000  ...   \n",
              "\n",
              "               Oct          Sep          Fri          Mon          Sat  \\\n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000  1629.000000   \n",
              "mean      0.087784     0.071209     0.143646     0.139963     0.141191   \n",
              "std       0.283067     0.257253     0.350839     0.347055     0.348325   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "               Sun          Thu          Tue          Wed  NUM_COLLISIONS  \n",
              "count  1629.000000  1629.000000  1629.000000  1629.000000     1629.000000  \n",
              "mean      0.139963     0.151627     0.138122     0.145488      596.513198  \n",
              "std       0.347055     0.358769     0.345133     0.352700      104.479660  \n",
              "min       0.000000     0.000000     0.000000     0.000000      188.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000      526.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000      597.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000      663.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000     1161.000000  \n",
              "\n",
              "[8 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7f5d167-29ba-4cad-ab04-0f2f1642184d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>gust</th>\n",
              "      <th>max</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1629.00000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "      <td>1629.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2015.91283</td>\n",
              "      <td>15.702885</td>\n",
              "      <td>47.909638</td>\n",
              "      <td>45.903254</td>\n",
              "      <td>1015.632904</td>\n",
              "      <td>8.225599</td>\n",
              "      <td>12.602087</td>\n",
              "      <td>20.060896</td>\n",
              "      <td>27.511602</td>\n",
              "      <td>55.73407</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087784</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.143646</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.141191</td>\n",
              "      <td>0.139963</td>\n",
              "      <td>0.151627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>596.513198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.01341</td>\n",
              "      <td>8.667634</td>\n",
              "      <td>13.746339</td>\n",
              "      <td>247.352840</td>\n",
              "      <td>8.134237</td>\n",
              "      <td>2.227285</td>\n",
              "      <td>3.986056</td>\n",
              "      <td>5.294117</td>\n",
              "      <td>7.366770</td>\n",
              "      <td>13.52726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283067</td>\n",
              "      <td>0.257253</td>\n",
              "      <td>0.350839</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.348325</td>\n",
              "      <td>0.347055</td>\n",
              "      <td>0.358769</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.352700</td>\n",
              "      <td>104.479660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.100000</td>\n",
              "      <td>28.200000</td>\n",
              "      <td>1010.600000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>46.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>526.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.00000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>40.200000</td>\n",
              "      <td>1015.400000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>55.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>597.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.00000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>58.800000</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>1021.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>66.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>663.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.00000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>9999.900000</td>\n",
              "      <td>1039.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>39.300000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7f5d167-29ba-4cad-ab04-0f2f1642184d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7f5d167-29ba-4cad-ab04-0f2f1642184d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7f5d167-29ba-4cad-ab04-0f2f1642184d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle = dnn.iloc[np.random.permutation(len(dnn))]\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "pOJhsz3dVybo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61d5c49-df8a-46fd-b21d-441ec3b01c9d"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      year  da  temp  dewp     slp  visib  wdsp  mxpsd  gust   max  ...  Nov  \\\n",
            "384   2013   6  34.8  30.4  1014.9    9.0   6.1   13.0  17.1  39.2  ...    0   \n",
            "3569  2015  27  52.9  49.0  1013.0    4.5  13.1   19.0  24.1  57.0  ...    0   \n",
            "2452  2013  23  70.6  65.0  1013.1    7.8  12.1   22.9  28.0  77.0  ...    0   \n",
            "2918  2014  21  57.7  52.3  1015.5    9.3  10.5   15.9  21.0  60.8  ...    0   \n",
            "760   2015   6  22.7  12.6  1028.3    8.3  11.7   19.0  26.0  37.0  ...    0   \n",
            "1038  2015  17  47.5  43.2  1021.5    6.9  12.5   15.9  24.1  54.0  ...    0   \n",
            "\n",
            "      Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "384     0    0    0    0    0    0    0    1    0  \n",
            "3569    0    0    0    0    1    0    0    0    0  \n",
            "2452    0    0    0    0    0    0    1    0    0  \n",
            "2918    1    0    0    1    0    0    0    0    0  \n",
            "760     0    0    0    0    0    0    1    0    0  \n",
            "1038    0    0    0    0    0    0    1    0    0  \n",
            "\n",
            "[6 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select the target as the last col\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "iOF3gP_XVybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524e0825-3d13-4b38-ae90-bb97ca8fb976"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384     566\n",
            "3569    518\n",
            "2452    636\n",
            "2918    607\n",
            "760     939\n",
            "1038    679\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)\n"
      ],
      "metadata": {
        "id": "7XAEry6uVybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9858ca05-fb39-4e09-8194-a9d607fe8bb7"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,11,5,3], optimizer=tf.train.AdamOptimizer(learning_rate=0.001), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_COLLISIONS, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_COLLISIONS\n",
        "#Test the model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "sb-ehJ2tVybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf2e236-aa1e-481d-f58e-4b0bd3340e50"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f217f9f3150>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.1504958, step = 1\n",
            "INFO:tensorflow:global_step/sec: 356.625\n",
            "INFO:tensorflow:loss = 0.00729577, step = 101 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.872\n",
            "INFO:tensorflow:loss = 0.0069492403, step = 201 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.751\n",
            "INFO:tensorflow:loss = 0.008179862, step = 301 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.627\n",
            "INFO:tensorflow:loss = 0.008755423, step = 401 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.636\n",
            "INFO:tensorflow:loss = 0.0059746047, step = 501 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.109\n",
            "INFO:tensorflow:loss = 0.007540924, step = 601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.519\n",
            "INFO:tensorflow:loss = 0.006275481, step = 701 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.308\n",
            "INFO:tensorflow:loss = 0.00870665, step = 801 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.474\n",
            "INFO:tensorflow:loss = 0.008795716, step = 901 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.415\n",
            "INFO:tensorflow:loss = 0.0061577274, step = 1001 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.308\n",
            "INFO:tensorflow:loss = 0.00618474, step = 1101 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.404\n",
            "INFO:tensorflow:loss = 0.005519619, step = 1201 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.021\n",
            "INFO:tensorflow:loss = 0.0071878145, step = 1301 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.542\n",
            "INFO:tensorflow:loss = 0.0070745056, step = 1401 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.429\n",
            "INFO:tensorflow:loss = 0.00668591, step = 1501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.581\n",
            "INFO:tensorflow:loss = 0.0070610363, step = 1601 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.38\n",
            "INFO:tensorflow:loss = 0.007884489, step = 1701 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.523\n",
            "INFO:tensorflow:loss = 0.0053673927, step = 1801 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.069\n",
            "INFO:tensorflow:loss = 0.006242981, step = 1901 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.154\n",
            "INFO:tensorflow:loss = 0.006569907, step = 2001 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.668\n",
            "INFO:tensorflow:loss = 0.0055710324, step = 2101 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.693\n",
            "INFO:tensorflow:loss = 0.005154959, step = 2201 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.074\n",
            "INFO:tensorflow:loss = 0.007890559, step = 2301 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.463\n",
            "INFO:tensorflow:loss = 0.0070859557, step = 2401 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.595\n",
            "INFO:tensorflow:loss = 0.0073760524, step = 2501 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.377\n",
            "INFO:tensorflow:loss = 0.0071992497, step = 2601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.099\n",
            "INFO:tensorflow:loss = 0.0057425313, step = 2701 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.085\n",
            "INFO:tensorflow:loss = 0.006619026, step = 2801 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.862\n",
            "INFO:tensorflow:loss = 0.0063599166, step = 2901 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.04\n",
            "INFO:tensorflow:loss = 0.008492172, step = 3001 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.505\n",
            "INFO:tensorflow:loss = 0.005868003, step = 3101 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.196\n",
            "INFO:tensorflow:loss = 0.0025183891, step = 3201 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.932\n",
            "INFO:tensorflow:loss = 0.004395933, step = 3301 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.443\n",
            "INFO:tensorflow:loss = 0.005431979, step = 3401 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.166\n",
            "INFO:tensorflow:loss = 0.0039400314, step = 3501 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.221\n",
            "INFO:tensorflow:loss = 0.0060357326, step = 3601 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.2\n",
            "INFO:tensorflow:loss = 0.0038679931, step = 3701 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.942\n",
            "INFO:tensorflow:loss = 0.0054311818, step = 3801 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.187\n",
            "INFO:tensorflow:loss = 0.0044529135, step = 3901 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.555\n",
            "INFO:tensorflow:loss = 0.0068683634, step = 4001 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.942\n",
            "INFO:tensorflow:loss = 0.004922648, step = 4101 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.668\n",
            "INFO:tensorflow:loss = 0.0048307227, step = 4201 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.629\n",
            "INFO:tensorflow:loss = 0.004451268, step = 4301 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.841\n",
            "INFO:tensorflow:loss = 0.005635743, step = 4401 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.176\n",
            "INFO:tensorflow:loss = 0.0046443725, step = 4501 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 480.64\n",
            "INFO:tensorflow:loss = 0.004662819, step = 4601 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.999\n",
            "INFO:tensorflow:loss = 0.0047257068, step = 4701 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.303\n",
            "INFO:tensorflow:loss = 0.00407234, step = 4801 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.346\n",
            "INFO:tensorflow:loss = 0.0066856844, step = 4901 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.82\n",
            "INFO:tensorflow:loss = 0.00560824, step = 5001 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 487.961\n",
            "INFO:tensorflow:loss = 0.0056693335, step = 5101 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.638\n",
            "INFO:tensorflow:loss = 0.004020586, step = 5201 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.829\n",
            "INFO:tensorflow:loss = 0.005873436, step = 5301 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.102\n",
            "INFO:tensorflow:loss = 0.009579221, step = 5401 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.69\n",
            "INFO:tensorflow:loss = 0.0044490146, step = 5501 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.307\n",
            "INFO:tensorflow:loss = 0.006549164, step = 5601 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.307\n",
            "INFO:tensorflow:loss = 0.0044001793, step = 5701 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.069\n",
            "INFO:tensorflow:loss = 0.004558389, step = 5801 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.245\n",
            "INFO:tensorflow:loss = 0.005613574, step = 5901 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.03\n",
            "INFO:tensorflow:loss = 0.0036618793, step = 6001 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.829\n",
            "INFO:tensorflow:loss = 0.0044038803, step = 6101 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.262\n",
            "INFO:tensorflow:loss = 0.005283477, step = 6201 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.286\n",
            "INFO:tensorflow:loss = 0.0074899904, step = 6301 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.296\n",
            "INFO:tensorflow:loss = 0.0039799046, step = 6401 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.284\n",
            "INFO:tensorflow:loss = 0.005331892, step = 6501 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.027\n",
            "INFO:tensorflow:loss = 0.005031377, step = 6601 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.214\n",
            "INFO:tensorflow:loss = 0.004785847, step = 6701 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.105\n",
            "INFO:tensorflow:loss = 0.0048374753, step = 6801 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.08\n",
            "INFO:tensorflow:loss = 0.005883584, step = 6901 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.568\n",
            "INFO:tensorflow:loss = 0.0042065536, step = 7001 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.538\n",
            "INFO:tensorflow:loss = 0.0061432375, step = 7101 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.791\n",
            "INFO:tensorflow:loss = 0.0040349835, step = 7201 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.881\n",
            "INFO:tensorflow:loss = 0.005649314, step = 7301 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.421\n",
            "INFO:tensorflow:loss = 0.003956478, step = 7401 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.289\n",
            "INFO:tensorflow:loss = 0.004331499, step = 7501 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.368\n",
            "INFO:tensorflow:loss = 0.005680964, step = 7601 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.609\n",
            "INFO:tensorflow:loss = 0.006752254, step = 7701 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.029\n",
            "INFO:tensorflow:loss = 0.006971864, step = 7801 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.981\n",
            "INFO:tensorflow:loss = 0.0032736172, step = 7901 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.077\n",
            "INFO:tensorflow:loss = 0.0035720584, step = 8001 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.664\n",
            "INFO:tensorflow:loss = 0.00470471, step = 8101 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.117\n",
            "INFO:tensorflow:loss = 0.007350346, step = 8201 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.075\n",
            "INFO:tensorflow:loss = 0.00782658, step = 8301 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.683\n",
            "INFO:tensorflow:loss = 0.004875287, step = 8401 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.802\n",
            "INFO:tensorflow:loss = 0.004180988, step = 8501 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.753\n",
            "INFO:tensorflow:loss = 0.006801332, step = 8601 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.964\n",
            "INFO:tensorflow:loss = 0.0053835697, step = 8701 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 485.642\n",
            "INFO:tensorflow:loss = 0.0042045894, step = 8801 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 496.844\n",
            "INFO:tensorflow:loss = 0.0031424484, step = 8901 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.35\n",
            "INFO:tensorflow:loss = 0.006625563, step = 9001 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.161\n",
            "INFO:tensorflow:loss = 0.0060096807, step = 9101 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.866\n",
            "INFO:tensorflow:loss = 0.0039077466, step = 9201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 486.509\n",
            "INFO:tensorflow:loss = 0.0061639883, step = 9301 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.11\n",
            "INFO:tensorflow:loss = 0.0067821853, step = 9401 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.846\n",
            "INFO:tensorflow:loss = 0.006836596, step = 9501 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.485\n",
            "INFO:tensorflow:loss = 0.004330271, step = 9601 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.932\n",
            "INFO:tensorflow:loss = 0.0052938387, step = 9701 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 507.509\n",
            "INFO:tensorflow:loss = 0.0026093165, step = 9801 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.841\n",
            "INFO:tensorflow:loss = 0.0060585625, step = 9901 (0.200 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.004677743.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 88.93854176237826\n",
            "Just using average = 594.9838833461243 has RMSE of 106.37525048712067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictors[trainsize:].values)\n",
        "\n",
        "#Ensure the hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,11,5,3], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_COLLISIONS\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "ssTSefyuVybq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc62817f-a120-4e1b-c16d-4631b8c2954a"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2180139dd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.016e+03 2.000e+00 6.920e+01 ... 1.000e+00 0.000e+00 0.000e+00]\n",
            " [2.013e+03 6.000e+00 3.570e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.013e+03 4.000e+00 3.700e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " ...\n",
            " [2.015e+03 3.000e+00 2.100e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
            " [2.015e+03 1.000e+00 3.180e+01 ... 0.000e+00 0.000e+00 1.000e+00]\n",
            " [2.019e+03 2.800e+01 5.600e+01 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5804361  0.36458325 0.5005898  0.56453085 0.4090857  0.53698355\n",
            " 0.5216763  0.51892114 0.51624924 0.54910743 0.4637513  0.540053\n",
            " 0.48329538 0.40637717 0.41842368 0.49793607 0.46268165 0.4855113\n",
            " 0.47952563 0.50860465 0.5278021  0.47708243 0.5283677  0.45664427\n",
            " 0.3662992  0.4640445  0.5292875  0.49303505 0.4456845  0.48155963\n",
            " 0.5617424  0.52067834 0.3760687  0.42993337 0.45064798 0.52033186\n",
            " 0.50704384 0.4621208  0.5054912  0.54431456 0.45516363 0.4289306\n",
            " 0.5706761  0.5585941  0.55604494 0.5415943  0.55249345 0.37524503\n",
            " 0.53940195 0.46085212 0.5589418  0.4878664  0.5276209  0.50284505\n",
            " 0.5512342  0.5349946  0.4657466  0.49300832 0.5120399  0.5029217\n",
            " 0.5759807  0.3934291  0.48674312 0.5018239  0.5229831  0.5630135\n",
            " 0.463028   0.47338292 0.54236007 0.531649   0.5279408  0.36029345\n",
            " 0.50616556 0.5223327  0.5123998  0.5269077  0.49584347 0.46650746\n",
            " 0.5183588  0.44963884 0.5538241  0.4947494  0.45724574 0.50156635\n",
            " 0.5072025  0.57479453 0.44723415 0.54868627 0.40763664 0.5558562\n",
            " 0.45216405 0.50815904 0.4797724  0.5192086  0.58947414 0.48519734\n",
            " 0.5296033  0.53955716 0.5576521  0.5749408  0.48950133 0.5840876\n",
            " 0.55694836 0.51530975 0.49226558 0.5616505  0.571352   0.43323213\n",
            " 0.53390634 0.4605668  0.49895114 0.51314473 0.43386376 0.5460644\n",
            " 0.5360414  0.5033624  0.45546573 0.46384647 0.59220785 0.47291243\n",
            " 0.5528232  0.5120069  0.4271121  0.5737587  0.47777104 0.5325811\n",
            " 0.58212745 0.39012486 0.60008025 0.5538084  0.48682505 0.5302761\n",
            " 0.4939059  0.5107741  0.43698213 0.42657432 0.38827077 0.54344916\n",
            " 0.50701886 0.4041631  0.4672245  0.5207987  0.51158017 0.4993415\n",
            " 0.5578656  0.5413816  0.48448226 0.4933037  0.4562752  0.54005295\n",
            " 0.5762518  0.37939253 0.5552778  0.5352609  0.44320348 0.48272127\n",
            " 0.38692307 0.5099841  0.47722435 0.5029394  0.47745827 0.53204936\n",
            " 0.47995833 0.4902423  0.56038636 0.5094574  0.5183022  0.61172825\n",
            " 0.49803853 0.50974697 0.47893333 0.54466057 0.53203696 0.5195341\n",
            " 0.5629405  0.5947404  0.5476797  0.5179383  0.533825   0.51480156\n",
            " 0.561232   0.538125   0.5436858  0.49936062 0.5349147  0.53144675\n",
            " 0.56640035 0.56157625 0.47962642 0.5911866  0.49481547 0.51907414\n",
            " 0.40855956 0.53019685 0.42511156 0.48469982 0.52178097 0.48242107\n",
            " 0.4745319  0.38805407 0.5046474  0.51995635 0.46139416 0.5339074\n",
            " 0.53881603 0.5558171  0.48861852 0.50087684 0.46738443 0.52050346\n",
            " 0.5299196  0.5036492  0.53641105 0.5421716  0.42333382 0.5350968\n",
            " 0.52719885 0.4728751  0.5922685  0.44198447 0.47071305 0.4926441\n",
            " 0.538293   0.49204102 0.518214   0.45008796 0.5089536  0.4857292\n",
            " 0.5212868  0.41163367 0.52813286 0.57522875 0.53973603 0.5584487\n",
            " 0.5079609  0.46271238 0.3869127  0.5294287  0.5747954  0.56596\n",
            " 0.4927736  0.48864958 0.5147666  0.50212866 0.54397476 0.5176467\n",
            " 0.54472876 0.57711303 0.52283585 0.45739228 0.49899936 0.51399046\n",
            " 0.479243   0.48220348 0.5284246  0.48936343 0.49729037 0.4633453\n",
            " 0.5160877  0.3656538  0.53262454 0.42127132 0.5265117  0.5581403\n",
            " 0.49486682 0.4004927  0.4854849  0.5433154  0.5799241  0.39507136\n",
            " 0.5005917  0.58519685 0.46897325 0.53246385 0.46295422 0.53836334\n",
            " 0.49119446 0.5304376  0.581487   0.59907633 0.47952685 0.49725243\n",
            " 0.44031966 0.49948034 0.40211952 0.5373157  0.5864703  0.5454767\n",
            " 0.36125442 0.5496313  0.48252782 0.4067657  0.4081396  0.57871556\n",
            " 0.5002477  0.36791822 0.52158046 0.47733137 0.5212282  0.53822136\n",
            " 0.51984656 0.4769273  0.52548677 0.59077084 0.4629329  0.53385323\n",
            " 0.4996422  0.5647212  0.5333976  0.5285843  0.58167005 0.4100029\n",
            " 0.5971137  0.48109406 0.5058334  0.4324126  0.513361   0.5118556\n",
            " 0.57347864 0.495053   0.5511666  0.5574659  0.5420461  0.49695933\n",
            " 0.4883778  0.5211959 ]\n",
            "[0.60034453 0.33850129 0.51421189 0.49612403 0.35228252 0.46942291\n",
            " 0.51765719 0.5994832  0.5374677  0.57622739 0.53057709 0.51937984\n",
            " 0.49956934 0.30060293 0.36950904 0.46080965 0.40137812 0.5211025\n",
            " 0.44186047 0.56933678 0.63738157 0.45391904 0.36175711 0.47975883\n",
            " 0.44702842 0.48837209 0.46080965 0.60551249 0.48664944 0.82687339\n",
            " 0.49870801 0.53229974 0.36692506 0.46511628 0.47717485 0.44444444\n",
            " 0.51507321 0.39276486 0.46511628 0.63221361 0.52024117 0.46339363\n",
            " 0.64082687 0.58570198 0.63910422 0.60723514 0.61326443 0.40913006\n",
            " 0.49095607 0.49009475 0.58914729 0.51162791 0.45305771 0.51248923\n",
            " 0.67011197 0.49440138 0.49784668 0.49698536 0.4005168  0.54091301\n",
            " 0.60551249 0.43066322 0.52540913 0.54435831 0.55900086 0.58570198\n",
            " 0.51765719 0.45391904 0.60120586 0.36950904 0.60378984 0.29371232\n",
            " 0.5211025  0.4039621  0.47717485 0.59345392 0.49440138 0.40913006\n",
            " 0.45650301 0.56933678 0.6089578  0.52799311 0.46511628 0.4788975\n",
            " 0.5374677  0.5667528  0.43410853 0.40999139 0.44788975 0.57364341\n",
            " 0.56589147 0.54005168 0.47717485 0.35228252 0.60292851 0.57192076\n",
            " 0.59086994 0.32988803 0.48492679 0.51076658 0.4788975  0.60981912\n",
            " 0.86046512 0.58828596 0.55555556 0.53919035 0.67355728 0.38673557\n",
            " 0.45650301 0.51765719 0.61412575 0.48492679 0.35745047 0.60034453\n",
            " 0.63652024 0.54866494 0.34022394 0.48062016 0.68819983 0.56072351\n",
            " 0.55813953 0.36606374 0.416882   0.64685616 0.50990525 0.68044789\n",
            " 0.58742463 0.40137812 0.62704565 0.54349699 0.43152455 0.57622739\n",
            " 0.46339363 0.37639966 0.41602067 0.41946598 0.42980189 0.47286822\n",
            " 0.49009475 0.42204996 0.40913006 0.48320413 0.51593454 0.52885444\n",
            " 0.60551249 0.53488372 0.51421189 0.5667528  0.49612403 0.51937984\n",
            " 0.52885444 0.44530577 0.67183463 0.50215332 0.43927649 0.56330749\n",
            " 0.34280792 0.57622739 0.41343669 0.5503876  0.44444444 0.52368648\n",
            " 0.44702842 0.49095607 0.66149871 0.48148148 0.5245478  0.70456503\n",
            " 0.50990525 0.52799311 0.47975883 0.51765719 0.63135228 0.58139535\n",
            " 0.55641688 0.53057709 0.64944014 0.54694229 0.51076658 0.52196382\n",
            " 0.31007752 0.49612403 0.56761413 0.50129199 0.65030146 0.4918174\n",
            " 0.65288544 0.60378984 0.43410853 0.52196382 0.57881137 0.60551249\n",
            " 0.48751077 0.53574505 0.52024117 0.58828596 0.60637382 1.\n",
            " 0.68217054 0.38329027 0.54521964 0.5796727  0.54005168 0.49784668\n",
            " 0.46339363 0.68217054 0.32816537 0.47114556 0.45650301 0.60637382\n",
            " 0.35486649 0.51765719 0.54177433 0.55986219 0.46511628 0.50129199\n",
            " 0.48751077 0.44099914 0.57536606 0.54521964 0.54608096 0.53229974\n",
            " 0.44358312 0.38501292 0.5211025  0.43669251 0.43755383 0.43927649\n",
            " 0.64254953 0.42463394 0.51421189 0.57536606 0.60378984 0.56761413\n",
            " 0.57105943 0.51765719 0.40482343 0.62187769 0.64944014 0.53402239\n",
            " 0.54005168 0.63824289 0.54091301 0.59776055 0.60809647 0.60551249\n",
            " 0.60292851 0.74677003 0.47372954 0.50301464 0.55124892 0.54866494\n",
            " 0.46856158 0.53057709 0.56589147 0.44272179 0.47459087 0.34366925\n",
            " 0.55555556 0.37812231 0.46425495 0.43152455 0.55727821 0.55727821\n",
            " 0.5081826  0.42463394 0.4461671  0.45908699 0.6287683  0.3910422\n",
            " 0.49956934 0.54608096 0.53660637 0.60206718 0.34711456 0.59086994\n",
            " 0.54177433 0.54263566 0.53488372 0.69336779 0.50387597 0.61154177\n",
            " 0.49009475 0.46942291 0.3875969  0.48406546 0.55297158 0.54694229\n",
            " 0.38845823 0.49095607 0.48923342 0.46339363 0.45908699 0.56847545\n",
            " 0.50990525 0.36950904 0.51679587 0.48492679 0.55986219 0.68217054\n",
            " 0.60292851 0.50215332 0.51076658 0.66925065 0.53143842 0.60465116\n",
            " 0.48751077 0.60465116 0.59259259 0.57364341 0.6873385  0.45478036\n",
            " 0.65891473 0.5047373  0.51593454 0.46167097 0.5211025  0.54866494\n",
            " 0.56330749 0.48664944 0.47028424 0.52713178 0.59862188 0.63738157\n",
            " 0.34022394 0.52282515]\n",
            "The trained model has an aproximate error rate of 17.37687666897028 which equates to 3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "        'year':[2019,2019,2019,2020],\n",
        "        'da':[10,10,10,20],\n",
        "        'temp':[35,25.5,10,1],\n",
        "        'dewp' : [33.2,10.5,66.1,10.5],\n",
        "        'slp' : [990.2,1022.4,1039.0,1022.4],\n",
        "        'visib' : [8.7,5,9.5,10],\n",
        "        'wdsp':[5,10,15,10],\n",
        "         'mxpsd' : [8.2,20.5,45.2,10.5],\n",
        "        'gust': [9,11,20,12],\n",
        "        'max':[37,26.2,12,2],\n",
        "        'min':[30,22,8.5,-1.2],\n",
        "        'prcp':[0,0,10.5,1.2],\n",
        "        'sndp':[0,0,0,1],\n",
        "        'fog':[1,0,0,1],\n",
        "        'rain_drizzle':[0,0,1,0],\n",
        "        'snow_ice_pellets':[0,0,0,0],\n",
        "        'hail':[0,0,0,0],\n",
        "        'thunder':[0,0,0,0],\n",
        "        'tornado_thunder_cloud':[0,0,0,0],\n",
        "         'Apr' : [0,0,0,0],\n",
        "         'Aug' : [1,1,1,1],\n",
        "         'Dec' : [0,0,0,0],\n",
        "         'Feb' : [0,0,0,0],\n",
        "         'Jan' : [0,0,0,0],\n",
        "         'Jul' : [0,0,0,0],\n",
        "         'Jun' : [0,0,0,0],\n",
        "         'Mar' : [0,0,0,0],\n",
        "         'May' : [0,0,0,0],\n",
        "         'Nov' : [0,0,0,0],\n",
        "         'Oct' : [0,0,0,0],\n",
        "         'Sep' : [0,0,0,0],\n",
        "         'Fri' : [0,0,0,0],\n",
        "         'Mon' : [1,1,1,1],\n",
        "         'Sat' : [0,0,0,0],\n",
        "         'Sun' : [0,0,0,0],\n",
        "         'Thu' : [0,0,0,0],\n",
        "         'Tue' : [0,0,0,0],\n",
        "         'Wed' : [0,0,0,0]\n",
        "      \n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model', hidden_units=[17,11,5,3], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "preds = estimator.predict(x=input.values*SCALE_COLLISIONS)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMHo2Vry2eUZ",
        "outputId": "7bb8ae06-4f7e-4498-f886-53e76686c060"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f217f762490>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[289.78656 242.54999 330.0182  280.4751 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low RMSE and the low percentage error rate suggest that using the whole cleaned dataset is an accurate predictor of the number of collisions."
      ],
      "metadata": {
        "id": "pdkBGr4CCjzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Location\n",
        "As identified in assignment 1, as the location tends towards the centre of New York there is stronger linear relationships. This suggests there is a link between the number of collisions, location and the observed weather conditions. A DNN will be trained to attempt to predict the number of collisions given the location, day and weather conditions."
      ],
      "metadata": {
        "id": "kHVsefPtZOYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data and extract from the zip\n",
        "#Reference - (geeksforgeeks.org 2021)\n",
        "df_loc = pd.read_csv('https://raw.githubusercontent.com/matthew110395/12004210_DataAnalytics/main/locdnn.zip', index_col=0,compression='zip' )\n",
        "print(df_loc[:6])"
      ],
      "metadata": {
        "id": "d4VkDncof2uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88115196-9261-4f29-c239-80caa74eda00"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da  NUM_COLLISIONS   latitude  longitude  temp  dewp     slp  visib  \\\n",
            "1  2018   2               1  40.681750 -73.967480  14.7   2.0  1024.9   10.0   \n",
            "2  2018   2               1  40.645370 -73.945110  14.7   2.0  1024.9   10.0   \n",
            "3  2018   2               1  40.614830 -73.998380  14.7   2.0  1024.9   10.0   \n",
            "4  2018   2               1  40.592190 -74.087395  14.7   2.0  1024.9   10.0   \n",
            "5  2018   2               1  40.769817 -73.782370  14.7   2.0  1024.9   10.0   \n",
            "6  2018   2               1  40.660175 -73.928200  14.7   2.0  1024.9   10.0   \n",
            "\n",
            "   wdsp  ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "1  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "2  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "3  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "4  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "5  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "6  12.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove unrequired cols\n",
        "df_loc_dnn = df_loc.drop(columns=['thunder','tornado_funnel_cloud','fog','rain_drizzle','snow_ice_pellets','hail'])\n",
        "#Clean data\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"year\"] != 2012]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"year\"] < 2020]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"dewp\"] != 9999]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"slp\"] != 9999]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"mxpsd\"] != 999.9]\n",
        "df_loc_dnn = df_loc_dnn.loc[df_loc_dnn[\"gust\"] != 999.9]\n",
        "#Move the target to the end\n",
        "cols = df_loc_dnn['NUM_COLLISIONS']\n",
        "df_loc_dnn = df_loc_dnn.drop(columns=['NUM_COLLISIONS'])\n",
        "df_loc_dnn.insert(loc=34, column='NUM_COLLISIONS', value=cols)\n",
        "print(df_loc_dnn[:6])\n",
        "df_loc_dnn.describe()"
      ],
      "metadata": {
        "id": "hl2pF-yuf2u0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "ff2b7af2-0ef1-48b5-d798-db9b336b89b3"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year  da   latitude  longitude  temp  dewp     slp  visib  wdsp  mxpsd  \\\n",
            "1  2018   2  40.681750 -73.967480  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "2  2018   2  40.645370 -73.945110  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "3  2018   2  40.614830 -73.998380  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "4  2018   2  40.592190 -74.087395  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "5  2018   2  40.769817 -73.782370  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "6  2018   2  40.660175 -73.928200  14.7   2.0  1024.9   10.0  12.9   20.0   \n",
            "\n",
            "   ...  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  NUM_COLLISIONS  \n",
            "1  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "2  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "3  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "4  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "5  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "6  ...    0    0    0    1    0    0    0    0    0               1  \n",
            "\n",
            "[6 rows x 35 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                year             da       latitude      longitude  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean     2016.070154      15.638823      40.723907     -73.920916   \n",
              "std         1.991298       8.613159       0.078454       0.086634   \n",
              "min      2013.000000       1.000000      40.498949     -74.253006   \n",
              "25%      2014.000000       8.000000      40.668860     -73.976715   \n",
              "50%      2016.000000      16.000000      40.722470     -73.929210   \n",
              "75%      2018.000000      23.000000      40.768165     -73.866650   \n",
              "max      2019.000000      31.000000      40.912884     -73.663010   \n",
              "\n",
              "                temp           dewp            slp          visib  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean       48.419836      47.274900    1015.556656       8.199143   \n",
              "std        13.750834     261.636367       8.136580       2.230079   \n",
              "min         5.800000      -6.700000     989.500000       0.600000   \n",
              "25%        38.400000      28.800000    1010.700000       6.900000   \n",
              "50%        47.800000      41.300000    1015.300000       9.300000   \n",
              "75%        59.500000      53.400000    1021.000000      10.000000   \n",
              "max        77.500000    9999.900000    1039.100000      10.000000   \n",
              "\n",
              "                wdsp          mxpsd  ...            Oct            Sep  \\\n",
              "count  830297.000000  830297.000000  ...  830297.000000  830297.000000   \n",
              "mean       12.598551      20.021545  ...       0.093866       0.074335   \n",
              "std         3.921832       5.219745  ...       0.291643       0.262315   \n",
              "min         4.500000       8.900000  ...       0.000000       0.000000   \n",
              "25%        10.000000      15.900000  ...       0.000000       0.000000   \n",
              "50%        12.000000      19.000000  ...       0.000000       0.000000   \n",
              "75%        14.400000      22.900000  ...       0.000000       0.000000   \n",
              "max        39.300000      49.000000  ...       1.000000       1.000000   \n",
              "\n",
              "                 Fri            Mon            Sat            Sun  \\\n",
              "count  830297.000000  830297.000000  830297.000000  830297.000000   \n",
              "mean        0.133032       0.146763       0.114698       0.142687   \n",
              "std         0.339609       0.353870       0.318657       0.349754   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 Thu            Tue            Wed  NUM_COLLISIONS  \n",
              "count  830297.000000  830297.000000  830297.000000   830297.000000  \n",
              "mean        0.170187       0.141897       0.150735        1.027090  \n",
              "std         0.375797       0.348945       0.357791        0.180994  \n",
              "min         0.000000       0.000000       0.000000        1.000000  \n",
              "25%         0.000000       0.000000       0.000000        1.000000  \n",
              "50%         0.000000       0.000000       0.000000        1.000000  \n",
              "75%         0.000000       0.000000       0.000000        1.000000  \n",
              "max         1.000000       1.000000       1.000000       11.000000  \n",
              "\n",
              "[8 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fe4655c-71ac-4fde-89a6-feed542f969c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>da</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>slp</th>\n",
              "      <th>visib</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>mxpsd</th>\n",
              "      <th>...</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>NUM_COLLISIONS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "      <td>830297.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.070154</td>\n",
              "      <td>15.638823</td>\n",
              "      <td>40.723907</td>\n",
              "      <td>-73.920916</td>\n",
              "      <td>48.419836</td>\n",
              "      <td>47.274900</td>\n",
              "      <td>1015.556656</td>\n",
              "      <td>8.199143</td>\n",
              "      <td>12.598551</td>\n",
              "      <td>20.021545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093866</td>\n",
              "      <td>0.074335</td>\n",
              "      <td>0.133032</td>\n",
              "      <td>0.146763</td>\n",
              "      <td>0.114698</td>\n",
              "      <td>0.142687</td>\n",
              "      <td>0.170187</td>\n",
              "      <td>0.141897</td>\n",
              "      <td>0.150735</td>\n",
              "      <td>1.027090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.991298</td>\n",
              "      <td>8.613159</td>\n",
              "      <td>0.078454</td>\n",
              "      <td>0.086634</td>\n",
              "      <td>13.750834</td>\n",
              "      <td>261.636367</td>\n",
              "      <td>8.136580</td>\n",
              "      <td>2.230079</td>\n",
              "      <td>3.921832</td>\n",
              "      <td>5.219745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291643</td>\n",
              "      <td>0.262315</td>\n",
              "      <td>0.339609</td>\n",
              "      <td>0.353870</td>\n",
              "      <td>0.318657</td>\n",
              "      <td>0.349754</td>\n",
              "      <td>0.375797</td>\n",
              "      <td>0.348945</td>\n",
              "      <td>0.357791</td>\n",
              "      <td>0.180994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.498949</td>\n",
              "      <td>-74.253006</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>-6.700000</td>\n",
              "      <td>989.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2014.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>40.668860</td>\n",
              "      <td>-73.976715</td>\n",
              "      <td>38.400000</td>\n",
              "      <td>28.800000</td>\n",
              "      <td>1010.700000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>40.722470</td>\n",
              "      <td>-73.929210</td>\n",
              "      <td>47.800000</td>\n",
              "      <td>41.300000</td>\n",
              "      <td>1015.300000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2018.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>40.768165</td>\n",
              "      <td>-73.866650</td>\n",
              "      <td>59.500000</td>\n",
              "      <td>53.400000</td>\n",
              "      <td>1021.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>40.912884</td>\n",
              "      <td>-73.663010</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>9999.900000</td>\n",
              "      <td>1039.100000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>39.300000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fe4655c-71ac-4fde-89a6-feed542f969c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fe4655c-71ac-4fde-89a6-feed542f969c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fe4655c-71ac-4fde-89a6-feed542f969c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the scale to the maximum value\n",
        "SCALE_LOC=11\n",
        "# Shuffle data\n",
        "shuffle = df_loc_dnn.iloc[np.random.permutation(len(df_loc_dnn))]\n",
        "\n",
        "predictors = shuffle.iloc[:,0:-1]\n",
        "print(predictors[:6])"
      ],
      "metadata": {
        "id": "cPhXM4DJf2u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bd1882-1920-4f83-8223-ca72c68357b9"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        year  da   latitude  longitude  temp  dewp     slp  visib  wdsp  \\\n",
            "756931  2015  24  40.710662 -73.798702  56.5  48.2  1026.6   10.0  15.5   \n",
            "103311  2013  25  40.608203 -73.920710  27.0   4.4  1025.3   10.0  15.4   \n",
            "500172  2016  22  40.862580 -73.925385  61.3  58.9   993.1    3.5  12.2   \n",
            "355778  2019  19  40.735360 -73.919310  35.2  22.6  1027.5   10.0   8.2   \n",
            "449942  2018  18  40.801190 -73.930030  32.4  29.5  1013.5    8.4  10.2   \n",
            "976418  2019   4  40.638268 -74.078800  37.9  34.0  1004.8    7.7  15.3   \n",
            "\n",
            "        mxpsd  ...  Nov  Oct  Sep  Fri  Mon  Sat  Sun  Thu  Tue  Wed  \n",
            "756931   22.0  ...    0    0    0    0    0    1    0    0    0    0  \n",
            "103311   27.0  ...    1    0    0    0    0    0    1    0    0    0  \n",
            "500172   27.0  ...    0    1    0    1    0    0    0    0    0    0  \n",
            "355778   15.9  ...    0    0    0    0    1    0    0    0    0    0  \n",
            "449942   15.0  ...    0    0    0    0    0    0    0    0    0    1  \n",
            "976418   28.0  ...    0    0    0    0    0    0    1    0    0    0  \n",
            "\n",
            "[6 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select last col as target\n",
        "targets = shuffle.iloc[:,-1]\n",
        "print(targets[:6])"
      ],
      "metadata": {
        "id": "sol3wzXcf2u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f822d4c-b8e7-41b0-dd1f-98870a40f0e6"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "756931    1\n",
            "103311    1\n",
            "500172    1\n",
            "355778    1\n",
            "449942    2\n",
            "976418    1\n",
            "Name: NUM_COLLISIONS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into test and train data\n",
        "trainsize = int(len(shuffle['NUM_COLLISIONS'])*0.8)\n",
        "testsize = len(shuffle['NUM_COLLISIONS']) - trainsize\n",
        "\n",
        "noutputs = 1\n",
        "# Calculate the number of predictors\n",
        "nppredictors = len(shuffle.columns) - noutputs\n",
        "print(nppredictors)"
      ],
      "metadata": {
        "id": "_fZ3mPt-f2u2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc38eef-f6a2-4b0e-b9ec-1d7285784205"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes a saved model from the last training attempt.\n",
        "shutil.rmtree('/tmp/DNN_regression_trained_model_loc', ignore_errors=True)\n",
        "\n",
        "#Setup the model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_loc', hidden_units=[19,15,11,7], optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values)))\n",
        "\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model.\n",
        "estimator.fit(predictors[:trainsize].values, targets[:trainsize].values.reshape(trainsize, noutputs)/SCALE_LOC, steps=10000)\n",
        "\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "predslistscale = preds['scores']*SCALE_LOC\n",
        "#Test Model\n",
        "rmse = np.sqrt(np.mean((targets[trainsize:].values - predslistscale)**2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "avg = np.mean(shuffle['NUM_COLLISIONS'][:trainsize])\n",
        "rmse = np.sqrt(np.mean((shuffle['NUM_COLLISIONS'][trainsize:] - avg)**2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "metadata": {
        "id": "FEMInwLGf2u3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec86d5e-272c-4323-8c6e-05827686483b"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21802a8c90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_loc', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_regression_trained_model_loc/model.ckpt.\n",
            "INFO:tensorflow:loss = 96392.33, step = 1\n",
            "INFO:tensorflow:global_step/sec: 295.648\n",
            "INFO:tensorflow:loss = 0.02186725, step = 101 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.821\n",
            "INFO:tensorflow:loss = 0.0002902802, step = 201 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.391\n",
            "INFO:tensorflow:loss = 0.00025037606, step = 301 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.266\n",
            "INFO:tensorflow:loss = 0.00044077414, step = 401 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.134\n",
            "INFO:tensorflow:loss = 0.00018970028, step = 501 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.707\n",
            "INFO:tensorflow:loss = 0.00031834198, step = 601 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.002\n",
            "INFO:tensorflow:loss = 6.653251e-05, step = 701 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.115\n",
            "INFO:tensorflow:loss = 6.669013e-05, step = 801 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 409.756\n",
            "INFO:tensorflow:loss = 0.00018920386, step = 901 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.043\n",
            "INFO:tensorflow:loss = 6.776104e-05, step = 1001 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.228\n",
            "INFO:tensorflow:loss = 0.0004939306, step = 1101 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.99\n",
            "INFO:tensorflow:loss = 0.0006914907, step = 1201 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.918\n",
            "INFO:tensorflow:loss = 0.00031197816, step = 1301 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.138\n",
            "INFO:tensorflow:loss = 0.00025689037, step = 1401 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.508\n",
            "INFO:tensorflow:loss = 0.00018916099, step = 1501 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 420.349\n",
            "INFO:tensorflow:loss = 0.00056379056, step = 1601 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 415.311\n",
            "INFO:tensorflow:loss = 6.595749e-05, step = 1701 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.313\n",
            "INFO:tensorflow:loss = 5.668012e-06, step = 1801 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.59\n",
            "INFO:tensorflow:loss = 0.00087984366, step = 1901 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.56\n",
            "INFO:tensorflow:loss = 0.0002502146, step = 2001 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.473\n",
            "INFO:tensorflow:loss = 0.00018949, step = 2101 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.398\n",
            "INFO:tensorflow:loss = 0.00031071302, step = 2201 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 406.666\n",
            "INFO:tensorflow:loss = 0.00012815646, step = 2301 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.723\n",
            "INFO:tensorflow:loss = 0.00037427375, step = 2401 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.892\n",
            "INFO:tensorflow:loss = 0.00018920397, step = 2501 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.21\n",
            "INFO:tensorflow:loss = 0.00056994637, step = 2601 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.34\n",
            "INFO:tensorflow:loss = 0.00018942312, step = 2701 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.529\n",
            "INFO:tensorflow:loss = 0.00031861043, step = 2801 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 425.192\n",
            "INFO:tensorflow:loss = 6.875313e-05, step = 2901 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.824\n",
            "INFO:tensorflow:loss = 0.0002510739, step = 3001 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.452\n",
            "INFO:tensorflow:loss = 0.0001274155, step = 3101 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.169\n",
            "INFO:tensorflow:loss = 0.00025036864, step = 3201 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 405.777\n",
            "INFO:tensorflow:loss = 6.677603e-05, step = 3301 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.917\n",
            "INFO:tensorflow:loss = 0.0002501942, step = 3401 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.968\n",
            "INFO:tensorflow:loss = 0.00018944817, step = 3501 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.088\n",
            "INFO:tensorflow:loss = 0.00018949748, step = 3601 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 406.978\n",
            "INFO:tensorflow:loss = 0.00056813075, step = 3701 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 378.206\n",
            "INFO:tensorflow:loss = 0.00018923872, step = 3801 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.569\n",
            "INFO:tensorflow:loss = 0.00068875495, step = 3901 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 441.672\n",
            "INFO:tensorflow:loss = 6.516211e-05, step = 4001 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.435\n",
            "INFO:tensorflow:loss = 0.00031025262, step = 4101 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.874\n",
            "INFO:tensorflow:loss = 0.0012038187, step = 4201 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.725\n",
            "INFO:tensorflow:loss = 0.00019477986, step = 4301 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.334\n",
            "INFO:tensorflow:loss = 0.00018918295, step = 4401 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 406.125\n",
            "INFO:tensorflow:loss = 0.0004394689, step = 4501 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 377.495\n",
            "INFO:tensorflow:loss = 0.0001906701, step = 4601 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.227\n",
            "INFO:tensorflow:loss = 0.0004985124, step = 4701 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 399.876\n",
            "INFO:tensorflow:loss = 0.00031435787, step = 4801 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 414.858\n",
            "INFO:tensorflow:loss = 0.00031517027, step = 4901 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 377.364\n",
            "INFO:tensorflow:loss = 0.00025112668, step = 5001 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.618\n",
            "INFO:tensorflow:loss = 0.00038075366, step = 5101 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.533\n",
            "INFO:tensorflow:loss = 0.00025159342, step = 5201 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.126\n",
            "INFO:tensorflow:loss = 0.00012759473, step = 5301 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 425.497\n",
            "INFO:tensorflow:loss = 0.00031036464, step = 5401 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.926\n",
            "INFO:tensorflow:loss = 0.00025060648, step = 5501 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.682\n",
            "INFO:tensorflow:loss = 0.00018915955, step = 5601 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 406.53\n",
            "INFO:tensorflow:loss = 0.00012838881, step = 5701 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 433.441\n",
            "INFO:tensorflow:loss = 0.00031416334, step = 5801 (0.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 371.795\n",
            "INFO:tensorflow:loss = 0.00013521906, step = 5901 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.715\n",
            "INFO:tensorflow:loss = 0.00012755512, step = 6001 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 417.017\n",
            "INFO:tensorflow:loss = 0.00019011108, step = 6101 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.017\n",
            "INFO:tensorflow:loss = 0.00012713617, step = 6201 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 378.3\n",
            "INFO:tensorflow:loss = 0.0001896154, step = 6301 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.016\n",
            "INFO:tensorflow:loss = 0.00025064134, step = 6401 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 410.402\n",
            "INFO:tensorflow:loss = 7.771102e-05, step = 6501 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 429.229\n",
            "INFO:tensorflow:loss = 0.00018930792, step = 6601 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.591\n",
            "INFO:tensorflow:loss = 0.00069761754, step = 6701 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.68\n",
            "INFO:tensorflow:loss = 0.00050318596, step = 6801 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.131\n",
            "INFO:tensorflow:loss = 0.0001892584, step = 6901 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.647\n",
            "INFO:tensorflow:loss = 0.00013844077, step = 7001 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.536\n",
            "INFO:tensorflow:loss = 0.00068551314, step = 7101 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 413.024\n",
            "INFO:tensorflow:loss = 4.726751e-06, step = 7201 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.245\n",
            "INFO:tensorflow:loss = 0.0002502296, step = 7301 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.696\n",
            "INFO:tensorflow:loss = 0.00014050429, step = 7401 (0.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.53\n",
            "INFO:tensorflow:loss = 0.00018917222, step = 7501 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.656\n",
            "INFO:tensorflow:loss = 0.00036929216, step = 7601 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.599\n",
            "INFO:tensorflow:loss = 0.00012711814, step = 7701 (0.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.819\n",
            "INFO:tensorflow:loss = 0.00038138163, step = 7801 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.575\n",
            "INFO:tensorflow:loss = 0.00031029404, step = 7901 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 414.595\n",
            "INFO:tensorflow:loss = 0.00019349974, step = 8001 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.661\n",
            "INFO:tensorflow:loss = 0.00037477916, step = 8101 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 346.871\n",
            "INFO:tensorflow:loss = 0.00019123338, step = 8201 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.081\n",
            "INFO:tensorflow:loss = 0.00037943074, step = 8301 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.047\n",
            "INFO:tensorflow:loss = 0.00018937912, step = 8401 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.732\n",
            "INFO:tensorflow:loss = 0.00039429188, step = 8501 (0.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.919\n",
            "INFO:tensorflow:loss = 0.0001892953, step = 8601 (0.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.64\n",
            "INFO:tensorflow:loss = 0.00031107396, step = 8701 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 404.644\n",
            "INFO:tensorflow:loss = 0.00013463543, step = 8801 (0.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 434.755\n",
            "INFO:tensorflow:loss = 0.00018950895, step = 8901 (0.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 416.732\n",
            "INFO:tensorflow:loss = 0.00019686313, step = 9001 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 414.503\n",
            "INFO:tensorflow:loss = 0.00019074033, step = 9101 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 403.188\n",
            "INFO:tensorflow:loss = 6.499905e-05, step = 9201 (0.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.19\n",
            "INFO:tensorflow:loss = 0.0003159962, step = 9301 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 412.104\n",
            "INFO:tensorflow:loss = 0.00054230064, step = 9401 (0.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.876\n",
            "INFO:tensorflow:loss = 0.0012621296, step = 9501 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.21\n",
            "INFO:tensorflow:loss = 0.001149928, step = 9601 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 411.015\n",
            "INFO:tensorflow:loss = 0.00012732064, step = 9701 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 419.926\n",
            "INFO:tensorflow:loss = 0.00032616153, step = 9801 (0.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.096\n",
            "INFO:tensorflow:loss = 0.00047249778, step = 9901 (0.255 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_regression_trained_model_loc/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 7.900312e-05.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_loc/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNNRegression has RMSE of 0.18208458200764135\n",
            "Just using average = 1.027133387631222 has RMSE of 0.17962055916059586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictors[trainsize:].values)\n",
        "#Ensure the number of hidden units match the trained model\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir='/tmp/DNN_regression_trained_model_loc', hidden_units=[19,15,11,7], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors[trainsize:].values)))\n",
        "preds = estimator.predict(x=predictors[trainsize:].values)\n",
        "\n",
        "print(preds['scores'])\n",
        "print(targets[trainsize:].values/SCALE_COLLISIONS)\n",
        "\n",
        "testdf = pd.DataFrame.from_dict(data={\n",
        "    'pred': preds['scores'],\n",
        "    'actual': targets[trainsize:].values/SCALE_LOC\n",
        "})\n",
        "\n",
        "testdf['diff'] = testdf['actual'] - testdf['pred']\n",
        "\n",
        "error=testdf['diff'].mean()*SCALE_COLLISIONS\n",
        "avgcol=targets[trainsize:].mean()\n",
        "print('The trained model has an aproximate error rate of {0} which equates to {1}%'.format(error, round((error/avgcol)*100),1));\n"
      ],
      "metadata": {
        "id": "UoS_IOAwf2u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cea5ed3-a799-43b4-8c25-bff1bb47cc6f"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f217aa7c9d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_regression_trained_model_loc', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.01700000e+03 2.00000000e+01 4.07041700e+01 ... 1.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01800000e+03 4.00000000e+00 4.06948740e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01400000e+03 2.20000000e+01 4.07432113e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [2.01500000e+03 3.00000000e+00 4.08240317e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.01900000e+03 2.00000000e+01 4.05924100e+01 ... 0.00000000e+00\n",
            "  1.00000000e+00 0.00000000e+00]\n",
            " [2.01900000e+03 2.10000000e+01 4.06609340e+01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_regression_trained_model_loc/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09064212 0.09064212 0.09064212 ... 0.09064212 0.09064212 0.09064212]\n",
            "[0.00086133 0.00086133 0.00086133 ... 0.00086133 0.00086133 0.00086133]\n",
            "The trained model has an aproximate error rate of 3.1510186881339606 which equates to 307%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite extensive training, the model is not accurately able to predict the number of collisions. This is inferred by the RMSE which is close to that of the mean RMSE. "
      ],
      "metadata": {
        "id": "Oir_cOA3ccIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "As shown above the given weather conditions for a particular day within New York, the number of collisions can be accurately predicted.\n",
        "\n",
        "Arguments can be made for both models; the linear regression models appear to be less efficient due to the higher RMSE values in comparison to the DNN models. In contrast the error rate is lower for the linear regression models. This suggests that although the DNN models produce more errors, but the margin of error is lower, due to the RMSE placing a larger weighting on larger errors.\n",
        "\n",
        "When testing the models using made data, the outputs followed the expected results. With the DNN models it is not as clear as the relationship between the variables is not as clear.\n",
        "\n",
        "In hindsight the way location has been encoded does not allow for accurate predictions to be made as the number of collisions always tends towards 1 for a given location.\n",
        "\n",
        "It is clear that the models produced above can accurately predict the number of collisions as set out in the specification of the assignment.\n"
      ],
      "metadata": {
        "id": "qBaLwNJocvpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#References\n",
        "geeksforgeeks.org (2021) Read a zipped file as a Pandas DataFrame [online]. Available from <<https://www.geeksforgeeks.org/read-a-zipped-file-as-a-pandas-dataframe/>? [12 November 2022] \n",
        "\n",
        "IBM (n.d.) What is linear regression? [online]. Available from <<https://www.ibm.com/uk-en/topics/linear-regression>> [17 November 2022] \n",
        "\n",
        "Karhunen, J., Raiko, T. and Cho, K. (2015) 'Chapter 7 - Unsupervised deep learning: A short review.' In Advances in Independent Component Analysis and Learning Machines. Academic Press. Ch. 7. 135-142.\n",
        "\n",
        "Zhang, Z. (2019) Understand Data Normalization in Machine Learning [online]. Available from <<https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0>> [17 November 2022] \n",
        "\n",
        "Zulkifli, H. (2018) Understanding Learning Rates and How It Improves Performance in Deep Learning [online]. Available from <<https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10>> [17 November 2022] \n",
        "\n"
      ],
      "metadata": {
        "id": "iDBndm4x6xGv"
      }
    }
  ]
}